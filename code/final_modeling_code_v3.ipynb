{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4653574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 센터별, 회귀, 분류 모델별로 결과 나옴\n",
    "# 피클 파일은 아직 저장 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8412b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "모든 기반 함수들이 로드되었습니다!\n",
      "이제 센터별 완전 분석 파이프라인을 실행할 수 있습니다.\n",
      "============================================================\n",
      "\n",
      "다음 단계:\n",
      "1. 센터별 완전 분석 파이프라인 코드를 실행하세요\n",
      "2. run_complete_analysis() 함수를 실행하세요\n",
      "\n",
      "필요한 라이브러리 확인:\n",
      "- XGBoost: ✓\n",
      "- LightGBM: ✓\n",
      "- CatBoost: ✓\n",
      "- SHAP: ✓\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# 전체 파이프라인을 위한 선행 실행 코드 (모든 기반 함수들)\n",
    "# ================================================================================================\n",
    "\n",
    "# 필수 라이브러리 import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os, sys, platform, random, time, json, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 선택적 라이브러리 import\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except ImportError:\n",
    "    HAS_LGB = False\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "    HAS_CATBOOST = True\n",
    "except ImportError:\n",
    "    HAS_CATBOOST = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except ImportError:\n",
    "    HAS_SHAP = False\n",
    "\n",
    "# 한글 폰트 설정. \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "try:\n",
    "    plt.rcParams['font.family'] = 'AppleGothic' # 맥\n",
    "except Exception:\n",
    "    plt.rcParams['font.family'] ='Malgun Gothic' # 윈도우\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ================================================================================================\n",
    "# 1. 모델 정의 함수들\n",
    "# ================================================================================================\n",
    "def build_regression_models():\n",
    "    \"\"\"회귀 모델들\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    models[\"RandomForest_Reg\"] = RandomForestRegressor(\n",
    "        n_estimators=300, min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    models[\"LinearRegression\"] = LinearRegression()\n",
    "    \n",
    "    models[\"GradientBoosting_Reg\"] = GradientBoostingRegressor(\n",
    "        n_estimators=200, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    if HAS_XGB:\n",
    "        models[\"XGBoost_Reg\"] = xgb.XGBRegressor(\n",
    "            n_estimators=400, max_depth=5, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models[\"LightGBM_Reg\"] = lgb.LGBMRegressor(\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbosity=-1\n",
    "        )\n",
    "    \n",
    "    if HAS_CATBOOST:\n",
    "        models[\"CatBoost_Reg\"] = cb.CatBoostRegressor(\n",
    "            iterations=500, learning_rate=0.05, depth=6,\n",
    "            random_state=42, verbose=False\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "def build_classification_models():\n",
    "    \"\"\"분류 모델들 (4등급)\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    models[\"RandomForest_Clf\"] = RandomForestClassifier(\n",
    "        n_estimators=300, min_samples_leaf=2, random_state=42, \n",
    "        n_jobs=-1, class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    models[\"GradientBoosting_Clf\"] = GradientBoostingClassifier(\n",
    "        n_estimators=200, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    models[\"LogisticRegression_Clf\"] = LogisticRegression(\n",
    "        multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000,\n",
    "        random_state=42, class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    if HAS_XGB:\n",
    "        models[\"XGBoost_Clf\"] = xgb.XGBClassifier(\n",
    "            n_estimators=400, max_depth=5, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"multi:softprob\", num_class=4,\n",
    "            tree_method=\"hist\", random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models[\"LightGBM_Clf\"] = lgb.LGBMClassifier(\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"multiclass\", num_class=4,\n",
    "            random_state=42, n_jobs=-1, verbosity=-1, is_unbalance=True\n",
    "        )\n",
    "    \n",
    "    if HAS_CATBOOST:\n",
    "        models[\"CatBoost_Clf\"] = cb.CatBoostClassifier(\n",
    "            iterations=500, learning_rate=0.05, depth=6,\n",
    "            random_state=42, verbose=False, auto_class_weights='Balanced'\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "# ================================================================================================\n",
    "# 2. 파이프라인 및 데이터 처리 함수들\n",
    "# ================================================================================================\n",
    "def make_pipeline_unified(model, model_name, model_type):\n",
    "    \"\"\"통합 전처리 파이프라인\"\"\"\n",
    "    if model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"]:\n",
    "        pre = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ])\n",
    "    else:\n",
    "        pre = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ])\n",
    "    return Pipeline(steps=[(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "def prepare_data_stratified(df, target_col, model_type, test_size=0.2, split_method='stratified'):\n",
    "    \"\"\"데이터 준비 - Stratified vs 시계열 분할\"\"\"\n",
    "    work = df.sort_values('날짜').reset_index(drop=True).copy()\n",
    "    dates = pd.to_datetime(work['날짜'])\n",
    "\n",
    "    not_use_col = [\n",
    "        '날짜',\n",
    "        '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "        '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "        '등급','등급_1일후','등급_2일후'\n",
    "    ]\n",
    "    \n",
    "    drop_cols = [c for c in (set(not_use_col) | {target_col}) if c in work.columns]\n",
    "    X_raw = work.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    \n",
    "    for c in X_raw.columns:\n",
    "        X_raw[c] = pd.to_numeric(X_raw[c], errors=\"coerce\")\n",
    "\n",
    "    if model_type == \"regression\":\n",
    "        y = pd.to_numeric(work[target_col], errors=\"coerce\")\n",
    "    else:\n",
    "        y = work[target_col].astype(\"int64\")\n",
    "\n",
    "    valid_idx = (~X_raw.isnull().all(axis=1)) & (~pd.isnull(y))\n",
    "    X_raw = X_raw[valid_idx].reset_index(drop=True)\n",
    "    y = y[valid_idx].reset_index(drop=True)\n",
    "    dates = dates[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    if split_method == 'stratified':\n",
    "        if model_type == \"classification\":\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "            train_idx, test_idx = next(sss.split(X_raw, y))\n",
    "        else:\n",
    "            train_idx, test_idx = train_test_split(\n",
    "                range(len(X_raw)), test_size=test_size, random_state=42\n",
    "            )\n",
    "            \n",
    "        X_train, X_test = X_raw.iloc[train_idx].copy(), X_raw.iloc[test_idx].copy()\n",
    "        y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "        dates_train, dates_test = dates.iloc[train_idx].copy(), dates.iloc[test_idx].copy()\n",
    "        \n",
    "    else:  # temporal split\n",
    "        n = len(X_raw)\n",
    "        split = int(n * (1 - test_size))\n",
    "        X_train, X_test = X_raw.iloc[:split].copy(), X_raw.iloc[split:].copy()\n",
    "        y_train, y_test = y.iloc[:split].copy(), y.iloc[split:].copy()\n",
    "        dates_train, dates_test = dates.iloc[:split].copy(), dates.iloc[split:].copy()\n",
    "\n",
    "    feature_names = list(X_raw.columns)\n",
    "    return X_train, X_test, y_train, y_test, feature_names, dates_train, dates_test\n",
    "\n",
    "# ================================================================================================\n",
    "# 3. 평가 함수들\n",
    "# ================================================================================================\n",
    "def evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"회귀 모델 평가\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"regression\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mape': mape,\n",
    "            'success': True\n",
    "        }, pipe, y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': np.nan,\n",
    "            'rmse': np.nan,\n",
    "            'r2': np.nan,\n",
    "            'mape': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None\n",
    "\n",
    "def evaluate_classification_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"분류 모델 평가\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"classification\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        if isinstance(y_pred, np.ndarray) and y_pred.ndim > 1:\n",
    "            y_pred = y_pred.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        extreme_classes = [0, 3]\n",
    "        y_true_extreme = pd.Series(y_test).isin(extreme_classes).astype(int)\n",
    "        y_pred_extreme = pd.Series(y_pred).isin(extreme_classes).astype(int)\n",
    "        extreme_f1 = f1_score(y_true_extreme, y_pred_extreme, zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1_macro,\n",
    "            'weighted_f1': f1_weighted,\n",
    "            'extreme_f1': extreme_f1,\n",
    "            'success': True\n",
    "        }, pipe, y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': np.nan,\n",
    "            'macro_f1': np.nan,\n",
    "            'weighted_f1': np.nan,\n",
    "            'extreme_f1': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None\n",
    "\n",
    "def comprehensive_evaluation_comparison(center_name, df):\n",
    "    \"\"\"Stratified vs 시계열 분할 비교 평가\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"센터: {center_name} - Stratified vs 시계열 분할 비교\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"데이터 크기: {len(df)}행, {len(df.columns)}컬럼\")\n",
    "    \n",
    "    if '등급_1일후' in df.columns:\n",
    "        grade_dist = df['등급_1일후'].value_counts().sort_index()\n",
    "        print(f\"등급 분포: {dict(grade_dist)}\")\n",
    "        \n",
    "        min_class = grade_dist.min()\n",
    "        max_class = grade_dist.max()\n",
    "        imbalance_ratio = max_class / min_class\n",
    "        print(f\"클래스 불균형 비율: {imbalance_ratio:.1f}:1 (최대:{max_class}, 최소:{min_class})\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for split_method in ['temporal', 'stratified']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"분할 방법: {split_method.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # 회귀 모델 평가\n",
    "        reg_method_name = \"random_shuffle\" if split_method == \"stratified\" else split_method\n",
    "        print(f\"\\n--- 회귀 모델 평가 ({reg_method_name}) ---\")\n",
    "        \n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test, feature_names, dates_train, dates_test = prepare_data_stratified(\n",
    "                df, target_col=\"합계_1일후\", model_type=\"regression\", test_size=0.2, split_method=split_method\n",
    "            )\n",
    "            \n",
    "            print(f\"회귀용 데이터: 학습 {len(X_train)}행, 테스트 {len(X_test)}행\")\n",
    "            \n",
    "            regression_models = build_regression_models()\n",
    "            \n",
    "            for model_name, model in tqdm(regression_models.items(), desc=f\"회귀({reg_method_name})\", leave=False):\n",
    "                result, pipe, y_pred = evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test)\n",
    "                result['center'] = center_name\n",
    "                result['split_method'] = split_method\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    print(f\"  {model_name:18s}: R²={result['r2']:.3f}, MAE={result['mae']:.0f}, MAPE={result['mape']:.1f}%\")\n",
    "                else:\n",
    "                    print(f\"  {model_name:18s}: 실패 - {result.get('error', '')[:50]}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"회귀 모델 평가 실패 ({reg_method_name}): {e}\")\n",
    "        \n",
    "        # 분류 모델 평가\n",
    "        print(f\"\\n--- 분류 모델 평가 ({split_method}) ---\")\n",
    "        \n",
    "        try:\n",
    "            X_train_clf, X_test_clf, y_train_clf, y_test_clf, feature_names_clf, _, _ = prepare_data_stratified(\n",
    "                df, target_col=\"등급_1일후\", model_type=\"classification\", test_size=0.2, split_method=split_method\n",
    "            )\n",
    "            \n",
    "            print(f\"분류용 데이터: 학습 {len(X_train_clf)}행, 테스트 {len(X_test_clf)}행\")\n",
    "            \n",
    "            test_dist = pd.Series(y_test_clf).value_counts().sort_index()\n",
    "            train_dist = pd.Series(y_train_clf).value_counts().sort_index()\n",
    "            print(f\"학습 세트 등급 분포: {dict(train_dist)}\")\n",
    "            print(f\"테스트 세트 등급 분포: {dict(test_dist)}\")\n",
    "            \n",
    "            classification_models = build_classification_models()\n",
    "            \n",
    "            for model_name, model in tqdm(classification_models.items(), desc=f\"분류({split_method})\", leave=False):\n",
    "                result, pipe, y_pred = evaluate_classification_model(model, model_name, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "                result['center'] = center_name\n",
    "                result['split_method'] = split_method\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    print(f\"  {model_name:18s}: ACC={result['accuracy']:.3f}, F1={result['macro_f1']:.3f}, 극값F1={result['extreme_f1']:.3f}\")\n",
    "                else:\n",
    "                    print(f\"  {model_name:18s}: 실패 - {result.get('error', '')[:50]}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"분류 모델 평가 실패 ({split_method}): {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# 4. Feature Importance & SHAP 분석 함수들\n",
    "# ================================================================================================\n",
    "def extract_feature_importance(model, model_name, feature_names):\n",
    "    \"\"\"모델별 Feature Importance 추출\"\"\"\n",
    "    try:\n",
    "        mdl = model.named_steps['model']\n",
    "        if hasattr(mdl, 'feature_importances_'):\n",
    "            importance = mdl.feature_importances_\n",
    "        elif hasattr(mdl, 'coef_'):\n",
    "            coef = mdl.coef_\n",
    "            if isinstance(coef, np.ndarray) and coef.ndim == 2:\n",
    "                importance = np.mean(np.abs(coef), axis=0)\n",
    "            else:\n",
    "                importance = np.abs(coef)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        if len(importance) != len(feature_names):\n",
    "            print(f\"[경고] importance 길이({len(importance)}) != feature_names({len(feature_names)})\")\n",
    "            m = min(len(importance), len(feature_names))\n",
    "            importance = np.asarray(importance)[:m]\n",
    "            feature_names = list(feature_names)[:m]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        return importance_df\n",
    "    except Exception as e:\n",
    "        print(f\"Feature importance 추출 실패 ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_feature_importance(importance_df, model_name, top_n=15):\n",
    "    \"\"\"Feature Importance 시각화\"\"\"\n",
    "    if importance_df is None or len(importance_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_features = importance_df.head(top_n)\n",
    "    \n",
    "    ax.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['feature'])\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title(f'{model_name} - Top {top_n} Feature Importance')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    for i, v in enumerate(top_features['importance']):\n",
    "        ax.text(v + 0.001, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_model_with_shap(model, X_test, feature_names, model_name, max_samples=100):\n",
    "    \"\"\"SHAP 분석\"\"\"\n",
    "    if not HAS_SHAP:\n",
    "        print(\"SHAP 라이브러리가 설치되지 않았습니다.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if len(X_test) > max_samples:\n",
    "            sample_idx = np.random.choice(len(X_test), max_samples, replace=False)\n",
    "            X_sample = X_test.iloc[sample_idx]\n",
    "        else:\n",
    "            X_sample = X_test\n",
    "        \n",
    "        X_processed = model.named_steps['pre'].transform(X_sample)\n",
    "        \n",
    "        if 'RandomForest' in model_name or 'GradientBoosting' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'XGBoost' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'LightGBM' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'CatBoost' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        else:\n",
    "            explainer = shap.LinearExplainer(model.named_steps['model'], X_processed)\n",
    "        \n",
    "        shap_values = explainer.shap_values(X_processed)\n",
    "        \n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[0]\n",
    "        \n",
    "        return shap_values, X_processed, explainer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP 분석 실패 ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_shap_summary(shap_values, X_processed, feature_names, model_name):\n",
    "    \"\"\"SHAP Summary Plot\"\"\"\n",
    "    if shap_values is None or not HAS_SHAP:\n",
    "        return []\n",
    "\n",
    "    figs = []\n",
    "    try:\n",
    "        # Bar plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_processed,\n",
    "                          feature_names=feature_names,\n",
    "                          plot_type=\"bar\", show=False)\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(f'{model_name} - SHAP Feature Importance')\n",
    "        figs.append(plt.gcf())\n",
    "\n",
    "        # Beeswarm plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_processed,\n",
    "                          feature_names=feature_names,\n",
    "                          show=False)\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(f'{model_name} - SHAP Summary Plot')\n",
    "        figs.append(plt.gcf())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP 시각화 실패 ({model_name}): {e}\")\n",
    "\n",
    "    return figs\n",
    "\n",
    "# ================================================================================================\n",
    "# 5. 피처 엔지니어링 함수들 (Data Leakage 방지 버전)\n",
    "# ================================================================================================\n",
    "def make_features(df, cutoff_date=None):\n",
    "    \"\"\"파생변수 생성 함수 - Data Leakage 방지 버전\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "    df = df.sort_values('날짜').reset_index(drop=True)\n",
    "\n",
    "    df['월'] = df['날짜'].dt.month\n",
    "    df['요일'] = df['날짜'].dt.weekday\n",
    "\n",
    "    season_map = {'봄': 0, '여름': 1, '가을': 2, '겨울': 3}\n",
    "    discomfort_map = {'쾌적': 0, '약간 불쾌': 1, '불쾌': 2, '매우 불쾌': 3, '극심한 불쾌': 4}\n",
    "    df['계절'] = df['계절'].map(season_map).astype('Int64')\n",
    "    df['불쾌지수등급'] = df['불쾌지수등급'].map(discomfort_map).astype('Int64')\n",
    "\n",
    "    # 강수량 시차 피처\n",
    "    df['강수량_1일전'] = df['일_일강수량(mm)'].shift(1)\n",
    "    df['강수량_2일전'] = df['일_일강수량(mm)'].shift(2)\n",
    "    df['강수량_1일_누적'] = df['일_일강수량(mm)'].rolling(1, min_periods=1).sum()\n",
    "    df['강수량_2일_누적'] = df['일_일강수량(mm)'].rolling(2, min_periods=1).sum()\n",
    "    df['강수량_3일_누적'] = df['일_일강수량(mm)'].rolling(3, min_periods=1).sum()\n",
    "    df['강수량_5일_누적'] = df['일_일강수량(mm)'].rolling(5, min_periods=1).sum()\n",
    "    df['강수량_7일_누적'] = df['일_일강수량(mm)'].rolling(7, min_periods=1).sum()\n",
    "\n",
    "    df['일교차'] = df['일_최고기온(°C)'] - df['일_최저기온(°C)']\n",
    "    df['폭우_여부'] = (df['일_일강수량(mm)'] >= 80).astype(int)\n",
    "    \n",
    "    # 체감온도 계산\n",
    "    if '일_평균기온(°C)' in df.columns:\n",
    "        T = pd.to_numeric(df['일_평균기온(°C)'], errors='coerce')\n",
    "    else:\n",
    "        T = pd.Series(np.nan, index=df.index)\n",
    "    if '일_평균풍속(m/s)' in df.columns:\n",
    "        V_ms = pd.to_numeric(df['일_평균풍속(m/s)'], errors='coerce')\n",
    "    else:\n",
    "        V_ms = pd.Series(np.nan, index=df.index)\n",
    "    if '평균습도(%)' in df.columns:\n",
    "        RH = pd.to_numeric(df['평균습도(%)'], errors='coerce')\n",
    "    else:\n",
    "        RH = pd.Series(np.nan, index=df.index)\n",
    "\n",
    "    # 체감온도 계산 (간단 버전)\n",
    "    e = (RH/100.0) * 6.105 * np.exp(17.27*T/(237.7 + T))\n",
    "    df['체감온도(°C)'] = T + 0.33*e - 0.70*V_ms - 4.00\n",
    "    \n",
    "    # 분류용 등급 계산\n",
    "    q = df['합계'].dropna().quantile([0.15, 0.70, 0.90])\n",
    "    q15, q70, q90 = float(q.loc[0.15]), float(q.loc[0.70]), float(q.loc[0.90])\n",
    "\n",
    "    def categorize(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        if x < q15:\n",
    "            return 0\n",
    "        elif x < q70:\n",
    "            return 1\n",
    "        elif x < q90:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    df['등급'] = df['합계'].apply(categorize)\n",
    "    \n",
    "    # 타겟 변수 생성 (Data Leakage 방지)\n",
    "    if cutoff_date is not None:\n",
    "        cutoff = pd.to_datetime(cutoff_date)\n",
    "        \n",
    "        df['합계_1일후'] = np.nan\n",
    "        df['합계_2일후'] = np.nan\n",
    "        df['등급_1일후'] = np.nan\n",
    "        df['등급_2일후'] = np.nan\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            current_date = df.loc[i, '날짜']\n",
    "            \n",
    "            if i + 1 < len(df) and current_date <= cutoff:\n",
    "                next_date = df.loc[i+1, '날짜']\n",
    "                if next_date <= cutoff:\n",
    "                    df.loc[i, '합계_1일후'] = df.loc[i+1, '합계']\n",
    "                    df.loc[i, '등급_1일후'] = df.loc[i+1, '등급']\n",
    "            \n",
    "            if i + 2 < len(df) and current_date <= cutoff:\n",
    "                next2_date = df.loc[i+2, '날짜']\n",
    "                if next2_date <= cutoff:\n",
    "                    df.loc[i, '합계_2일후'] = df.loc[i+2, '합계']\n",
    "                    df.loc[i, '등급_2일후'] = df.loc[i+2, '등급']\n",
    "    else:\n",
    "        df['합계_1일후'] = df['합계'].shift(-1)\n",
    "        df['합계_2일후'] = df['합계'].shift(-2)\n",
    "        df['등급_1일후'] = df['등급'].shift(-1).astype('Int64')\n",
    "        df['등급_2일후'] = df['등급'].shift(-2).astype('Int64')\n",
    "\n",
    "    df.attrs['cutoffs'] = {\"q15\": q15, \"q70\": q70, \"q90\": q90}\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    df = df[df[\"날짜\"] < \"2025-06-01\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_features_for_prediction(historical_df, future_df):\n",
    "    \"\"\"새로운 데이터에 대한 파생변수 생성 (과거 데이터 활용)\"\"\"\n",
    "    combined_df = pd.concat([historical_df, future_df], ignore_index=True)\n",
    "    combined_df['날짜'] = pd.to_datetime(combined_df['날짜'])\n",
    "    combined_df = combined_df.sort_values('날짜').reset_index(drop=True)\n",
    "    \n",
    "    combined_df['월'] = combined_df['날짜'].dt.month\n",
    "    combined_df['요일'] = combined_df['날짜'].dt.weekday\n",
    "    \n",
    "    season_map = {'봄': 0, '여름': 1, '가을': 2, '겨울': 3}\n",
    "    discomfort_map = {'쾌적': 0, '약간 불쾌': 1, '불쾌': 2, '매우 불쾌': 3, '극심한 불쾌': 4}\n",
    "    combined_df['계절'] = combined_df['계절'].map(season_map).astype('Int64')\n",
    "    combined_df['불쾌지수등급'] = combined_df['불쾌지수등급'].map(discomfort_map).astype('Int64')\n",
    "    \n",
    "    # 시차 변수들\n",
    "    combined_df['강수량_1일전'] = combined_df['일_일강수량(mm)'].shift(1)\n",
    "    combined_df['강수량_2일전'] = combined_df['일_일강수량(mm)'].shift(2)\n",
    "    combined_df['강수량_1일_누적'] = combined_df['일_일강수량(mm)'].rolling(1, min_periods=1).sum()\n",
    "    combined_df['강수량_2일_누적'] = combined_df['일_일강수량(mm)'].rolling(2, min_periods=1).sum()\n",
    "    combined_df['강수량_3일_누적'] = combined_df['일_일강수량(mm)'].rolling(3, min_periods=1).sum()\n",
    "    combined_df['강수량_5일_누적'] = combined_df['일_일강수량(mm)'].rolling(5, min_periods=1).sum()\n",
    "    combined_df['강수량_7일_누적'] = combined_df['일_일강수량(mm)'].rolling(7, min_periods=1).sum()\n",
    "    \n",
    "    combined_df['일교차'] = combined_df['일_최고기온(°C)'] - combined_df['일_최저기온(°C)']\n",
    "    combined_df['폭우_여부'] = (combined_df['일_일강수량(mm)'] >= 80).astype(int)\n",
    "    \n",
    "    # 체감온도 계산\n",
    "    T = pd.to_numeric(combined_df.get('일_평균기온(°C)', np.nan), errors='coerce')\n",
    "    V_ms = pd.to_numeric(combined_df.get('일_평균풍속(m/s)', np.nan), errors='coerce')\n",
    "    RH = pd.to_numeric(combined_df.get('평균습도(%)', np.nan), errors='coerce')\n",
    "    \n",
    "    e = (RH/100.0) * 6.105 * np.exp(17.27*T/(237.7 + T))\n",
    "    combined_df['체감온도(°C)'] = T + 0.33*e - 0.70*V_ms - 4.00\n",
    "    \n",
    "    # 새 데이터 부분만 반환\n",
    "    historical_len = len(historical_df)\n",
    "    return combined_df.iloc[historical_len:].reset_index(drop=True)\n",
    "\n",
    "# ================================================================================================\n",
    "# 6. 유틸리티 함수들\n",
    "# ================================================================================================\n",
    "def load_original_data():\n",
    "    \"\"\"원본 데이터 로드\"\"\"\n",
    "    nanji_raw = pd.read_csv('../data/processed/center_season/nanji/난지_merged.csv', encoding='utf-8-sig')\n",
    "    jungnang_raw = pd.read_csv('../data/processed/center_season/jungnang/중랑_merged.csv', encoding='utf-8-sig')\n",
    "    seonam_raw = pd.read_csv('../data/processed/center_season/seonam/서남_merged.csv', encoding='utf-8-sig')\n",
    "    tancheon_raw = pd.read_csv('../data/processed/center_season/tancheon/탄천_merged.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    return {\n",
    "        \"nanji\": nanji_raw,\n",
    "        \"jungnang\": jungnang_raw,\n",
    "        \"seonam\": seonam_raw,\n",
    "        \"tancheon\": tancheon_raw\n",
    "    }\n",
    "\n",
    "def prepare_prediction_features(future_data, expected_features):\n",
    "    \"\"\"예측용 피처 준비\"\"\"\n",
    "    not_use_col = [\n",
    "        '날짜', '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "        '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "        '등급','등급_1일후','등급_2일후'\n",
    "    ]\n",
    "    \n",
    "    available_cols = [col for col in future_data.columns if col not in not_use_col]\n",
    "    X_future = future_data[available_cols].copy()\n",
    "    \n",
    "    for c in X_future.columns:\n",
    "        X_future[c] = pd.to_numeric(X_future[c], errors=\"coerce\")\n",
    "    \n",
    "    missing_features = set(expected_features) - set(X_future.columns)\n",
    "    if missing_features:\n",
    "        for feature in missing_features:\n",
    "            X_future[feature] = 0\n",
    "    \n",
    "    X_future = X_future[expected_features].copy()\n",
    "    return X_future\n",
    "\n",
    "def create_performance_summary(results_df):\n",
    "    \"\"\"성능 요약 생성\"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    for center in results_df['center'].unique():\n",
    "        center_data = results_df[results_df['center'] == center]\n",
    "        summary[center] = {}\n",
    "        \n",
    "        for task_type in ['regression', 'classification']:\n",
    "            task_data = center_data[center_data['task_type'] == task_type]\n",
    "            task_data_clean = task_data.dropna(subset=['actual_value', 'predicted_value'])\n",
    "            \n",
    "            if len(task_data_clean) > 0:\n",
    "                if task_type == 'regression':\n",
    "                    # 회귀 지표 계산\n",
    "                    abs_errors = np.abs(task_data_clean['actual_value'] - task_data_clean['predicted_value'])\n",
    "                    squared_errors = (task_data_clean['actual_value'] - task_data_clean['predicted_value']) ** 2\n",
    "                    pct_errors = abs_errors / (np.abs(task_data_clean['actual_value']) + 1e-8) * 100\n",
    "                    \n",
    "                    # R² 계산\n",
    "                    y_true = task_data_clean['actual_value'].values\n",
    "                    y_pred = task_data_clean['predicted_value'].values\n",
    "                    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "                    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "                    r2 = 1 - (ss_res / (ss_tot + 1e-8))\n",
    "                    \n",
    "                    summary[center]['regression'] = {\n",
    "                        'model_name': task_data_clean.iloc[0]['model_name'],\n",
    "                        'prediction_count': len(task_data_clean),\n",
    "                        'mae': abs_errors.mean(),\n",
    "                        'rmse': np.sqrt(squared_errors.mean()),\n",
    "                        'mape': pct_errors.mean(),\n",
    "                        'r2_on_predictions': r2\n",
    "                    }\n",
    "                else:\n",
    "                    # 분류 지표 계산\n",
    "                    correct = (task_data_clean['actual_value'] == task_data_clean['predicted_value']).astype(int)\n",
    "                    \n",
    "                    summary[center]['classification'] = {\n",
    "                        'model_name': task_data_clean.iloc[0]['model_name'],\n",
    "                        'prediction_count': len(task_data_clean),\n",
    "                        'accuracy': correct.mean(),\n",
    "                        'correct_count': int(correct.sum()),\n",
    "                        'total_count': len(task_data_clean)\n",
    "                    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# ================================================================================================\n",
    "# 7. 모든 기반 함수 준비 완료 메시지\n",
    "# ================================================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"모든 기반 함수들이 로드되었습니다!\")\n",
    "print(\"이제 센터별 완전 분석 파이프라인을 실행할 수 있습니다.\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"다음 단계:\")\n",
    "print(\"1. 센터별 완전 분석 파이프라인 코드를 실행하세요\")\n",
    "print(\"2. run_complete_analysis() 함수를 실행하세요\")\n",
    "print()\n",
    "print(\"필요한 라이브러리 확인:\")\n",
    "print(f\"- XGBoost: {'✓' if HAS_XGB else '✗'}\")\n",
    "print(f\"- LightGBM: {'✓' if HAS_LGB else '✗'}\")\n",
    "print(f\"- CatBoost: {'✓' if HAS_CATBOOST else '✗'}\")\n",
    "print(f\"- SHAP: {'✓' if HAS_SHAP else '✗'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c7d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 센터별 완전 분석 파이프라인 ===\n",
      "\n",
      "이 파이프라인은 다음을 수행합니다:\n",
      "1. 4개 센터별 개별 분석\n",
      "2. 센터별 회귀/분류 최고 성능 모델 선택\n",
      "3. Feature Importance + SHAP 시각화 생성\n",
      "4. 선택된 모델로 예측 수행\n",
      "5. 결과 CSV 파일 및 시각화 이미지 저장\n",
      "\n",
      "실행 방법:\n",
      "results = run_complete_analysis(cutoff_date='2025-05-20')\n",
      "\n",
      "생성되는 파일:\n",
      "- complete_analysis_predictions_YYYYMMDD_HHMMSS.csv\n",
      "- complete_analysis_training_YYYYMMDD_HHMMSS.csv\n",
      "- complete_analysis_best_models_YYYYMMDD_HHMMSS.csv\n",
      "- feature_importance_센터명_모델명_태스크.png\n",
      "- shap_bar_센터명_모델명_태스크.png\n",
      "- shap_beeswarm_센터명_모델명_태스크.png\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# 센터별 완전 분석 파이프라인 (회귀/분류 각각 + 시각화 포함)\n",
    "# ================================================================================================\n",
    "\n",
    "\n",
    "def run_complete_center_analysis(cutoff_date='2025-05-20', save_visualizations=True):\n",
    "    \"\"\"\n",
    "    센터별 완전 분석 파이프라인\n",
    "    - 4개 센터 x 2개 태스크(회귀/분류) = 총 8개 분석\n",
    "    - 각 센터별 최고 성능 모델 선택\n",
    "    - Feature Importance + SHAP 시각화 포함\n",
    "    - 최종 예측 수행\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"센터별 완전 분석 파이프라인 시작\")\n",
    "    print(f\"학습 기간: ~ {cutoff_date}\")\n",
    "    print(f\"예측 기간: {cutoff_date} 이후\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 데이터 로드\n",
    "    try:\n",
    "        centers_data = load_original_data()\n",
    "        print(f\"데이터 로드 완료:\")\n",
    "        for name, df in centers_data.items():\n",
    "            print(f\"  {name}: {len(df)}행\")\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 로드 실패: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 결과 저장용\n",
    "    all_results = {}\n",
    "    all_training_results = []\n",
    "    all_predictions = []\n",
    "    best_models_summary = []\n",
    "    \n",
    "    # 각 센터별 개별 분석\n",
    "    for center_name, df_raw in centers_data.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"센터: {center_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 센터별 분석 실행\n",
    "        center_results = analyze_single_center_complete(\n",
    "            center_name, df_raw, cutoff_date, save_visualizations\n",
    "        )\n",
    "        \n",
    "        if center_results:\n",
    "            all_results[center_name] = center_results\n",
    "            all_training_results.extend(center_results['training_results'])\n",
    "            all_predictions.extend(center_results['predictions'])\n",
    "            best_models_summary.extend(center_results['best_models_info'])\n",
    "    \n",
    "    # 전체 결과 요약\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"전체 분석 결과 요약\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 센터별 최고 성능 모델 요약\n",
    "    print_best_models_summary(best_models_summary)\n",
    "    \n",
    "    # 예측 성능 요약\n",
    "    if all_predictions:\n",
    "        final_results_df = pd.DataFrame(all_predictions)\n",
    "        performance_summary = create_performance_summary(final_results_df)\n",
    "        print_prediction_performance(performance_summary)\n",
    "        \n",
    "        # 결과 저장\n",
    "        save_complete_results(final_results_df, all_training_results, best_models_summary)\n",
    "    \n",
    "    return {\n",
    "        'center_results': all_results,\n",
    "        'predictions': all_predictions,\n",
    "        'training_results': all_training_results,\n",
    "        'best_models': best_models_summary\n",
    "    }\n",
    "\n",
    "def analyze_single_center_complete(center_name, df_raw, cutoff_date, save_visualizations=True):\n",
    "    \"\"\"단일 센터 완전 분석\"\"\"\n",
    "    \n",
    "    print(f\"\\n[{center_name.upper()} 센터 분석 시작]\")\n",
    "    \n",
    "    try:\n",
    "        # 1. 데이터 준비\n",
    "        df_raw['날짜'] = pd.to_datetime(df_raw['날짜'])\n",
    "        df_raw = df_raw.sort_values('날짜').reset_index(drop=True)\n",
    "        cutoff = pd.to_datetime(cutoff_date)\n",
    "        \n",
    "        # 학습/예측 데이터 분할\n",
    "        raw_train_data = df_raw[df_raw['날짜'] <= cutoff].copy()\n",
    "        raw_future_data = df_raw[df_raw['날짜'] > cutoff].copy()\n",
    "        \n",
    "        print(f\"  학습 데이터: {len(raw_train_data)}행\")\n",
    "        print(f\"  예측 데이터: {len(raw_future_data)}행\")\n",
    "        \n",
    "        if len(raw_train_data) < 50:\n",
    "            print(f\"  학습 데이터 부족\")\n",
    "            return None\n",
    "        \n",
    "        # 2. 피처 엔지니어링 (Data Leakage 방지)\n",
    "        train_data = make_features(raw_train_data, cutoff_date=cutoff_date)\n",
    "        print(f\"  피처 생성 완료: {len(train_data)}행\")\n",
    "        \n",
    "        # 3. 모델 학습 및 평가\n",
    "        training_results = comprehensive_evaluation_comparison(center_name, train_data)\n",
    "        \n",
    "        # 4. 최고 성능 모델 선택 및 상세 분석\n",
    "        best_models = select_best_models_for_center(center_name, train_data, training_results)\n",
    "        best_models_info = []\n",
    "        \n",
    "        if best_models:\n",
    "            # 각 태스크별 최고 모델 상세 분석\n",
    "            for task_type, model_info in best_models.items():\n",
    "                print(f\"\\n--- {center_name.upper()} {task_type.upper()} 최고 모델 분석 ---\")\n",
    "                \n",
    "                # 상세 분석 수행 (Feature Importance + SHAP)\n",
    "                detailed_analysis = perform_detailed_model_analysis(\n",
    "                    center_name, train_data, model_info, task_type, save_visualizations\n",
    "                )\n",
    "                \n",
    "                if detailed_analysis:\n",
    "                    model_info.update(detailed_analysis)\n",
    "                    best_models_info.append({\n",
    "                        'center': center_name,\n",
    "                        'task_type': task_type,\n",
    "                        'model_name': model_info['model_name'],\n",
    "                        'performance': model_info['performance'],\n",
    "                        'analysis_completed': True\n",
    "                    })\n",
    "        \n",
    "        # 5. 예측 수행\n",
    "        predictions = []\n",
    "        if len(raw_future_data) > 0 and best_models:\n",
    "            print(f\"\\n--- {center_name.upper()} 예측 수행 ---\")\n",
    "            \n",
    "            # 예측용 데이터 준비\n",
    "            future_data_processed = make_features_for_prediction(raw_train_data, raw_future_data)\n",
    "            \n",
    "            # 각 태스크별 예측\n",
    "            for task_type, model_info in best_models.items():\n",
    "                task_predictions = make_predictions_for_task(\n",
    "                    center_name, future_data_processed, model_info, task_type\n",
    "                )\n",
    "                predictions.extend(task_predictions)\n",
    "        \n",
    "        return {\n",
    "            'training_results': training_results,\n",
    "            'best_models': best_models,\n",
    "            'best_models_info': best_models_info,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  센터 분석 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def select_best_models_for_center(center_name, train_data, training_results):\n",
    "    \"\"\"센터별 최고 성능 모델 선택\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(training_results)\n",
    "    successful_results = results_df[results_df['success'] == True]\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(f\"  성공한 모델이 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    # 회귀 최고 성능 모델\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"  최고 회귀 모델: {best_reg['model']} (R²={best_reg['r2']:.3f})\")\n",
    "        \n",
    "        # 모델 재학습\n",
    "        reg_model = retrain_best_model_full(\n",
    "            train_data, best_reg['model'], 'regression', best_reg['split_method']\n",
    "        )\n",
    "        \n",
    "        if reg_model:\n",
    "            best_models['regression'] = {\n",
    "                'model_name': best_reg['model'],\n",
    "                'pipeline': reg_model['pipeline'],\n",
    "                'feature_names': reg_model['feature_names'],\n",
    "                'performance': dict(best_reg),\n",
    "                'split_method': best_reg['split_method']\n",
    "            }\n",
    "    \n",
    "    # 분류 최고 성능 모델\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"  최고 분류 모델: {best_clf['model']} (F1={best_clf['macro_f1']:.3f})\")\n",
    "        \n",
    "        # 모델 재학습\n",
    "        clf_model = retrain_best_model_full(\n",
    "            train_data, best_clf['model'], 'classification', best_clf['split_method']\n",
    "        )\n",
    "        \n",
    "        if clf_model:\n",
    "            best_models['classification'] = {\n",
    "                'model_name': best_clf['model'],\n",
    "                'pipeline': clf_model['pipeline'],\n",
    "                'feature_names': clf_model['feature_names'],\n",
    "                'performance': dict(best_clf),\n",
    "                'split_method': best_clf['split_method']\n",
    "            }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "def retrain_best_model_full(train_data, model_name, model_type, split_method):\n",
    "    \"\"\"최고 성능 모델 전체 데이터로 재학습\"\"\"\n",
    "    \n",
    "    try:\n",
    "        target_col = \"합계_1일후\" if model_type == \"regression\" else \"등급_1일후\"\n",
    "        \n",
    "        # 전체 데이터 사용\n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            train_data, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.05, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # 전체 데이터 결합\n",
    "        X_all = pd.concat([X_train, X_test], ignore_index=True)\n",
    "        y_all = pd.concat([y_train, y_test], ignore_index=True)\n",
    "        \n",
    "        # 모델 구축\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "        \n",
    "        model = models[model_name]\n",
    "        pipeline = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipeline.fit(X_all, y_all)\n",
    "        \n",
    "        return {\n",
    "            'pipeline': pipeline,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    모델 재학습 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def perform_detailed_model_analysis(center_name, train_data, model_info, task_type, save_visualizations=True):\n",
    "    \"\"\"상세 모델 분석 (Feature Importance + SHAP)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        pipeline = model_info['pipeline']\n",
    "        feature_names = model_info['feature_names']\n",
    "        model_name = model_info['model_name']\n",
    "        \n",
    "        # 테스트 데이터 준비\n",
    "        target_col = \"합계_1일후\" if task_type == \"regression\" else \"등급_1일후\"\n",
    "        X_train, X_test, y_train, y_test, _, _, _ = prepare_data_stratified(\n",
    "            train_data, target_col=target_col, model_type=task_type, \n",
    "            test_size=0.2, split_method=model_info['split_method']\n",
    "        )\n",
    "        \n",
    "        analysis_results = {}\n",
    "        \n",
    "        # 1. Feature Importance 분석\n",
    "        print(f\"    Feature Importance 분석...\")\n",
    "        importance_df = extract_feature_importance(pipeline, model_name, feature_names)\n",
    "        \n",
    "        if importance_df is not None:\n",
    "            print(f\"    Top 5 중요 피처:\")\n",
    "            for idx, row in importance_df.head(5).iterrows():\n",
    "                print(f\"      {row['feature']}: {row['importance']:.3f}\")\n",
    "            \n",
    "            # 시각화\n",
    "            if save_visualizations:\n",
    "                fig = plot_feature_importance(importance_df, f\"{center_name}_{model_name}\")\n",
    "                if fig:\n",
    "                    save_path = f\"feature_importance_{center_name}_{model_name}_{task_type}.png\"\n",
    "                    fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                    plt.close(fig)\n",
    "                    print(f\"    Feature Importance 시각화 저장: {save_path}\")\n",
    "            \n",
    "            analysis_results['feature_importance'] = importance_df\n",
    "        \n",
    "        # 2. SHAP 분석\n",
    "        print(f\"    SHAP 분석...\")\n",
    "        try:\n",
    "            shap_result = analyze_model_with_shap(pipeline, X_test, feature_names, model_name, max_samples=50)\n",
    "            \n",
    "            if shap_result:\n",
    "                shap_values, X_processed, explainer = shap_result\n",
    "                \n",
    "                # SHAP 시각화\n",
    "                if save_visualizations:\n",
    "                    shap_figs = plot_shap_summary(shap_values, X_processed, feature_names, \n",
    "                                                f\"{center_name}_{model_name}\")\n",
    "                    \n",
    "                    for i, fig in enumerate(shap_figs):\n",
    "                        suffix = \"bar\" if i == 0 else \"beeswarm\"\n",
    "                        save_path = f\"shap_{suffix}_{center_name}_{model_name}_{task_type}.png\"\n",
    "                        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "                        plt.close(fig)\n",
    "                        print(f\"    SHAP {suffix} 시각화 저장: {save_path}\")\n",
    "                \n",
    "                analysis_results['shap_analysis'] = {\n",
    "                    'shap_values': shap_values,\n",
    "                    'feature_names': feature_names\n",
    "                }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"    SHAP 분석 실패: {e}\")\n",
    "        \n",
    "        return analysis_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    상세 분석 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def make_predictions_for_task(center_name, future_data, model_info, task_type):\n",
    "    \"\"\"태스크별 예측 수행\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    try:\n",
    "        pipeline = model_info['pipeline']\n",
    "        feature_names = model_info['feature_names']\n",
    "        model_name = model_info['model_name']\n",
    "        \n",
    "        # 예측 데이터 준비\n",
    "        X_future = prepare_prediction_features(future_data, feature_names)\n",
    "        \n",
    "        if X_future is None or len(X_future) == 0:\n",
    "            return predictions\n",
    "        \n",
    "        # 예측 수행\n",
    "        y_pred = pipeline.predict(X_future)\n",
    "        target_col = \"합계_1일후\" if task_type == \"regression\" else \"등급_1일후\"\n",
    "        \n",
    "        print(f\"    {task_type} 예측 완료: {len(y_pred)}개\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        for i in range(len(X_future)):\n",
    "            # 실제값 추출 (가능한 경우)\n",
    "            actual_val = None\n",
    "            if target_col in future_data.columns and i < len(future_data):\n",
    "                actual_val = future_data.iloc[i].get(target_col)\n",
    "                if pd.notna(actual_val):\n",
    "                    actual_val = int(actual_val) if task_type == 'classification' else float(actual_val)\n",
    "            \n",
    "            pred_result = {\n",
    "                'date': future_data.iloc[i]['날짜'],\n",
    "                'center': center_name,\n",
    "                'task_type': task_type,\n",
    "                'model_name': model_name,\n",
    "                'target_column': target_col,\n",
    "                'actual_value': actual_val,\n",
    "                'predicted_value': int(y_pred[i]) if task_type == 'classification' else float(y_pred[i])\n",
    "            }\n",
    "            predictions.append(pred_result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    {task_type} 예측 실패: {e}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def print_best_models_summary(best_models_summary):\n",
    "    \"\"\"최고 성능 모델 요약 출력\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- 센터별 최고 성능 모델 요약 ---\")\n",
    "    \n",
    "    centers = {}\n",
    "    for model in best_models_summary:\n",
    "        center = model['center']\n",
    "        if center not in centers:\n",
    "            centers[center] = {}\n",
    "        centers[center][model['task_type']] = model\n",
    "    \n",
    "    for center, tasks in centers.items():\n",
    "        print(f\"\\n{center.upper()} 센터:\")\n",
    "        \n",
    "        if 'regression' in tasks:\n",
    "            reg = tasks['regression']\n",
    "            perf = reg['performance']\n",
    "            print(f\"  회귀: {reg['model_name']} (R²={perf['r2']:.3f}, MAE={perf['mae']:.1f})\")\n",
    "        \n",
    "        if 'classification' in tasks:\n",
    "            clf = tasks['classification']\n",
    "            perf = clf['performance']\n",
    "            print(f\"  분류: {clf['model_name']} (F1={perf['macro_f1']:.3f}, ACC={perf['accuracy']:.3f})\")\n",
    "\n",
    "def print_prediction_performance(performance_summary):\n",
    "    \"\"\"예측 성능 출력\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- 예측 성능 요약 ---\")\n",
    "    \n",
    "    for center, perf in performance_summary.items():\n",
    "        print(f\"\\n{center.upper()} 센터:\")\n",
    "        \n",
    "        if 'regression' in perf:\n",
    "            reg = perf['regression']\n",
    "            print(f\"  회귀 예측 ({reg['prediction_count']}개):\")\n",
    "            print(f\"    MAE: {reg['mae']:.2f}\")\n",
    "            print(f\"    RMSE: {reg['rmse']:.2f}\")\n",
    "            if reg.get('r2_on_predictions'):\n",
    "                print(f\"    R²: {reg['r2_on_predictions']:.3f}\")\n",
    "        \n",
    "        if 'classification' in perf:\n",
    "            clf = perf['classification']\n",
    "            print(f\"  분류 예측 ({clf['prediction_count']}개):\")\n",
    "            print(f\"    정확도: {clf['accuracy']:.1%}\")\n",
    "            print(f\"    정답: {clf['correct_count']}/{clf['total_count']}\")\n",
    "\n",
    "def save_complete_results(predictions_df, training_results, best_models_summary):\n",
    "    \"\"\"결과 저장\"\"\"\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. 예측 결과\n",
    "    pred_filename = f\"complete_analysis_predictions_{timestamp}.csv\"\n",
    "    predictions_df.to_csv(pred_filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n예측 결과 저장: {pred_filename}\")\n",
    "    \n",
    "    # 2. 학습 결과\n",
    "    if training_results:\n",
    "        train_df = pd.DataFrame(training_results)\n",
    "        train_filename = f\"complete_analysis_training_{timestamp}.csv\"\n",
    "        train_df.to_csv(train_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"학습 결과 저장: {train_filename}\")\n",
    "    \n",
    "    # 3. 최고 모델 요약\n",
    "    if best_models_summary:\n",
    "        best_df = pd.DataFrame(best_models_summary)\n",
    "        best_filename = f\"complete_analysis_best_models_{timestamp}.csv\"\n",
    "        best_df.to_csv(best_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"최고 모델 요약 저장: {best_filename}\")\n",
    "\n",
    "# ================================================================================================\n",
    "# 실행 함수\n",
    "# ================================================================================================\n",
    "\n",
    "def run_complete_analysis(cutoff_date='2025-05-20'):\n",
    "    \"\"\"완전 분석 실행\"\"\"\n",
    "    \n",
    "    print(\"센터별 완전 분석 파이프라인을 시작합니다...\")\n",
    "    print(\"이 과정은 시간이 오래 걸릴 수 있습니다.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 분석 실행\n",
    "    results = run_complete_center_analysis(cutoff_date=cutoff_date, save_visualizations=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"완전 분석 완료!\")\n",
    "    print(f\"총 소요시간: {elapsed_time:.1f}초 ({elapsed_time/60:.1f}분)\")\n",
    "    print(f\"분석된 센터: {len(results['center_results'])}개\")\n",
    "    print(f\"생성된 예측: {len(results['predictions'])}개\")\n",
    "    print(f\"시각화 파일들이 현재 디렉토리에 저장되었습니다.\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 센터별 완전 분석 파이프라인 ===\")\n",
    "    print()\n",
    "    print(\"이 파이프라인은 다음을 수행합니다:\")\n",
    "    print(\"1. 4개 센터별 개별 분석\")\n",
    "    print(\"2. 센터별 회귀/분류 최고 성능 모델 선택\")\n",
    "    print(\"3. Feature Importance + SHAP 시각화 생성\")\n",
    "    print(\"4. 선택된 모델로 예측 수행\")\n",
    "    print(\"5. 결과 CSV 파일 및 시각화 이미지 저장\")\n",
    "    print()\n",
    "    print(\"실행 방법:\")\n",
    "    print(\"results = run_complete_analysis(cutoff_date='2025-05-20')\")\n",
    "    print()\n",
    "    print(\"생성되는 파일:\")\n",
    "    print(\"- complete_analysis_predictions_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"- complete_analysis_training_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"- complete_analysis_best_models_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"- feature_importance_센터명_모델명_태스크.png\")\n",
    "    print(\"- shap_bar_센터명_모델명_태스크.png\")\n",
    "    print(\"- shap_beeswarm_센터명_모델명_태스크.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43235b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "센터별 완전 분석 파이프라인을 시작합니다...\n",
      "이 과정은 시간이 오래 걸릴 수 있습니다.\n",
      "================================================================================\n",
      "센터별 완전 분석 파이프라인 시작\n",
      "학습 기간: ~ 2025-05-20\n",
      "예측 기간: 2025-05-20 이후\n",
      "================================================================================\n",
      "데이터 로드 완료:\n",
      "  nanji: 3103행\n",
      "  jungnang: 3103행\n",
      "  seonam: 3103행\n",
      "  tancheon: 3103행\n",
      "\n",
      "============================================================\n",
      "센터: NANJI\n",
      "============================================================\n",
      "\n",
      "[NANJI 센터 분석 시작]\n",
      "  학습 데이터: 3062행\n",
      "  예측 데이터: 41행\n",
      "  피처 생성 완료: 3058행\n",
      "\n",
      "======================================================================\n",
      "센터: nanji - Stratified vs 시계열 분할 비교\n",
      "======================================================================\n",
      "데이터 크기: 3058행, 44컬럼\n",
      "등급 분포: {0.0: 458, 1.0: 1682, 2.0: 611, 3.0: 307}\n",
      "클래스 불균형 비율: 5.5:1 (최대:1682, 최소:307)\n",
      "\n",
      "==================================================\n",
      "분할 방법: TEMPORAL\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (temporal) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  17%|█▋        | 1/6 [00:00<00:03,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.557, MAE=49542, MAPE=7.3%\n",
      "  LinearRegression  : R²=0.513, MAE=62439, MAPE=9.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  50%|█████     | 3/6 [00:02<00:02,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.395, MAE=58665, MAPE=9.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  67%|██████▋   | 4/6 [00:02<00:01,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.480, MAE=56356, MAPE=8.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  83%|████████▎ | 5/6 [00:04<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.492, MAE=54005, MAPE=8.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.540, MAE=48369, MAPE=7.1%\n",
      "\n",
      "--- 분류 모델 평가 (temporal) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 453, 1: 1309, 2: 435, 3: 249}\n",
      "테스트 세트 등급 분포: {0: 5, 1: 373, 2: 176, 3: 58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  17%|█▋        | 1/6 [00:00<00:01,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.748, F1=0.481, 극값F1=0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  33%|███▎      | 2/6 [00:06<00:15,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.665, F1=0.468, 극값F1=0.386\n",
      "  LogisticRegression_Clf: ACC=0.314, F1=0.308, 극값F1=0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  67%|██████▋   | 4/6 [00:08<00:04,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.722, F1=0.567, 극값F1=0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  83%|████████▎ | 5/6 [00:15<00:03,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.694, F1=0.527, 극값F1=0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.672, F1=0.508, 극값F1=0.404\n",
      "\n",
      "==================================================\n",
      "분할 방법: STRATIFIED\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (random_shuffle) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  17%|█▋        | 1/6 [00:00<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.612, MAE=47300, MAPE=7.0%\n",
      "  LinearRegression  : R²=0.592, MAE=50530, MAPE=7.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  50%|█████     | 3/6 [00:02<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.620, MAE=46878, MAPE=6.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  67%|██████▋   | 4/6 [00:02<00:01,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.637, MAE=45859, MAPE=6.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  83%|████████▎ | 5/6 [00:04<00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.605, MAE=48431, MAPE=7.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.648, MAE=44875, MAPE=6.6%\n",
      "\n",
      "--- 분류 모델 평가 (stratified) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 366, 1: 1345, 2: 489, 3: 246}\n",
      "테스트 세트 등급 분포: {0: 92, 1: 337, 2: 122, 3: 61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  17%|█▋        | 1/6 [00:00<00:01,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.725, F1=0.664, 극값F1=0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  33%|███▎      | 2/6 [00:06<00:15,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.725, F1=0.658, 극값F1=0.648\n",
      "  LogisticRegression_Clf: ACC=0.613, F1=0.578, 극값F1=0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  67%|██████▋   | 4/6 [00:08<00:04,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.745, F1=0.667, 극값F1=0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  83%|████████▎ | 5/6 [00:15<00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.735, F1=0.665, 극값F1=0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.675, F1=0.630, 극값F1=0.632\n",
      "  최고 회귀 모델: CatBoost_Reg (R²=0.648)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  최고 분류 모델: XGBoost_Clf (F1=0.667)\n",
      "\n",
      "--- NANJI REGRESSION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      강수량_7일_누적: 12.240\n",
      "      하천: 5.756\n",
      "      강수량_1일_누적: 5.337\n",
      "      세탁업: 5.043\n",
      "      체감온도(°C): 4.405\n",
      "    Feature Importance 시각화 저장: feature_importance_nanji_CatBoost_Reg_regression.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_nanji_CatBoost_Reg_regression.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_nanji_CatBoost_Reg_regression.png\n",
      "\n",
      "--- NANJI CLASSIFICATION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      체감온도(°C): 0.071\n",
      "      일_최저기온(°C): 0.058\n",
      "      강수량_7일_누적: 0.058\n",
      "      강수량_2일_누적: 0.054\n",
      "      목욕장업: 0.047\n",
      "    Feature Importance 시각화 저장: feature_importance_nanji_XGBoost_Clf_classification.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_nanji_XGBoost_Clf_classification.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_nanji_XGBoost_Clf_classification.png\n",
      "\n",
      "--- NANJI 예측 수행 ---\n",
      "    regression 예측 완료: 41개\n",
      "    classification 예측 완료: 41개\n",
      "\n",
      "============================================================\n",
      "센터: JUNGNANG\n",
      "============================================================\n",
      "\n",
      "[JUNGNANG 센터 분석 시작]\n",
      "  학습 데이터: 3062행\n",
      "  예측 데이터: 41행\n",
      "  피처 생성 완료: 3058행\n",
      "\n",
      "======================================================================\n",
      "센터: jungnang - Stratified vs 시계열 분할 비교\n",
      "======================================================================\n",
      "데이터 크기: 3058행, 44컬럼\n",
      "등급 분포: {0.0: 460, 1.0: 1680, 2.0: 611, 3.0: 307}\n",
      "클래스 불균형 비율: 5.5:1 (최대:1680, 최소:307)\n",
      "\n",
      "==================================================\n",
      "분할 방법: TEMPORAL\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (temporal) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  17%|█▋        | 1/6 [00:00<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.304, MAE=91088, MAPE=7.1%\n",
      "  LinearRegression  : R²=0.055, MAE=131262, MAPE=10.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  50%|█████     | 3/6 [00:02<00:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.137, MAE=105765, MAPE=8.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  67%|██████▋   | 4/6 [00:02<00:01,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.269, MAE=96690, MAPE=7.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  83%|████████▎ | 5/6 [00:04<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.254, MAE=96761, MAPE=7.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.259, MAE=99822, MAPE=7.9%\n",
      "\n",
      "--- 분류 모델 평가 (temporal) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 405, 1: 1321, 2: 458, 3: 262}\n",
      "테스트 세트 등급 분포: {0: 55, 1: 359, 2: 153, 3: 45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  17%|█▋        | 1/6 [00:00<00:01,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.627, F1=0.425, 극값F1=0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  33%|███▎      | 2/6 [00:06<00:16,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.547, F1=0.380, 극값F1=0.303\n",
      "  LogisticRegression_Clf: ACC=0.359, F1=0.296, 극값F1=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  67%|██████▋   | 4/6 [00:08<00:04,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.541, F1=0.442, 극값F1=0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  83%|████████▎ | 5/6 [00:15<00:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.531, F1=0.468, 극값F1=0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.554, F1=0.411, 극값F1=0.325\n",
      "\n",
      "==================================================\n",
      "분할 방법: STRATIFIED\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (random_shuffle) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  17%|█▋        | 1/6 [00:00<00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.576, MAE=76240, MAPE=5.5%\n",
      "  LinearRegression  : R²=0.522, MAE=89786, MAPE=6.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  50%|█████     | 3/6 [00:02<00:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.572, MAE=78344, MAPE=5.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  67%|██████▋   | 4/6 [00:02<00:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.575, MAE=76245, MAPE=5.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  83%|████████▎ | 5/6 [00:04<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.562, MAE=78893, MAPE=5.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.602, MAE=75195, MAPE=5.5%\n",
      "\n",
      "--- 분류 모델 평가 (stratified) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 368, 1: 1344, 2: 489, 3: 245}\n",
      "테스트 세트 등급 분포: {0: 92, 1: 336, 2: 122, 3: 62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  17%|█▋        | 1/6 [00:00<00:01,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.711, F1=0.629, 극값F1=0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  33%|███▎      | 2/6 [00:07<00:16,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.730, F1=0.640, 극값F1=0.603\n",
      "  LogisticRegression_Clf: ACC=0.560, F1=0.548, 극값F1=0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  67%|██████▋   | 4/6 [00:08<00:04,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.745, F1=0.661, 극값F1=0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  83%|████████▎ | 5/6 [00:15<00:03,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.739, F1=0.647, 극값F1=0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.691, F1=0.653, 극값F1=0.654\n",
      "  최고 회귀 모델: CatBoost_Reg (R²=0.602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  최고 분류 모델: XGBoost_Clf (F1=0.661)\n",
      "\n",
      "--- JUNGNANG REGRESSION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      강수량_7일_누적: 9.430\n",
      "      세탁업: 6.933\n",
      "      체력단련장업: 6.412\n",
      "      목욕장업: 5.363\n",
      "      하천: 4.950\n",
      "    Feature Importance 시각화 저장: feature_importance_jungnang_CatBoost_Reg_regression.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_jungnang_CatBoost_Reg_regression.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_jungnang_CatBoost_Reg_regression.png\n",
      "\n",
      "--- JUNGNANG CLASSIFICATION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      수영장업: 0.066\n",
      "      체력단련장업: 0.058\n",
      "      강수량_7일_누적: 0.058\n",
      "      목욕장업: 0.053\n",
      "      일_최저기온(°C): 0.047\n",
      "    Feature Importance 시각화 저장: feature_importance_jungnang_XGBoost_Clf_classification.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_jungnang_XGBoost_Clf_classification.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_jungnang_XGBoost_Clf_classification.png\n",
      "\n",
      "--- JUNGNANG 예측 수행 ---\n",
      "    regression 예측 완료: 41개\n",
      "    classification 예측 완료: 41개\n",
      "\n",
      "============================================================\n",
      "센터: SEONAM\n",
      "============================================================\n",
      "\n",
      "[SEONAM 센터 분석 시작]\n",
      "  학습 데이터: 3062행\n",
      "  예측 데이터: 41행\n",
      "  피처 생성 완료: 3058행\n",
      "\n",
      "======================================================================\n",
      "센터: seonam - Stratified vs 시계열 분할 비교\n",
      "======================================================================\n",
      "데이터 크기: 3058행, 43컬럼\n",
      "등급 분포: {0.0: 459, 1.0: 1680, 2.0: 612, 3.0: 307}\n",
      "클래스 불균형 비율: 5.5:1 (최대:1680, 최소:307)\n",
      "\n",
      "==================================================\n",
      "분할 방법: TEMPORAL\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (temporal) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  17%|█▋        | 1/6 [00:00<00:04,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.037, MAE=157633, MAPE=10.9%\n",
      "  LinearRegression  : R²=0.058, MAE=156666, MAPE=10.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  50%|█████     | 3/6 [00:02<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.270, MAE=124493, MAPE=8.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  67%|██████▋   | 4/6 [00:03<00:01,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.244, MAE=127234, MAPE=8.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  83%|████████▎ | 5/6 [00:04<00:01,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.280, MAE=120014, MAPE=8.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.327, MAE=124794, MAPE=8.5%\n",
      "\n",
      "--- 분류 모델 평가 (temporal) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 136, 1: 1493, 2: 544, 3: 273}\n",
      "테스트 세트 등급 분포: {0: 323, 1: 187, 2: 68, 3: 34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  17%|█▋        | 1/6 [00:00<00:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.304, F1=0.323, 극값F1=0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  33%|███▎      | 2/6 [00:07<00:16,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.477, F1=0.432, 극값F1=0.593\n",
      "  LogisticRegression_Clf: ACC=0.271, F1=0.306, 극값F1=0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  67%|██████▋   | 4/6 [00:08<00:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.317, F1=0.307, 극값F1=0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  83%|████████▎ | 5/6 [00:15<00:03,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.301, F1=0.265, 극값F1=0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.252, F1=0.265, 극값F1=0.149\n",
      "\n",
      "==================================================\n",
      "분할 방법: STRATIFIED\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (random_shuffle) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  17%|█▋        | 1/6 [00:00<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.562, MAE=91557, MAPE=5.4%\n",
      "  LinearRegression  : R²=0.528, MAE=100152, MAPE=6.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  50%|█████     | 3/6 [00:02<00:02,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.604, MAE=86879, MAPE=5.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  67%|██████▋   | 4/6 [00:03<00:01,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.590, MAE=87201, MAPE=5.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  83%|████████▎ | 5/6 [00:05<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.578, MAE=89065, MAPE=5.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.594, MAE=86488, MAPE=5.1%\n",
      "\n",
      "--- 분류 모델 평가 (stratified) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 367, 1: 1344, 2: 489, 3: 246}\n",
      "테스트 세트 등급 분포: {0: 92, 1: 336, 2: 123, 3: 61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  17%|█▋        | 1/6 [00:00<00:01,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.727, F1=0.652, 극값F1=0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  33%|███▎      | 2/6 [00:07<00:16,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.735, F1=0.655, 극값F1=0.662\n",
      "  LogisticRegression_Clf: ACC=0.595, F1=0.562, 극값F1=0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  67%|██████▋   | 4/6 [00:09<00:04,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.745, F1=0.658, 극값F1=0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  83%|████████▎ | 5/6 [00:16<00:03,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.745, F1=0.652, 극값F1=0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.699, F1=0.644, 극값F1=0.673\n",
      "  최고 회귀 모델: GradientBoosting_Reg (R²=0.604)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  최고 분류 모델: XGBoost_Clf (F1=0.658)\n",
      "\n",
      "--- SEONAM REGRESSION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      일_일강수량(mm): 0.258\n",
      "      강수량_1일_누적: 0.141\n",
      "      강수량_7일_누적: 0.114\n",
      "      일_최저기온(°C): 0.085\n",
      "      세탁업: 0.080\n",
      "    Feature Importance 시각화 저장: feature_importance_seonam_GradientBoosting_Reg_regression.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_seonam_GradientBoosting_Reg_regression.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_seonam_GradientBoosting_Reg_regression.png\n",
      "\n",
      "--- SEONAM CLASSIFICATION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      일_일강수량(mm): 0.087\n",
      "      강수량_1일_누적: 0.086\n",
      "      체력단련장업: 0.071\n",
      "      폭우_여부: 0.064\n",
      "      목욕장업: 0.047\n",
      "    Feature Importance 시각화 저장: feature_importance_seonam_XGBoost_Clf_classification.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_seonam_XGBoost_Clf_classification.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_seonam_XGBoost_Clf_classification.png\n",
      "\n",
      "--- SEONAM 예측 수행 ---\n",
      "    regression 예측 완료: 41개\n",
      "    classification 예측 완료: 41개\n",
      "\n",
      "============================================================\n",
      "센터: TANCHEON\n",
      "============================================================\n",
      "\n",
      "[TANCHEON 센터 분석 시작]\n",
      "  학습 데이터: 3062행\n",
      "  예측 데이터: 41행\n",
      "  피처 생성 완료: 3058행\n",
      "\n",
      "======================================================================\n",
      "센터: tancheon - Stratified vs 시계열 분할 비교\n",
      "======================================================================\n",
      "데이터 크기: 3058행, 42컬럼\n",
      "등급 분포: {0.0: 459, 1.0: 1680, 2.0: 612, 3.0: 307}\n",
      "클래스 불균형 비율: 5.5:1 (최대:1680, 최소:307)\n",
      "\n",
      "==================================================\n",
      "분할 방법: TEMPORAL\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (temporal) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  17%|█▋        | 1/6 [00:00<00:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.275, MAE=62889, MAPE=8.3%\n",
      "  LinearRegression  : R²=0.287, MAE=66726, MAPE=8.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  50%|█████     | 3/6 [00:02<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.027, MAE=75273, MAPE=10.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  67%|██████▋   | 4/6 [00:02<00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.109, MAE=72585, MAPE=9.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(temporal):  83%|████████▎ | 5/6 [00:04<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.202, MAE=66029, MAPE=8.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.197, MAE=68829, MAPE=9.2%\n",
      "\n",
      "--- 분류 모델 평가 (temporal) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 345, 1: 1348, 2: 496, 3: 257}\n",
      "테스트 세트 등급 분포: {0: 114, 1: 332, 2: 116, 3: 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  17%|█▋        | 1/6 [00:00<00:01,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.557, F1=0.410, 극값F1=0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  33%|███▎      | 2/6 [00:06<00:15,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.364, F1=0.361, 극값F1=0.371\n",
      "  LogisticRegression_Clf: ACC=0.268, F1=0.259, 극값F1=0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  67%|██████▋   | 4/6 [00:08<00:03,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.477, F1=0.405, 극값F1=0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(temporal):  83%|████████▎ | 5/6 [00:16<00:03,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.454, F1=0.382, 극값F1=0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.358, F1=0.354, 극값F1=0.369\n",
      "\n",
      "==================================================\n",
      "분할 방법: STRATIFIED\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (random_shuffle) ---\n",
      "회귀용 데이터: 학습 2446행, 테스트 612행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  17%|█▋        | 1/6 [00:00<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Reg  : R²=0.500, MAE=48022, MAPE=6.0%\n",
      "  LinearRegression  : R²=0.377, MAE=57635, MAPE=7.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  50%|█████     | 3/6 [00:02<00:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Reg: R²=0.510, MAE=47588, MAPE=6.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  67%|██████▋   | 4/6 [00:02<00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Reg       : R²=0.514, MAE=46528, MAPE=5.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "회귀(random_shuffle):  83%|████████▎ | 5/6 [00:04<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Reg      : R²=0.482, MAE=48315, MAPE=6.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Reg      : R²=0.515, MAE=47014, MAPE=5.9%\n",
      "\n",
      "--- 분류 모델 평가 (stratified) ---\n",
      "분류용 데이터: 학습 2446행, 테스트 612행\n",
      "학습 세트 등급 분포: {0: 367, 1: 1344, 2: 489, 3: 246}\n",
      "테스트 세트 등급 분포: {0: 92, 1: 336, 2: 123, 3: 61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  17%|█▋        | 1/6 [00:00<00:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RandomForest_Clf  : ACC=0.641, F1=0.538, 극값F1=0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  33%|███▎      | 2/6 [00:06<00:15,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GradientBoosting_Clf: ACC=0.636, F1=0.524, 극값F1=0.485\n",
      "  LogisticRegression_Clf: ACC=0.449, F1=0.432, 극값F1=0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  67%|██████▋   | 4/6 [00:08<00:03,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost_Clf       : ACC=0.658, F1=0.547, 극값F1=0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "분류(stratified):  83%|████████▎ | 5/6 [00:15<00:03,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM_Clf      : ACC=0.647, F1=0.545, 극값F1=0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost_Clf      : ACC=0.614, F1=0.559, 극값F1=0.577\n",
      "  최고 회귀 모델: CatBoost_Reg (R²=0.515)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  최고 분류 모델: CatBoost_Clf (F1=0.559)\n",
      "\n",
      "--- TANCHEON REGRESSION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      세탁업: 8.238\n",
      "      체력단련장업: 7.269\n",
      "      강수량_7일_누적: 5.583\n",
      "      하천: 5.496\n",
      "      일_일강수량(mm): 5.422\n",
      "    Feature Importance 시각화 저장: feature_importance_tancheon_CatBoost_Reg_regression.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_tancheon_CatBoost_Reg_regression.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_tancheon_CatBoost_Reg_regression.png\n",
      "\n",
      "--- TANCHEON CLASSIFICATION 최고 모델 분석 ---\n",
      "    Feature Importance 분석...\n",
      "    Top 5 중요 피처:\n",
      "      세탁업: 8.290\n",
      "      강수량_7일_누적: 6.579\n",
      "      생활인구: 5.513\n",
      "      월: 5.492\n",
      "      체력단련장업: 4.324\n",
      "    Feature Importance 시각화 저장: feature_importance_tancheon_CatBoost_Clf_classification.png\n",
      "    SHAP 분석...\n",
      "    SHAP bar 시각화 저장: shap_bar_tancheon_CatBoost_Clf_classification.png\n",
      "    SHAP beeswarm 시각화 저장: shap_beeswarm_tancheon_CatBoost_Clf_classification.png\n",
      "\n",
      "--- TANCHEON 예측 수행 ---\n",
      "    regression 예측 완료: 41개\n",
      "    classification 예측 완료: 41개\n",
      "\n",
      "================================================================================\n",
      "전체 분석 결과 요약\n",
      "================================================================================\n",
      "\n",
      "--- 센터별 최고 성능 모델 요약 ---\n",
      "\n",
      "NANJI 센터:\n",
      "  회귀: CatBoost_Reg (R²=0.648, MAE=44874.8)\n",
      "  분류: XGBoost_Clf (F1=0.667, ACC=0.745)\n",
      "\n",
      "JUNGNANG 센터:\n",
      "  회귀: CatBoost_Reg (R²=0.602, MAE=75195.0)\n",
      "  분류: XGBoost_Clf (F1=0.661, ACC=0.745)\n",
      "\n",
      "SEONAM 센터:\n",
      "  회귀: GradientBoosting_Reg (R²=0.604, MAE=86878.9)\n",
      "  분류: XGBoost_Clf (F1=0.658, ACC=0.745)\n",
      "\n",
      "TANCHEON 센터:\n",
      "  회귀: CatBoost_Reg (R²=0.515, MAE=47014.5)\n",
      "  분류: CatBoost_Clf (F1=0.559, ACC=0.614)\n",
      "\n",
      "--- 예측 성능 요약 ---\n",
      "\n",
      "NANJI 센터:\n",
      "\n",
      "JUNGNANG 센터:\n",
      "\n",
      "SEONAM 센터:\n",
      "\n",
      "TANCHEON 센터:\n",
      "\n",
      "예측 결과 저장: complete_analysis_predictions_20250827_083856.csv\n",
      "학습 결과 저장: complete_analysis_training_20250827_083856.csv\n",
      "최고 모델 요약 저장: complete_analysis_best_models_20250827_083856.csv\n",
      "\n",
      "================================================================================\n",
      "완전 분석 완료!\n",
      "총 소요시간: 198.3초 (3.3분)\n",
      "분석된 센터: 4개\n",
      "생성된 예측: 328개\n",
      "시각화 파일들이 현재 디렉토리에 저장되었습니다.\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 선행 코드 실행 (모든 import, 모델 정의, 평가 함수들)\n",
    "# (위 코드 전체 실행)\n",
    "\n",
    "# 2. 센터별 완전 분석 파이프라인 코드 실행\n",
    "# (complete_center_analysis 아티팩트의 코드 실행)\n",
    "\n",
    "# 3. 분석 실행\n",
    "results = run_complete_analysis(cutoff_date='2025-05-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1e3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
