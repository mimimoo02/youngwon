{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94e4cb0",
   "metadata": {},
   "source": [
    "# 모델링 전략\n",
    "\n",
    "## 데이터 분할\n",
    "    1. 2025년 5월 20일 데이터까지만 train, test로 사용하여 모델 평가 등 결과내기\n",
    "    2. 2025년 5월 21일부터 31일까지 데이터를 지금은 정답을 가지고 있지만 실제는 없다고 가정하고 예측해보기(즉 합계_1일후, 등급_1일후를 실제 상황처럼 예측해보기)\n",
    "\n",
    "## 모델링 방법\n",
    "    1. 1일 후의 하수처리량을 각각 합계_1일후, 등급_1일후 컬럼을 생성\n",
    "    2. 파생변수 만드는 함수 작성 -> 이건 추후에 새로운 데이터가 들어와도 알아서 계산될 수 잇도록 해야함\n",
    "    3. 모델링은 분류, 회귀 각각에 대해 randomforest, xgboost, catboost, lightgbm, gradientboost 개씩 평가 (각각 결과를 테이블 형태로 정리하고 시각화 비교자료)\n",
    "    4. 센터별 분류, 회귀 모델별로 가장 좋은 성능을 보이는 모델에 대해(좋은 모델에 대한 기준이 있어야함) 새로운데이터가 들어와도 예측할 수 있도록 해야함\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80a9c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, platform, random, time, json, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
    ")\n",
    "\n",
    "# 선택적 라이브러리 확인\n",
    "try:\n",
    "    import xgboost as xgb; HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False; print(\"XGBoost 미설치 → 건너뜀\")\n",
    "try:\n",
    "    import lightgbm as lgb; HAS_LGB = True\n",
    "except ImportError:\n",
    "    HAS_LGB = False; print(\"LightGBM 미설치 → 건너뜀\")\n",
    "try:\n",
    "    import catboost as cb; HAS_CATBOOST = True\n",
    "except ImportError:\n",
    "    HAS_CATBOOST = False; print(\"CatBoost 미설치 → 건너뜀\")\n",
    "try:\n",
    "    import shap; HAS_SHAP = True\n",
    "except ImportError:\n",
    "    HAS_SHAP = False; print(\"SHAP 미설치 → 건너뜀\")\n",
    "\n",
    "# 경고 필터\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "\n",
    "try:\n",
    "    plt.rcParams['font.family'] = 'AppleGothic' # 맥\n",
    "except Exception:\n",
    "    plt.rcParams['font.family'] ='Malgun Gothic' # 윈도우\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e752e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 완성된 Stratified vs 시계열 분할 비교 실험 ===\n",
      "\n",
      "📁 결과 저장 구조:\n",
      "../data/results/\n",
      "├── stratified_comparison/  # 분할 방법 비교 결과\n",
      "│   ├── stratified_comparison_YYYYMMDD_HHMMSS.csv\n",
      "│   ├── stratified_summary_YYYYMMDD_HHMMSS.csv\n",
      "│   └── stratified_best_models_YYYYMMDD_HHMMSS.csv\n",
      "├── feature_importance/     # 피처 중요도 분석\n",
      "│   └── importance_센터명_모델명_YYYYMMDD_HHMMSS.csv\n",
      "├── shap_analysis/         # SHAP 분석 결과\n",
      "│   ├── shap_values_센터명_모델명_YYYYMMDD_HHMMSS.pkl\n",
      "│   └── shap_summary_센터명_모델명_YYYYMMDD_HHMMSS.csv\n",
      "├── model_performance/     # 모델 성능 상세 분석\n",
      "│   └── performance_YYYYMMDD_HHMMSS.csv\n",
      "└── visualizations/        # 생성된 그래프 이미지\n",
      "    ├── stratified_comparison_plots_YYYYMMDD_HHMMSS.png\n",
      "    ├── feature_importance_센터명_모델명_YYYYMMDD_HHMMSS.png\n",
      "    └── shap_센터명_모델명_YYYYMMDD_HHMMSS.png\n",
      "\n",
      "🚀 실행 방법:\n",
      "1. 전체 실험 (권장): \n",
      "   results_df = run_stratified_comparison()\n",
      "\n",
      "2. 단일 센터 테스트:\n",
      "   results_df = quick_stratified_test('nanji')\n",
      "\n",
      "3. 결과 분석만:\n",
      "   analyze_stratified_comparison(results_df)\n",
      "\n",
      "💡 주요 개선사항:\n",
      "- CatBoost 회귀 모델 오류 수정\n",
      "- CatBoost 분류 모델 파라미터 오류 수정\n",
      "- 체계적인 폴더 구조로 결과 저장\n",
      "- Feature Importance & SHAP 분석 결과 저장\n",
      "- 시각화 이미지 자동 저장\n",
      "- 요약 통계 및 최고 성능 모델 별도 저장\n",
      "- 모델별 상세 분석 결과 추적 가능\n",
      "\n",
      "📊 실험 구성:\n",
      "- 4개 센터 (nanji, jungnang, seonam, tancheon)\n",
      "- 2가지 분할방법 (temporal, stratified)\n",
      "- 12개 모델 (회귀 6개 + 분류 6개)\n",
      "- 총 96개 실험 (4×2×12)\n",
      "\n",
      "📈 평가 지표:\n",
      "회귀: R², MAE, RMSE, MAPE\n",
      "분류: Accuracy, Macro F1, Weighted F1, Extreme F1\n",
      "\n",
      "⚠️ 사용 전 확인사항:\n",
      "1. 데이터 준비: nanji, jungnang, seonam, tancheon 변수가 로드되어 있어야 함\n",
      "2. 필요 라이브러리: pandas, numpy, matplotlib, sklearn 등\n",
      "3. 선택 라이브러리: xgboost, lightgbm, catboost, shap\n",
      "4. 실행 권한: ../data/results/ 폴더 생성 권한 필요\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# 2. 모델 정의 함수들 (오류 수정됨)\n",
    "# ================================================================================================\n",
    "def build_regression_models():\n",
    "    \"\"\"회귀 모델들\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    models[\"RandomForest_Reg\"] = RandomForestRegressor(\n",
    "        n_estimators=300, min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    models[\"LinearRegression\"] = LinearRegression()\n",
    "    \n",
    "    models[\"GradientBoosting_Reg\"] = GradientBoostingRegressor(\n",
    "        n_estimators=200, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    if HAS_XGB:\n",
    "        models[\"XGBoost_Reg\"] = xgb.XGBRegressor(\n",
    "            n_estimators=400, max_depth=5, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models[\"LightGBM_Reg\"] = lgb.LGBMRegressor(\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbosity=-1\n",
    "        )\n",
    "    \n",
    "    # 수정: 회귀 모델로 정정\n",
    "    if HAS_CATBOOST:\n",
    "        models[\"CatBoost_Reg\"] = cb.CatBoostRegressor(\n",
    "            iterations=500, learning_rate=0.05, depth=6,\n",
    "            random_state=42, verbose=False\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "def build_classification_models():\n",
    "    \"\"\"분류 모델들 (4등급)\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    models[\"RandomForest_Clf\"] = RandomForestClassifier(\n",
    "        n_estimators=300, min_samples_leaf=2, random_state=42, \n",
    "        n_jobs=-1, class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    models[\"GradientBoosting_Clf\"] = GradientBoostingClassifier(\n",
    "        n_estimators=200, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    models[\"LogisticRegression_Clf\"] = LogisticRegression(\n",
    "        multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000,\n",
    "        random_state=42, class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    if HAS_XGB:\n",
    "        models[\"XGBoost_Clf\"] = xgb.XGBClassifier(\n",
    "            n_estimators=400, max_depth=5, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"multi:softprob\", num_class=4,\n",
    "            tree_method=\"hist\", random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models[\"LightGBM_Clf\"] = lgb.LGBMClassifier(\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"multiclass\", num_class=4,\n",
    "            random_state=42, n_jobs=-1, verbosity=-1, is_unbalance=True\n",
    "        )\n",
    "    \n",
    "    # 수정: auto_class_weights로 정정\n",
    "    if HAS_CATBOOST:\n",
    "        models[\"CatBoost_Clf\"] = cb.CatBoostClassifier(\n",
    "            iterations=500, learning_rate=0.05, depth=6,\n",
    "            random_state=42, verbose=False, auto_class_weights='Balanced'\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "# ================================================================================================\n",
    "# 3. 결과 저장 시스템 (새로 추가)\n",
    "# ================================================================================================\n",
    "def create_result_directories():\n",
    "    \"\"\"결과 저장용 디렉토리 생성\"\"\"\n",
    "    base_dir = '../data/results'\n",
    "    subdirs = [\n",
    "        'stratified_comparison',\n",
    "        'feature_importance', \n",
    "        'shap_analysis',\n",
    "        'model_performance',\n",
    "        'visualizations'\n",
    "    ]\n",
    "    \n",
    "    for subdir in [base_dir] + [os.path.join(base_dir, d) for d in subdirs]:\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "    \n",
    "    return base_dir\n",
    "\n",
    "def save_results_comprehensive(results_df, analysis_type='stratified_comparison', \n",
    "                             center_name=None, model_name=None, extra_data=None):\n",
    "    \"\"\"포괄적 결과 저장 함수\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"저장할 결과가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # 디렉토리 생성\n",
    "    base_dir = create_result_directories()\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    if analysis_type == 'stratified_comparison':\n",
    "        # 1. 전체 실험 결과\n",
    "        filename = f\"stratified_comparison_{timestamp}.csv\"\n",
    "        filepath = os.path.join(base_dir, 'stratified_comparison', filename)\n",
    "        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(filepath)\n",
    "        \n",
    "        # 2. 성공한 결과만 필터링\n",
    "        successful_results = results_df[results_df['success'] == True]\n",
    "        \n",
    "        if len(successful_results) > 0:\n",
    "            # 3. 요약 통계\n",
    "            summary_stats = create_summary_statistics(successful_results)\n",
    "            if len(summary_stats) > 0:\n",
    "                summary_filename = f\"stratified_summary_{timestamp}.csv\"\n",
    "                summary_filepath = os.path.join(base_dir, 'stratified_comparison', summary_filename)\n",
    "                summary_stats.to_csv(summary_filepath, index=False, encoding='utf-8-sig')\n",
    "                saved_files.append(summary_filepath)\n",
    "            \n",
    "            # 4. 최고 성능 모델\n",
    "            best_models = identify_best_models(successful_results)\n",
    "            if len(best_models) > 0:\n",
    "                best_filename = f\"stratified_best_models_{timestamp}.csv\"\n",
    "                best_filepath = os.path.join(base_dir, 'stratified_comparison', best_filename)\n",
    "                best_models.to_csv(best_filepath, index=False, encoding='utf-8-sig')\n",
    "                saved_files.append(best_filepath)\n",
    "    \n",
    "    elif analysis_type == 'feature_importance':\n",
    "        # 피처 중요도 저장\n",
    "        filename = f\"importance_{center_name}_{model_name}_{timestamp}.csv\"\n",
    "        filepath = os.path.join(base_dir, 'feature_importance', filename)\n",
    "        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(filepath)\n",
    "    \n",
    "    elif analysis_type == 'shap_analysis':\n",
    "        # SHAP 값 저장 (pickle)\n",
    "        if extra_data is not None and 'shap_values' in extra_data:\n",
    "            shap_filename = f\"shap_values_{center_name}_{model_name}_{timestamp}.pkl\"\n",
    "            shap_filepath = os.path.join(base_dir, 'shap_analysis', shap_filename)\n",
    "            with open(shap_filepath, 'wb') as f:\n",
    "                pickle.dump(extra_data['shap_values'], f)\n",
    "            saved_files.append(shap_filepath)\n",
    "        \n",
    "        # SHAP 요약 정보 저장 (CSV)\n",
    "        summary_filename = f\"shap_summary_{center_name}_{model_name}_{timestamp}.csv\"\n",
    "        summary_filepath = os.path.join(base_dir, 'shap_analysis', summary_filename)\n",
    "        results_df.to_csv(summary_filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(summary_filepath)\n",
    "    \n",
    "    elif analysis_type == 'model_performance':\n",
    "        filename = f\"performance_{timestamp}.csv\"\n",
    "        filepath = os.path.join(base_dir, 'model_performance', filename)\n",
    "        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(filepath)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n=== 저장 완료 ===\")\n",
    "    for file in saved_files:\n",
    "        print(f\"저장됨: {file}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "def create_summary_statistics(successful_results):\n",
    "    \"\"\"요약 통계 생성\"\"\"\n",
    "    summary_stats = []\n",
    "    \n",
    "    for model_type in ['regression', 'classification']:\n",
    "        type_data = successful_results[successful_results['type'] == model_type]\n",
    "        if len(type_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        if model_type == 'regression':\n",
    "            metrics = ['r2', 'mae', 'rmse', 'mape']\n",
    "        else:\n",
    "            metrics = ['accuracy', 'macro_f1', 'weighted_f1', 'extreme_f1']\n",
    "        \n",
    "        for metric in metrics:\n",
    "            if metric in type_data.columns:\n",
    "                # 모델별, 분할방법별 평균/표준편차\n",
    "                grouped = type_data.groupby(['model', 'split_method'])[metric].agg(['mean', 'std', 'count']).round(4)\n",
    "                grouped = grouped.reset_index()\n",
    "                grouped['metric'] = metric\n",
    "                grouped['type'] = model_type\n",
    "                summary_stats.append(grouped)\n",
    "    \n",
    "    if summary_stats:\n",
    "        return pd.concat(summary_stats, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def identify_best_models(successful_results):\n",
    "    \"\"\"센터별, 타입별 최고 성능 모델 식별\"\"\"\n",
    "    best_models = []\n",
    "    \n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        # 회귀 최고 성능 (R² 기준)\n",
    "        reg_data = center_data[center_data['type'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            best_reg_idx = reg_data['r2'].idxmax()\n",
    "            best_reg = reg_data.loc[best_reg_idx].copy()\n",
    "            best_reg['rank_type'] = 'regression_best'\n",
    "            best_models.append(best_reg)\n",
    "        \n",
    "        # 분류 최고 성능 (Macro F1 기준)\n",
    "        clf_data = center_data[center_data['type'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            best_clf_idx = clf_data['macro_f1'].idxmax()\n",
    "            best_clf = clf_data.loc[best_clf_idx].copy()\n",
    "            best_clf['rank_type'] = 'classification_best'\n",
    "            best_models.append(best_clf)\n",
    "    \n",
    "    if best_models:\n",
    "        return pd.DataFrame(best_models)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_visualization(fig, filename):\n",
    "    \"\"\"시각화 결과 저장\"\"\"\n",
    "    base_dir = create_result_directories()\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    filepath = os.path.join(base_dir, 'visualizations', f\"{filename}_{timestamp}.png\")\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    print(f\"시각화 저장: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def create_performance_comparison_data(successful_results):\n",
    "    \"\"\"성능 비교 데이터 생성\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    # 센터별 성능 비교\n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        for split_method in center_data['split_method'].unique():\n",
    "            method_data = center_data[center_data['split_method'] == split_method]\n",
    "            \n",
    "            # 회귀 평균 성능\n",
    "            reg_data = method_data[method_data['type'] == 'regression']\n",
    "            if len(reg_data) > 0:\n",
    "                comparison_data.append({\n",
    "                    'center': center,\n",
    "                    'split_method': split_method,\n",
    "                    'type': 'regression',\n",
    "                    'avg_r2': reg_data['r2'].mean(),\n",
    "                    'std_r2': reg_data['r2'].std(),\n",
    "                    'avg_mae': reg_data['mae'].mean(),\n",
    "                    'model_count': len(reg_data)\n",
    "                })\n",
    "            \n",
    "            # 분류 평균 성능\n",
    "            clf_data = method_data[method_data['type'] == 'classification']\n",
    "            if len(clf_data) > 0:\n",
    "                comparison_data.append({\n",
    "                    'center': center,\n",
    "                    'split_method': split_method,\n",
    "                    'type': 'classification',\n",
    "                    'avg_accuracy': clf_data['accuracy'].mean(),\n",
    "                    'std_accuracy': clf_data['accuracy'].std(),\n",
    "                    'avg_macro_f1': clf_data['macro_f1'].mean(),\n",
    "                    'std_macro_f1': clf_data['macro_f1'].std(),\n",
    "                    'avg_extreme_f1': clf_data['extreme_f1'].mean(),\n",
    "                    'model_count': len(clf_data)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "# ================================================================================================\n",
    "# 4. Feature Importance & SHAP 분석 함수들\n",
    "# ================================================================================================\n",
    "def extract_feature_importance(model, model_name, feature_names):\n",
    "    \"\"\"모델별 Feature Importance 추출\"\"\"\n",
    "    try:\n",
    "        mdl = model.named_steps['model']\n",
    "        if hasattr(mdl, 'feature_importances_'):\n",
    "            importance = mdl.feature_importances_\n",
    "        elif hasattr(mdl, 'coef_'):\n",
    "            coef = mdl.coef_\n",
    "            # (n_features,) 또는 (n_classes, n_features) 모두 대응\n",
    "            if isinstance(coef, np.ndarray) and coef.ndim == 2:\n",
    "                importance = np.mean(np.abs(coef), axis=0)   # 클래스 평균\n",
    "            else:\n",
    "                importance = np.abs(coef)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # 길이 안전가드\n",
    "        if len(importance) != len(feature_names):\n",
    "            print(f\"[경고] importance 길이({len(importance)}) != feature_names({len(feature_names)}). \"\n",
    "                  \"가능한 경우에만 앞쪽 피처로 맞춰서 반환합니다.\")\n",
    "            m = min(len(importance), len(feature_names))\n",
    "            importance = np.asarray(importance)[:m]\n",
    "            feature_names = list(feature_names)[:m]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        return importance_df\n",
    "    except Exception as e:\n",
    "        print(f\"Feature importance 추출 실패 ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_feature_importance(importance_df, model_name, top_n=15):\n",
    "    \"\"\"Feature Importance 시각화 (fig 객체 리턴)\"\"\"\n",
    "    # plot_feature_importance 자체가 새 figure를 생성하고 plt.show() 해버리기 때문에, fig는 사실상 빈 도화지예요. 그래서 저장하면 빈 그림이 찍히는 거죠.\n",
    "    # 빈그림이 저장되어서 코드 수정한게 아래임\n",
    "    if importance_df is None or len(importance_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_features = importance_df.head(top_n)\n",
    "    \n",
    "    ax.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['feature'])\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title(f'{model_name} - Top {top_n} Feature Importance')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # 값 표시\n",
    "    for i, v in enumerate(top_features['importance']):\n",
    "        ax.text(v + 0.001, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig   # ← 여기서 figure 객체 반환\n",
    "\n",
    "\n",
    "def analyze_model_with_shap(model, X_test, feature_names, model_name, max_samples=100):\n",
    "    \"\"\"SHAP 분석\"\"\"\n",
    "    if not HAS_SHAP:\n",
    "        print(\"SHAP 라이브러리가 설치되지 않았습니다.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # 샘플 수 제한 (SHAP 계산 시간 단축)\n",
    "        if len(X_test) > max_samples:\n",
    "            sample_idx = np.random.choice(len(X_test), max_samples, replace=False)\n",
    "            X_sample = X_test.iloc[sample_idx]\n",
    "        else:\n",
    "            X_sample = X_test\n",
    "        \n",
    "        # 전처리된 데이터 얻기\n",
    "        X_processed = model.named_steps['pre'].transform(X_sample)\n",
    "        \n",
    "        # 모델별 SHAP Explainer 선택\n",
    "        if 'RandomForest' in model_name or 'GradientBoosting' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'XGBoost' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'LightGBM' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'CatBoost' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        else:\n",
    "            # Linear models\n",
    "            explainer = shap.LinearExplainer(model.named_steps['model'], X_processed)\n",
    "        \n",
    "        # SHAP values 계산\n",
    "        shap_values = explainer.shap_values(X_processed)\n",
    "        \n",
    "        # 다중 클래스의 경우 첫 번째 클래스만 사용\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[0]\n",
    "        \n",
    "        return shap_values, X_processed, explainer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP 분석 실패 ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_shap_summary(shap_values, X_processed, feature_names, model_name):\n",
    "    \"\"\"SHAP Summary Plot을 만들고 figure 목록을 반환 -> 빈그림 저장 방지\"\"\"\n",
    "    if shap_values is None or not HAS_SHAP:\n",
    "        return []\n",
    "\n",
    "    figs = []\n",
    "    try:\n",
    "        # (1) Bar plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_processed,\n",
    "                          feature_names=feature_names,\n",
    "                          plot_type=\"bar\", show=False)\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(f'{model_name} - SHAP Feature Importance')\n",
    "        figs.append(plt.gcf())\n",
    "\n",
    "        # (2) Beeswarm plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_processed,\n",
    "                          feature_names=feature_names,\n",
    "                          show=False)\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(f'{model_name} - SHAP Summary Plot')\n",
    "        figs.append(plt.gcf())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP 시각화 실패 ({model_name}): {e}\")\n",
    "\n",
    "    return figs\n",
    "\n",
    "def comprehensive_model_analysis_with_save(model, model_name, X_train, X_test, y_train, y_test, \n",
    "                                         feature_names, model_type, center_name=None):\n",
    "    \"\"\"종합적인 모델 분석 (Feature Importance + SHAP) + 저장\"\"\"\n",
    "    print(f\"\\n--- {model_name} 상세 분석 ---\")\n",
    "    \n",
    "    # 1. Feature Importance 추출 및 시각화\n",
    "    importance_df = extract_feature_importance(model, model_name, feature_names)\n",
    "    if importance_df is not None:\n",
    "        print(f\"Top 10 중요 피처:\")\n",
    "        print(importance_df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Feature Importance 저장\n",
    "        if center_name:\n",
    "            save_results_comprehensive(\n",
    "                importance_df, \n",
    "                analysis_type='feature_importance',\n",
    "                center_name=center_name,\n",
    "                model_name=model_name\n",
    "            )\n",
    "        \n",
    "        # 시각화\n",
    "        fig = plot_feature_importance(importance_df, model_name)\n",
    "        if fig is not None:\n",
    "            fig.show()  # 화면에 띄우고\n",
    "            if center_name:\n",
    "                save_visualization(fig, f\"feature_importance_{center_name}_{model_name}\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    \n",
    "    # 2. SHAP 분석\n",
    "    shap_result = analyze_model_with_shap(model, X_test, feature_names, model_name)\n",
    "    if shap_result is not None:\n",
    "        shap_values, X_processed, explainer = shap_result\n",
    "\n",
    "        # SHAP 요약 통계 저장\n",
    "        if isinstance(shap_values, np.ndarray):\n",
    "            mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "            shap_summary_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'mean_abs_shap': mean_abs_shap\n",
    "            }).sort_values('mean_abs_shap', ascending=False)\n",
    "            if center_name:\n",
    "                extra_data = {'shap_values': shap_values, 'X_processed': X_processed}\n",
    "                save_results_comprehensive(\n",
    "                    shap_summary_df,\n",
    "                    analysis_type='shap_analysis',\n",
    "                    center_name=center_name,\n",
    "                    model_name=model_name,\n",
    "                    extra_data=extra_data\n",
    "                )\n",
    "\n",
    "        # SHAP 플롯 생성(리턴받음)\n",
    "        shap_figs = plot_shap_summary(shap_values, X_processed, feature_names, model_name)\n",
    "        if shap_figs:\n",
    "            for i, fig in enumerate(shap_figs):\n",
    "                fig.show()  # 또는 plt.show()\n",
    "                if center_name:\n",
    "                    suffix = \"shap_bar\" if i == 0 else \"shap_beeswarm\"\n",
    "                    save_visualization(fig, f\"{suffix}_{center_name}_{model_name}\")\n",
    "                plt.close(fig)  # 메모리 정리\n",
    "\n",
    "    \n",
    "    return importance_df, shap_result\n",
    "\n",
    "# ================================================================================================\n",
    "# 5. 데이터 처리 및 평가 함수들\n",
    "# ================================================================================================\n",
    "def make_pipeline_unified(model, model_name, model_type):\n",
    "    \"\"\"통합 전처리 파이프라인\"\"\"\n",
    "    if model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"]:\n",
    "        # 선형 모델은 정규화 필요\n",
    "        pre = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ])\n",
    "    else:\n",
    "        # 트리 기반 모델들은 정규화 불필요\n",
    "        pre = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ])\n",
    "    return Pipeline(steps=[(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "def prepare_data_stratified(df, target_col, model_type, test_size=0.2, split_method='stratified'):\n",
    "    \"\"\"\n",
    "    데이터 준비 - Stratified vs 시계열 분할 선택 가능\n",
    "    \n",
    "    Parameters:\n",
    "    - split_method: 'stratified' 또는 'temporal'\n",
    "    \"\"\"\n",
    "    work = df.sort_values('날짜').reset_index(drop=True).copy()\n",
    "    dates = pd.to_datetime(work['날짜'])\n",
    "\n",
    "    # 제외할 컬럼들\n",
    "    not_use_col = [\n",
    "        '날짜',\n",
    "        '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "        '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "        '등급','등급_1일후','등급_2일후'\n",
    "    ]\n",
    "    \n",
    "    drop_cols = [c for c in (set(not_use_col) | {target_col}) if c in work.columns]\n",
    "    X_raw = work.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    \n",
    "    # 수치형 변환\n",
    "    for c in X_raw.columns:\n",
    "        X_raw[c] = pd.to_numeric(X_raw[c], errors=\"coerce\")\n",
    "\n",
    "    if model_type == \"regression\":\n",
    "        y = pd.to_numeric(work[target_col], errors=\"coerce\")\n",
    "    else:  # classification\n",
    "        y = work[target_col].astype(\"int64\")\n",
    "\n",
    "    # 결측치 제거\n",
    "    valid_idx = (~X_raw.isnull().all(axis=1)) & (~pd.isnull(y))\n",
    "    X_raw = X_raw[valid_idx].reset_index(drop=True)\n",
    "    y = y[valid_idx].reset_index(drop=True)\n",
    "    dates = dates[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    if split_method == 'stratified':\n",
    "        # Stratified 분할 (분류에만 적용, 회귀는 일반 random split)\n",
    "        if model_type == \"classification\":\n",
    "            # 등급별 균등 분할\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "            train_idx, test_idx = next(sss.split(X_raw, y))\n",
    "        else:\n",
    "            # 회귀는 일반 랜덤 분할 (연속값이므로 stratify 불가)\n",
    "            train_idx, test_idx = train_test_split(\n",
    "                range(len(X_raw)), test_size=test_size, random_state=42\n",
    "            )\n",
    "            \n",
    "        X_train, X_test = X_raw.iloc[train_idx].copy(), X_raw.iloc[test_idx].copy()\n",
    "        y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "        dates_train, dates_test = dates.iloc[train_idx].copy(), dates.iloc[test_idx].copy()\n",
    "        \n",
    "    else:  # temporal split\n",
    "        # 기존 시계열 분할\n",
    "        n = len(X_raw) # len(work)\n",
    "        split = int(n * (1 - test_size))\n",
    "        X_train, X_test = X_raw.iloc[:split].copy(), X_raw.iloc[split:].copy()\n",
    "        y_train, y_test = y.iloc[:split].copy(), y.iloc[split:].copy()\n",
    "        dates_train, dates_test = dates.iloc[:split].copy(), dates.iloc[split:].copy()\n",
    "\n",
    "    feature_names = list(X_raw.columns)\n",
    "    return X_train, X_test, y_train, y_test, feature_names, dates_train, dates_test\n",
    "\n",
    "def evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"회귀 모델 평가 (수정됨)\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"regression\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # MAPE (Mean Absolute Percentage Error)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "        \n",
    "        # 올바른 return 문\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': mae,         # ← 계산된 값 사용\n",
    "            'rmse': rmse,       # ← 계산된 값 사용\n",
    "            'r2': r2,           # ← 계산된 값 사용\n",
    "            'mape': mape,       # ← 계산된 값 사용\n",
    "            'success': True     # ← 성공 시 True\n",
    "        }, pipe, y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 실패 시에만 이 부분 실행\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': np.nan,\n",
    "            'rmse': np.nan,\n",
    "            'r2': np.nan,\n",
    "            'mape': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None\n",
    "        \n",
    "def evaluate_classification_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"분류 모델 평가\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"classification\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # 차원 문제 해결\n",
    "        if isinstance(y_pred, np.ndarray) and y_pred.ndim > 1:\n",
    "            y_pred = y_pred.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        # 극값 분류 성능 (등급 0, 3로 수정: 0-base 변환 때문에)\n",
    "        extreme_classes = [0, 3]  # 원래 1,4가 0,3으로 변환됨\n",
    "        y_true_extreme = pd.Series(y_test).isin(extreme_classes).astype(int)\n",
    "        y_pred_extreme = pd.Series(y_pred).isin(extreme_classes).astype(int)\n",
    "        extreme_f1 = f1_score(y_true_extreme, y_pred_extreme, zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1_macro,\n",
    "            'weighted_f1': f1_weighted,\n",
    "            'extreme_f1': extreme_f1,\n",
    "            'success': True\n",
    "        }, pipe, y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': np.nan,\n",
    "            'macro_f1': np.nan,\n",
    "            'weighted_f1': np.nan,\n",
    "            'extreme_f1': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None\n",
    "\n",
    "def comprehensive_evaluation_comparison(center_name, df):\n",
    "    \"\"\"Stratified vs 시계열 분할 비교 평가\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"센터: {center_name} - Stratified vs 시계열 분할 비교\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # 데이터 확인\n",
    "    print(f\"데이터 크기: {len(df)}행, {len(df.columns)}컬럼\")\n",
    "    \n",
    "    # 등급 분포 확인\n",
    "    if '등급_1일후' in df.columns:\n",
    "        grade_dist = df['등급_1일후'].value_counts().sort_index()\n",
    "        print(f\"등급 분포: {dict(grade_dist)}\")\n",
    "        \n",
    "        # 불균형 정도 확인\n",
    "        min_class = grade_dist.min()\n",
    "        max_class = grade_dist.max()\n",
    "        imbalance_ratio = max_class / min_class\n",
    "        print(f\"클래스 불균형 비율: {imbalance_ratio:.1f}:1 (최대:{max_class}, 최소:{min_class})\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # 두 가지 분할 방법 비교\n",
    "    for split_method in ['temporal', 'stratified']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"분할 방법: {split_method.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # =========================\n",
    "        # 1. 회귀 모델 평가\n",
    "        # =========================\n",
    "        reg_method_name = \"random_shuffle\" if split_method == \"stratified\" else split_method\n",
    "        print(f\"\\n--- 회귀 모델 평가 ({reg_method_name}) ---\")\n",
    "        \n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test, feature_names, dates_train, dates_test = prepare_data_stratified(\n",
    "                df, target_col=\"합계_1일후\", model_type=\"regression\", test_size=0.2, split_method=split_method\n",
    "            )\n",
    "            \n",
    "            print(f\"회귀용 데이터: 학습 {len(X_train)}행, 테스트 {len(X_test)}행\")\n",
    "            \n",
    "            regression_models = build_regression_models()\n",
    "            \n",
    "            for model_name, model in tqdm(regression_models.items(), desc=f\"회귀({reg_method_name})\", leave=False):\n",
    "                result, pipe, y_pred = evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test)\n",
    "                result['center'] = center_name\n",
    "                result['split_method'] = split_method\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    print(f\"  {model_name:18s}: R²={result['r2']:.3f}, MAE={result['mae']:.0f}, MAPE={result['mape']:.1f}%\")\n",
    "                else:\n",
    "                    print(f\"  {model_name:18s}: 실패 - {result.get('error', '')[:50]}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"회귀 모델 평가 실패 ({reg_method_name}): {e}\")\n",
    "        \n",
    "        # =========================\n",
    "        # 2. 분류 모델 평가\n",
    "        # =========================\n",
    "        print(f\"\\n--- 분류 모델 평가 ({split_method}) ---\")\n",
    "        \n",
    "        try:\n",
    "            X_train_clf, X_test_clf, y_train_clf, y_test_clf, feature_names_clf, _, _ = prepare_data_stratified(\n",
    "                df, target_col=\"등급_1일후\", model_type=\"classification\", test_size=0.2, split_method=split_method\n",
    "            )\n",
    "            \n",
    "            print(f\"분류용 데이터: 학습 {len(X_train_clf)}행, 테스트 {len(X_test_clf)}행\")\n",
    "            \n",
    "            # 테스트 세트 등급 분포 확인\n",
    "            test_dist = pd.Series(y_test_clf).value_counts().sort_index()\n",
    "            train_dist = pd.Series(y_train_clf).value_counts().sort_index()\n",
    "            print(f\"학습 세트 등급 분포: {dict(train_dist)}\")\n",
    "            print(f\"테스트 세트 등급 분포: {dict(test_dist)}\")\n",
    "            \n",
    "            classification_models = build_classification_models()\n",
    "            \n",
    "            for model_name, model in tqdm(classification_models.items(), desc=f\"분류({split_method})\", leave=False):\n",
    "                result, pipe, y_pred = evaluate_classification_model(model, model_name, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "                result['center'] = center_name\n",
    "                result['split_method'] = split_method\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    print(f\"  {model_name:18s}: ACC={result['accuracy']:.3f}, F1={result['macro_f1']:.3f}, 극값F1={result['extreme_f1']:.3f}\")\n",
    "                else:\n",
    "                    print(f\"  {model_name:18s}: 실패 - {result.get('error', '')[:50]}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"분류 모델 평가 실패 ({split_method}): {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# 6. 시각화 함수들\n",
    "# ================================================================================================\n",
    "def plot_stratified_comparison(results_df):\n",
    "    \"\"\"비교 결과 시각화\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"시각화할 결과가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # successful_results가 results_df 안에 있어야 함\n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    if len(successful_results) == 0:\n",
    "        print(\"성공한 결과가 없어 시각화를 생략합니다.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Stratified vs 시계열 분할 비교', fontsize=16)\n",
    "    \n",
    "    # 1. 회귀 모델 R² 비교\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        reg_pivot = reg_results.pivot_table(\n",
    "            index='model', columns='split_method', values='r2', aggfunc='mean'\n",
    "        )\n",
    "        reg_pivot = reg_pivot.rename(columns={'stratified': 'random_shuffle'})\n",
    "        reg_pivot.plot(kind='bar', ax=axes[0,0], color=['lightblue', 'orange'])\n",
    "        axes[0,0].set_title('회귀 모델 R² 성능 비교')\n",
    "        axes[0,0].set_ylabel('R² Score')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        axes[0,0].legend(title='Split Method')\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "    \n",
    "    # 2. 분류 모델 F1 비교\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        clf_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='macro_f1', aggfunc='mean'\n",
    "        )\n",
    "        clf_pivot.plot(kind='bar', ax=axes[0,1], color=['lightgreen', 'red'])\n",
    "        axes[0,1].set_title('분류 모델 Macro F1 성능 비교')\n",
    "        axes[0,1].set_ylabel('Macro F1 Score')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        axes[0,1].legend(title='Split Method')\n",
    "        axes[0,1].set_ylim(0, 1)\n",
    "    \n",
    "    # 3. 센터별 회귀 성능\n",
    "    if len(reg_results) > 0:\n",
    "        center_reg = reg_results.groupby(['center', 'split_method'])['r2'].mean().unstack()\n",
    "        center_reg = center_reg.rename(columns={'stratified': 'random_shuffle'})\n",
    "        center_reg.plot(kind='bar', ax=axes[1,0], color=['lightblue', 'orange'])\n",
    "        axes[1,0].set_title('센터별 회귀 평균 성능')\n",
    "        axes[1,0].set_ylabel('평균 R² Score')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        axes[1,0].legend(title='Split Method')\n",
    "    \n",
    "    # 4. 센터별 분류 성능\n",
    "    if len(clf_results) > 0:\n",
    "        center_clf = clf_results.groupby(['center', 'split_method'])['macro_f1'].mean().unstack()\n",
    "        center_clf.plot(kind='bar', ax=axes[1,1], color=['lightgreen', 'red'])\n",
    "        axes[1,1].set_title('센터별 분류 평균 성능')\n",
    "        axes[1,1].set_ylabel('평균 Macro F1 Score')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        axes[1,1].legend(title='Split Method')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 시각화 저장\n",
    "    save_visualization(fig, \"stratified_comparison_plots\")\n",
    "\n",
    "def plot_model_performance_comparison(results_df):\n",
    "    \"\"\"모델별 성능 상세 비교 시각화\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        return\n",
    "        \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    # 1. 모든 모델 성능 한눈에 보기\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('모델별 성능 상세 비교', fontsize=16)\n",
    "    \n",
    "    # 1-1. 회귀 모델 R² (분할 방법별)\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        reg_pivot = reg_results.pivot_table(\n",
    "            index='model', columns='split_method', values='r2', aggfunc='mean'\n",
    "        )\n",
    "        reg_pivot.plot(kind='bar', ax=axes[0,0], color=['lightblue', 'orange'])\n",
    "        axes[0,0].set_title('회귀 모델 R² 성능')\n",
    "        axes[0,0].set_ylabel('R² Score')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        axes[0,0].legend(title='Split Method')\n",
    "    \n",
    "    # 1-2. 분류 모델 Macro F1 (분할 방법별)\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        clf_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='macro_f1', aggfunc='mean'\n",
    "        )\n",
    "        clf_pivot.plot(kind='bar', ax=axes[0,1], color=['lightgreen', 'red'])\n",
    "        axes[0,1].set_title('분류 모델 Macro F1 성능')\n",
    "        axes[0,1].set_ylabel('Macro F1 Score')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        axes[0,1].legend(title='Split Method')\n",
    "    \n",
    "    # 1-3. 분류 모델 Extreme F1 성능\n",
    "    if len(clf_results) > 0:\n",
    "        extreme_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='extreme_f1', aggfunc='mean'\n",
    "        )\n",
    "        extreme_pivot.plot(kind='bar', ax=axes[0,2], color=['lightcoral', 'gold'])\n",
    "        axes[0,2].set_title('분류 모델 Extreme F1 성능')\n",
    "        axes[0,2].set_ylabel('Extreme F1 Score')\n",
    "        axes[0,2].tick_params(axis='x', rotation=45)\n",
    "        axes[0,2].legend(title='Split Method')\n",
    "    \n",
    "    # 2-1. 회귀 모델 MAE 성능\n",
    "    if len(reg_results) > 0:\n",
    "        mae_pivot = reg_results.pivot_table(\n",
    "            index='model', columns='split_method', values='mae', aggfunc='mean'\n",
    "        )\n",
    "        mae_pivot.plot(kind='bar', ax=axes[1,0], color=['lightsteelblue', 'sandybrown'])\n",
    "        axes[1,0].set_title('회귀 모델 MAE 성능 (낮을수록 좋음)')\n",
    "        axes[1,0].set_ylabel('Mean Absolute Error')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        axes[1,0].legend(title='Split Method')\n",
    "    \n",
    "    # 2-2. 분류 모델 Accuracy\n",
    "    if len(clf_results) > 0:\n",
    "        acc_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='accuracy', aggfunc='mean'\n",
    "        )\n",
    "        acc_pivot.plot(kind='bar', ax=axes[1,1], color=['mediumseagreen', 'indianred'])\n",
    "        axes[1,1].set_title('분류 모델 Accuracy 성능')\n",
    "        axes[1,1].set_ylabel('Accuracy Score')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        axes[1,1].legend(title='Split Method')\n",
    "    \n",
    "    # 2-3. 센터별 최고 성능 모델\n",
    "    plot_best_models_per_center(successful_results, axes[1,2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 시각화 저장\n",
    "    save_visualization(fig, \"model_performance_comparison\")\n",
    "\n",
    "def plot_best_models_per_center(results_df, ax):\n",
    "    \"\"\"센터별 최고 성능 모델 표시\"\"\"\n",
    "    centers = results_df['center'].unique()\n",
    "    reg_best = []\n",
    "    clf_best = []\n",
    "    \n",
    "    for center in centers:\n",
    "        center_data = results_df[results_df['center'] == center]\n",
    "        \n",
    "        # 회귀 최고 성능\n",
    "        reg_data = center_data[center_data['type'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            best_reg_idx = reg_data['r2'].idxmax()\n",
    "            reg_best.append(reg_data.loc[best_reg_idx, 'r2'])\n",
    "        else:\n",
    "            reg_best.append(0)\n",
    "        \n",
    "        # 분류 최고 성능\n",
    "        clf_data = center_data[center_data['type'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            best_clf_idx = clf_data['macro_f1'].idxmax()\n",
    "            clf_best.append(clf_data.loc[best_clf_idx, 'macro_f1'])\n",
    "        else:\n",
    "            clf_best.append(0)\n",
    "    \n",
    "    x = np.arange(len(centers))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, reg_best, width, label='회귀 R²', color='skyblue')\n",
    "    ax.bar(x + width/2, clf_best, width, label='분류 F1', color='lightcoral')\n",
    "    \n",
    "    ax.set_xlabel('센터')\n",
    "    ax.set_ylabel('성능 점수')\n",
    "    ax.set_title('센터별 최고 성능')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(centers)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # 값 표시\n",
    "    for i, (r, c) in enumerate(zip(reg_best, clf_best)):\n",
    "        if r > 0:\n",
    "            ax.text(i - width/2, r + 0.01, f'{r:.3f}', ha='center', va='bottom')\n",
    "        if c > 0:\n",
    "            ax.text(i + width/2, c + 0.01, f'{c:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# ================================================================================================\n",
    "# 7. 분석 함수들\n",
    "# ================================================================================================\n",
    "def analyze_stratified_comparison(results_df):\n",
    "    \"\"\"Stratified vs 시계열 비교 분석\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== Stratified vs 시계열 분할 비교 분석 ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    # 분할 방법별 성능 비교\n",
    "    for task_type in ['regression', 'classification']:\n",
    "        print(f\"\\n--- {task_type.upper()} 모델 비교 ---\")\n",
    "        \n",
    "        task_results = successful_results[successful_results['type'] == task_type]\n",
    "        if len(task_results) == 0:\n",
    "            continue\n",
    "            \n",
    "        if task_type == 'regression':\n",
    "            metric = 'r2'\n",
    "            metric_name = 'R²'\n",
    "        else:\n",
    "            metric = 'macro_f1'  \n",
    "            metric_name = 'Macro F1'\n",
    "        \n",
    "        # 분할 방법별 평균 성능\n",
    "        split_performance = task_results.groupby('split_method')[metric].agg(['mean', 'std', 'count'])\n",
    "        \n",
    "        for split_method in split_performance.index:\n",
    "            mean_val = split_performance.loc[split_method, 'mean']\n",
    "            std_val = split_performance.loc[split_method, 'std']\n",
    "            count_val = split_performance.loc[split_method, 'count']\n",
    "            method_display = \"random_shuffle\" if split_method == \"stratified\" and task_type == \"regression\" else split_method\n",
    "            print(f\"  {method_display:13s}: {metric_name}={mean_val:.3f} ± {std_val:.3f} ({count_val}개)\")\n",
    "        \n",
    "        # 모델별 비교\n",
    "        print(f\"\\n  모델별 {metric_name} 비교:\")\n",
    "        model_comparison = task_results.pivot_table(\n",
    "            index='model', columns='split_method', values=metric, aggfunc='mean'\n",
    "        ).round(3)\n",
    "        \n",
    "        print(model_comparison.to_string())\n",
    "        \n",
    "        # 개선 정도 분석 (stratified가 temporal보다 좋은 경우)\n",
    "        if 'temporal' in model_comparison.columns and 'stratified' in model_comparison.columns:\n",
    "            improvement = model_comparison['stratified'] - model_comparison['temporal']\n",
    "            improvement_name = \"Random Shuffle 개선 정도\" if task_type == \"regression\" else \"Stratified 개선 정도\"\n",
    "            print(f\"\\n  {improvement_name} ({metric_name}):\")\n",
    "            for model in improvement.index:\n",
    "                imp_val = improvement[model]\n",
    "                if not pd.isna(imp_val):\n",
    "                    symbol = \"↑\" if imp_val > 0 else \"↓\" if imp_val < 0 else \"=\"\n",
    "                    print(f\"    {model:18s}: {imp_val:+.3f} {symbol}\")\n",
    "    \n",
    "    # 센터별 분할 방법 효과\n",
    "    print(f\"\\n--- 센터별 분할 방법 효과 ---\")\n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        reg_data = center_data[center_data['type'] == 'regression']\n",
    "        clf_data = center_data[center_data['type'] == 'classification']\n",
    "        \n",
    "        print(f\"\\n  {center.upper()} 센터:\")\n",
    "        \n",
    "        # 회귀 성능\n",
    "        if len(reg_data) > 0:\n",
    "            reg_perf = reg_data.groupby('split_method')['r2'].mean()\n",
    "            for method in reg_perf.index:\n",
    "                method_display = \"random_shuffle\" if method == \"stratified\" else method\n",
    "                print(f\"    회귀 R² ({method_display:13s}): {reg_perf[method]:.3f}\")\n",
    "        \n",
    "        # 분류 성능  \n",
    "        if len(clf_data) > 0:\n",
    "            clf_perf = clf_data.groupby('split_method')['macro_f1'].mean()\n",
    "            for method in clf_perf.index:\n",
    "                print(f\"    분류 F1 ({method:13s}): {clf_perf[method]:.3f}\")\n",
    "    \n",
    "    # 기본 시각화\n",
    "    plot_stratified_comparison(successful_results)\n",
    "    \n",
    "    # 상세 모델 성능 비교\n",
    "    plot_model_performance_comparison(successful_results)\n",
    "\n",
    "def perform_detailed_analysis_with_save(results_df, centers):\n",
    "    \"\"\"최고 성능 모델에 대한 상세 분석 (저장 기능 포함)\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== 최고 성능 모델 상세 분석 ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    # 최고 성능 모델 찾기\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    \n",
    "    analyzed_models = []\n",
    "    \n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"\\n최고 회귀 성능: {best_reg['center']} - {best_reg['model']} ({best_reg['split_method']}) R²={best_reg['r2']:.3f}\")\n",
    "        \n",
    "        # 최고 성능 모델 재학습 및 분석\n",
    "        model_info = analyze_best_model_with_save(best_reg, centers, 'regression')\n",
    "        if model_info:\n",
    "            analyzed_models.append(model_info)\n",
    "    \n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"\\n최고 분류 성능: {best_clf['center']} - {best_clf['model']} ({best_clf['split_method']}) F1={best_clf['macro_f1']:.3f}\")\n",
    "        \n",
    "        # 최고 성능 모델 재학습 및 분석\n",
    "        model_info = analyze_best_model_with_save(best_clf, centers, 'classification')\n",
    "        if model_info:\n",
    "            analyzed_models.append(model_info)\n",
    "    \n",
    "    return analyzed_models\n",
    "\n",
    "def analyze_best_model_with_save(best_result, centers, model_type):\n",
    "    \"\"\"최고 성능 모델 상세 분석 (저장 기능 포함)\"\"\"\n",
    "    center_name = best_result['center']\n",
    "    model_name = best_result['model']\n",
    "    split_method = best_result['split_method']\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"모델 재학습 및 분석: {center_name} - {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # 데이터 준비\n",
    "        df = centers[center_name]\n",
    "        target_col = \"합계_1일후\" if model_type == \"regression\" else \"등급_1일후\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            df, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.2, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # 모델 재구축 및 학습\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "            \n",
    "        model = models[model_name]\n",
    "        pipe = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # 상세 분석 수행 (저장 포함)\n",
    "        importance_df, shap_result = comprehensive_model_analysis_with_save(\n",
    "            pipe, model_name, X_train, X_test, y_train, y_test, \n",
    "            feature_names, model_type, center_name\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'center': center_name,\n",
    "            'model': model_name,\n",
    "            'type': model_type,\n",
    "            'split_method': split_method,\n",
    "            'performance': best_result,\n",
    "            'analysis_completed': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"상세 분석 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# ================================================================================================\n",
    "# 8. 메인 실행 함수들 (개선된 버전)\n",
    "# ================================================================================================\n",
    "def run_stratified_comparison():\n",
    "    \"\"\"전체 센터 Stratified vs 시계열 비교 (개선된 저장 기능)\"\"\"\n",
    "    print(\"=== Stratified vs 시계열 분할 비교 실험 ===\")\n",
    "    \n",
    "    # 데이터 로드 확인\n",
    "    try:\n",
    "        centers = {\n",
    "            \"nanji\": nanji,\n",
    "            \"jungnang\": jungnang,  \n",
    "            \"seonam\": seonam,\n",
    "            \"tancheon\": tancheon\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n데이터 확인:\")\n",
    "        for name, df in centers.items():\n",
    "            print(f\"  {name}: {len(df)}행\")\n",
    "    \n",
    "    except NameError:\n",
    "        print(\"데이터가 로드되지 않았습니다. 먼저 make_features를 실행하세요.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 전체 실험 실행\n",
    "    all_results = []\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        try:\n",
    "            center_results = comprehensive_evaluation_comparison(center_name, df)\n",
    "            all_results.extend(center_results)\n",
    "        except Exception as e:\n",
    "            print(f\"[{center_name}] 실험 실패: {e}\")\n",
    "    \n",
    "    # 결과 분석\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # 분석 및 시각화\n",
    "        analyze_stratified_comparison(results_df)\n",
    "        \n",
    "        # 최고 성능 모델 식별 및 상세 분석\n",
    "        perform_detailed_analysis_with_save(results_df, centers)\n",
    "        \n",
    "        # 포괄적 결과 저장\n",
    "        saved_files = save_results_comprehensive(results_df, 'stratified_comparison')\n",
    "        \n",
    "        # 모델 성능 비교 데이터도 별도 저장\n",
    "        successful_results = results_df[results_df['success'] == True]\n",
    "        if len(successful_results) > 0:\n",
    "            performance_comparison = create_performance_comparison_data(successful_results)\n",
    "            save_results_comprehensive(\n",
    "                performance_comparison, \n",
    "                'model_performance'\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n=== 실험 완료 ===\")\n",
    "        print(f\"총 {len(results_df)}개 실험 중 {len(successful_results)}개 성공\")\n",
    "        print(f\"결과 저장 위치: ../data/results/\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def quick_stratified_test(center_name=\"nanji\"):\n",
    "    \"\"\"단일 센터 Stratified 테스트\"\"\"\n",
    "    print(f\"=== {center_name} 센터 Stratified vs 시계열 비교 ===\")\n",
    "    \n",
    "    try:\n",
    "        if center_name == \"nanji\":\n",
    "            df = nanji\n",
    "        elif center_name == \"jungnang\":\n",
    "            df = jungnang\n",
    "        elif center_name == \"seonam\":\n",
    "            df = seonam\n",
    "        elif center_name == \"tancheon\":\n",
    "            df = tancheon\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown center: {center_name}\")\n",
    "            \n",
    "        results = comprehensive_evaluation_comparison(center_name, df)\n",
    "        return pd.DataFrame(results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"테스트 실패: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "# ================================================================================================\n",
    "# 모델 저장 함수들 (기존 코드에 추가)\n",
    "# ================================================================================================\n",
    "\n",
    "def save_trained_model(model_pipeline, model_info, performance_metrics, feature_names, \n",
    "                      center_name, model_name, split_method):\n",
    "    \"\"\"학습된 모델과 모든 관련 정보를 저장\"\"\"\n",
    "    \n",
    "    # 저장 디렉토리 생성\n",
    "    base_dir = create_result_directories()\n",
    "    model_dir = os.path.join(base_dir, 'trained_models')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 파일명 생성\n",
    "    model_filename = f\"{center_name}_{model_name}_{split_method}_{timestamp}\"\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    try:\n",
    "        # 1. 모델 파이프라인 저장 (joblib - sklearn 모델에 최적화)\n",
    "        model_path = os.path.join(model_dir, f\"{model_filename}_model.pkl\")\n",
    "        joblib.dump(model_pipeline, model_path)\n",
    "        saved_files.append(model_path)\n",
    "        \n",
    "        # 2. 모델 메타데이터 저장 (JSON)\n",
    "        metadata = {\n",
    "            'model_info': {\n",
    "                'center_name': center_name,\n",
    "                'model_name': model_name,\n",
    "                'model_type': model_info.get('type', 'unknown'),\n",
    "                'split_method': split_method,\n",
    "                'training_timestamp': timestamp,\n",
    "                'training_date': datetime.now().isoformat()\n",
    "            },\n",
    "            'data_info': {\n",
    "                'feature_names': feature_names,\n",
    "                'feature_count': len(feature_names),\n",
    "                'target_column': \"합계_1일후\" if model_info.get('type') == 'regression' else \"등급_1일후\"\n",
    "            },\n",
    "            'preprocessing_info': {\n",
    "                'imputer_strategy': 'median',\n",
    "                'scaling_applied': model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"],\n",
    "                'pipeline_steps': ['imputer'] + (['scaler'] if model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"] else [])\n",
    "            },\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'model_parameters': get_model_parameters(model_pipeline, model_name)\n",
    "        }\n",
    "        \n",
    "        metadata_path = os.path.join(model_dir, f\"{model_filename}_metadata.json\")\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        saved_files.append(metadata_path)\n",
    "        \n",
    "        # 3. 피처 이름 리스트 별도 저장 (빠른 접근용)\n",
    "        feature_path = os.path.join(model_dir, f\"{model_filename}_features.txt\")\n",
    "        with open(feature_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(feature_names))\n",
    "        saved_files.append(feature_path)\n",
    "        \n",
    "        print(f\"\\n=== 모델 저장 완료 ===\")\n",
    "        print(f\"모델: {center_name} - {model_name} ({split_method})\")\n",
    "        for file in saved_files:\n",
    "            print(f\"저장됨: {file}\")\n",
    "            \n",
    "        return model_filename, saved_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"모델 저장 실패: {e}\")\n",
    "        return None, []\n",
    "\n",
    "def get_model_parameters(model_pipeline, model_name):\n",
    "    \"\"\"모델의 하이퍼파라미터 추출\"\"\"\n",
    "    try:\n",
    "        model = model_pipeline.named_steps['model']\n",
    "        params = model.get_params()\n",
    "        \n",
    "        # 중요한 파라미터만 저장 (너무 많으면 파일이 커짐)\n",
    "        important_params = {}\n",
    "        \n",
    "        if 'RandomForest' in model_name:\n",
    "            important_params = {\n",
    "                'n_estimators': params.get('n_estimators'),\n",
    "                'max_depth': params.get('max_depth'), \n",
    "                'min_samples_leaf': params.get('min_samples_leaf'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        elif 'XGBoost' in model_name:\n",
    "            important_params = {\n",
    "                'n_estimators': params.get('n_estimators'),\n",
    "                'max_depth': params.get('max_depth'),\n",
    "                'learning_rate': params.get('learning_rate'),\n",
    "                'subsample': params.get('subsample'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        elif 'LightGBM' in model_name:\n",
    "            important_params = {\n",
    "                'n_estimators': params.get('n_estimators'),\n",
    "                'learning_rate': params.get('learning_rate'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        elif 'CatBoost' in model_name:\n",
    "            important_params = {\n",
    "                'iterations': params.get('iterations'),\n",
    "                'learning_rate': params.get('learning_rate'),\n",
    "                'depth': params.get('depth'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        else:\n",
    "            # Linear models 등\n",
    "            important_params = {key: val for key, val in params.items() \n",
    "                              if key in ['C', 'max_iter', 'random_state', 'solver']}\n",
    "        \n",
    "        return important_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"파라미터 추출 실패: {e}\")\n",
    "        return {}\n",
    "\n",
    "def load_trained_model(model_filename, model_dir=None):\n",
    "    \"\"\"저장된 모델과 메타데이터 로드\"\"\"\n",
    "    \n",
    "    if model_dir is None:\n",
    "        base_dir = create_result_directories()\n",
    "        model_dir = os.path.join(base_dir, 'trained_models')\n",
    "    \n",
    "    try:\n",
    "        # 1. 모델 로드\n",
    "        model_path = os.path.join(model_dir, f\"{model_filename}_model.pkl\")\n",
    "        model_pipeline = joblib.load(model_path)\n",
    "        \n",
    "        # 2. 메타데이터 로드\n",
    "        metadata_path = os.path.join(model_dir, f\"{model_filename}_metadata.json\")\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # 3. 피처 이름 로드\n",
    "        feature_path = os.path.join(model_dir, f\"{model_filename}_features.txt\")\n",
    "        with open(feature_path, 'r', encoding='utf-8') as f:\n",
    "            feature_names = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        print(f\"모델 로드 완료: {metadata['model_info']['center_name']} - {metadata['model_info']['model_name']}\")\n",
    "        print(f\"학습 일시: {metadata['model_info']['training_date']}\")\n",
    "        print(f\"성능 지표: {metadata['performance_metrics']}\")\n",
    "        \n",
    "        return {\n",
    "            'model_pipeline': model_pipeline,\n",
    "            'metadata': metadata,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"모델 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_with_saved_model(model_data, new_data):\n",
    "    \"\"\"저장된 모델로 새로운 데이터 예측\"\"\"\n",
    "    \n",
    "    try:\n",
    "        model_pipeline = model_data['model_pipeline']\n",
    "        expected_features = model_data['feature_names']\n",
    "        metadata = model_data['metadata']\n",
    "        \n",
    "        # 1. 피처 확인 및 정렬\n",
    "        if isinstance(new_data, pd.DataFrame):\n",
    "            # 필요한 피처만 선택하고 순서 맞춤\n",
    "            missing_features = set(expected_features) - set(new_data.columns)\n",
    "            if missing_features:\n",
    "                print(f\"경고: 다음 피처들이 누락됨: {missing_features}\")\n",
    "                # 누락된 피처는 0으로 채움\n",
    "                for feature in missing_features:\n",
    "                    new_data[feature] = 0\n",
    "            \n",
    "            # 피처 순서 맞춤\n",
    "            X_new = new_data[expected_features].copy()\n",
    "        else:\n",
    "            raise ValueError(\"새 데이터는 pandas DataFrame이어야 합니다.\")\n",
    "        \n",
    "        # 2. 예측 수행\n",
    "        predictions = model_pipeline.predict(X_new)\n",
    "        \n",
    "        # 3. 예측 결과 후처리\n",
    "        model_type = metadata['model_info']['model_type']\n",
    "        \n",
    "        if model_type == 'classification':\n",
    "            # 분류의 경우 확률도 함께 반환\n",
    "            try:\n",
    "                probabilities = model_pipeline.predict_proba(X_new)\n",
    "                return {\n",
    "                    'predictions': predictions,\n",
    "                    'probabilities': probabilities,\n",
    "                    'model_type': model_type,\n",
    "                    'model_name': metadata['model_info']['model_name']\n",
    "                }\n",
    "            except:\n",
    "                return {\n",
    "                    'predictions': predictions,\n",
    "                    'model_type': model_type,\n",
    "                    'model_name': metadata['model_info']['model_name']\n",
    "                }\n",
    "        else:\n",
    "            # 회귀의 경우\n",
    "            return {\n",
    "                'predictions': predictions,\n",
    "                'model_type': model_type,\n",
    "                'model_name': metadata['model_info']['model_name']\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"예측 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def list_saved_models(model_dir=None):\n",
    "    \"\"\"저장된 모델 목록 조회\"\"\"\n",
    "    \n",
    "    if model_dir is None:\n",
    "        base_dir = create_result_directories()\n",
    "        model_dir = os.path.join(base_dir, 'trained_models')\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        print(\"저장된 모델이 없습니다.\")\n",
    "        return []\n",
    "    \n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('_metadata.json')]\n",
    "    models_info = []\n",
    "    \n",
    "    for metadata_file in model_files:\n",
    "        try:\n",
    "            metadata_path = os.path.join(model_dir, metadata_file)\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            model_filename = metadata_file.replace('_metadata.json', '')\n",
    "            \n",
    "            info = {\n",
    "                'filename': model_filename,\n",
    "                'center': metadata['model_info']['center_name'],\n",
    "                'model': metadata['model_info']['model_name'],\n",
    "                'type': metadata['model_info']['model_type'],\n",
    "                'split_method': metadata['model_info']['split_method'],\n",
    "                'training_date': metadata['model_info']['training_date'],\n",
    "                'performance': metadata['performance_metrics']\n",
    "            }\n",
    "            models_info.append(info)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"메타데이터 읽기 실패 ({metadata_file}): {e}\")\n",
    "    \n",
    "    return models_info\n",
    "\n",
    "# ================================================================================================\n",
    "# 기존 평가 함수들 수정 (모델 저장 기능 추가)\n",
    "# ================================================================================================\n",
    "\n",
    "def evaluate_regression_model_with_save(model, model_name, X_train, X_test, y_train, y_test, \n",
    "                                       feature_names=None, center_name=None, split_method=None, \n",
    "                                       save_model=False):\n",
    "    \"\"\"회귀 모델 평가 + 모델 저장 옵션\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"regression\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "        \n",
    "        performance_metrics = {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mape': mape\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            **performance_metrics,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        # 모델 저장 (요청 시)\n",
    "        saved_model_info = None\n",
    "        if save_model and feature_names and center_name and split_method:\n",
    "            model_info = {'type': 'regression'}\n",
    "            filename, files = save_trained_model(\n",
    "                pipe, model_info, performance_metrics, feature_names,\n",
    "                center_name, model_name, split_method\n",
    "            )\n",
    "            saved_model_info = {'filename': filename, 'files': files}\n",
    "        \n",
    "        return result, pipe, y_pred, saved_model_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': np.nan,\n",
    "            'rmse': np.nan,\n",
    "            'r2': np.nan,\n",
    "            'mape': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None, None\n",
    "\n",
    "def evaluate_classification_model_with_save(model, model_name, X_train, X_test, y_train, y_test,\n",
    "                                          feature_names=None, center_name=None, split_method=None,\n",
    "                                          save_model=False):\n",
    "    \"\"\"분류 모델 평가 + 모델 저장 옵션\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"classification\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        if isinstance(y_pred, np.ndarray) and y_pred.ndim > 1:\n",
    "            y_pred = y_pred.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        extreme_classes = [0, 3]\n",
    "        y_true_extreme = pd.Series(y_test).isin(extreme_classes).astype(int)\n",
    "        y_pred_extreme = pd.Series(y_pred).isin(extreme_classes).astype(int)\n",
    "        extreme_f1 = f1_score(y_true_extreme, y_pred_extreme, zero_division=0)\n",
    "        \n",
    "        performance_metrics = {\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1_macro,\n",
    "            'weighted_f1': f1_weighted,\n",
    "            'extreme_f1': extreme_f1\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            **performance_metrics,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        # 모델 저장 (요청 시)\n",
    "        saved_model_info = None\n",
    "        if save_model and feature_names and center_name and split_method:\n",
    "            model_info = {'type': 'classification'}\n",
    "            filename, files = save_trained_model(\n",
    "                pipe, model_info, performance_metrics, feature_names,\n",
    "                center_name, model_name, split_method\n",
    "            )\n",
    "            saved_model_info = {'filename': filename, 'files': files}\n",
    "        \n",
    "        return result, pipe, y_pred, saved_model_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': np.nan,\n",
    "            'macro_f1': np.nan,\n",
    "            'weighted_f1': np.nan,\n",
    "            'extreme_f1': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None, None\n",
    "\n",
    "# ================================================================================================\n",
    "# 최고 성능 모델 자동 저장 함수\n",
    "# ================================================================================================\n",
    "\n",
    "def save_best_models_automatically(results_df, centers):\n",
    "    \"\"\"최고 성능 모델들을 자동으로 재학습하여 저장\"\"\"\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(\"저장할 성공한 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== 최고 성능 모델 자동 저장 ===\")\n",
    "    \n",
    "    saved_models = []\n",
    "    \n",
    "    # 센터별, 타입별 최고 성능 모델 저장\n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        for model_type in ['regression', 'classification']:\n",
    "            type_data = center_data[center_data['type'] == model_type]\n",
    "            \n",
    "            if len(type_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # 최고 성능 모델 선택\n",
    "            if model_type == 'regression':\n",
    "                best_model = type_data.loc[type_data['r2'].idxmax()]\n",
    "                metric_name = 'R²'\n",
    "                metric_value = best_model['r2']\n",
    "            else:\n",
    "                best_model = type_data.loc[type_data['macro_f1'].idxmax()]\n",
    "                metric_name = 'Macro F1'\n",
    "                metric_value = best_model['macro_f1']\n",
    "            \n",
    "            print(f\"\\n저장 중: {center} - {best_model['model']} ({model_type})\")\n",
    "            print(f\"성능: {metric_name}={metric_value:.3f}\")\n",
    "            \n",
    "            try:\n",
    "                # 모델 재학습 및 저장\n",
    "                df = centers[center]\n",
    "                target_col = \"합계_1일후\" if model_type == \"regression\" else \"등급_1일후\"\n",
    "                \n",
    "                X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "                    df, target_col=target_col, model_type=model_type, \n",
    "                    test_size=0.2, split_method=best_model['split_method']\n",
    "                )\n",
    "                \n",
    "                # 모델 재구축\n",
    "                if model_type == \"regression\":\n",
    "                    models = build_regression_models()\n",
    "                    result, pipe, y_pred, saved_info = evaluate_regression_model_with_save(\n",
    "                        models[best_model['model']], best_model['model'],\n",
    "                        X_train, X_test, y_train, y_test,\n",
    "                        feature_names, center, best_model['split_method'], \n",
    "                        save_model=True\n",
    "                    )\n",
    "                else:\n",
    "                    models = build_classification_models()\n",
    "                    result, pipe, y_pred, saved_info = evaluate_classification_model_with_save(\n",
    "                        models[best_model['model']], best_model['model'],\n",
    "                        X_train, X_test, y_train, y_test,\n",
    "                        feature_names, center, best_model['split_method'],\n",
    "                        save_model=True\n",
    "                    )\n",
    "                \n",
    "                if saved_info:\n",
    "                    saved_models.append(saved_info['filename'])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"저장 실패: {e}\")\n",
    "    \n",
    "    print(f\"\\n총 {len(saved_models)}개 모델 저장 완료\")\n",
    "    return saved_models\n",
    "\n",
    "# ================================================================================================\n",
    "# 사용 예시\n",
    "# ================================================================================================\n",
    "\n",
    "def demo_model_usage():\n",
    "    \"\"\"모델 저장 및 사용 데모\"\"\"\n",
    "    \n",
    "    print(\"=== 모델 저장 및 사용 데모 ===\")\n",
    "    \n",
    "    # 1. 저장된 모델 목록 확인\n",
    "    print(\"\\n1. 저장된 모델 목록:\")\n",
    "    models = list_saved_models()\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"  {i+1}. {model['center']} - {model['model']} ({model['type']})\")\n",
    "        print(f\"     성능: {model['performance']}\")\n",
    "        print(f\"     파일명: {model['filename']}\")\n",
    "    \n",
    "    # 2. 모델 로드 및 예측 (예시)\n",
    "    if models:\n",
    "        print(f\"\\n2. 첫 번째 모델 로드 및 예측 테스트:\")\n",
    "        first_model = models[0]\n",
    "        \n",
    "        # 모델 로드\n",
    "        model_data = load_trained_model(first_model['filename'])\n",
    "        \n",
    "        if model_data:\n",
    "            print(\"모델 로드 성공!\")\n",
    "            print(f\"예상 피처 개수: {len(model_data['feature_names'])}\")\n",
    "            \n",
    "            # 더미 데이터로 예측 테스트 (실제 사용시에는 실제 데이터 사용)\n",
    "            dummy_data = pd.DataFrame({\n",
    "                feature: [0.5] for feature in model_data['feature_names']\n",
    "            })\n",
    "            \n",
    "            result = predict_with_saved_model(model_data, dummy_data)\n",
    "            if result:\n",
    "                print(f\"예측 결과: {result['predictions']}\")\n",
    "                if 'probabilities' in result:\n",
    "                    print(f\"예측 확률: {result['probabilities']}\")\n",
    "\n",
    "# 센터별 최고 성능 모델 분석을 위한 함수 수정\n",
    "\n",
    "def perform_detailed_analysis_with_save_by_center(results_df, centers):\n",
    "    \"\"\"센터별 최고 성능 모델에 대한 상세 분석 (저장 기능 포함)\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== 센터별 최고 성능 모델 상세 분석 ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(\"분석할 성공한 모델이 없습니다.\")\n",
    "        return []\n",
    "    \n",
    "    analyzed_models = []\n",
    "    \n",
    "    # 센터별로 최고 성능 모델 분석\n",
    "    for center in successful_results['center'].unique():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"센터: {center.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        # 1. 센터별 회귀 최고 성능 모델\n",
    "        reg_results = center_data[center_data['type'] == 'regression']\n",
    "        if len(reg_results) > 0:\n",
    "            best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "            print(f\"\\n[{center}] 최고 회귀 성능: {best_reg['model']} ({best_reg['split_method']}) R²={best_reg['r2']:.3f}\")\n",
    "            \n",
    "            # 회귀 모델 재학습 및 분석\n",
    "            model_info = analyze_best_model_with_save_detailed(best_reg, centers, 'regression')\n",
    "            if model_info:\n",
    "                analyzed_models.append(model_info)\n",
    "        \n",
    "        # 2. 센터별 분류 최고 성능 모델\n",
    "        clf_results = center_data[center_data['type'] == 'classification']\n",
    "        if len(clf_results) > 0:\n",
    "            best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "            print(f\"\\n[{center}] 최고 분류 성능: {best_clf['model']} ({best_clf['split_method']}) F1={best_clf['macro_f1']:.3f}\")\n",
    "            \n",
    "            # 분류 모델 재학습 및 분석\n",
    "            model_info = analyze_best_model_with_save_detailed(best_clf, centers, 'classification')\n",
    "            if model_info:\n",
    "                analyzed_models.append(model_info)\n",
    "    \n",
    "    print(f\"\\n총 {len(analyzed_models)}개 모델 상세 분석 완료\")\n",
    "    return analyzed_models\n",
    "\n",
    "def analyze_best_model_with_save_detailed(best_result, centers, model_type):\n",
    "    \"\"\"개별 최고 성능 모델 상세 분석 (저장 기능 포함)\"\"\"\n",
    "    center_name = best_result['center']\n",
    "    model_name = best_result['model']\n",
    "    split_method = best_result['split_method']\n",
    "    \n",
    "    print(f\"\\n분석 중: {center_name} - {model_name} ({model_type})\")\n",
    "    \n",
    "    try:\n",
    "        # 데이터 준비\n",
    "        df = centers[center_name]\n",
    "        target_col = \"합계_1일후\" if model_type == \"regression\" else \"등급_1일후\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            df, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.2, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # 모델 재구축 및 학습\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "            \n",
    "        model = models[model_name]\n",
    "        pipe = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # 상세 분석 수행 (Feature Importance + SHAP + 저장)\n",
    "        print(f\"  Feature Importance & SHAP 분석 진행 중...\")\n",
    "        importance_df, shap_result = comprehensive_model_analysis_with_save(\n",
    "            pipe, model_name, X_train, X_test, y_train, y_test, \n",
    "            feature_names, model_type, center_name\n",
    "        )\n",
    "        \n",
    "        # 모델도 저장\n",
    "        performance_metrics = {}\n",
    "        if model_type == \"regression\":\n",
    "            y_pred = pipe.predict(X_test)\n",
    "            performance_metrics = {\n",
    "                'r2': best_result['r2'],\n",
    "                'mae': best_result['mae'], \n",
    "                'rmse': best_result['rmse'],\n",
    "                'mape': best_result['mape']\n",
    "            }\n",
    "        else:\n",
    "            performance_metrics = {\n",
    "                'accuracy': best_result['accuracy'],\n",
    "                'macro_f1': best_result['macro_f1'],\n",
    "                'weighted_f1': best_result['weighted_f1'],\n",
    "                'extreme_f1': best_result['extreme_f1']\n",
    "            }\n",
    "        \n",
    "        # 학습된 모델 저장\n",
    "        model_info = {'type': model_type}\n",
    "        filename, files = save_trained_model(\n",
    "            pipe, model_info, performance_metrics, feature_names,\n",
    "            center_name, model_name, split_method\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'center': center_name,\n",
    "            'model': model_name,\n",
    "            'type': model_type,\n",
    "            'split_method': split_method,\n",
    "            'performance': best_result,\n",
    "            'saved_model_filename': filename,\n",
    "            'analysis_completed': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  분석 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 기존 run_stratified_comparison 함수에서 호출 부분 수정\n",
    "def run_stratified_comparison_with_center_analysis():\n",
    "    \"\"\"전체 센터 Stratified vs 시계열 비교 + 센터별 상세 분석\"\"\"\n",
    "    print(\"=== Stratified vs 시계열 분할 비교 실험 (센터별 분석) ===\")\n",
    "    \n",
    "    # 데이터 로드 확인\n",
    "    try:\n",
    "        centers = {\n",
    "            \"nanji\": nanji,\n",
    "            \"jungnang\": jungnang,  \n",
    "            \"seonam\": seonam,\n",
    "            \"tancheon\": tancheon\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n데이터 확인:\")\n",
    "        for name, df in centers.items():\n",
    "            print(f\"  {name}: {len(df)}행\")\n",
    "    \n",
    "    except NameError:\n",
    "        print(\"데이터가 로드되지 않았습니다. 먼저 make_features를 실행하세요.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 전체 실험 실행\n",
    "    all_results = []\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        try:\n",
    "            center_results = comprehensive_evaluation_comparison(center_name, df)\n",
    "            all_results.extend(center_results)\n",
    "        except Exception as e:\n",
    "            print(f\"[{center_name}] 실험 실패: {e}\")\n",
    "    \n",
    "    # 결과 분석\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # 기본 분석 및 시각화\n",
    "        analyze_stratified_comparison(results_df)\n",
    "        \n",
    "        # 센터별 최고 성능 모델 상세 분석 (수정된 함수 사용)\n",
    "        analyzed_models = perform_detailed_analysis_with_save_by_center(results_df, centers)\n",
    "        \n",
    "        # 포괄적 결과 저장\n",
    "        saved_files = save_results_comprehensive(results_df, 'stratified_comparison')\n",
    "        \n",
    "        # 모델 성능 비교 데이터도 별도 저장\n",
    "        successful_results = results_df[results_df['success'] == True]\n",
    "        if len(successful_results) > 0:\n",
    "            performance_comparison = create_performance_comparison_data(successful_results)\n",
    "            save_results_comprehensive(\n",
    "                performance_comparison, \n",
    "                'model_performance'\n",
    "            )\n",
    "        \n",
    "        # 분석 결과 요약\n",
    "        print(f\"\\n=== 실험 완료 ===\")\n",
    "        print(f\"총 {len(results_df)}개 실험 중 {len(successful_results)}개 성공\")\n",
    "        print(f\"센터별 상세 분석: {len(analyzed_models)}개 모델\")\n",
    "        print(f\"결과 저장 위치: ../data/results/\")\n",
    "        \n",
    "        # 분석된 모델 목록 출력\n",
    "        if analyzed_models:\n",
    "            print(f\"\\n=== 분석된 모델 목록 ===\")\n",
    "            for model in analyzed_models:\n",
    "                print(f\"  {model['center']} - {model['model']} ({model['type']}) [{model['split_method']}]\")\n",
    "                print(f\"    저장된 모델: {model.get('saved_model_filename', 'N/A')}\")\n",
    "    \n",
    "    return results_df, analyzed_models\n",
    "\n",
    "# 센터별 분석 결과 요약 함수\n",
    "def summarize_center_analysis(analyzed_models):\n",
    "    \"\"\"센터별 분석 결과 요약\"\"\"\n",
    "    if not analyzed_models:\n",
    "        print(\"분석된 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== 센터별 최고 성능 모델 요약 ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    centers = {}\n",
    "    for model in analyzed_models:\n",
    "        center = model['center']\n",
    "        if center not in centers:\n",
    "            centers[center] = {'regression': None, 'classification': None}\n",
    "        centers[center][model['type']] = model\n",
    "    \n",
    "    for center, models in centers.items():\n",
    "        print(f\"\\n[{center.upper()} 센터]\")\n",
    "        \n",
    "        if models['regression']:\n",
    "            reg_model = models['regression']\n",
    "            print(f\"  회귀: {reg_model['model']} ({reg_model['split_method']})\")\n",
    "            print(f\"       R² = {reg_model['performance']['r2']:.3f}\")\n",
    "        \n",
    "        if models['classification']:\n",
    "            clf_model = models['classification']\n",
    "            print(f\"  분류: {clf_model['model']} ({clf_model['split_method']})\")\n",
    "            print(f\"       F1 = {clf_model['performance']['macro_f1']:.3f}\")\n",
    "\n",
    "# 실행 예시 함수\n",
    "def demo_center_wise_analysis():\n",
    "    \"\"\"센터별 분석 데모\"\"\"\n",
    "    print(\"=== 센터별 분석 실행 ===\")\n",
    "    \n",
    "    # 센터별 분석 실행\n",
    "    results_df, analyzed_models = run_stratified_comparison_with_center_analysis()\n",
    "    \n",
    "    # 결과 요약\n",
    "    summarize_center_analysis(analyzed_models)\n",
    "    \n",
    "    return results_df, analyzed_models\n",
    "\n",
    "# ================================================================================================\n",
    "# 9. 실행 가이드 및 메인 실행 부분\n",
    "# ================================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 완성된 Stratified vs 시계열 분할 비교 실험 ===\")\n",
    "    \n",
    "    print(\"\\n📁 결과 저장 구조:\")\n",
    "    print(\"../data/results/\")\n",
    "    print(\"├── stratified_comparison/  # 분할 방법 비교 결과\")\n",
    "    print(\"│   ├── stratified_comparison_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"│   ├── stratified_summary_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"│   └── stratified_best_models_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"├── feature_importance/     # 피처 중요도 분석\")\n",
    "    print(\"│   └── importance_센터명_모델명_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"├── shap_analysis/         # SHAP 분석 결과\")\n",
    "    print(\"│   ├── shap_values_센터명_모델명_YYYYMMDD_HHMMSS.pkl\")\n",
    "    print(\"│   └── shap_summary_센터명_모델명_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"├── model_performance/     # 모델 성능 상세 분석\")\n",
    "    print(\"│   └── performance_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"└── visualizations/        # 생성된 그래프 이미지\")\n",
    "    print(\"    ├── stratified_comparison_plots_YYYYMMDD_HHMMSS.png\")\n",
    "    print(\"    ├── feature_importance_센터명_모델명_YYYYMMDD_HHMMSS.png\")\n",
    "    print(\"    └── shap_센터명_모델명_YYYYMMDD_HHMMSS.png\")\n",
    "    \n",
    "    print(\"\\n🚀 실행 방법:\")\n",
    "    print(\"1. 전체 실험 (권장): \")\n",
    "    print(\"   results_df = run_stratified_comparison()\")\n",
    "    print(\"\\n2. 단일 센터 테스트:\")\n",
    "    print(\"   results_df = quick_stratified_test('nanji')\")\n",
    "    print(\"\\n3. 결과 분석만:\")\n",
    "    print(\"   analyze_stratified_comparison(results_df)\")\n",
    "    \n",
    "    print(f\"\\n💡 주요 개선사항:\")\n",
    "    print(\"- CatBoost 회귀 모델 오류 수정\")\n",
    "    print(\"- CatBoost 분류 모델 파라미터 오류 수정\")\n",
    "    print(\"- 체계적인 폴더 구조로 결과 저장\")\n",
    "    print(\"- Feature Importance & SHAP 분석 결과 저장\")\n",
    "    print(\"- 시각화 이미지 자동 저장\")\n",
    "    print(\"- 요약 통계 및 최고 성능 모델 별도 저장\")\n",
    "    print(\"- 모델별 상세 분석 결과 추적 가능\")\n",
    "    \n",
    "    print(f\"\\n📊 실험 구성:\")\n",
    "    print(\"- 4개 센터 (nanji, jungnang, seonam, tancheon)\")\n",
    "    print(\"- 2가지 분할방법 (temporal, stratified)\")\n",
    "    print(\"- 12개 모델 (회귀 6개 + 분류 6개)\")\n",
    "    print(\"- 총 96개 실험 (4×2×12)\")\n",
    "    \n",
    "    print(f\"\\n📈 평가 지표:\")\n",
    "    print(\"회귀: R², MAE, RMSE, MAPE\")\n",
    "    print(\"분류: Accuracy, Macro F1, Weighted F1, Extreme F1\")\n",
    "    \n",
    "    print(f\"\\n⚠️ 사용 전 확인사항:\")\n",
    "    print(\"1. 데이터 준비: nanji, jungnang, seonam, tancheon 변수가 로드되어 있어야 함\")\n",
    "    print(\"2. 필요 라이브러리: pandas, numpy, matplotlib, sklearn 등\")\n",
    "    print(\"3. 선택 라이브러리: xgboost, lightgbm, catboost, shap\")\n",
    "    print(\"4. 실행 권한: ../data/results/ 폴더 생성 권한 필요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7155fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n실제 사용 예시:\\n\\n# 1. 전체 실험 실행\\nresults_df = run_stratified_comparison()\\n\\n# 2. 결과 확인\\nprint(f\"총 {len(results_df)}개 실험 완료\")\\nsuccessful = results_df[results_df[\\'success\\'] == True]\\nprint(f\"성공: {len(successful)}개\")\\n\\n# 3. 최고 성능 모델 확인\\nreg_best = successful[successful[\\'type\\'] == \\'regression\\'].nlargest(1, \\'r2\\')\\nclf_best = successful[successful[\\'type\\'] == \\'classification\\'].nlargest(1, \\'macro_f1\\')\\n\\nprint(\"최고 회귀 성능:\", reg_best[[\\'center\\', \\'model\\', \\'split_method\\', \\'r2\\']].iloc[0])\\nprint(\"최고 분류 성능:\", clf_best[[\\'center\\', \\'model\\', \\'split_method\\', \\'macro_f1\\']].iloc[0])\\n\\n# 4. 저장된 파일 확인\\nimport os\\nfor root, dirs, files in os.walk(\\'../data/results\\'):\\n    level = root.replace(\\'../data/results\\', \\'\\').count(os.sep)\\n    indent = \\' \\' * 2 * level\\n    print(f\\'{indent}{os.path.basename(root)}/\\')\\n    subindent = \\' \\' * 2 * (level + 1)\\n    for file in files:\\n        print(f\\'{subindent}{file}\\')\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용 예시\n",
    "\"\"\"\n",
    "# 센터별 최고 성능 모델 분석 실행\n",
    "results_df, analyzed_models = run_stratified_comparison_with_center_analysis()\n",
    "\n",
    "# 분석 결과 요약\n",
    "summarize_center_analysis(analyzed_models)\n",
    "\n",
    "# 저장된 모델 목록 확인\n",
    "models = list_saved_models()\n",
    "for model in models:\n",
    "    print(f\"{model['center']} - {model['model']} ({model['type']}): {model['performance']}\")\n",
    "\"\"\"\n",
    "\n",
    "# 실행 예시\n",
    "\"\"\"\n",
    "# 1. 실험 실행 후 최고 성능 모델들 자동 저장\n",
    "results_df = run_stratified_comparison()\n",
    "saved_models = save_best_models_automatically(results_df, centers)\n",
    "\n",
    "# 2. 저장된 모델 확인\n",
    "demo_model_usage()\n",
    "\n",
    "# 3. 새로운 데이터에 예측\n",
    "model_data = load_trained_model('nanji_XGBoost_Reg_temporal_20250826_143022')\n",
    "new_predictions = predict_with_saved_model(model_data, new_dataframe)\n",
    "\"\"\"\n",
    "\n",
    "# ================================================================================================\n",
    "# 10. 사용 예시\n",
    "# ================================================================================================\n",
    "\"\"\"\n",
    "실제 사용 예시:\n",
    "\n",
    "# 1. 전체 실험 실행\n",
    "results_df = run_stratified_comparison()\n",
    "\n",
    "# 2. 결과 확인\n",
    "print(f\"총 {len(results_df)}개 실험 완료\")\n",
    "successful = results_df[results_df['success'] == True]\n",
    "print(f\"성공: {len(successful)}개\")\n",
    "\n",
    "# 3. 최고 성능 모델 확인\n",
    "reg_best = successful[successful['type'] == 'regression'].nlargest(1, 'r2')\n",
    "clf_best = successful[successful['type'] == 'classification'].nlargest(1, 'macro_f1')\n",
    "\n",
    "print(\"최고 회귀 성능:\", reg_best[['center', 'model', 'split_method', 'r2']].iloc[0])\n",
    "print(\"최고 분류 성능:\", clf_best[['center', 'model', 'split_method', 'macro_f1']].iloc[0])\n",
    "\n",
    "# 4. 저장된 파일 확인\n",
    "import os\n",
    "for root, dirs, files in os.walk('../data/results'):\n",
    "    level = root.replace('../data/results', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f'{subindent}{file}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f63189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 완전한 운영 환경 시뮬레이션 파이프라인 ===\n",
      "\n",
      "사용법:\n",
      "results = run_complete_production_pipeline()\n",
      "\n",
      "또는 cutoff_date를 변경하여:\n",
      "results = run_complete_production_pipeline(cutoff_date='2025-05-15')\n",
      "\n",
      "반환값:\n",
      "- results[0]: 최종 예측 결과 테이블\n",
      "- results[1]: 학습된 모델 정보\n",
      "- results[2]: 성능 요약\n",
      "\n",
      "생성되는 파일:\n",
      "- production_simulation_YYYYMMDD_HHMMSS_predictions.csv\n",
      "- production_simulation_YYYYMMDD_HHMMSS_summary.csv\n",
      "- production_simulation_YYYYMMDD_HHMMSS_training.csv\n",
      "완전한 운영 환경 시뮬레이션 파이프라인을 시작합니다...\n",
      "이 과정은 다소 시간이 걸릴 수 있습니다.\n",
      "================================================================================\n",
      "완전한 운영 환경 시뮬레이션 파이프라인 시작\n",
      "학습 기간: ~ 2025-05-20\n",
      "예측 기간: 2025-05-20 이후\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "1단계: 모델 학습 및 성능 평가 (~ 2025-05-20)\n",
      "============================================================\n",
      "\n",
      "[NANJI 센터 처리 중...]\n",
      "  학습 데이터: 3062행\n",
      "  예측 데이터: 41행\n",
      "\n",
      "======================================================================\n",
      "센터: nanji - Stratified vs 시계열 분할 비교\n",
      "======================================================================\n",
      "데이터 크기: 3062행, 28컬럼\n",
      "\n",
      "==================================================\n",
      "분할 방법: TEMPORAL\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (temporal) ---\n",
      "회귀 모델 평가 실패 (temporal): '합계_1일후'\n",
      "\n",
      "--- 분류 모델 평가 (temporal) ---\n",
      "분류 모델 평가 실패 (temporal): '등급_1일후'\n",
      "\n",
      "==================================================\n",
      "분할 방법: STRATIFIED\n",
      "==================================================\n",
      "\n",
      "--- 회귀 모델 평가 (random_shuffle) ---\n",
      "회귀 모델 평가 실패 (random_shuffle): '합계_1일후'\n",
      "\n",
      "--- 분류 모델 평가 (stratified) ---\n",
      "분류 모델 평가 실패 (stratified): '등급_1일후'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'success'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 588\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- production_simulation_YYYYMMDD_HHMMSS_training.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# 완전한 파이프라인 실행\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_complete_production_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcutoff_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2025-05-20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# 결과 확인\u001b[39;00m\n\u001b[1;32m    591\u001b[0m final_table, trained_models, performance_summary \u001b[38;5;241m=\u001b[39m results\n",
      "Cell \u001b[0;32mIn[59], line 552\u001b[0m, in \u001b[0;36mrun_complete_production_pipeline\u001b[0;34m(cutoff_date)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# 핵심 파이프라인 함수 호출 (자기 자신이 아닌!)\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcomplete_production_simulation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    555\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[59], line 84\u001b[0m, in \u001b[0;36mcomplete_production_simulation_pipeline\u001b[0;34m(centers, cutoff_date)\u001b[0m\n\u001b[1;32m     81\u001b[0m all_training_results\u001b[38;5;241m.\u001b[39mextend(center_results)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# 최고 성능 모델 선택\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m center_best_models \u001b[38;5;241m=\u001b[39m \u001b[43mselect_and_train_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center_best_models:\n\u001b[1;32m     86\u001b[0m     best_models_by_center[center_name] \u001b[38;5;241m=\u001b[39m center_best_models\n",
      "Cell \u001b[0;32mIn[59], line 164\u001b[0m, in \u001b[0;36mselect_and_train_best_models\u001b[0;34m(center_name, train_data, evaluation_results)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"최고 성능 모델 선택 및 학습\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(evaluation_results)\n\u001b[0;32m--> 164\u001b[0m successful_results \u001b[38;5;241m=\u001b[39m results_df[\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuccess\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(successful_results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    성공한 모델이 없습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'success'"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# 완전한 운영 환경 시뮬레이션 파이프라인\n",
    "# 1단계: 5월 20일까지 데이터로 모델 학습 및 성능 평가\n",
    "# 2단계: 최고 성능 모델 선택 및 저장\n",
    "# 3단계: 5월 21일~31일 데이터로 예측 수행\n",
    "# 4단계: 결과 테이블 생성 및 성능 평가\n",
    "# ================================================================================================\n",
    "\n",
    "# 기존 함수들 활용\n",
    "def complete_production_simulation_pipeline(centers=None, cutoff_date='2025-05-20'):\n",
    "    \"\"\"\n",
    "    완전한 운영 환경 시뮬레이션 파이프라인\n",
    "    \n",
    "    Parameters:\n",
    "    - centers: 센터별 데이터 딕셔너리\n",
    "    - cutoff_date: 학습/예측 분할 기준일\n",
    "    \n",
    "    Returns:\n",
    "    - final_results_table: 최종 예측 결과 테이블\n",
    "    - trained_models_info: 학습된 모델 정보\n",
    "    - performance_summary: 성능 요약\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"완전한 운영 환경 시뮬레이션 파이프라인 시작\")\n",
    "    print(f\"학습 기간: ~ {cutoff_date}\")\n",
    "    print(f\"예측 기간: {cutoff_date} 이후\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 데이터 로드 확인\n",
    "    if centers is None:\n",
    "        try:\n",
    "            centers = {\n",
    "                \"nanji\": nanji,\n",
    "                \"jungnang\": jungnang,  \n",
    "                \"seonam\": seonam,\n",
    "                \"tancheon\": tancheon\n",
    "            }\n",
    "            print(f\"데이터 로드 완료:\")\n",
    "            for name, df in centers.items():\n",
    "                print(f\"  {name}: {len(df)}행\")\n",
    "        except NameError:\n",
    "            print(\"데이터가 로드되지 않았습니다. 먼저 데이터를 로드하세요.\")\n",
    "            return None\n",
    "    \n",
    "    cutoff = pd.to_datetime(cutoff_date)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 1단계: 각 센터별로 5월 20일까지 데이터로 모델 학습 및 성능 평가\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"1단계: 모델 학습 및 성능 평가 (~ {cutoff_date})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_training_results = []\n",
    "    best_models_by_center = {}\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        print(f\"\\n[{center_name.upper()} 센터 처리 중...]\")\n",
    "        \n",
    "        # 날짜 변환 및 데이터 분할\n",
    "        df_work = df.copy()\n",
    "        df_work['날짜'] = pd.to_datetime(df_work['날짜'])\n",
    "        \n",
    "        train_data = df_work[df_work['날짜'] <= cutoff].copy()\n",
    "        future_data = df_work[df_work['날짜'] > cutoff].copy()\n",
    "        \n",
    "        print(f\"  학습 데이터: {len(train_data)}행\")\n",
    "        print(f\"  예측 데이터: {len(future_data)}행\")\n",
    "        \n",
    "        if len(train_data) < 50:\n",
    "            print(f\"  학습 데이터가 부족합니다. 건너뜁니다.\")\n",
    "            continue\n",
    "            \n",
    "        if len(future_data) == 0:\n",
    "            print(f\"  예측할 데이터가 없습니다. 건너뜁니다.\")\n",
    "            continue\n",
    "        \n",
    "        # 모델 성능 평가 (기존 함수 활용)\n",
    "        center_results = comprehensive_evaluation_comparison(center_name, train_data)\n",
    "        all_training_results.extend(center_results)\n",
    "        \n",
    "        # 최고 성능 모델 선택\n",
    "        center_best_models = select_and_train_best_models(center_name, train_data, center_results)\n",
    "        if center_best_models:\n",
    "            best_models_by_center[center_name] = center_best_models\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 2단계: 최고 성능 모델 선택 결과 요약\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"2단계: 최고 성능 모델 선택 완료\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    training_results_df = pd.DataFrame(all_training_results)\n",
    "    \n",
    "    for center, models in best_models_by_center.items():\n",
    "        print(f\"\\n[{center.upper()} 센터 최고 성능 모델]\")\n",
    "        if 'regression' in models:\n",
    "            reg_info = models['regression']\n",
    "            print(f\"  회귀: {reg_info['model_name']} (R²={reg_info['performance']['r2']:.3f})\")\n",
    "        if 'classification' in models:\n",
    "            clf_info = models['classification']\n",
    "            print(f\"  분류: {clf_info['model_name']} (F1={clf_info['performance']['macro_f1']:.3f})\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 3단계: 5월 21일~31일 데이터로 예측 수행\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"3단계: 새로운 데이터 예측 수행 ({cutoff_date} 이후)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        if center_name not in best_models_by_center:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n[{center_name.upper()} 센터 예측 중...]\")\n",
    "        \n",
    "        # 데이터 준비\n",
    "        df_work = df.copy()\n",
    "        df_work['날짜'] = pd.to_datetime(df_work['날짜'])\n",
    "        future_data = df_work[df_work['날짜'] > cutoff].copy()\n",
    "        \n",
    "        if len(future_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 예측 수행\n",
    "        center_predictions = make_predictions_for_center(\n",
    "            center_name, future_data, best_models_by_center[center_name]\n",
    "        )\n",
    "        all_predictions.extend(center_predictions)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 4단계: 결과 테이블 생성 및 성능 평가\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"4단계: 결과 테이블 생성 및 성능 평가\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"예측 결과가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # 최종 결과 테이블 생성\n",
    "    final_results_table = create_final_results_table(all_predictions)\n",
    "    \n",
    "    # 성능 요약 생성\n",
    "    performance_summary = create_performance_summary(final_results_table)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print_final_results(final_results_table, performance_summary)\n",
    "    \n",
    "    # 결과 저장\n",
    "    save_final_results(final_results_table, performance_summary, training_results_df)\n",
    "    \n",
    "    return final_results_table, best_models_by_center, performance_summary\n",
    "\n",
    "def select_and_train_best_models(center_name, train_data, evaluation_results):\n",
    "    \"\"\"최고 성능 모델 선택 및 학습\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    successful_results = results_df[results_df['success'] == True]\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(f\"    성공한 모델이 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    # 회귀 최고 성능 모델\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"    최고 회귀 모델: {best_reg['model']} (R²={best_reg['r2']:.3f})\")\n",
    "        \n",
    "        # 모델 재학습\n",
    "        reg_pipeline = retrain_best_model(\n",
    "            train_data, best_reg['model'], 'regression', best_reg['split_method']\n",
    "        )\n",
    "        \n",
    "        if reg_pipeline:\n",
    "            best_models['regression'] = {\n",
    "                'model_name': best_reg['model'],\n",
    "                'pipeline': reg_pipeline['pipeline'],\n",
    "                'feature_names': reg_pipeline['feature_names'],\n",
    "                'performance': dict(best_reg),\n",
    "                'split_method': best_reg['split_method']\n",
    "            }\n",
    "    \n",
    "    # 분류 최고 성능 모델\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"    최고 분류 모델: {best_clf['model']} (F1={best_clf['macro_f1']:.3f})\")\n",
    "        \n",
    "        # 모델 재학습\n",
    "        clf_pipeline = retrain_best_model(\n",
    "            train_data, best_clf['model'], 'classification', best_clf['split_method']\n",
    "        )\n",
    "        \n",
    "        if clf_pipeline:\n",
    "            best_models['classification'] = {\n",
    "                'model_name': best_clf['model'],\n",
    "                'pipeline': clf_pipeline['pipeline'],\n",
    "                'feature_names': clf_pipeline['feature_names'],\n",
    "                'performance': dict(best_clf),\n",
    "                'split_method': best_clf['split_method']\n",
    "            }\n",
    "    \n",
    "    return best_models if best_models else None\n",
    "\n",
    "def retrain_best_model(train_data, model_name, model_type, split_method):\n",
    "    \"\"\"최고 성능 모델 재학습\"\"\"\n",
    "    \n",
    "    try:\n",
    "        target_col = \"합계_1일후\" if model_type == \"regression\" else \"등급_1일후\"\n",
    "        \n",
    "        # 전체 학습 데이터로 재학습 (test_size를 매우 작게 설정)\n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            train_data, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.05, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # 전체 데이터 사용 (X_train + X_test)\n",
    "        X_all = pd.concat([X_train, X_test], ignore_index=True)\n",
    "        y_all = pd.concat([y_train, y_test], ignore_index=True)\n",
    "        X_all = X_all[feature_names]  # ✅ 피처 순서 고정\n",
    "        \n",
    "        # 모델 구축 및 학습\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "        \n",
    "        model = models[model_name]\n",
    "        pipeline = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipeline.fit(X_all, y_all)\n",
    "        \n",
    "        return {\n",
    "            'pipeline': pipeline,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    모델 재학습 실패 ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def make_predictions_for_center(center_name, future_data, trained_models):\n",
    "    \"\"\"센터별 예측 수행\"\"\"\n",
    "    predictions = []\n",
    "    future_data = future_data.reset_index(drop=True)  # make_predictions_for_center 진입 직후\n",
    "\n",
    "    for task_type, model_info in trained_models.items():\n",
    "        try:\n",
    "            pipeline = model_info['pipeline']\n",
    "            feature_names = model_info['feature_names']\n",
    "            model_name = model_info['model_name']\n",
    "            \n",
    "            # 타겟 컬럼 설정\n",
    "            target_col = \"합계_1일후\" if task_type == \"regression\" else \"등급_1일후\"\n",
    "            \n",
    "            # 예측 데이터 준비\n",
    "            X_future, y_true = prepare_prediction_data(future_data, feature_names, target_col)\n",
    "            \n",
    "            if X_future is None or len(X_future) == 0:\n",
    "                print(f\"    {task_type} 예측 데이터 준비 실패\")\n",
    "                continue\n",
    "            \n",
    "            # 예측 수행\n",
    "            y_pred = pipeline.predict(X_future)\n",
    "            # 타입 보정\n",
    "            if task_type == \"classification\":\n",
    "                # numpy 타입 포함 -> 파이썬 int로\n",
    "                y_pred = [int(v) for v in y_pred]\n",
    "            \n",
    "            print(f\"    {task_type} 예측 완료: {len(y_pred)}개\")\n",
    "            \n",
    "            # 결과 저장\n",
    "            for i in range(len(X_future)):\n",
    "                actual_val = (y_true.iloc[i] if (y_true is not None and i < len(y_true) and not pd.isna(y_true.iloc[i])) else None)\n",
    "                \n",
    "                pred_result = {\n",
    "                    'date': future_data.iloc[i]['날짜'],\n",
    "                    'center': center_name,\n",
    "                    'task_type': task_type,\n",
    "                    'model_name': model_name,\n",
    "                    'target_column': target_col,\n",
    "                    # 'actual_value': y_true.iloc[i] if i < len(y_true) and not pd.isna(y_true.iloc[i]) else None,\n",
    "                    'actual_value': actual_val,\n",
    "                    # 'predicted_value': float(y_pred[i])\n",
    "                    'predicted_value': int(y_pred[i]) if task_type=='classification' else float(y_pred[i])\n",
    "                }\n",
    "                predictions.append(pred_result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    {task_type} 예측 실패: {e}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def prepare_prediction_data(future_data, expected_features, target_col):\n",
    "    \"\"\"예측용 데이터 전처리\"\"\"\n",
    "    \n",
    "    # 제외할 컬럼들\n",
    "    not_use_col = [\n",
    "        '날짜',\n",
    "        '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "        '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "        '등급','등급_1일후','등급_2일후'\n",
    "    ]\n",
    "    \n",
    "    # 피처 데이터 준비\n",
    "    drop_cols = [c for c in (set(not_use_col) | {target_col}) if c in future_data.columns]\n",
    "    X_future = future_data.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    \n",
    "    # 수치형 변환\n",
    "    for c in X_future.columns:\n",
    "        X_future[c] = pd.to_numeric(X_future[c], errors=\"coerce\")\n",
    "    \n",
    "    # 실제값 추출\n",
    "    y_true = None\n",
    "    if target_col in future_data.columns:\n",
    "        if target_col == \"등급_1일후\":\n",
    "            y_true = pd.to_numeric(future_data[target_col], errors=\"coerce\").astype(\"Int64\")\n",
    "        else:\n",
    "            y_true = pd.to_numeric(future_data[target_col], errors=\"coerce\")\n",
    "    \n",
    "    # 피처 순서 맞춤 및 누락 피처 처리\n",
    "    missing_features = set(expected_features) - set(X_future.columns)\n",
    "    if missing_features:\n",
    "        for feature in missing_features:\n",
    "            X_future[feature] = 0\n",
    "    \n",
    "    # 피처 순서 맞춤\n",
    "    X_future = X_future[expected_features].copy()\n",
    "    \n",
    "    return X_future, y_true\n",
    "\n",
    "def create_final_results_table(all_predictions):\n",
    "    \"\"\"최종 결과 테이블 생성\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(all_predictions)\n",
    "    \n",
    "    # 날짜 정렬\n",
    "    results_df = results_df.sort_values(['date', 'center', 'task_type'])\n",
    "    \n",
    "    # 평가 지표 계산\n",
    "    results_df = calculate_prediction_metrics_enhanced(results_df)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def calculate_prediction_metrics_enhanced(results_df):\n",
    "    \"\"\"향상된 예측 평가 지표 계산\"\"\"\n",
    "    \n",
    "    results_df = results_df.copy()\n",
    "    \n",
    "    # 평가 지표 컬럼 초기화\n",
    "    results_df['absolute_error'] = None\n",
    "    results_df['squared_error'] = None\n",
    "    results_df['percentage_error'] = None\n",
    "    results_df['correct_prediction'] = None\n",
    "    results_df['residual'] = None\n",
    "    \n",
    "    for idx, row in results_df.iterrows():\n",
    "        if pd.isna(row['actual_value']) or pd.isna(row['predicted_value']):\n",
    "            continue\n",
    "            \n",
    "        actual = row['actual_value']\n",
    "        predicted = row['predicted_value']\n",
    "        \n",
    "        if row['task_type'] == 'regression':\n",
    "            # 회귀 평가 지표\n",
    "            residual = actual - predicted\n",
    "            abs_error = abs(residual)\n",
    "            sq_error = residual ** 2\n",
    "            pct_error = abs(residual) / (abs(actual) + 1e-8) * 100\n",
    "            \n",
    "            results_df.at[idx, 'residual'] = residual\n",
    "            results_df.at[idx, 'absolute_error'] = abs_error\n",
    "            results_df.at[idx, 'squared_error'] = sq_error\n",
    "            results_df.at[idx, 'percentage_error'] = pct_error\n",
    "            \n",
    "        else:  # classification\n",
    "            # 분류 평가 지표\n",
    "            correct = 1 if int(actual) == int(predicted) else 0\n",
    "            results_df.at[idx, 'correct_prediction'] = correct\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def create_performance_summary(results_df):\n",
    "    \"\"\"성능 요약 생성\"\"\"\n",
    "    \n",
    "    summary = {}\n",
    "    \n",
    "    for center in results_df['center'].unique():\n",
    "        center_data = results_df[results_df['center'] == center]\n",
    "        summary[center] = {}\n",
    "        \n",
    "        for task_type in ['regression', 'classification']:\n",
    "            task_data = center_data[center_data['task_type'] == task_type]\n",
    "            task_data_clean = task_data.dropna(subset=['actual_value', 'predicted_value'])\n",
    "            \n",
    "            if len(task_data_clean) > 0:\n",
    "                if task_type == 'regression':\n",
    "                    summary[center]['regression'] = {\n",
    "                        'model_name': task_data_clean.iloc[0]['model_name'],\n",
    "                        'prediction_count': len(task_data_clean),\n",
    "                        'mae': task_data_clean['absolute_error'].mean(),\n",
    "                        'rmse': np.sqrt(task_data_clean['squared_error'].mean()),\n",
    "                        'mape': task_data_clean['percentage_error'].mean(),\n",
    "                        'r2_on_predictions': calculate_r2_on_predictions(\n",
    "                            task_data_clean['actual_value'], \n",
    "                            task_data_clean['predicted_value']\n",
    "                        )\n",
    "                    }\n",
    "                else:\n",
    "                    summary[center]['classification'] = {\n",
    "                        'model_name': task_data_clean.iloc[0]['model_name'],\n",
    "                        'prediction_count': len(task_data_clean),\n",
    "                        'accuracy': task_data_clean['correct_prediction'].mean(),\n",
    "                        'correct_count': int(task_data_clean['correct_prediction'].sum()),\n",
    "                        'total_count': len(task_data_clean)\n",
    "                    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def calculate_r2_on_predictions(y_true, y_pred):\n",
    "    \"\"\"예측값에 대한 R² 계산\"\"\"\n",
    "    from sklearn.metrics import r2_score\n",
    "    y_true = pd.Series(y_true).astype(float)\n",
    "    y_pred = pd.Series(y_pred).astype(float)\n",
    "    if len(y_true) < 2:\n",
    "        return None\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def print_final_results(results_df, performance_summary):\n",
    "    \"\"\"최종 결과 출력\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"=== 최종 예측 결과 요약 ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 전체 요약\n",
    "    total_predictions = len(results_df)\n",
    "    date_range = f\"{results_df['date'].min()} ~ {results_df['date'].max()}\"\n",
    "    centers = results_df['center'].unique()\n",
    "    \n",
    "    print(f\"예측 기간: {date_range}\")\n",
    "    print(f\"총 예측 건수: {total_predictions}\")\n",
    "    print(f\"센터 수: {len(centers)} ({', '.join(centers)})\")\n",
    "    \n",
    "    # 센터별 성능 요약\n",
    "    for center, perf in performance_summary.items():\n",
    "        print(f\"\\n--- {center.upper()} 센터 성능 ---\")\n",
    "        \n",
    "        if 'regression' in perf:\n",
    "            reg = perf['regression']\n",
    "            print(f\"  회귀 ({reg['model_name']}):\")\n",
    "            print(f\"    예측 건수: {reg['prediction_count']}\")\n",
    "            print(f\"    MAE: {reg['mae']:.2f}\")\n",
    "            print(f\"    RMSE: {reg['rmse']:.2f}\")\n",
    "            print(f\"    MAPE: {reg['mape']:.1f}%\")\n",
    "            if reg['r2_on_predictions'] is not None:\n",
    "                print(f\"    R²: {reg['r2_on_predictions']:.3f}\")\n",
    "        \n",
    "        if 'classification' in perf:\n",
    "            clf = perf['classification']\n",
    "            print(f\"  분류 ({clf['model_name']}):\")\n",
    "            print(f\"    예측 건수: {clf['prediction_count']}\")\n",
    "            print(f\"    정확도: {clf['accuracy']:.1%}\")\n",
    "            print(f\"    정답 개수: {clf['correct_count']}/{clf['total_count']}\")\n",
    "    \n",
    "    # 결과 테이블 미리보기\n",
    "    print(f\"\\n--- 결과 테이블 미리보기 ---\")\n",
    "    display_columns = ['date', 'center', 'task_type', 'model_name', 'actual_value', 'predicted_value']\n",
    "    if all(col in results_df.columns for col in display_columns):\n",
    "        print(results_df[display_columns].head(10).to_string(index=False))\n",
    "\n",
    "def save_final_results(results_df, performance_summary, training_results_df):\n",
    "    \"\"\"최종 결과 저장\"\"\"\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_filename = f\"production_simulation_{timestamp}\"\n",
    "    \n",
    "    try:\n",
    "        # 1. 예측 결과 테이블 저장\n",
    "        results_filename = f\"{base_filename}_predictions.csv\"\n",
    "        results_df.to_csv(results_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\n예측 결과 저장: {results_filename}\")\n",
    "        \n",
    "        # 2. 성능 요약 저장\n",
    "        summary_data = []\n",
    "        for center, perf in performance_summary.items():\n",
    "            for task_type, metrics in perf.items():\n",
    "                summary_row = {'center': center, 'task_type': task_type}\n",
    "                summary_row.update(metrics)\n",
    "                summary_data.append(summary_row)\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_filename = f\"{base_filename}_summary.csv\"\n",
    "            summary_df.to_csv(summary_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"성능 요약 저장: {summary_filename}\")\n",
    "        \n",
    "        # 3. 학습 결과 저장\n",
    "        if len(training_results_df) > 0:\n",
    "            training_filename = f\"{base_filename}_training.csv\"\n",
    "            training_results_df.to_csv(training_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"학습 결과 저장: {training_filename}\")\n",
    "        \n",
    "        print(f\"\\n모든 결과가 저장되었습니다. 파일명 접두사: {base_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"결과 저장 중 오류 발생: {e}\")\n",
    "\n",
    "# ================================================================================================\n",
    "# 메인 실행 함수\n",
    "# ================================================================================================\n",
    "\n",
    "# ================================================================================================\n",
    "# 메인 실행 함수 (✅ 수정된 버전)\n",
    "# ================================================================================================\n",
    "\n",
    "def run_complete_production_pipeline(cutoff_date='2025-05-20'):\n",
    "    \"\"\"완전한 파이프라인 실행\"\"\"\n",
    "    \n",
    "    print(\"완전한 운영 환경 시뮬레이션 파이프라인을 시작합니다...\")\n",
    "    print(\"이 과정은 다소 시간이 걸릴 수 있습니다.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 데이터 로드 (이 부분은 실행기에서 직접 처리하는 것이 더 명확합니다)\n",
    "    try:\n",
    "        nanji_raw = pd.read_csv('../data/processed/center_season/nanji/난지_merged.csv', encoding='utf-8-sig')\n",
    "        jungnang_raw = pd.read_csv('../data/processed/center_season/jungnang/중랑_merged.csv', encoding='utf-8-sig')\n",
    "        seonam_raw = pd.read_csv('../data/processed/center_season/seonam/서남_merged.csv', encoding='utf-8-sig')\n",
    "        tancheon_raw = pd.read_csv('../data/processed/center_season/tancheon/탄천_merged.csv', encoding='utf-8-sig')\n",
    "        \n",
    "        centers = {\n",
    "            \"nanji\": nanji_raw,\n",
    "            \"jungnang\": jungnang_raw,\n",
    "            \"seonam\": seonam_raw,\n",
    "            \"tancheon\": tancheon_raw\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"원본 데이터 파일 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 핵심 파이프라인 함수 호출 (자기 자신이 아닌!)\n",
    "    results = complete_production_simulation_pipeline(centers=centers, cutoff_date=cutoff_date)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"파이프라인 실행 완료!\")\n",
    "    print(f\"총 소요시간: {elapsed_time:.1f}초 ({elapsed_time/60:.1f}분)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# 사용 예시\n",
    "# ================================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 완전한 운영 환경 시뮬레이션 파이프라인 ===\")\n",
    "    print()\n",
    "    print(\"사용법:\")\n",
    "    print(\"results = run_complete_production_pipeline()\")\n",
    "    print()\n",
    "    print(\"또는 cutoff_date를 변경하여:\")\n",
    "    print(\"results = run_complete_production_pipeline(cutoff_date='2025-05-15')\")\n",
    "    print()\n",
    "    print(\"반환값:\")\n",
    "    print(\"- results[0]: 최종 예측 결과 테이블\")\n",
    "    print(\"- results[1]: 학습된 모델 정보\")  \n",
    "    print(\"- results[2]: 성능 요약\")\n",
    "    print()\n",
    "    print(\"생성되는 파일:\")\n",
    "    print(\"- production_simulation_YYYYMMDD_HHMMSS_predictions.csv\")\n",
    "    print(\"- production_simulation_YYYYMMDD_HHMMSS_summary.csv\")\n",
    "    print(\"- production_simulation_YYYYMMDD_HHMMSS_training.csv\")\n",
    "\n",
    "# 완전한 파이프라인 실행\n",
    "results = run_complete_production_pipeline(cutoff_date='2025-05-20')\n",
    "\n",
    "# 결과 확인\n",
    "final_table, trained_models, performance_summary = results\n",
    "print(final_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================================\n",
    "# 1. 수정된 make_features 함수\n",
    "# ================================================================================================\n",
    "\n",
    "def make_features(df, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    파생변수 생성 함수 - Data Leakage 방지 버전\n",
    "    \n",
    "    Parameters:\n",
    "    - df: 원본 데이터\n",
    "    - cutoff_date: 타겟 변수 생성 제한 날짜 (None이면 전체 데이터 사용)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 날짜 정리 및 정렬\n",
    "    df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "    df = df.sort_values('날짜').reset_index(drop=True)\n",
    "\n",
    "    # 달/요일 숫자\n",
    "    df['월'] = df['날짜'].dt.month\n",
    "    df['요일'] = df['날짜'].dt.weekday\n",
    "\n",
    "    # 계절/불쾌지수등급 숫자 매핑\n",
    "    season_map = {'봄': 0, '여름': 1, '가을': 2, '겨울': 3}\n",
    "    discomfort_map = {'쾌적': 0, '약간 불쾌': 1, '불쾌': 2, '매우 불쾌': 3, '극심한 불쾌': 4}\n",
    "    df['계절'] = df['계절'].map(season_map).astype('Int64')\n",
    "    df['불쾌지수등급'] = df['불쾌지수등급'].map(discomfort_map).astype('Int64')\n",
    "\n",
    "    # 강수량 시차 피처\n",
    "    df['강수량_1일전'] = df['일_일강수량(mm)'].shift(1)\n",
    "    df['강수량_2일전'] = df['일_일강수량(mm)'].shift(2)\n",
    "    df['강수량_1일_누적'] = df['일_일강수량(mm)'].rolling(1, min_periods=1).sum()\n",
    "    df['강수량_2일_누적'] = df['일_일강수량(mm)'].rolling(2, min_periods=1).sum()\n",
    "    df['강수량_3일_누적'] = df['일_일강수량(mm)'].rolling(3, min_periods=1).sum()\n",
    "    df['강수량_5일_누적'] = df['일_일강수량(mm)'].rolling(5, min_periods=1).sum()\n",
    "    df['강수량_7일_누적'] = df['일_일강수량(mm)'].rolling(7, min_periods=1).sum()\n",
    "\n",
    "    df['일교차'] = df['일_최고기온(°C)'] - df['일_최저기온(°C)']\n",
    "    df['폭우_여부'] = (df['일_일강수량(mm)'] >= 80).astype(int)\n",
    "    \n",
    "    # 체감온도 계산\n",
    "    if '일_평균기온(°C)' in df.columns:\n",
    "        T = pd.to_numeric(df['일_평균기온(°C)'], errors='coerce')\n",
    "    else:\n",
    "        T = pd.Series(np.nan, index=df.index)\n",
    "    if '일_평균풍속(m/s)' in df.columns:\n",
    "        V_ms = pd.to_numeric(df['일_평균풍속(m/s)'], errors='coerce')\n",
    "    else:\n",
    "        V_ms = pd.Series(np.nan, index=df.index)\n",
    "    if '평균습도(%)' in df.columns:\n",
    "        RH = pd.to_numeric(df['평균습도(%)'], errors='coerce')\n",
    "    else:\n",
    "        RH = pd.Series(np.nan, index=df.index)\n",
    "\n",
    "    # 윈드칠\n",
    "    V_kmh = V_ms * 3.6\n",
    "    wct_raw = 13.12 + 0.6215*T - 11.37*np.power(V_kmh, 0.16) + 0.3965*T*np.power(V_kmh, 0.16)\n",
    "    wc_valid = (T <= 10.0) & (V_kmh >= 4.8)\n",
    "    wct = T.copy()\n",
    "    wct[wc_valid] = wct_raw[wc_valid]\n",
    "\n",
    "    # 열지수\n",
    "    T_f = T * 9/5 + 32\n",
    "    HI_f = (-42.379 + 2.04901523*T_f + 10.14333127*RH\n",
    "            - 0.22475541*T_f*RH - 0.00683783*T_f**2 - 0.05481717*RH**2\n",
    "            + 0.00122874*T_f**2*RH + 0.00085282*T_f*RH**2\n",
    "            - 0.00000199*T_f**2*RH**2)\n",
    "    mask_low = (RH < 13) & (T_f >= 80) & (T_f <= 112)\n",
    "    adj_low = ((13 - RH)/4) * np.sqrt((17 - np.abs(T_f - 95))/17)\n",
    "    HI_f = HI_f.where(~mask_low, HI_f - adj_low)\n",
    "    mask_high = (RH > 85) & (T_f >= 80) & (T_f <= 87)\n",
    "    adj_high = ((RH - 85)/10) * ((87 - T_f)/5)\n",
    "    HI_f = HI_f.where(~mask_high, HI_f + adj_high)\n",
    "    hi_valid = (T_f >= 80) & (RH >= 40)\n",
    "    HI_c = (HI_f - 32) * 5/9\n",
    "    hi = T.copy()\n",
    "    hi[hi_valid] = HI_c[hi_valid]\n",
    "\n",
    "    # 스테드먼 체감온도\n",
    "    e = (RH/100.0) * 6.105 * np.exp(17.27*T/(237.7 + T))\n",
    "    at = T + 0.33*e - 0.70*V_ms - 4.00\n",
    "\n",
    "    # 최종 체감온도\n",
    "    apparent = at.copy()\n",
    "    apparent[hi_valid] = hi[hi_valid]\n",
    "    apparent[wc_valid] = wct[wc_valid]\n",
    "    df['체감온도(°C)'] = apparent\n",
    "    \n",
    "    # 분류용 등급 계산\n",
    "    q = df['합계'].dropna().quantile([0.15, 0.70, 0.90])\n",
    "    q15, q70, q90 = float(q.loc[0.15]), float(q.loc[0.70]), float(q.loc[0.90])\n",
    "\n",
    "    def categorize(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        if x < q15:\n",
    "            return 0\n",
    "        elif x < q70:\n",
    "            return 1\n",
    "        elif x < q90:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    df['등급'] = df['합계'].apply(categorize)\n",
    "    \n",
    "    # 타겟 변수 생성 (핵심 수정 부분)\n",
    "    if cutoff_date is not None:\n",
    "        cutoff = pd.to_datetime(cutoff_date)\n",
    "        \n",
    "        # 타겟 변수 초기화\n",
    "        df['합계_1일후'] = np.nan\n",
    "        df['합계_2일후'] = np.nan\n",
    "        df['등급_1일후'] = np.nan\n",
    "        df['등급_2일후'] = np.nan\n",
    "        \n",
    "        # cutoff_date 내에서만 타겟 변수 생성\n",
    "        for i in range(len(df)):\n",
    "            current_date = df.loc[i, '날짜']\n",
    "            \n",
    "            if i + 1 < len(df) and current_date <= cutoff:\n",
    "                next_date = df.loc[i+1, '날짜']\n",
    "                if next_date <= cutoff:\n",
    "                    df.loc[i, '합계_1일후'] = df.loc[i+1, '합계']\n",
    "                    df.loc[i, '등급_1일후'] = df.loc[i+1, '등급']\n",
    "            \n",
    "            if i + 2 < len(df) and current_date <= cutoff:\n",
    "                next2_date = df.loc[i+2, '날짜']\n",
    "                if next2_date <= cutoff:\n",
    "                    df.loc[i, '합계_2일후'] = df.loc[i+2, '합계']\n",
    "                    df.loc[i, '등급_2일후'] = df.loc[i+2, '등급']\n",
    "    else:\n",
    "        # 기존 방식\n",
    "        df['합계_1일후'] = df['합계'].shift(-1)\n",
    "        df['합계_2일후'] = df['합계'].shift(-2)\n",
    "        df['등급_1일후'] = df['등급'].shift(-1).astype('Int64')\n",
    "        df['등급_2일후'] = df['등급'].shift(-2).astype('Int64')\n",
    "\n",
    "    # 컷 기준 저장\n",
    "    df.attrs['cutoffs'] = {\"q15\": q15, \"q70\": q70, \"q90\": q90}\n",
    "\n",
    "    # 결측 제거 및 리셋\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # 6월 데이터 제거\n",
    "    df = df[df[\"날짜\"] < \"2025-06-01\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ================================================================================================\n",
    "# 2. 예측용 파생변수 생성 함수\n",
    "# ================================================================================================\n",
    "\n",
    "def make_features_for_prediction(historical_df, future_df):\n",
    "    \"\"\"새로운 데이터에 대한 파생변수 생성 (과거 데이터 활용)\"\"\"\n",
    "    \n",
    "    # 전체 데이터 결합\n",
    "    combined_df = pd.concat([historical_df, future_df], ignore_index=True)\n",
    "    combined_df['날짜'] = pd.to_datetime(combined_df['날짜'])\n",
    "    combined_df = combined_df.sort_values('날짜').reset_index(drop=True)\n",
    "    \n",
    "    # 기본 파생변수들만 생성 (lag 변수 중심)\n",
    "    combined_df['월'] = combined_df['날짜'].dt.month\n",
    "    combined_df['요일'] = combined_df['날짜'].dt.weekday\n",
    "    \n",
    "    # 계절/불쾌지수 매핑\n",
    "    season_map = {'봄': 0, '여름': 1, '가을': 2, '겨울': 3}\n",
    "    discomfort_map = {'쾌적': 0, '약간 불쾌': 1, '불쾌': 2, '매우 불쾌': 3, '극심한 불쾌': 4}\n",
    "    combined_df['계절'] = combined_df['계절'].map(season_map).astype('Int64')\n",
    "    combined_df['불쾌지수등급'] = combined_df['불쾌지수등급'].map(discomfort_map).astype('Int64')\n",
    "    \n",
    "    # 시차 변수들\n",
    "    combined_df['강수량_1일전'] = combined_df['일_일강수량(mm)'].shift(1)\n",
    "    combined_df['강수량_2일전'] = combined_df['일_일강수량(mm)'].shift(2)\n",
    "    combined_df['강수량_1일_누적'] = combined_df['일_일강수량(mm)'].rolling(1, min_periods=1).sum()\n",
    "    combined_df['강수량_2일_누적'] = combined_df['일_일강수량(mm)'].rolling(2, min_periods=1).sum()\n",
    "    combined_df['강수량_3일_누적'] = combined_df['일_일강수량(mm)'].rolling(3, min_periods=1).sum()\n",
    "    combined_df['강수량_5일_누적'] = combined_df['일_일강수량(mm)'].rolling(5, min_periods=1).sum()\n",
    "    combined_df['강수량_7일_누적'] = combined_df['일_일강수량(mm)'].rolling(7, min_periods=1).sum()\n",
    "    \n",
    "    combined_df['일교차'] = combined_df['일_최고기온(°C)'] - combined_df['일_최저기온(°C)']\n",
    "    combined_df['폭우_여부'] = (combined_df['일_일강수량(mm)'] >= 80).astype(int)\n",
    "    \n",
    "    # 체감온도 계산 (동일한 로직)\n",
    "    T = pd.to_numeric(combined_df.get('일_평균기온(°C)', np.nan), errors='coerce')\n",
    "    V_ms = pd.to_numeric(combined_df.get('일_평균풍속(m/s)', np.nan), errors='coerce')\n",
    "    RH = pd.to_numeric(combined_df.get('평균습도(%)', np.nan), errors='coerce')\n",
    "    \n",
    "    # 체감온도 계산 (간단 버전)\n",
    "    e = (RH/100.0) * 6.105 * np.exp(17.27*T/(237.7 + T))\n",
    "    combined_df['체감온도(°C)'] = T + 0.33*e - 0.70*V_ms - 4.00\n",
    "    \n",
    "    # 새 데이터 부분만 반환\n",
    "    historical_len = len(historical_df)\n",
    "    return combined_df.iloc[historical_len:].reset_index(drop=True)\n",
    "\n",
    "# ================================================================================================\n",
    "# 3. 수정된 메인 파이프라인\n",
    "# ================================================================================================\n",
    "\n",
    "def complete_production_simulation_safe(centers=None, cutoff_date='2025-05-20'):\n",
    "    \"\"\"Data Leakage 방지 완전 파이프라인\"\"\"\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Data Leakage 방지 운영 환경 시뮬레이션\")\n",
    "    print(f\"학습 기간: ~ {cutoff_date}\")\n",
    "    print(f\"예측 기간: {cutoff_date} 이후\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if centers is None:\n",
    "        try:\n",
    "            centers = load_original_data()\n",
    "        except:\n",
    "            print(\"데이터를 로드할 수 없습니다.\")\n",
    "            return None\n",
    "    \n",
    "    cutoff = pd.to_datetime(cutoff_date)\n",
    "    all_training_results = []\n",
    "    best_models_by_center = {}\n",
    "    all_predictions = []\n",
    "    \n",
    "    # 각 센터별 처리\n",
    "    for center_name, df_raw in centers.items():\n",
    "        print(f\"\\n[{center_name.upper()} 센터 처리]\")\n",
    "        \n",
    "        # 원본 데이터 날짜 기준 분할\n",
    "        df_raw['날짜'] = pd.to_datetime(df_raw['날짜'])\n",
    "        df_raw = df_raw.sort_values('날짜').reset_index(drop=True)\n",
    "        \n",
    "        raw_train_data = df_raw[df_raw['날짜'] <= cutoff].copy()\n",
    "        raw_future_data = df_raw[df_raw['날짜'] > cutoff].copy()\n",
    "        \n",
    "        print(f\"  원본 학습 데이터: {len(raw_train_data)}행\")\n",
    "        print(f\"  원본 예측 데이터: {len(raw_future_data)}행\")\n",
    "        \n",
    "        if len(raw_train_data) < 50 or len(raw_future_data) == 0:\n",
    "            print(f\"  데이터 부족으로 건너뜀\")\n",
    "            continue\n",
    "        \n",
    "        # 1단계: 학습용 데이터 안전하게 준비\n",
    "        train_data_safe = make_features(raw_train_data, cutoff_date=cutoff_date)\n",
    "        print(f\"  처리된 학습 데이터: {len(train_data_safe)}행\")\n",
    "        \n",
    "        # 2단계: 모델 평가 및 선택\n",
    "        center_results = comprehensive_evaluation_comparison(center_name, train_data_safe)\n",
    "        all_training_results.extend(center_results)\n",
    "        \n",
    "        center_best_models = select_and_train_best_models_safe(center_name, train_data_safe, center_results)\n",
    "        if center_best_models:\n",
    "            best_models_by_center[center_name] = center_best_models\n",
    "        \n",
    "        # 3단계: 예측용 데이터 준비 (과거 정보만 활용)\n",
    "        if len(raw_future_data) > 0 and center_name in best_models_by_center:\n",
    "            future_data_with_features = make_features_for_prediction(raw_train_data, raw_future_data)\n",
    "            \n",
    "            # 4단계: 예측 수행\n",
    "            center_predictions = make_predictions_safe(\n",
    "                center_name, future_data_with_features, best_models_by_center[center_name]\n",
    "            )\n",
    "            all_predictions.extend(center_predictions)\n",
    "    \n",
    "    # 5단계: 결과 정리\n",
    "    if not all_predictions:\n",
    "        print(\"예측 결과가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    final_results_table = create_final_results_table(all_predictions)\n",
    "    performance_summary = create_performance_summary(final_results_table)\n",
    "    \n",
    "    print_final_results(final_results_table, performance_summary)\n",
    "    save_final_results(final_results_table, performance_summary, pd.DataFrame(all_training_results))\n",
    "    \n",
    "    return final_results_table, best_models_by_center, performance_summary\n",
    "\n",
    "def select_and_train_best_models_safe(center_name, train_data, evaluation_results):\n",
    "    \"\"\"안전한 모델 선택 및 학습\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    successful_results = results_df[results_df['success'] == True]\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(f\"    성공한 모델이 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    # 회귀 최고 성능 모델\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"    최고 회귀 모델: {best_reg['model']} (R²={best_reg['r2']:.3f})\")\n",
    "        \n",
    "        reg_pipeline = retrain_on_full_safe_data(train_data, best_reg['model'], 'regression', best_reg['split_method'])\n",
    "        \n",
    "        if reg_pipeline:\n",
    "            best_models['regression'] = {\n",
    "                'model_name': best_reg['model'],\n",
    "                'pipeline': reg_pipeline['pipeline'],\n",
    "                'feature_names': reg_pipeline['feature_names'],\n",
    "                'performance': dict(best_reg),\n",
    "                'split_method': best_reg['split_method']\n",
    "            }\n",
    "    \n",
    "    # 분류 최고 성능 모델\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"    최고 분류 모델: {best_clf['model']} (F1={best_clf['macro_f1']:.3f})\")\n",
    "        \n",
    "        clf_pipeline = retrain_on_full_safe_data(train_data, best_clf['model'], 'classification', best_clf['split_method'])\n",
    "        \n",
    "        if clf_pipeline:\n",
    "            best_models['classification'] = {\n",
    "                'model_name': best_clf['model'],\n",
    "                'pipeline': clf_pipeline['pipeline'],\n",
    "                'feature_names': clf_pipeline['feature_names'],\n",
    "                'performance': dict(best_clf),\n",
    "                'split_method': best_clf['split_method']\n",
    "            }\n",
    "    \n",
    "    return best_models if best_models else None\n",
    "\n",
    "def retrain_on_full_safe_data(train_data, model_name, model_type, split_method):\n",
    "    \"\"\"안전한 전체 데이터 재학습\"\"\"\n",
    "    \n",
    "    try:\n",
    "        target_col = \"합계_1일후\" if model_type == \"regression\" else \"등급_1일후\"\n",
    "        \n",
    "        # 전체 데이터를 train으로 사용 (test_size를 아주 작게)\n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            train_data, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.01, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # 전체 결합\n",
    "        X_all = pd.concat([X_train, X_test], ignore_index=True)\n",
    "        y_all = pd.concat([y_train, y_test], ignore_index=True)\n",
    "        \n",
    "        # 모델 학습\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "        \n",
    "        model = models[model_name]\n",
    "        pipeline = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipeline.fit(X_all, y_all)\n",
    "        \n",
    "        return {'pipeline': pipeline, 'feature_names': feature_names}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    모델 재학습 실패 ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def make_predictions_safe(center_name, future_data, trained_models):\n",
    "    \"\"\"안전한 예측 수행\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for task_type, model_info in trained_models.items():\n",
    "        try:\n",
    "            pipeline = model_info['pipeline']\n",
    "            feature_names = model_info['feature_names']\n",
    "            model_name = model_info['model_name']\n",
    "            \n",
    "            # 예측 데이터 준비\n",
    "            X_future = prepare_prediction_features(future_data, feature_names)\n",
    "            \n",
    "            if X_future is None or len(X_future) == 0:\n",
    "                continue\n",
    "            \n",
    "            # 예측 수행\n",
    "            y_pred = pipeline.predict(X_future)\n",
    "            print(f\"    {task_type} 예측 완료: {len(y_pred)}개\")\n",
    "            \n",
    "            # 결과 저장\n",
    "            for i in range(len(X_future)):\n",
    "                pred_result = {\n",
    "                    'date': future_data.iloc[i]['날짜'],\n",
    "                    'center': center_name,\n",
    "                    'task_type': task_type,\n",
    "                    'model_name': model_name,\n",
    "                    'target_column': \"합계_1일후\" if task_type == \"regression\" else \"등급_1일후\",\n",
    "                    'actual_value': None,  # 운영 환경에서는 모름\n",
    "                    'predicted_value': float(y_pred[i])\n",
    "                }\n",
    "                predictions.append(pred_result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    {task_type} 예측 실패: {e}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def prepare_prediction_features(future_data, expected_features):\n",
    "    \"\"\"예측용 피처 준비\"\"\"\n",
    "    \n",
    "    not_use_col = [\n",
    "        '날짜', '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "        '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "        '등급','등급_1일후','등급_2일후'\n",
    "    ]\n",
    "    \n",
    "    # 피처 선택\n",
    "    available_cols = [col for col in future_data.columns if col not in not_use_col]\n",
    "    X_future = future_data[available_cols].copy()\n",
    "    \n",
    "    # 수치형 변환\n",
    "    for c in X_future.columns:\n",
    "        X_future[c] = pd.to_numeric(X_future[c], errors=\"coerce\")\n",
    "    \n",
    "    # 누락된 피처 처리\n",
    "    missing_features = set(expected_features) - set(X_future.columns)\n",
    "    if missing_features:\n",
    "        for feature in missing_features:\n",
    "            X_future[feature] = 0\n",
    "    \n",
    "    # 피처 순서 맞춤\n",
    "    X_future = X_future[expected_features].copy()\n",
    "    \n",
    "    return X_future\n",
    "\n",
    "def load_original_data():\n",
    "    \"\"\"원본 데이터 로드\"\"\"\n",
    "    nanji_raw = pd.read_csv('../data/processed/center_season/nanji/난지_merged.csv', encoding='utf-8-sig')\n",
    "    jungnang_raw = pd.read_csv('../data/processed/center_season/jungnang/중랑_merged.csv', encoding='utf-8-sig')\n",
    "    seonam_raw = pd.read_csv('../data/processed/center_season/seonam/서남_merged.csv', encoding='utf-8-sig')\n",
    "    tancheon_raw = pd.read_csv('../data/processed/center_season/tancheon/탄천_merged.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    return {\n",
    "        \"nanji\": nanji_raw,\n",
    "        \"jungnang\": jungnang_raw,\n",
    "        \"seonam\": seonam_raw,\n",
    "        \"tancheon\": tancheon_raw\n",
    "    }\n",
    "\n",
    "# ================================================================================================\n",
    "# 4. 실행 함수\n",
    "# ================================================================================================\n",
    "\n",
    "def run_safe_production_pipeline(cutoff_date='2025-05-20'):\n",
    "    \"\"\"안전한 파이프라인 실행\"\"\"\n",
    "    \n",
    "    print(\"Data Leakage 방지 파이프라인을 시작합니다...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 파이프라인 실행\n",
    "    results = complete_production_simulation_safe(cutoff_date=cutoff_date)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n파이프라인 실행 완료! 소요시간: {elapsed_time:.1f}초\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# 5. 사용 방법\n",
    "# ================================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Data Leakage 방지 운영 환경 시뮬레이션 ===\")\n",
    "    print()\n",
    "    print(\"사용법:\")\n",
    "    print(\"results = run_safe_production_pipeline(cutoff_date='2025-05-20')\")\n",
    "    print()\n",
    "    print(\"특징:\")\n",
    "    print(\"- 5월 20일까지만 학습용 타겟 변수 생성\")\n",
    "    print(\"- 5월 21일 이후는 완전히 새로운 데이터로 취급\")\n",
    "    print(\"- 파생변수는 과거 정보만 활용해서 생성\")\n",
    "    print(\"- 모델은 절대 재학습하지 않음\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 모든 코드 위에 이 코드를 추가하고\n",
    "results = run_safe_production_pipeline(cutoff_date='2025-05-20')\n",
    "\n",
    "# ================================================================================================\n",
    "# 최종 파이프라인 실행\n",
    "# ================================================================================================\n",
    "\n",
    "# 이 함수 하나만 호출하면 위에서 정의한 모든 과정이 자동으로 실행됩니다.\n",
    "results = run_safe_production_pipeline(cutoff_date='2025-05-20')\n",
    "\n",
    "# 결과 확인 (오류 없이 실행 완료되었을 경우)\n",
    "if results:\n",
    "    final_table, trained_models, performance_summary = results\n",
    "    print(\"\\n--- 최종 결과 테이블 미리보기 ---\")\n",
    "    print(final_table.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
