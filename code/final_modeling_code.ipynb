{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94e4cb0",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ë§ ì „ëžµ\n",
    "\n",
    "## ë°ì´í„° ë¶„í• \n",
    "    1. 2025ë…„ 5ì›” 20ì¼ ë°ì´í„°ê¹Œì§€ë§Œ train, testë¡œ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í‰ê°€ ë“± ê²°ê³¼ë‚´ê¸°\n",
    "    2. 2025ë…„ 5ì›” 21ì¼ë¶€í„° 31ì¼ê¹Œì§€ ë°ì´í„°ë¥¼ ì§€ê¸ˆì€ ì •ë‹µì„ ê°€ì§€ê³  ìžˆì§€ë§Œ ì‹¤ì œëŠ” ì—†ë‹¤ê³  ê°€ì •í•˜ê³  ì˜ˆì¸¡í•´ë³´ê¸°(ì¦‰ í•©ê³„_1ì¼í›„, ë“±ê¸‰_1ì¼í›„ë¥¼ ì‹¤ì œ ìƒí™©ì²˜ëŸ¼ ì˜ˆì¸¡í•´ë³´ê¸°)\n",
    "\n",
    "## ëª¨ë¸ë§ ë°©ë²•\n",
    "    1. 1ì¼ í›„ì˜ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ì„ ê°ê° í•©ê³„_1ì¼í›„, ë“±ê¸‰_1ì¼í›„ ì»¬ëŸ¼ì„ ìƒì„±\n",
    "    2. íŒŒìƒë³€ìˆ˜ ë§Œë“œëŠ” í•¨ìˆ˜ ìž‘ì„± -> ì´ê±´ ì¶”í›„ì— ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì™€ë„ ì•Œì•„ì„œ ê³„ì‚°ë  ìˆ˜ ìž‡ë„ë¡ í•´ì•¼í•¨\n",
    "    3. ëª¨ë¸ë§ì€ ë¶„ë¥˜, íšŒê·€ ê°ê°ì— ëŒ€í•´ randomforest, xgboost, catboost, lightgbm, gradientboost ê°œì”© í‰ê°€ (ê°ê° ê²°ê³¼ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ì •ë¦¬í•˜ê³  ì‹œê°í™” ë¹„êµìžë£Œ)\n",
    "    4. ì„¼í„°ë³„ ë¶„ë¥˜, íšŒê·€ ëª¨ë¸ë³„ë¡œ ê°€ìž¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì— ëŒ€í•´(ì¢‹ì€ ëª¨ë¸ì— ëŒ€í•œ ê¸°ì¤€ì´ ìžˆì–´ì•¼í•¨) ìƒˆë¡œìš´ë°ì´í„°ê°€ ë“¤ì–´ì™€ë„ ì˜ˆì¸¡í•  ìˆ˜ ìžˆë„ë¡ í•´ì•¼í•¨\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80a9c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, platform, random, time, json, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix,\n",
    ")\n",
    "\n",
    "# ì„ íƒì  ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸\n",
    "try:\n",
    "    import xgboost as xgb; HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False; print(\"XGBoost ë¯¸ì„¤ì¹˜ â†’ ê±´ë„ˆëœ€\")\n",
    "try:\n",
    "    import lightgbm as lgb; HAS_LGB = True\n",
    "except ImportError:\n",
    "    HAS_LGB = False; print(\"LightGBM ë¯¸ì„¤ì¹˜ â†’ ê±´ë„ˆëœ€\")\n",
    "try:\n",
    "    import catboost as cb; HAS_CATBOOST = True\n",
    "except ImportError:\n",
    "    HAS_CATBOOST = False; print(\"CatBoost ë¯¸ì„¤ì¹˜ â†’ ê±´ë„ˆëœ€\")\n",
    "try:\n",
    "    import shap; HAS_SHAP = True\n",
    "except ImportError:\n",
    "    HAS_SHAP = False; print(\"SHAP ë¯¸ì„¤ì¹˜ â†’ ê±´ë„ˆëœ€\")\n",
    "\n",
    "# ê²½ê³  í•„í„°\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "\n",
    "try:\n",
    "    plt.rcParams['font.family'] = 'AppleGothic' # ë§¥\n",
    "except Exception:\n",
    "    plt.rcParams['font.family'] ='Malgun Gothic' # ìœˆë„ìš°\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e752e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì™„ì„±ëœ Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ ì‹¤í—˜ ===\n",
      "\n",
      "ðŸ“ ê²°ê³¼ ì €ìž¥ êµ¬ì¡°:\n",
      "../data/results/\n",
      "â”œâ”€â”€ stratified_comparison/  # ë¶„í•  ë°©ë²• ë¹„êµ ê²°ê³¼\n",
      "â”‚   â”œâ”€â”€ stratified_comparison_YYYYMMDD_HHMMSS.csv\n",
      "â”‚   â”œâ”€â”€ stratified_summary_YYYYMMDD_HHMMSS.csv\n",
      "â”‚   â””â”€â”€ stratified_best_models_YYYYMMDD_HHMMSS.csv\n",
      "â”œâ”€â”€ feature_importance/     # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„\n",
      "â”‚   â””â”€â”€ importance_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.csv\n",
      "â”œâ”€â”€ shap_analysis/         # SHAP ë¶„ì„ ê²°ê³¼\n",
      "â”‚   â”œâ”€â”€ shap_values_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.pkl\n",
      "â”‚   â””â”€â”€ shap_summary_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.csv\n",
      "â”œâ”€â”€ model_performance/     # ëª¨ë¸ ì„±ëŠ¥ ìƒì„¸ ë¶„ì„\n",
      "â”‚   â””â”€â”€ performance_YYYYMMDD_HHMMSS.csv\n",
      "â””â”€â”€ visualizations/        # ìƒì„±ëœ ê·¸ëž˜í”„ ì´ë¯¸ì§€\n",
      "    â”œâ”€â”€ stratified_comparison_plots_YYYYMMDD_HHMMSS.png\n",
      "    â”œâ”€â”€ feature_importance_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.png\n",
      "    â””â”€â”€ shap_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.png\n",
      "\n",
      "ðŸš€ ì‹¤í–‰ ë°©ë²•:\n",
      "1. ì „ì²´ ì‹¤í—˜ (ê¶Œìž¥): \n",
      "   results_df = run_stratified_comparison()\n",
      "\n",
      "2. ë‹¨ì¼ ì„¼í„° í…ŒìŠ¤íŠ¸:\n",
      "   results_df = quick_stratified_test('nanji')\n",
      "\n",
      "3. ê²°ê³¼ ë¶„ì„ë§Œ:\n",
      "   analyze_stratified_comparison(results_df)\n",
      "\n",
      "ðŸ’¡ ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
      "- CatBoost íšŒê·€ ëª¨ë¸ ì˜¤ë¥˜ ìˆ˜ì •\n",
      "- CatBoost ë¶„ë¥˜ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ ìˆ˜ì •\n",
      "- ì²´ê³„ì ì¸ í´ë” êµ¬ì¡°ë¡œ ê²°ê³¼ ì €ìž¥\n",
      "- Feature Importance & SHAP ë¶„ì„ ê²°ê³¼ ì €ìž¥\n",
      "- ì‹œê°í™” ì´ë¯¸ì§€ ìžë™ ì €ìž¥\n",
      "- ìš”ì•½ í†µê³„ ë° ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ìž¥\n",
      "- ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì¶”ì  ê°€ëŠ¥\n",
      "\n",
      "ðŸ“Š ì‹¤í—˜ êµ¬ì„±:\n",
      "- 4ê°œ ì„¼í„° (nanji, jungnang, seonam, tancheon)\n",
      "- 2ê°€ì§€ ë¶„í• ë°©ë²• (temporal, stratified)\n",
      "- 12ê°œ ëª¨ë¸ (íšŒê·€ 6ê°œ + ë¶„ë¥˜ 6ê°œ)\n",
      "- ì´ 96ê°œ ì‹¤í—˜ (4Ã—2Ã—12)\n",
      "\n",
      "ðŸ“ˆ í‰ê°€ ì§€í‘œ:\n",
      "íšŒê·€: RÂ², MAE, RMSE, MAPE\n",
      "ë¶„ë¥˜: Accuracy, Macro F1, Weighted F1, Extreme F1\n",
      "\n",
      "âš ï¸ ì‚¬ìš© ì „ í™•ì¸ì‚¬í•­:\n",
      "1. ë°ì´í„° ì¤€ë¹„: nanji, jungnang, seonam, tancheon ë³€ìˆ˜ê°€ ë¡œë“œë˜ì–´ ìžˆì–´ì•¼ í•¨\n",
      "2. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: pandas, numpy, matplotlib, sklearn ë“±\n",
      "3. ì„ íƒ ë¼ì´ë¸ŒëŸ¬ë¦¬: xgboost, lightgbm, catboost, shap\n",
      "4. ì‹¤í–‰ ê¶Œí•œ: ../data/results/ í´ë” ìƒì„± ê¶Œí•œ í•„ìš”\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# 2. ëª¨ë¸ ì •ì˜ í•¨ìˆ˜ë“¤ (ì˜¤ë¥˜ ìˆ˜ì •ë¨)\n",
    "# ================================================================================================\n",
    "def build_regression_models():\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ë“¤\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    models[\"RandomForest_Reg\"] = RandomForestRegressor(\n",
    "        n_estimators=300, min_samples_leaf=2, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    models[\"LinearRegression\"] = LinearRegression()\n",
    "    \n",
    "    models[\"GradientBoosting_Reg\"] = GradientBoostingRegressor(\n",
    "        n_estimators=200, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    if HAS_XGB:\n",
    "        models[\"XGBoost_Reg\"] = xgb.XGBRegressor(\n",
    "            n_estimators=400, max_depth=5, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models[\"LightGBM_Reg\"] = lgb.LGBMRegressor(\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbosity=-1\n",
    "        )\n",
    "    \n",
    "    # ìˆ˜ì •: íšŒê·€ ëª¨ë¸ë¡œ ì •ì •\n",
    "    if HAS_CATBOOST:\n",
    "        models[\"CatBoost_Reg\"] = cb.CatBoostRegressor(\n",
    "            iterations=500, learning_rate=0.05, depth=6,\n",
    "            random_state=42, verbose=False\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "def build_classification_models():\n",
    "    \"\"\"ë¶„ë¥˜ ëª¨ë¸ë“¤ (4ë“±ê¸‰)\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    models[\"RandomForest_Clf\"] = RandomForestClassifier(\n",
    "        n_estimators=300, min_samples_leaf=2, random_state=42, \n",
    "        n_jobs=-1, class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    models[\"GradientBoosting_Clf\"] = GradientBoostingClassifier(\n",
    "        n_estimators=200, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    models[\"LogisticRegression_Clf\"] = LogisticRegression(\n",
    "        multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000,\n",
    "        random_state=42, class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    if HAS_XGB:\n",
    "        models[\"XGBoost_Clf\"] = xgb.XGBClassifier(\n",
    "            n_estimators=400, max_depth=5, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"multi:softprob\", num_class=4,\n",
    "            tree_method=\"hist\", random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "    \n",
    "    if HAS_LGB:\n",
    "        models[\"LightGBM_Clf\"] = lgb.LGBMClassifier(\n",
    "            n_estimators=500, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"multiclass\", num_class=4,\n",
    "            random_state=42, n_jobs=-1, verbosity=-1, is_unbalance=True\n",
    "        )\n",
    "    \n",
    "    # ìˆ˜ì •: auto_class_weightsë¡œ ì •ì •\n",
    "    if HAS_CATBOOST:\n",
    "        models[\"CatBoost_Clf\"] = cb.CatBoostClassifier(\n",
    "            iterations=500, learning_rate=0.05, depth=6,\n",
    "            random_state=42, verbose=False, auto_class_weights='Balanced'\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "# ================================================================================================\n",
    "# 3. ê²°ê³¼ ì €ìž¥ ì‹œìŠ¤í…œ (ìƒˆë¡œ ì¶”ê°€)\n",
    "# ================================================================================================\n",
    "def create_result_directories():\n",
    "    \"\"\"ê²°ê³¼ ì €ìž¥ìš© ë””ë ‰í† ë¦¬ ìƒì„±\"\"\"\n",
    "    base_dir = '../data/results'\n",
    "    subdirs = [\n",
    "        'stratified_comparison',\n",
    "        'feature_importance', \n",
    "        'shap_analysis',\n",
    "        'model_performance',\n",
    "        'visualizations'\n",
    "    ]\n",
    "    \n",
    "    for subdir in [base_dir] + [os.path.join(base_dir, d) for d in subdirs]:\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "    \n",
    "    return base_dir\n",
    "\n",
    "def save_results_comprehensive(results_df, analysis_type='stratified_comparison', \n",
    "                             center_name=None, model_name=None, extra_data=None):\n",
    "    \"\"\"í¬ê´„ì  ê²°ê³¼ ì €ìž¥ í•¨ìˆ˜\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"ì €ìž¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    base_dir = create_result_directories()\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    if analysis_type == 'stratified_comparison':\n",
    "        # 1. ì „ì²´ ì‹¤í—˜ ê²°ê³¼\n",
    "        filename = f\"stratified_comparison_{timestamp}.csv\"\n",
    "        filepath = os.path.join(base_dir, 'stratified_comparison', filename)\n",
    "        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(filepath)\n",
    "        \n",
    "        # 2. ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§\n",
    "        successful_results = results_df[results_df['success'] == True]\n",
    "        \n",
    "        if len(successful_results) > 0:\n",
    "            # 3. ìš”ì•½ í†µê³„\n",
    "            summary_stats = create_summary_statistics(successful_results)\n",
    "            if len(summary_stats) > 0:\n",
    "                summary_filename = f\"stratified_summary_{timestamp}.csv\"\n",
    "                summary_filepath = os.path.join(base_dir, 'stratified_comparison', summary_filename)\n",
    "                summary_stats.to_csv(summary_filepath, index=False, encoding='utf-8-sig')\n",
    "                saved_files.append(summary_filepath)\n",
    "            \n",
    "            # 4. ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "            best_models = identify_best_models(successful_results)\n",
    "            if len(best_models) > 0:\n",
    "                best_filename = f\"stratified_best_models_{timestamp}.csv\"\n",
    "                best_filepath = os.path.join(base_dir, 'stratified_comparison', best_filename)\n",
    "                best_models.to_csv(best_filepath, index=False, encoding='utf-8-sig')\n",
    "                saved_files.append(best_filepath)\n",
    "    \n",
    "    elif analysis_type == 'feature_importance':\n",
    "        # í”¼ì²˜ ì¤‘ìš”ë„ ì €ìž¥\n",
    "        filename = f\"importance_{center_name}_{model_name}_{timestamp}.csv\"\n",
    "        filepath = os.path.join(base_dir, 'feature_importance', filename)\n",
    "        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(filepath)\n",
    "    \n",
    "    elif analysis_type == 'shap_analysis':\n",
    "        # SHAP ê°’ ì €ìž¥ (pickle)\n",
    "        if extra_data is not None and 'shap_values' in extra_data:\n",
    "            shap_filename = f\"shap_values_{center_name}_{model_name}_{timestamp}.pkl\"\n",
    "            shap_filepath = os.path.join(base_dir, 'shap_analysis', shap_filename)\n",
    "            with open(shap_filepath, 'wb') as f:\n",
    "                pickle.dump(extra_data['shap_values'], f)\n",
    "            saved_files.append(shap_filepath)\n",
    "        \n",
    "        # SHAP ìš”ì•½ ì •ë³´ ì €ìž¥ (CSV)\n",
    "        summary_filename = f\"shap_summary_{center_name}_{model_name}_{timestamp}.csv\"\n",
    "        summary_filepath = os.path.join(base_dir, 'shap_analysis', summary_filename)\n",
    "        results_df.to_csv(summary_filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(summary_filepath)\n",
    "    \n",
    "    elif analysis_type == 'model_performance':\n",
    "        filename = f\"performance_{timestamp}.csv\"\n",
    "        filepath = os.path.join(base_dir, 'model_performance', filename)\n",
    "        results_df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "        saved_files.append(filepath)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"\\n=== ì €ìž¥ ì™„ë£Œ ===\")\n",
    "    for file in saved_files:\n",
    "        print(f\"ì €ìž¥ë¨: {file}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "def create_summary_statistics(successful_results):\n",
    "    \"\"\"ìš”ì•½ í†µê³„ ìƒì„±\"\"\"\n",
    "    summary_stats = []\n",
    "    \n",
    "    for model_type in ['regression', 'classification']:\n",
    "        type_data = successful_results[successful_results['type'] == model_type]\n",
    "        if len(type_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        if model_type == 'regression':\n",
    "            metrics = ['r2', 'mae', 'rmse', 'mape']\n",
    "        else:\n",
    "            metrics = ['accuracy', 'macro_f1', 'weighted_f1', 'extreme_f1']\n",
    "        \n",
    "        for metric in metrics:\n",
    "            if metric in type_data.columns:\n",
    "                # ëª¨ë¸ë³„, ë¶„í• ë°©ë²•ë³„ í‰ê· /í‘œì¤€íŽ¸ì°¨\n",
    "                grouped = type_data.groupby(['model', 'split_method'])[metric].agg(['mean', 'std', 'count']).round(4)\n",
    "                grouped = grouped.reset_index()\n",
    "                grouped['metric'] = metric\n",
    "                grouped['type'] = model_type\n",
    "                summary_stats.append(grouped)\n",
    "    \n",
    "    if summary_stats:\n",
    "        return pd.concat(summary_stats, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def identify_best_models(successful_results):\n",
    "    \"\"\"ì„¼í„°ë³„, íƒ€ìž…ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì‹ë³„\"\"\"\n",
    "    best_models = []\n",
    "    \n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        # íšŒê·€ ìµœê³  ì„±ëŠ¥ (RÂ² ê¸°ì¤€)\n",
    "        reg_data = center_data[center_data['type'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            best_reg_idx = reg_data['r2'].idxmax()\n",
    "            best_reg = reg_data.loc[best_reg_idx].copy()\n",
    "            best_reg['rank_type'] = 'regression_best'\n",
    "            best_models.append(best_reg)\n",
    "        \n",
    "        # ë¶„ë¥˜ ìµœê³  ì„±ëŠ¥ (Macro F1 ê¸°ì¤€)\n",
    "        clf_data = center_data[center_data['type'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            best_clf_idx = clf_data['macro_f1'].idxmax()\n",
    "            best_clf = clf_data.loc[best_clf_idx].copy()\n",
    "            best_clf['rank_type'] = 'classification_best'\n",
    "            best_models.append(best_clf)\n",
    "    \n",
    "    if best_models:\n",
    "        return pd.DataFrame(best_models)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_visualization(fig, filename):\n",
    "    \"\"\"ì‹œê°í™” ê²°ê³¼ ì €ìž¥\"\"\"\n",
    "    base_dir = create_result_directories()\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    filepath = os.path.join(base_dir, 'visualizations', f\"{filename}_{timestamp}.png\")\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    print(f\"ì‹œê°í™” ì €ìž¥: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def create_performance_comparison_data(successful_results):\n",
    "    \"\"\"ì„±ëŠ¥ ë¹„êµ ë°ì´í„° ìƒì„±\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    # ì„¼í„°ë³„ ì„±ëŠ¥ ë¹„êµ\n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        for split_method in center_data['split_method'].unique():\n",
    "            method_data = center_data[center_data['split_method'] == split_method]\n",
    "            \n",
    "            # íšŒê·€ í‰ê·  ì„±ëŠ¥\n",
    "            reg_data = method_data[method_data['type'] == 'regression']\n",
    "            if len(reg_data) > 0:\n",
    "                comparison_data.append({\n",
    "                    'center': center,\n",
    "                    'split_method': split_method,\n",
    "                    'type': 'regression',\n",
    "                    'avg_r2': reg_data['r2'].mean(),\n",
    "                    'std_r2': reg_data['r2'].std(),\n",
    "                    'avg_mae': reg_data['mae'].mean(),\n",
    "                    'model_count': len(reg_data)\n",
    "                })\n",
    "            \n",
    "            # ë¶„ë¥˜ í‰ê·  ì„±ëŠ¥\n",
    "            clf_data = method_data[method_data['type'] == 'classification']\n",
    "            if len(clf_data) > 0:\n",
    "                comparison_data.append({\n",
    "                    'center': center,\n",
    "                    'split_method': split_method,\n",
    "                    'type': 'classification',\n",
    "                    'avg_accuracy': clf_data['accuracy'].mean(),\n",
    "                    'std_accuracy': clf_data['accuracy'].std(),\n",
    "                    'avg_macro_f1': clf_data['macro_f1'].mean(),\n",
    "                    'std_macro_f1': clf_data['macro_f1'].std(),\n",
    "                    'avg_extreme_f1': clf_data['extreme_f1'].mean(),\n",
    "                    'model_count': len(clf_data)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "# ================================================================================================\n",
    "# 4. Feature Importance & SHAP ë¶„ì„ í•¨ìˆ˜ë“¤\n",
    "# ================================================================================================\n",
    "def extract_feature_importance(model, model_name, feature_names):\n",
    "    \"\"\"ëª¨ë¸ë³„ Feature Importance ì¶”ì¶œ\"\"\"\n",
    "    try:\n",
    "        mdl = model.named_steps['model']\n",
    "        if hasattr(mdl, 'feature_importances_'):\n",
    "            importance = mdl.feature_importances_\n",
    "        elif hasattr(mdl, 'coef_'):\n",
    "            coef = mdl.coef_\n",
    "            # (n_features,) ë˜ëŠ” (n_classes, n_features) ëª¨ë‘ ëŒ€ì‘\n",
    "            if isinstance(coef, np.ndarray) and coef.ndim == 2:\n",
    "                importance = np.mean(np.abs(coef), axis=0)   # í´ëž˜ìŠ¤ í‰ê· \n",
    "            else:\n",
    "                importance = np.abs(coef)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # ê¸¸ì´ ì•ˆì „ê°€ë“œ\n",
    "        if len(importance) != len(feature_names):\n",
    "            print(f\"[ê²½ê³ ] importance ê¸¸ì´({len(importance)}) != feature_names({len(feature_names)}). \"\n",
    "                  \"ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ ì•žìª½ í”¼ì²˜ë¡œ ë§žì¶°ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.\")\n",
    "            m = min(len(importance), len(feature_names))\n",
    "            importance = np.asarray(importance)[:m]\n",
    "            feature_names = list(feature_names)[:m]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        return importance_df\n",
    "    except Exception as e:\n",
    "        print(f\"Feature importance ì¶”ì¶œ ì‹¤íŒ¨ ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_feature_importance(importance_df, model_name, top_n=15):\n",
    "    \"\"\"Feature Importance ì‹œê°í™” (fig ê°ì²´ ë¦¬í„´)\"\"\"\n",
    "    # plot_feature_importance ìžì²´ê°€ ìƒˆ figureë¥¼ ìƒì„±í•˜ê³  plt.show() í•´ë²„ë¦¬ê¸° ë•Œë¬¸ì—, figëŠ” ì‚¬ì‹¤ìƒ ë¹ˆ ë„í™”ì§€ì˜ˆìš”. ê·¸ëž˜ì„œ ì €ìž¥í•˜ë©´ ë¹ˆ ê·¸ë¦¼ì´ ì°ížˆëŠ” ê±°ì£ .\n",
    "    # ë¹ˆê·¸ë¦¼ì´ ì €ìž¥ë˜ì–´ì„œ ì½”ë“œ ìˆ˜ì •í•œê²Œ ì•„ëž˜ìž„\n",
    "    if importance_df is None or len(importance_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    top_features = importance_df.head(top_n)\n",
    "    \n",
    "    ax.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['feature'])\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title(f'{model_name} - Top {top_n} Feature Importance')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # ê°’ í‘œì‹œ\n",
    "    for i, v in enumerate(top_features['importance']):\n",
    "        ax.text(v + 0.001, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig   # â† ì—¬ê¸°ì„œ figure ê°ì²´ ë°˜í™˜\n",
    "\n",
    "\n",
    "def analyze_model_with_shap(model, X_test, feature_names, model_name, max_samples=100):\n",
    "    \"\"\"SHAP ë¶„ì„\"\"\"\n",
    "    if not HAS_SHAP:\n",
    "        print(\"SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # ìƒ˜í”Œ ìˆ˜ ì œí•œ (SHAP ê³„ì‚° ì‹œê°„ ë‹¨ì¶•)\n",
    "        if len(X_test) > max_samples:\n",
    "            sample_idx = np.random.choice(len(X_test), max_samples, replace=False)\n",
    "            X_sample = X_test.iloc[sample_idx]\n",
    "        else:\n",
    "            X_sample = X_test\n",
    "        \n",
    "        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì–»ê¸°\n",
    "        X_processed = model.named_steps['pre'].transform(X_sample)\n",
    "        \n",
    "        # ëª¨ë¸ë³„ SHAP Explainer ì„ íƒ\n",
    "        if 'RandomForest' in model_name or 'GradientBoosting' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'XGBoost' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'LightGBM' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        elif 'CatBoost' in model_name:\n",
    "            explainer = shap.TreeExplainer(model.named_steps['model'])\n",
    "        else:\n",
    "            # Linear models\n",
    "            explainer = shap.LinearExplainer(model.named_steps['model'], X_processed)\n",
    "        \n",
    "        # SHAP values ê³„ì‚°\n",
    "        shap_values = explainer.shap_values(X_processed)\n",
    "        \n",
    "        # ë‹¤ì¤‘ í´ëž˜ìŠ¤ì˜ ê²½ìš° ì²« ë²ˆì§¸ í´ëž˜ìŠ¤ë§Œ ì‚¬ìš©\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[0]\n",
    "        \n",
    "        return shap_values, X_processed, explainer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP ë¶„ì„ ì‹¤íŒ¨ ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_shap_summary(shap_values, X_processed, feature_names, model_name):\n",
    "    \"\"\"SHAP Summary Plotì„ ë§Œë“¤ê³  figure ëª©ë¡ì„ ë°˜í™˜ -> ë¹ˆê·¸ë¦¼ ì €ìž¥ ë°©ì§€\"\"\"\n",
    "    if shap_values is None or not HAS_SHAP:\n",
    "        return []\n",
    "\n",
    "    figs = []\n",
    "    try:\n",
    "        # (1) Bar plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_processed,\n",
    "                          feature_names=feature_names,\n",
    "                          plot_type=\"bar\", show=False)\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(f'{model_name} - SHAP Feature Importance')\n",
    "        figs.append(plt.gcf())\n",
    "\n",
    "        # (2) Beeswarm plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_processed,\n",
    "                          feature_names=feature_names,\n",
    "                          show=False)\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(f'{model_name} - SHAP Summary Plot')\n",
    "        figs.append(plt.gcf())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP ì‹œê°í™” ì‹¤íŒ¨ ({model_name}): {e}\")\n",
    "\n",
    "    return figs\n",
    "\n",
    "def comprehensive_model_analysis_with_save(model, model_name, X_train, X_test, y_train, y_test, \n",
    "                                         feature_names, model_type, center_name=None):\n",
    "    \"\"\"ì¢…í•©ì ì¸ ëª¨ë¸ ë¶„ì„ (Feature Importance + SHAP) + ì €ìž¥\"\"\"\n",
    "    print(f\"\\n--- {model_name} ìƒì„¸ ë¶„ì„ ---\")\n",
    "    \n",
    "    # 1. Feature Importance ì¶”ì¶œ ë° ì‹œê°í™”\n",
    "    importance_df = extract_feature_importance(model, model_name, feature_names)\n",
    "    if importance_df is not None:\n",
    "        print(f\"Top 10 ì¤‘ìš” í”¼ì²˜:\")\n",
    "        print(importance_df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Feature Importance ì €ìž¥\n",
    "        if center_name:\n",
    "            save_results_comprehensive(\n",
    "                importance_df, \n",
    "                analysis_type='feature_importance',\n",
    "                center_name=center_name,\n",
    "                model_name=model_name\n",
    "            )\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        fig = plot_feature_importance(importance_df, model_name)\n",
    "        if fig is not None:\n",
    "            fig.show()  # í™”ë©´ì— ë„ìš°ê³ \n",
    "            if center_name:\n",
    "                save_visualization(fig, f\"feature_importance_{center_name}_{model_name}\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    \n",
    "    # 2. SHAP ë¶„ì„\n",
    "    shap_result = analyze_model_with_shap(model, X_test, feature_names, model_name)\n",
    "    if shap_result is not None:\n",
    "        shap_values, X_processed, explainer = shap_result\n",
    "\n",
    "        # SHAP ìš”ì•½ í†µê³„ ì €ìž¥\n",
    "        if isinstance(shap_values, np.ndarray):\n",
    "            mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "            shap_summary_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'mean_abs_shap': mean_abs_shap\n",
    "            }).sort_values('mean_abs_shap', ascending=False)\n",
    "            if center_name:\n",
    "                extra_data = {'shap_values': shap_values, 'X_processed': X_processed}\n",
    "                save_results_comprehensive(\n",
    "                    shap_summary_df,\n",
    "                    analysis_type='shap_analysis',\n",
    "                    center_name=center_name,\n",
    "                    model_name=model_name,\n",
    "                    extra_data=extra_data\n",
    "                )\n",
    "\n",
    "        # SHAP í”Œë¡¯ ìƒì„±(ë¦¬í„´ë°›ìŒ)\n",
    "        shap_figs = plot_shap_summary(shap_values, X_processed, feature_names, model_name)\n",
    "        if shap_figs:\n",
    "            for i, fig in enumerate(shap_figs):\n",
    "                fig.show()  # ë˜ëŠ” plt.show()\n",
    "                if center_name:\n",
    "                    suffix = \"shap_bar\" if i == 0 else \"shap_beeswarm\"\n",
    "                    save_visualization(fig, f\"{suffix}_{center_name}_{model_name}\")\n",
    "                plt.close(fig)  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "    \n",
    "    return importance_df, shap_result\n",
    "\n",
    "# ================================================================================================\n",
    "# 5. ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ í•¨ìˆ˜ë“¤\n",
    "# ================================================================================================\n",
    "def make_pipeline_unified(model, model_name, model_type):\n",
    "    \"\"\"í†µí•© ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    if model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"]:\n",
    "        # ì„ í˜• ëª¨ë¸ì€ ì •ê·œí™” í•„ìš”\n",
    "        pre = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ])\n",
    "    else:\n",
    "        # íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ë“¤ì€ ì •ê·œí™” ë¶ˆí•„ìš”\n",
    "        pre = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ])\n",
    "    return Pipeline(steps=[(\"pre\", pre), (\"model\", model)])\n",
    "\n",
    "def prepare_data_stratified(df, target_col, model_type, test_size=0.2, split_method='stratified'):\n",
    "    \"\"\"\n",
    "    ë°ì´í„° ì¤€ë¹„ - Stratified vs ì‹œê³„ì—´ ë¶„í•  ì„ íƒ ê°€ëŠ¥\n",
    "    \n",
    "    Parameters:\n",
    "    - split_method: 'stratified' ë˜ëŠ” 'temporal'\n",
    "    \"\"\"\n",
    "    work = df.sort_values('ë‚ ì§œ').reset_index(drop=True).copy()\n",
    "    dates = pd.to_datetime(work['ë‚ ì§œ'])\n",
    "\n",
    "    # ì œì™¸í•  ì»¬ëŸ¼ë“¤\n",
    "    not_use_col = [\n",
    "        'ë‚ ì§œ',\n",
    "        '1ì²˜ë¦¬ìž¥','2ì²˜ë¦¬ìž¥','ì •í™”ì¡°','ì¤‘ê³„íŽŒí”„ìž¥','í•©ê³„','ì‹œì„¤í˜„ëŒ€í™”',\n",
    "        '3ì²˜ë¦¬ìž¥','4ì²˜ë¦¬ìž¥','í•©ê³„', 'í•©ê³„_1ì¼í›„','í•©ê³„_2ì¼í›„',\n",
    "        'ë“±ê¸‰','ë“±ê¸‰_1ì¼í›„','ë“±ê¸‰_2ì¼í›„'\n",
    "    ]\n",
    "    \n",
    "    drop_cols = [c for c in (set(not_use_col) | {target_col}) if c in work.columns]\n",
    "    X_raw = work.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• ë³€í™˜\n",
    "    for c in X_raw.columns:\n",
    "        X_raw[c] = pd.to_numeric(X_raw[c], errors=\"coerce\")\n",
    "\n",
    "    if model_type == \"regression\":\n",
    "        y = pd.to_numeric(work[target_col], errors=\"coerce\")\n",
    "    else:  # classification\n",
    "        y = work[target_col].astype(\"int64\")\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ ì œê±°\n",
    "    valid_idx = (~X_raw.isnull().all(axis=1)) & (~pd.isnull(y))\n",
    "    X_raw = X_raw[valid_idx].reset_index(drop=True)\n",
    "    y = y[valid_idx].reset_index(drop=True)\n",
    "    dates = dates[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    if split_method == 'stratified':\n",
    "        # Stratified ë¶„í•  (ë¶„ë¥˜ì—ë§Œ ì ìš©, íšŒê·€ëŠ” ì¼ë°˜ random split)\n",
    "        if model_type == \"classification\":\n",
    "            # ë“±ê¸‰ë³„ ê· ë“± ë¶„í• \n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "            train_idx, test_idx = next(sss.split(X_raw, y))\n",
    "        else:\n",
    "            # íšŒê·€ëŠ” ì¼ë°˜ ëžœë¤ ë¶„í•  (ì—°ì†ê°’ì´ë¯€ë¡œ stratify ë¶ˆê°€)\n",
    "            train_idx, test_idx = train_test_split(\n",
    "                range(len(X_raw)), test_size=test_size, random_state=42\n",
    "            )\n",
    "            \n",
    "        X_train, X_test = X_raw.iloc[train_idx].copy(), X_raw.iloc[test_idx].copy()\n",
    "        y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "        dates_train, dates_test = dates.iloc[train_idx].copy(), dates.iloc[test_idx].copy()\n",
    "        \n",
    "    else:  # temporal split\n",
    "        # ê¸°ì¡´ ì‹œê³„ì—´ ë¶„í• \n",
    "        n = len(X_raw) # len(work)\n",
    "        split = int(n * (1 - test_size))\n",
    "        X_train, X_test = X_raw.iloc[:split].copy(), X_raw.iloc[split:].copy()\n",
    "        y_train, y_test = y.iloc[:split].copy(), y.iloc[split:].copy()\n",
    "        dates_train, dates_test = dates.iloc[:split].copy(), dates.iloc[split:].copy()\n",
    "\n",
    "    feature_names = list(X_raw.columns)\n",
    "    return X_train, X_test, y_train, y_test, feature_names, dates_train, dates_test\n",
    "\n",
    "def evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ í‰ê°€ (ìˆ˜ì •ë¨)\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"regression\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # MAPE (Mean Absolute Percentage Error)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "        \n",
    "        # ì˜¬ë°”ë¥¸ return ë¬¸\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': mae,         # â† ê³„ì‚°ëœ ê°’ ì‚¬ìš©\n",
    "            'rmse': rmse,       # â† ê³„ì‚°ëœ ê°’ ì‚¬ìš©\n",
    "            'r2': r2,           # â† ê³„ì‚°ëœ ê°’ ì‚¬ìš©\n",
    "            'mape': mape,       # â† ê³„ì‚°ëœ ê°’ ì‚¬ìš©\n",
    "            'success': True     # â† ì„±ê³µ ì‹œ True\n",
    "        }, pipe, y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        # ì‹¤íŒ¨ ì‹œì—ë§Œ ì´ ë¶€ë¶„ ì‹¤í–‰\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': np.nan,\n",
    "            'rmse': np.nan,\n",
    "            'r2': np.nan,\n",
    "            'mape': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None\n",
    "        \n",
    "def evaluate_classification_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"ë¶„ë¥˜ ëª¨ë¸ í‰ê°€\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"classification\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # ì°¨ì› ë¬¸ì œ í•´ê²°\n",
    "        if isinstance(y_pred, np.ndarray) and y_pred.ndim > 1:\n",
    "            y_pred = y_pred.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        # ê·¹ê°’ ë¶„ë¥˜ ì„±ëŠ¥ (ë“±ê¸‰ 0, 3ë¡œ ìˆ˜ì •: 0-base ë³€í™˜ ë•Œë¬¸ì—)\n",
    "        extreme_classes = [0, 3]  # ì›ëž˜ 1,4ê°€ 0,3ìœ¼ë¡œ ë³€í™˜ë¨\n",
    "        y_true_extreme = pd.Series(y_test).isin(extreme_classes).astype(int)\n",
    "        y_pred_extreme = pd.Series(y_pred).isin(extreme_classes).astype(int)\n",
    "        extreme_f1 = f1_score(y_true_extreme, y_pred_extreme, zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1_macro,\n",
    "            'weighted_f1': f1_weighted,\n",
    "            'extreme_f1': extreme_f1,\n",
    "            'success': True\n",
    "        }, pipe, y_pred\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': np.nan,\n",
    "            'macro_f1': np.nan,\n",
    "            'weighted_f1': np.nan,\n",
    "            'extreme_f1': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None\n",
    "\n",
    "def comprehensive_evaluation_comparison(center_name, df):\n",
    "    \"\"\"Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ í‰ê°€\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ì„¼í„°: {center_name} - Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # ë°ì´í„° í™•ì¸\n",
    "    print(f\"ë°ì´í„° í¬ê¸°: {len(df)}í–‰, {len(df.columns)}ì»¬ëŸ¼\")\n",
    "    \n",
    "    # ë“±ê¸‰ ë¶„í¬ í™•ì¸\n",
    "    if 'ë“±ê¸‰_1ì¼í›„' in df.columns:\n",
    "        grade_dist = df['ë“±ê¸‰_1ì¼í›„'].value_counts().sort_index()\n",
    "        print(f\"ë“±ê¸‰ ë¶„í¬: {dict(grade_dist)}\")\n",
    "        \n",
    "        # ë¶ˆê· í˜• ì •ë„ í™•ì¸\n",
    "        min_class = grade_dist.min()\n",
    "        max_class = grade_dist.max()\n",
    "        imbalance_ratio = max_class / min_class\n",
    "        print(f\"í´ëž˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.1f}:1 (ìµœëŒ€:{max_class}, ìµœì†Œ:{min_class})\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # ë‘ ê°€ì§€ ë¶„í•  ë°©ë²• ë¹„êµ\n",
    "    for split_method in ['temporal', 'stratified']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ë¶„í•  ë°©ë²•: {split_method.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # =========================\n",
    "        # 1. íšŒê·€ ëª¨ë¸ í‰ê°€\n",
    "        # =========================\n",
    "        reg_method_name = \"random_shuffle\" if split_method == \"stratified\" else split_method\n",
    "        print(f\"\\n--- íšŒê·€ ëª¨ë¸ í‰ê°€ ({reg_method_name}) ---\")\n",
    "        \n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test, feature_names, dates_train, dates_test = prepare_data_stratified(\n",
    "                df, target_col=\"í•©ê³„_1ì¼í›„\", model_type=\"regression\", test_size=0.2, split_method=split_method\n",
    "            )\n",
    "            \n",
    "            print(f\"íšŒê·€ìš© ë°ì´í„°: í•™ìŠµ {len(X_train)}í–‰, í…ŒìŠ¤íŠ¸ {len(X_test)}í–‰\")\n",
    "            \n",
    "            regression_models = build_regression_models()\n",
    "            \n",
    "            for model_name, model in tqdm(regression_models.items(), desc=f\"íšŒê·€({reg_method_name})\", leave=False):\n",
    "                result, pipe, y_pred = evaluate_regression_model(model, model_name, X_train, X_test, y_train, y_test)\n",
    "                result['center'] = center_name\n",
    "                result['split_method'] = split_method\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    print(f\"  {model_name:18s}: RÂ²={result['r2']:.3f}, MAE={result['mae']:.0f}, MAPE={result['mape']:.1f}%\")\n",
    "                else:\n",
    "                    print(f\"  {model_name:18s}: ì‹¤íŒ¨ - {result.get('error', '')[:50]}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"íšŒê·€ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ ({reg_method_name}): {e}\")\n",
    "        \n",
    "        # =========================\n",
    "        # 2. ë¶„ë¥˜ ëª¨ë¸ í‰ê°€\n",
    "        # =========================\n",
    "        print(f\"\\n--- ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ({split_method}) ---\")\n",
    "        \n",
    "        try:\n",
    "            X_train_clf, X_test_clf, y_train_clf, y_test_clf, feature_names_clf, _, _ = prepare_data_stratified(\n",
    "                df, target_col=\"ë“±ê¸‰_1ì¼í›„\", model_type=\"classification\", test_size=0.2, split_method=split_method\n",
    "            )\n",
    "            \n",
    "            print(f\"ë¶„ë¥˜ìš© ë°ì´í„°: í•™ìŠµ {len(X_train_clf)}í–‰, í…ŒìŠ¤íŠ¸ {len(X_test_clf)}í–‰\")\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë“±ê¸‰ ë¶„í¬ í™•ì¸\n",
    "            test_dist = pd.Series(y_test_clf).value_counts().sort_index()\n",
    "            train_dist = pd.Series(y_train_clf).value_counts().sort_index()\n",
    "            print(f\"í•™ìŠµ ì„¸íŠ¸ ë“±ê¸‰ ë¶„í¬: {dict(train_dist)}\")\n",
    "            print(f\"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë“±ê¸‰ ë¶„í¬: {dict(test_dist)}\")\n",
    "            \n",
    "            classification_models = build_classification_models()\n",
    "            \n",
    "            for model_name, model in tqdm(classification_models.items(), desc=f\"ë¶„ë¥˜({split_method})\", leave=False):\n",
    "                result, pipe, y_pred = evaluate_classification_model(model, model_name, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "                result['center'] = center_name\n",
    "                result['split_method'] = split_method\n",
    "                results.append(result)\n",
    "                \n",
    "                if result['success']:\n",
    "                    print(f\"  {model_name:18s}: ACC={result['accuracy']:.3f}, F1={result['macro_f1']:.3f}, ê·¹ê°’F1={result['extreme_f1']:.3f}\")\n",
    "                else:\n",
    "                    print(f\"  {model_name:18s}: ì‹¤íŒ¨ - {result.get('error', '')[:50]}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ ({split_method}): {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# 6. ì‹œê°í™” í•¨ìˆ˜ë“¤\n",
    "# ================================================================================================\n",
    "def plot_stratified_comparison(results_df):\n",
    "    \"\"\"ë¹„êµ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # successful_resultsê°€ results_df ì•ˆì— ìžˆì–´ì•¼ í•¨\n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    if len(successful_results) == 0:\n",
    "        print(\"ì„±ê³µí•œ ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ìƒëžµí•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ', fontsize=16)\n",
    "    \n",
    "    # 1. íšŒê·€ ëª¨ë¸ RÂ² ë¹„êµ\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        reg_pivot = reg_results.pivot_table(\n",
    "            index='model', columns='split_method', values='r2', aggfunc='mean'\n",
    "        )\n",
    "        reg_pivot = reg_pivot.rename(columns={'stratified': 'random_shuffle'})\n",
    "        reg_pivot.plot(kind='bar', ax=axes[0,0], color=['lightblue', 'orange'])\n",
    "        axes[0,0].set_title('íšŒê·€ ëª¨ë¸ RÂ² ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,0].set_ylabel('RÂ² Score')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        axes[0,0].legend(title='Split Method')\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "    \n",
    "    # 2. ë¶„ë¥˜ ëª¨ë¸ F1 ë¹„êµ\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        clf_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='macro_f1', aggfunc='mean'\n",
    "        )\n",
    "        clf_pivot.plot(kind='bar', ax=axes[0,1], color=['lightgreen', 'red'])\n",
    "        axes[0,1].set_title('ë¶„ë¥˜ ëª¨ë¸ Macro F1 ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,1].set_ylabel('Macro F1 Score')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        axes[0,1].legend(title='Split Method')\n",
    "        axes[0,1].set_ylim(0, 1)\n",
    "    \n",
    "    # 3. ì„¼í„°ë³„ íšŒê·€ ì„±ëŠ¥\n",
    "    if len(reg_results) > 0:\n",
    "        center_reg = reg_results.groupby(['center', 'split_method'])['r2'].mean().unstack()\n",
    "        center_reg = center_reg.rename(columns={'stratified': 'random_shuffle'})\n",
    "        center_reg.plot(kind='bar', ax=axes[1,0], color=['lightblue', 'orange'])\n",
    "        axes[1,0].set_title('ì„¼í„°ë³„ íšŒê·€ í‰ê·  ì„±ëŠ¥')\n",
    "        axes[1,0].set_ylabel('í‰ê·  RÂ² Score')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        axes[1,0].legend(title='Split Method')\n",
    "    \n",
    "    # 4. ì„¼í„°ë³„ ë¶„ë¥˜ ì„±ëŠ¥\n",
    "    if len(clf_results) > 0:\n",
    "        center_clf = clf_results.groupby(['center', 'split_method'])['macro_f1'].mean().unstack()\n",
    "        center_clf.plot(kind='bar', ax=axes[1,1], color=['lightgreen', 'red'])\n",
    "        axes[1,1].set_title('ì„¼í„°ë³„ ë¶„ë¥˜ í‰ê·  ì„±ëŠ¥')\n",
    "        axes[1,1].set_ylabel('í‰ê·  Macro F1 Score')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        axes[1,1].legend(title='Split Method')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ì‹œê°í™” ì €ìž¥\n",
    "    save_visualization(fig, \"stratified_comparison_plots\")\n",
    "\n",
    "def plot_model_performance_comparison(results_df):\n",
    "    \"\"\"ëª¨ë¸ë³„ ì„±ëŠ¥ ìƒì„¸ ë¹„êµ ì‹œê°í™”\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        return\n",
    "        \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    # 1. ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ í•œëˆˆì— ë³´ê¸°\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle('ëª¨ë¸ë³„ ì„±ëŠ¥ ìƒì„¸ ë¹„êµ', fontsize=16)\n",
    "    \n",
    "    # 1-1. íšŒê·€ ëª¨ë¸ RÂ² (ë¶„í•  ë°©ë²•ë³„)\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        reg_pivot = reg_results.pivot_table(\n",
    "            index='model', columns='split_method', values='r2', aggfunc='mean'\n",
    "        )\n",
    "        reg_pivot.plot(kind='bar', ax=axes[0,0], color=['lightblue', 'orange'])\n",
    "        axes[0,0].set_title('íšŒê·€ ëª¨ë¸ RÂ² ì„±ëŠ¥')\n",
    "        axes[0,0].set_ylabel('RÂ² Score')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        axes[0,0].legend(title='Split Method')\n",
    "    \n",
    "    # 1-2. ë¶„ë¥˜ ëª¨ë¸ Macro F1 (ë¶„í•  ë°©ë²•ë³„)\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        clf_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='macro_f1', aggfunc='mean'\n",
    "        )\n",
    "        clf_pivot.plot(kind='bar', ax=axes[0,1], color=['lightgreen', 'red'])\n",
    "        axes[0,1].set_title('ë¶„ë¥˜ ëª¨ë¸ Macro F1 ì„±ëŠ¥')\n",
    "        axes[0,1].set_ylabel('Macro F1 Score')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        axes[0,1].legend(title='Split Method')\n",
    "    \n",
    "    # 1-3. ë¶„ë¥˜ ëª¨ë¸ Extreme F1 ì„±ëŠ¥\n",
    "    if len(clf_results) > 0:\n",
    "        extreme_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='extreme_f1', aggfunc='mean'\n",
    "        )\n",
    "        extreme_pivot.plot(kind='bar', ax=axes[0,2], color=['lightcoral', 'gold'])\n",
    "        axes[0,2].set_title('ë¶„ë¥˜ ëª¨ë¸ Extreme F1 ì„±ëŠ¥')\n",
    "        axes[0,2].set_ylabel('Extreme F1 Score')\n",
    "        axes[0,2].tick_params(axis='x', rotation=45)\n",
    "        axes[0,2].legend(title='Split Method')\n",
    "    \n",
    "    # 2-1. íšŒê·€ ëª¨ë¸ MAE ì„±ëŠ¥\n",
    "    if len(reg_results) > 0:\n",
    "        mae_pivot = reg_results.pivot_table(\n",
    "            index='model', columns='split_method', values='mae', aggfunc='mean'\n",
    "        )\n",
    "        mae_pivot.plot(kind='bar', ax=axes[1,0], color=['lightsteelblue', 'sandybrown'])\n",
    "        axes[1,0].set_title('íšŒê·€ ëª¨ë¸ MAE ì„±ëŠ¥ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')\n",
    "        axes[1,0].set_ylabel('Mean Absolute Error')\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        axes[1,0].legend(title='Split Method')\n",
    "    \n",
    "    # 2-2. ë¶„ë¥˜ ëª¨ë¸ Accuracy\n",
    "    if len(clf_results) > 0:\n",
    "        acc_pivot = clf_results.pivot_table(\n",
    "            index='model', columns='split_method', values='accuracy', aggfunc='mean'\n",
    "        )\n",
    "        acc_pivot.plot(kind='bar', ax=axes[1,1], color=['mediumseagreen', 'indianred'])\n",
    "        axes[1,1].set_title('ë¶„ë¥˜ ëª¨ë¸ Accuracy ì„±ëŠ¥')\n",
    "        axes[1,1].set_ylabel('Accuracy Score')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        axes[1,1].legend(title='Split Method')\n",
    "    \n",
    "    # 2-3. ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "    plot_best_models_per_center(successful_results, axes[1,2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ì‹œê°í™” ì €ìž¥\n",
    "    save_visualization(fig, \"model_performance_comparison\")\n",
    "\n",
    "def plot_best_models_per_center(results_df, ax):\n",
    "    \"\"\"ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í‘œì‹œ\"\"\"\n",
    "    centers = results_df['center'].unique()\n",
    "    reg_best = []\n",
    "    clf_best = []\n",
    "    \n",
    "    for center in centers:\n",
    "        center_data = results_df[results_df['center'] == center]\n",
    "        \n",
    "        # íšŒê·€ ìµœê³  ì„±ëŠ¥\n",
    "        reg_data = center_data[center_data['type'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            best_reg_idx = reg_data['r2'].idxmax()\n",
    "            reg_best.append(reg_data.loc[best_reg_idx, 'r2'])\n",
    "        else:\n",
    "            reg_best.append(0)\n",
    "        \n",
    "        # ë¶„ë¥˜ ìµœê³  ì„±ëŠ¥\n",
    "        clf_data = center_data[center_data['type'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            best_clf_idx = clf_data['macro_f1'].idxmax()\n",
    "            clf_best.append(clf_data.loc[best_clf_idx, 'macro_f1'])\n",
    "        else:\n",
    "            clf_best.append(0)\n",
    "    \n",
    "    x = np.arange(len(centers))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, reg_best, width, label='íšŒê·€ RÂ²', color='skyblue')\n",
    "    ax.bar(x + width/2, clf_best, width, label='ë¶„ë¥˜ F1', color='lightcoral')\n",
    "    \n",
    "    ax.set_xlabel('ì„¼í„°')\n",
    "    ax.set_ylabel('ì„±ëŠ¥ ì ìˆ˜')\n",
    "    ax.set_title('ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(centers)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # ê°’ í‘œì‹œ\n",
    "    for i, (r, c) in enumerate(zip(reg_best, clf_best)):\n",
    "        if r > 0:\n",
    "            ax.text(i - width/2, r + 0.01, f'{r:.3f}', ha='center', va='bottom')\n",
    "        if c > 0:\n",
    "            ax.text(i + width/2, c + 0.01, f'{c:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# ================================================================================================\n",
    "# 7. ë¶„ì„ í•¨ìˆ˜ë“¤\n",
    "# ================================================================================================\n",
    "def analyze_stratified_comparison(results_df):\n",
    "    \"\"\"Stratified vs ì‹œê³„ì—´ ë¹„êµ ë¶„ì„\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ ë¶„ì„ ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    # ë¶„í•  ë°©ë²•ë³„ ì„±ëŠ¥ ë¹„êµ\n",
    "    for task_type in ['regression', 'classification']:\n",
    "        print(f\"\\n--- {task_type.upper()} ëª¨ë¸ ë¹„êµ ---\")\n",
    "        \n",
    "        task_results = successful_results[successful_results['type'] == task_type]\n",
    "        if len(task_results) == 0:\n",
    "            continue\n",
    "            \n",
    "        if task_type == 'regression':\n",
    "            metric = 'r2'\n",
    "            metric_name = 'RÂ²'\n",
    "        else:\n",
    "            metric = 'macro_f1'  \n",
    "            metric_name = 'Macro F1'\n",
    "        \n",
    "        # ë¶„í•  ë°©ë²•ë³„ í‰ê·  ì„±ëŠ¥\n",
    "        split_performance = task_results.groupby('split_method')[metric].agg(['mean', 'std', 'count'])\n",
    "        \n",
    "        for split_method in split_performance.index:\n",
    "            mean_val = split_performance.loc[split_method, 'mean']\n",
    "            std_val = split_performance.loc[split_method, 'std']\n",
    "            count_val = split_performance.loc[split_method, 'count']\n",
    "            method_display = \"random_shuffle\" if split_method == \"stratified\" and task_type == \"regression\" else split_method\n",
    "            print(f\"  {method_display:13s}: {metric_name}={mean_val:.3f} Â± {std_val:.3f} ({count_val}ê°œ)\")\n",
    "        \n",
    "        # ëª¨ë¸ë³„ ë¹„êµ\n",
    "        print(f\"\\n  ëª¨ë¸ë³„ {metric_name} ë¹„êµ:\")\n",
    "        model_comparison = task_results.pivot_table(\n",
    "            index='model', columns='split_method', values=metric, aggfunc='mean'\n",
    "        ).round(3)\n",
    "        \n",
    "        print(model_comparison.to_string())\n",
    "        \n",
    "        # ê°œì„  ì •ë„ ë¶„ì„ (stratifiedê°€ temporalë³´ë‹¤ ì¢‹ì€ ê²½ìš°)\n",
    "        if 'temporal' in model_comparison.columns and 'stratified' in model_comparison.columns:\n",
    "            improvement = model_comparison['stratified'] - model_comparison['temporal']\n",
    "            improvement_name = \"Random Shuffle ê°œì„  ì •ë„\" if task_type == \"regression\" else \"Stratified ê°œì„  ì •ë„\"\n",
    "            print(f\"\\n  {improvement_name} ({metric_name}):\")\n",
    "            for model in improvement.index:\n",
    "                imp_val = improvement[model]\n",
    "                if not pd.isna(imp_val):\n",
    "                    symbol = \"â†‘\" if imp_val > 0 else \"â†“\" if imp_val < 0 else \"=\"\n",
    "                    print(f\"    {model:18s}: {imp_val:+.3f} {symbol}\")\n",
    "    \n",
    "    # ì„¼í„°ë³„ ë¶„í•  ë°©ë²• íš¨ê³¼\n",
    "    print(f\"\\n--- ì„¼í„°ë³„ ë¶„í•  ë°©ë²• íš¨ê³¼ ---\")\n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        reg_data = center_data[center_data['type'] == 'regression']\n",
    "        clf_data = center_data[center_data['type'] == 'classification']\n",
    "        \n",
    "        print(f\"\\n  {center.upper()} ì„¼í„°:\")\n",
    "        \n",
    "        # íšŒê·€ ì„±ëŠ¥\n",
    "        if len(reg_data) > 0:\n",
    "            reg_perf = reg_data.groupby('split_method')['r2'].mean()\n",
    "            for method in reg_perf.index:\n",
    "                method_display = \"random_shuffle\" if method == \"stratified\" else method\n",
    "                print(f\"    íšŒê·€ RÂ² ({method_display:13s}): {reg_perf[method]:.3f}\")\n",
    "        \n",
    "        # ë¶„ë¥˜ ì„±ëŠ¥  \n",
    "        if len(clf_data) > 0:\n",
    "            clf_perf = clf_data.groupby('split_method')['macro_f1'].mean()\n",
    "            for method in clf_perf.index:\n",
    "                print(f\"    ë¶„ë¥˜ F1 ({method:13s}): {clf_perf[method]:.3f}\")\n",
    "    \n",
    "    # ê¸°ë³¸ ì‹œê°í™”\n",
    "    plot_stratified_comparison(successful_results)\n",
    "    \n",
    "    # ìƒì„¸ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "    plot_model_performance_comparison(successful_results)\n",
    "\n",
    "def perform_detailed_analysis_with_save(results_df, centers):\n",
    "    \"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (ì €ìž¥ ê¸°ëŠ¥ í¬í•¨)\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ë¶„ì„ ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    \n",
    "    analyzed_models = []\n",
    "    \n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"\\nìµœê³  íšŒê·€ ì„±ëŠ¥: {best_reg['center']} - {best_reg['model']} ({best_reg['split_method']}) RÂ²={best_reg['r2']:.3f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìž¬í•™ìŠµ ë° ë¶„ì„\n",
    "        model_info = analyze_best_model_with_save(best_reg, centers, 'regression')\n",
    "        if model_info:\n",
    "            analyzed_models.append(model_info)\n",
    "    \n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"\\nìµœê³  ë¶„ë¥˜ ì„±ëŠ¥: {best_clf['center']} - {best_clf['model']} ({best_clf['split_method']}) F1={best_clf['macro_f1']:.3f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìž¬í•™ìŠµ ë° ë¶„ì„\n",
    "        model_info = analyze_best_model_with_save(best_clf, centers, 'classification')\n",
    "        if model_info:\n",
    "            analyzed_models.append(model_info)\n",
    "    \n",
    "    return analyzed_models\n",
    "\n",
    "def analyze_best_model_with_save(best_result, centers, model_type):\n",
    "    \"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ë¶„ì„ (ì €ìž¥ ê¸°ëŠ¥ í¬í•¨)\"\"\"\n",
    "    center_name = best_result['center']\n",
    "    model_name = best_result['model']\n",
    "    split_method = best_result['split_method']\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ëª¨ë¸ ìž¬í•™ìŠµ ë° ë¶„ì„: {center_name} - {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        df = centers[center_name]\n",
    "        target_col = \"í•©ê³„_1ì¼í›„\" if model_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            df, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.2, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë¸ ìž¬êµ¬ì¶• ë° í•™ìŠµ\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "            \n",
    "        model = models[model_name]\n",
    "        pipe = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # ìƒì„¸ ë¶„ì„ ìˆ˜í–‰ (ì €ìž¥ í¬í•¨)\n",
    "        importance_df, shap_result = comprehensive_model_analysis_with_save(\n",
    "            pipe, model_name, X_train, X_test, y_train, y_test, \n",
    "            feature_names, model_type, center_name\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'center': center_name,\n",
    "            'model': model_name,\n",
    "            'type': model_type,\n",
    "            'split_method': split_method,\n",
    "            'performance': best_result,\n",
    "            'analysis_completed': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ================================================================================================\n",
    "# 8. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ë“¤ (ê°œì„ ëœ ë²„ì „)\n",
    "# ================================================================================================\n",
    "def run_stratified_comparison():\n",
    "    \"\"\"ì „ì²´ ì„¼í„° Stratified vs ì‹œê³„ì—´ ë¹„êµ (ê°œì„ ëœ ì €ìž¥ ê¸°ëŠ¥)\"\"\"\n",
    "    print(\"=== Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ ì‹¤í—˜ ===\")\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ í™•ì¸\n",
    "    try:\n",
    "        centers = {\n",
    "            \"nanji\": nanji,\n",
    "            \"jungnang\": jungnang,  \n",
    "            \"seonam\": seonam,\n",
    "            \"tancheon\": tancheon\n",
    "        }\n",
    "        \n",
    "        print(f\"\\në°ì´í„° í™•ì¸:\")\n",
    "        for name, df in centers.items():\n",
    "            print(f\"  {name}: {len(df)}í–‰\")\n",
    "    \n",
    "    except NameError:\n",
    "        print(\"ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € make_featuresë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ì „ì²´ ì‹¤í—˜ ì‹¤í–‰\n",
    "    all_results = []\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        try:\n",
    "            center_results = comprehensive_evaluation_comparison(center_name, df)\n",
    "            all_results.extend(center_results)\n",
    "        except Exception as e:\n",
    "            print(f\"[{center_name}] ì‹¤í—˜ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # ë¶„ì„ ë° ì‹œê°í™”\n",
    "        analyze_stratified_comparison(results_df)\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì‹ë³„ ë° ìƒì„¸ ë¶„ì„\n",
    "        perform_detailed_analysis_with_save(results_df, centers)\n",
    "        \n",
    "        # í¬ê´„ì  ê²°ê³¼ ì €ìž¥\n",
    "        saved_files = save_results_comprehensive(results_df, 'stratified_comparison')\n",
    "        \n",
    "        # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë°ì´í„°ë„ ë³„ë„ ì €ìž¥\n",
    "        successful_results = results_df[results_df['success'] == True]\n",
    "        if len(successful_results) > 0:\n",
    "            performance_comparison = create_performance_comparison_data(successful_results)\n",
    "            save_results_comprehensive(\n",
    "                performance_comparison, \n",
    "                'model_performance'\n",
    "            )\n",
    "        \n",
    "        print(f\"\\n=== ì‹¤í—˜ ì™„ë£Œ ===\")\n",
    "        print(f\"ì´ {len(results_df)}ê°œ ì‹¤í—˜ ì¤‘ {len(successful_results)}ê°œ ì„±ê³µ\")\n",
    "        print(f\"ê²°ê³¼ ì €ìž¥ ìœ„ì¹˜: ../data/results/\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def quick_stratified_test(center_name=\"nanji\"):\n",
    "    \"\"\"ë‹¨ì¼ ì„¼í„° Stratified í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"=== {center_name} ì„¼í„° Stratified vs ì‹œê³„ì—´ ë¹„êµ ===\")\n",
    "    \n",
    "    try:\n",
    "        if center_name == \"nanji\":\n",
    "            df = nanji\n",
    "        elif center_name == \"jungnang\":\n",
    "            df = jungnang\n",
    "        elif center_name == \"seonam\":\n",
    "            df = seonam\n",
    "        elif center_name == \"tancheon\":\n",
    "            df = tancheon\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown center: {center_name}\")\n",
    "            \n",
    "        results = comprehensive_evaluation_comparison(center_name, df)\n",
    "        return pd.DataFrame(results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "# ================================================================================================\n",
    "# ëª¨ë¸ ì €ìž¥ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œì— ì¶”ê°€)\n",
    "# ================================================================================================\n",
    "\n",
    "def save_trained_model(model_pipeline, model_info, performance_metrics, feature_names, \n",
    "                      center_name, model_name, split_method):\n",
    "    \"\"\"í•™ìŠµëœ ëª¨ë¸ê³¼ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ì €ìž¥\"\"\"\n",
    "    \n",
    "    # ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    base_dir = create_result_directories()\n",
    "    model_dir = os.path.join(base_dir, 'trained_models')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # íŒŒì¼ëª… ìƒì„±\n",
    "    model_filename = f\"{center_name}_{model_name}_{split_method}_{timestamp}\"\n",
    "    \n",
    "    saved_files = []\n",
    "    \n",
    "    try:\n",
    "        # 1. ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì €ìž¥ (joblib - sklearn ëª¨ë¸ì— ìµœì í™”)\n",
    "        model_path = os.path.join(model_dir, f\"{model_filename}_model.pkl\")\n",
    "        joblib.dump(model_pipeline, model_path)\n",
    "        saved_files.append(model_path)\n",
    "        \n",
    "        # 2. ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì €ìž¥ (JSON)\n",
    "        metadata = {\n",
    "            'model_info': {\n",
    "                'center_name': center_name,\n",
    "                'model_name': model_name,\n",
    "                'model_type': model_info.get('type', 'unknown'),\n",
    "                'split_method': split_method,\n",
    "                'training_timestamp': timestamp,\n",
    "                'training_date': datetime.now().isoformat()\n",
    "            },\n",
    "            'data_info': {\n",
    "                'feature_names': feature_names,\n",
    "                'feature_count': len(feature_names),\n",
    "                'target_column': \"í•©ê³„_1ì¼í›„\" if model_info.get('type') == 'regression' else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "            },\n",
    "            'preprocessing_info': {\n",
    "                'imputer_strategy': 'median',\n",
    "                'scaling_applied': model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"],\n",
    "                'pipeline_steps': ['imputer'] + (['scaler'] if model_name in [\"LinearRegression\", \"LogisticRegression_Clf\"] else [])\n",
    "            },\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'model_parameters': get_model_parameters(model_pipeline, model_name)\n",
    "        }\n",
    "        \n",
    "        metadata_path = os.path.join(model_dir, f\"{model_filename}_metadata.json\")\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "        saved_files.append(metadata_path)\n",
    "        \n",
    "        # 3. í”¼ì²˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ë³„ë„ ì €ìž¥ (ë¹ ë¥¸ ì ‘ê·¼ìš©)\n",
    "        feature_path = os.path.join(model_dir, f\"{model_filename}_features.txt\")\n",
    "        with open(feature_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(feature_names))\n",
    "        saved_files.append(feature_path)\n",
    "        \n",
    "        print(f\"\\n=== ëª¨ë¸ ì €ìž¥ ì™„ë£Œ ===\")\n",
    "        print(f\"ëª¨ë¸: {center_name} - {model_name} ({split_method})\")\n",
    "        for file in saved_files:\n",
    "            print(f\"ì €ìž¥ë¨: {file}\")\n",
    "            \n",
    "        return model_filename, saved_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ëª¨ë¸ ì €ìž¥ ì‹¤íŒ¨: {e}\")\n",
    "        return None, []\n",
    "\n",
    "def get_model_parameters(model_pipeline, model_name):\n",
    "    \"\"\"ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ\"\"\"\n",
    "    try:\n",
    "        model = model_pipeline.named_steps['model']\n",
    "        params = model.get_params()\n",
    "        \n",
    "        # ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„°ë§Œ ì €ìž¥ (ë„ˆë¬´ ë§Žìœ¼ë©´ íŒŒì¼ì´ ì»¤ì§)\n",
    "        important_params = {}\n",
    "        \n",
    "        if 'RandomForest' in model_name:\n",
    "            important_params = {\n",
    "                'n_estimators': params.get('n_estimators'),\n",
    "                'max_depth': params.get('max_depth'), \n",
    "                'min_samples_leaf': params.get('min_samples_leaf'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        elif 'XGBoost' in model_name:\n",
    "            important_params = {\n",
    "                'n_estimators': params.get('n_estimators'),\n",
    "                'max_depth': params.get('max_depth'),\n",
    "                'learning_rate': params.get('learning_rate'),\n",
    "                'subsample': params.get('subsample'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        elif 'LightGBM' in model_name:\n",
    "            important_params = {\n",
    "                'n_estimators': params.get('n_estimators'),\n",
    "                'learning_rate': params.get('learning_rate'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        elif 'CatBoost' in model_name:\n",
    "            important_params = {\n",
    "                'iterations': params.get('iterations'),\n",
    "                'learning_rate': params.get('learning_rate'),\n",
    "                'depth': params.get('depth'),\n",
    "                'random_state': params.get('random_state')\n",
    "            }\n",
    "        else:\n",
    "            # Linear models ë“±\n",
    "            important_params = {key: val for key, val in params.items() \n",
    "                              if key in ['C', 'max_iter', 'random_state', 'solver']}\n",
    "        \n",
    "        return important_params\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "        return {}\n",
    "\n",
    "def load_trained_model(model_filename, model_dir=None):\n",
    "    \"\"\"ì €ìž¥ëœ ëª¨ë¸ê³¼ ë©”íƒ€ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "    \n",
    "    if model_dir is None:\n",
    "        base_dir = create_result_directories()\n",
    "        model_dir = os.path.join(base_dir, 'trained_models')\n",
    "    \n",
    "    try:\n",
    "        # 1. ëª¨ë¸ ë¡œë“œ\n",
    "        model_path = os.path.join(model_dir, f\"{model_filename}_model.pkl\")\n",
    "        model_pipeline = joblib.load(model_path)\n",
    "        \n",
    "        # 2. ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "        metadata_path = os.path.join(model_dir, f\"{model_filename}_metadata.json\")\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # 3. í”¼ì²˜ ì´ë¦„ ë¡œë“œ\n",
    "        feature_path = os.path.join(model_dir, f\"{model_filename}_features.txt\")\n",
    "        with open(feature_path, 'r', encoding='utf-8') as f:\n",
    "            feature_names = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        print(f\"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {metadata['model_info']['center_name']} - {metadata['model_info']['model_name']}\")\n",
    "        print(f\"í•™ìŠµ ì¼ì‹œ: {metadata['model_info']['training_date']}\")\n",
    "        print(f\"ì„±ëŠ¥ ì§€í‘œ: {metadata['performance_metrics']}\")\n",
    "        \n",
    "        return {\n",
    "            'model_pipeline': model_pipeline,\n",
    "            'metadata': metadata,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_with_saved_model(model_data, new_data):\n",
    "    \"\"\"ì €ìž¥ëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡\"\"\"\n",
    "    \n",
    "    try:\n",
    "        model_pipeline = model_data['model_pipeline']\n",
    "        expected_features = model_data['feature_names']\n",
    "        metadata = model_data['metadata']\n",
    "        \n",
    "        # 1. í”¼ì²˜ í™•ì¸ ë° ì •ë ¬\n",
    "        if isinstance(new_data, pd.DataFrame):\n",
    "            # í•„ìš”í•œ í”¼ì²˜ë§Œ ì„ íƒí•˜ê³  ìˆœì„œ ë§žì¶¤\n",
    "            missing_features = set(expected_features) - set(new_data.columns)\n",
    "            if missing_features:\n",
    "                print(f\"ê²½ê³ : ë‹¤ìŒ í”¼ì²˜ë“¤ì´ ëˆ„ë½ë¨: {missing_features}\")\n",
    "                # ëˆ„ë½ëœ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€\n",
    "                for feature in missing_features:\n",
    "                    new_data[feature] = 0\n",
    "            \n",
    "            # í”¼ì²˜ ìˆœì„œ ë§žì¶¤\n",
    "            X_new = new_data[expected_features].copy()\n",
    "        else:\n",
    "            raise ValueError(\"ìƒˆ ë°ì´í„°ëŠ” pandas DataFrameì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # 2. ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        predictions = model_pipeline.predict(X_new)\n",
    "        \n",
    "        # 3. ì˜ˆì¸¡ ê²°ê³¼ í›„ì²˜ë¦¬\n",
    "        model_type = metadata['model_info']['model_type']\n",
    "        \n",
    "        if model_type == 'classification':\n",
    "            # ë¶„ë¥˜ì˜ ê²½ìš° í™•ë¥ ë„ í•¨ê»˜ ë°˜í™˜\n",
    "            try:\n",
    "                probabilities = model_pipeline.predict_proba(X_new)\n",
    "                return {\n",
    "                    'predictions': predictions,\n",
    "                    'probabilities': probabilities,\n",
    "                    'model_type': model_type,\n",
    "                    'model_name': metadata['model_info']['model_name']\n",
    "                }\n",
    "            except:\n",
    "                return {\n",
    "                    'predictions': predictions,\n",
    "                    'model_type': model_type,\n",
    "                    'model_name': metadata['model_info']['model_name']\n",
    "                }\n",
    "        else:\n",
    "            # íšŒê·€ì˜ ê²½ìš°\n",
    "            return {\n",
    "                'predictions': predictions,\n",
    "                'model_type': model_type,\n",
    "                'model_name': metadata['model_info']['model_name']\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜ˆì¸¡ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def list_saved_models(model_dir=None):\n",
    "    \"\"\"ì €ìž¥ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ\"\"\"\n",
    "    \n",
    "    if model_dir is None:\n",
    "        base_dir = create_result_directories()\n",
    "        model_dir = os.path.join(base_dir, 'trained_models')\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        print(\"ì €ìž¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return []\n",
    "    \n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('_metadata.json')]\n",
    "    models_info = []\n",
    "    \n",
    "    for metadata_file in model_files:\n",
    "        try:\n",
    "            metadata_path = os.path.join(model_dir, metadata_file)\n",
    "            with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "                metadata = json.load(f)\n",
    "            \n",
    "            model_filename = metadata_file.replace('_metadata.json', '')\n",
    "            \n",
    "            info = {\n",
    "                'filename': model_filename,\n",
    "                'center': metadata['model_info']['center_name'],\n",
    "                'model': metadata['model_info']['model_name'],\n",
    "                'type': metadata['model_info']['model_type'],\n",
    "                'split_method': metadata['model_info']['split_method'],\n",
    "                'training_date': metadata['model_info']['training_date'],\n",
    "                'performance': metadata['performance_metrics']\n",
    "            }\n",
    "            models_info.append(info)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ë©”íƒ€ë°ì´í„° ì½ê¸° ì‹¤íŒ¨ ({metadata_file}): {e}\")\n",
    "    \n",
    "    return models_info\n",
    "\n",
    "# ================================================================================================\n",
    "# ê¸°ì¡´ í‰ê°€ í•¨ìˆ˜ë“¤ ìˆ˜ì • (ëª¨ë¸ ì €ìž¥ ê¸°ëŠ¥ ì¶”ê°€)\n",
    "# ================================================================================================\n",
    "\n",
    "def evaluate_regression_model_with_save(model, model_name, X_train, X_test, y_train, y_test, \n",
    "                                       feature_names=None, center_name=None, split_method=None, \n",
    "                                       save_model=False):\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ í‰ê°€ + ëª¨ë¸ ì €ìž¥ ì˜µì…˜\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"regression\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "        \n",
    "        performance_metrics = {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mape': mape\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            **performance_metrics,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        # ëª¨ë¸ ì €ìž¥ (ìš”ì²­ ì‹œ)\n",
    "        saved_model_info = None\n",
    "        if save_model and feature_names and center_name and split_method:\n",
    "            model_info = {'type': 'regression'}\n",
    "            filename, files = save_trained_model(\n",
    "                pipe, model_info, performance_metrics, feature_names,\n",
    "                center_name, model_name, split_method\n",
    "            )\n",
    "            saved_model_info = {'filename': filename, 'files': files}\n",
    "        \n",
    "        return result, pipe, y_pred, saved_model_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'regression',\n",
    "            'mae': np.nan,\n",
    "            'rmse': np.nan,\n",
    "            'r2': np.nan,\n",
    "            'mape': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None, None\n",
    "\n",
    "def evaluate_classification_model_with_save(model, model_name, X_train, X_test, y_train, y_test,\n",
    "                                          feature_names=None, center_name=None, split_method=None,\n",
    "                                          save_model=False):\n",
    "    \"\"\"ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ + ëª¨ë¸ ì €ìž¥ ì˜µì…˜\"\"\"\n",
    "    try:\n",
    "        pipe = make_pipeline_unified(model, model_name, \"classification\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        if isinstance(y_pred, np.ndarray) and y_pred.ndim > 1:\n",
    "            y_pred = y_pred.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        \n",
    "        extreme_classes = [0, 3]\n",
    "        y_true_extreme = pd.Series(y_test).isin(extreme_classes).astype(int)\n",
    "        y_pred_extreme = pd.Series(y_pred).isin(extreme_classes).astype(int)\n",
    "        extreme_f1 = f1_score(y_true_extreme, y_pred_extreme, zero_division=0)\n",
    "        \n",
    "        performance_metrics = {\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': f1_macro,\n",
    "            'weighted_f1': f1_weighted,\n",
    "            'extreme_f1': extreme_f1\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            **performance_metrics,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        # ëª¨ë¸ ì €ìž¥ (ìš”ì²­ ì‹œ)\n",
    "        saved_model_info = None\n",
    "        if save_model and feature_names and center_name and split_method:\n",
    "            model_info = {'type': 'classification'}\n",
    "            filename, files = save_trained_model(\n",
    "                pipe, model_info, performance_metrics, feature_names,\n",
    "                center_name, model_name, split_method\n",
    "            )\n",
    "            saved_model_info = {'filename': filename, 'files': files}\n",
    "        \n",
    "        return result, pipe, y_pred, saved_model_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'type': 'classification',\n",
    "            'accuracy': np.nan,\n",
    "            'macro_f1': np.nan,\n",
    "            'weighted_f1': np.nan,\n",
    "            'extreme_f1': np.nan,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }, None, None, None\n",
    "\n",
    "# ================================================================================================\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìžë™ ì €ìž¥ í•¨ìˆ˜\n",
    "# ================================================================================================\n",
    "\n",
    "def save_best_models_automatically(results_df, centers):\n",
    "    \"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ì„ ìžë™ìœ¼ë¡œ ìž¬í•™ìŠµí•˜ì—¬ ì €ìž¥\"\"\"\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(\"ì €ìž¥í•  ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìžë™ ì €ìž¥ ===\")\n",
    "    \n",
    "    saved_models = []\n",
    "    \n",
    "    # ì„¼í„°ë³„, íƒ€ìž…ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ìž¥\n",
    "    for center in successful_results['center'].unique():\n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        for model_type in ['regression', 'classification']:\n",
    "            type_data = center_data[center_data['type'] == model_type]\n",
    "            \n",
    "            if len(type_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\n",
    "            if model_type == 'regression':\n",
    "                best_model = type_data.loc[type_data['r2'].idxmax()]\n",
    "                metric_name = 'RÂ²'\n",
    "                metric_value = best_model['r2']\n",
    "            else:\n",
    "                best_model = type_data.loc[type_data['macro_f1'].idxmax()]\n",
    "                metric_name = 'Macro F1'\n",
    "                metric_value = best_model['macro_f1']\n",
    "            \n",
    "            print(f\"\\nì €ìž¥ ì¤‘: {center} - {best_model['model']} ({model_type})\")\n",
    "            print(f\"ì„±ëŠ¥: {metric_name}={metric_value:.3f}\")\n",
    "            \n",
    "            try:\n",
    "                # ëª¨ë¸ ìž¬í•™ìŠµ ë° ì €ìž¥\n",
    "                df = centers[center]\n",
    "                target_col = \"í•©ê³„_1ì¼í›„\" if model_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "                \n",
    "                X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "                    df, target_col=target_col, model_type=model_type, \n",
    "                    test_size=0.2, split_method=best_model['split_method']\n",
    "                )\n",
    "                \n",
    "                # ëª¨ë¸ ìž¬êµ¬ì¶•\n",
    "                if model_type == \"regression\":\n",
    "                    models = build_regression_models()\n",
    "                    result, pipe, y_pred, saved_info = evaluate_regression_model_with_save(\n",
    "                        models[best_model['model']], best_model['model'],\n",
    "                        X_train, X_test, y_train, y_test,\n",
    "                        feature_names, center, best_model['split_method'], \n",
    "                        save_model=True\n",
    "                    )\n",
    "                else:\n",
    "                    models = build_classification_models()\n",
    "                    result, pipe, y_pred, saved_info = evaluate_classification_model_with_save(\n",
    "                        models[best_model['model']], best_model['model'],\n",
    "                        X_train, X_test, y_train, y_test,\n",
    "                        feature_names, center, best_model['split_method'],\n",
    "                        save_model=True\n",
    "                    )\n",
    "                \n",
    "                if saved_info:\n",
    "                    saved_models.append(saved_info['filename'])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"ì €ìž¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    print(f\"\\nì´ {len(saved_models)}ê°œ ëª¨ë¸ ì €ìž¥ ì™„ë£Œ\")\n",
    "    return saved_models\n",
    "\n",
    "# ================================================================================================\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# ================================================================================================\n",
    "\n",
    "def demo_model_usage():\n",
    "    \"\"\"ëª¨ë¸ ì €ìž¥ ë° ì‚¬ìš© ë°ëª¨\"\"\"\n",
    "    \n",
    "    print(\"=== ëª¨ë¸ ì €ìž¥ ë° ì‚¬ìš© ë°ëª¨ ===\")\n",
    "    \n",
    "    # 1. ì €ìž¥ëœ ëª¨ë¸ ëª©ë¡ í™•ì¸\n",
    "    print(\"\\n1. ì €ìž¥ëœ ëª¨ë¸ ëª©ë¡:\")\n",
    "    models = list_saved_models()\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"  {i+1}. {model['center']} - {model['model']} ({model['type']})\")\n",
    "        print(f\"     ì„±ëŠ¥: {model['performance']}\")\n",
    "        print(f\"     íŒŒì¼ëª…: {model['filename']}\")\n",
    "    \n",
    "    # 2. ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ (ì˜ˆì‹œ)\n",
    "    if models:\n",
    "        print(f\"\\n2. ì²« ë²ˆì§¸ ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:\")\n",
    "        first_model = models[0]\n",
    "        \n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        model_data = load_trained_model(first_model['filename'])\n",
    "        \n",
    "        if model_data:\n",
    "            print(\"ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "            print(f\"ì˜ˆìƒ í”¼ì²˜ ê°œìˆ˜: {len(model_data['feature_names'])}\")\n",
    "            \n",
    "            # ë”ë¯¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)\n",
    "            dummy_data = pd.DataFrame({\n",
    "                feature: [0.5] for feature in model_data['feature_names']\n",
    "            })\n",
    "            \n",
    "            result = predict_with_saved_model(model_data, dummy_data)\n",
    "            if result:\n",
    "                print(f\"ì˜ˆì¸¡ ê²°ê³¼: {result['predictions']}\")\n",
    "                if 'probabilities' in result:\n",
    "                    print(f\"ì˜ˆì¸¡ í™•ë¥ : {result['probabilities']}\")\n",
    "\n",
    "# ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¶„ì„ì„ ìœ„í•œ í•¨ìˆ˜ ìˆ˜ì •\n",
    "\n",
    "def perform_detailed_analysis_with_save_by_center(results_df, centers):\n",
    "    \"\"\"ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (ì €ìž¥ ê¸°ëŠ¥ í¬í•¨)\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ë¶„ì„ ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(\"ë¶„ì„í•  ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return []\n",
    "    \n",
    "    analyzed_models = []\n",
    "    \n",
    "    # ì„¼í„°ë³„ë¡œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¶„ì„\n",
    "    for center in successful_results['center'].unique():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ì„¼í„°: {center.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        center_data = successful_results[successful_results['center'] == center]\n",
    "        \n",
    "        # 1. ì„¼í„°ë³„ íšŒê·€ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "        reg_results = center_data[center_data['type'] == 'regression']\n",
    "        if len(reg_results) > 0:\n",
    "            best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "            print(f\"\\n[{center}] ìµœê³  íšŒê·€ ì„±ëŠ¥: {best_reg['model']} ({best_reg['split_method']}) RÂ²={best_reg['r2']:.3f}\")\n",
    "            \n",
    "            # íšŒê·€ ëª¨ë¸ ìž¬í•™ìŠµ ë° ë¶„ì„\n",
    "            model_info = analyze_best_model_with_save_detailed(best_reg, centers, 'regression')\n",
    "            if model_info:\n",
    "                analyzed_models.append(model_info)\n",
    "        \n",
    "        # 2. ì„¼í„°ë³„ ë¶„ë¥˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "        clf_results = center_data[center_data['type'] == 'classification']\n",
    "        if len(clf_results) > 0:\n",
    "            best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "            print(f\"\\n[{center}] ìµœê³  ë¶„ë¥˜ ì„±ëŠ¥: {best_clf['model']} ({best_clf['split_method']}) F1={best_clf['macro_f1']:.3f}\")\n",
    "            \n",
    "            # ë¶„ë¥˜ ëª¨ë¸ ìž¬í•™ìŠµ ë° ë¶„ì„\n",
    "            model_info = analyze_best_model_with_save_detailed(best_clf, centers, 'classification')\n",
    "            if model_info:\n",
    "                analyzed_models.append(model_info)\n",
    "    \n",
    "    print(f\"\\nì´ {len(analyzed_models)}ê°œ ëª¨ë¸ ìƒì„¸ ë¶„ì„ ì™„ë£Œ\")\n",
    "    return analyzed_models\n",
    "\n",
    "def analyze_best_model_with_save_detailed(best_result, centers, model_type):\n",
    "    \"\"\"ê°œë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ë¶„ì„ (ì €ìž¥ ê¸°ëŠ¥ í¬í•¨)\"\"\"\n",
    "    center_name = best_result['center']\n",
    "    model_name = best_result['model']\n",
    "    split_method = best_result['split_method']\n",
    "    \n",
    "    print(f\"\\në¶„ì„ ì¤‘: {center_name} - {model_name} ({model_type})\")\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        df = centers[center_name]\n",
    "        target_col = \"í•©ê³„_1ì¼í›„\" if model_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            df, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.2, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë¸ ìž¬êµ¬ì¶• ë° í•™ìŠµ\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "            \n",
    "        model = models[model_name]\n",
    "        pipe = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # ìƒì„¸ ë¶„ì„ ìˆ˜í–‰ (Feature Importance + SHAP + ì €ìž¥)\n",
    "        print(f\"  Feature Importance & SHAP ë¶„ì„ ì§„í–‰ ì¤‘...\")\n",
    "        importance_df, shap_result = comprehensive_model_analysis_with_save(\n",
    "            pipe, model_name, X_train, X_test, y_train, y_test, \n",
    "            feature_names, model_type, center_name\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë¸ë„ ì €ìž¥\n",
    "        performance_metrics = {}\n",
    "        if model_type == \"regression\":\n",
    "            y_pred = pipe.predict(X_test)\n",
    "            performance_metrics = {\n",
    "                'r2': best_result['r2'],\n",
    "                'mae': best_result['mae'], \n",
    "                'rmse': best_result['rmse'],\n",
    "                'mape': best_result['mape']\n",
    "            }\n",
    "        else:\n",
    "            performance_metrics = {\n",
    "                'accuracy': best_result['accuracy'],\n",
    "                'macro_f1': best_result['macro_f1'],\n",
    "                'weighted_f1': best_result['weighted_f1'],\n",
    "                'extreme_f1': best_result['extreme_f1']\n",
    "            }\n",
    "        \n",
    "        # í•™ìŠµëœ ëª¨ë¸ ì €ìž¥\n",
    "        model_info = {'type': model_type}\n",
    "        filename, files = save_trained_model(\n",
    "            pipe, model_info, performance_metrics, feature_names,\n",
    "            center_name, model_name, split_method\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'center': center_name,\n",
    "            'model': model_name,\n",
    "            'type': model_type,\n",
    "            'split_method': split_method,\n",
    "            'performance': best_result,\n",
    "            'saved_model_filename': filename,\n",
    "            'analysis_completed': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ê¸°ì¡´ run_stratified_comparison í•¨ìˆ˜ì—ì„œ í˜¸ì¶œ ë¶€ë¶„ ìˆ˜ì •\n",
    "def run_stratified_comparison_with_center_analysis():\n",
    "    \"\"\"ì „ì²´ ì„¼í„° Stratified vs ì‹œê³„ì—´ ë¹„êµ + ì„¼í„°ë³„ ìƒì„¸ ë¶„ì„\"\"\"\n",
    "    print(\"=== Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ ì‹¤í—˜ (ì„¼í„°ë³„ ë¶„ì„) ===\")\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ í™•ì¸\n",
    "    try:\n",
    "        centers = {\n",
    "            \"nanji\": nanji,\n",
    "            \"jungnang\": jungnang,  \n",
    "            \"seonam\": seonam,\n",
    "            \"tancheon\": tancheon\n",
    "        }\n",
    "        \n",
    "        print(f\"\\në°ì´í„° í™•ì¸:\")\n",
    "        for name, df in centers.items():\n",
    "            print(f\"  {name}: {len(df)}í–‰\")\n",
    "    \n",
    "    except NameError:\n",
    "        print(\"ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € make_featuresë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # ì „ì²´ ì‹¤í—˜ ì‹¤í–‰\n",
    "    all_results = []\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        try:\n",
    "            center_results = comprehensive_evaluation_comparison(center_name, df)\n",
    "            all_results.extend(center_results)\n",
    "        except Exception as e:\n",
    "            print(f\"[{center_name}] ì‹¤í—˜ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # ê¸°ë³¸ ë¶„ì„ ë° ì‹œê°í™”\n",
    "        analyze_stratified_comparison(results_df)\n",
    "        \n",
    "        # ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ë¶„ì„ (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "        analyzed_models = perform_detailed_analysis_with_save_by_center(results_df, centers)\n",
    "        \n",
    "        # í¬ê´„ì  ê²°ê³¼ ì €ìž¥\n",
    "        saved_files = save_results_comprehensive(results_df, 'stratified_comparison')\n",
    "        \n",
    "        # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë°ì´í„°ë„ ë³„ë„ ì €ìž¥\n",
    "        successful_results = results_df[results_df['success'] == True]\n",
    "        if len(successful_results) > 0:\n",
    "            performance_comparison = create_performance_comparison_data(successful_results)\n",
    "            save_results_comprehensive(\n",
    "                performance_comparison, \n",
    "                'model_performance'\n",
    "            )\n",
    "        \n",
    "        # ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "        print(f\"\\n=== ì‹¤í—˜ ì™„ë£Œ ===\")\n",
    "        print(f\"ì´ {len(results_df)}ê°œ ì‹¤í—˜ ì¤‘ {len(successful_results)}ê°œ ì„±ê³µ\")\n",
    "        print(f\"ì„¼í„°ë³„ ìƒì„¸ ë¶„ì„: {len(analyzed_models)}ê°œ ëª¨ë¸\")\n",
    "        print(f\"ê²°ê³¼ ì €ìž¥ ìœ„ì¹˜: ../data/results/\")\n",
    "        \n",
    "        # ë¶„ì„ëœ ëª¨ë¸ ëª©ë¡ ì¶œë ¥\n",
    "        if analyzed_models:\n",
    "            print(f\"\\n=== ë¶„ì„ëœ ëª¨ë¸ ëª©ë¡ ===\")\n",
    "            for model in analyzed_models:\n",
    "                print(f\"  {model['center']} - {model['model']} ({model['type']}) [{model['split_method']}]\")\n",
    "                print(f\"    ì €ìž¥ëœ ëª¨ë¸: {model.get('saved_model_filename', 'N/A')}\")\n",
    "    \n",
    "    return results_df, analyzed_models\n",
    "\n",
    "# ì„¼í„°ë³„ ë¶„ì„ ê²°ê³¼ ìš”ì•½ í•¨ìˆ˜\n",
    "def summarize_center_analysis(analyzed_models):\n",
    "    \"\"\"ì„¼í„°ë³„ ë¶„ì„ ê²°ê³¼ ìš”ì•½\"\"\"\n",
    "    if not analyzed_models:\n",
    "        print(\"ë¶„ì„ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"=== ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìš”ì•½ ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    centers = {}\n",
    "    for model in analyzed_models:\n",
    "        center = model['center']\n",
    "        if center not in centers:\n",
    "            centers[center] = {'regression': None, 'classification': None}\n",
    "        centers[center][model['type']] = model\n",
    "    \n",
    "    for center, models in centers.items():\n",
    "        print(f\"\\n[{center.upper()} ì„¼í„°]\")\n",
    "        \n",
    "        if models['regression']:\n",
    "            reg_model = models['regression']\n",
    "            print(f\"  íšŒê·€: {reg_model['model']} ({reg_model['split_method']})\")\n",
    "            print(f\"       RÂ² = {reg_model['performance']['r2']:.3f}\")\n",
    "        \n",
    "        if models['classification']:\n",
    "            clf_model = models['classification']\n",
    "            print(f\"  ë¶„ë¥˜: {clf_model['model']} ({clf_model['split_method']})\")\n",
    "            print(f\"       F1 = {clf_model['performance']['macro_f1']:.3f}\")\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ í•¨ìˆ˜\n",
    "def demo_center_wise_analysis():\n",
    "    \"\"\"ì„¼í„°ë³„ ë¶„ì„ ë°ëª¨\"\"\"\n",
    "    print(\"=== ì„¼í„°ë³„ ë¶„ì„ ì‹¤í–‰ ===\")\n",
    "    \n",
    "    # ì„¼í„°ë³„ ë¶„ì„ ì‹¤í–‰\n",
    "    results_df, analyzed_models = run_stratified_comparison_with_center_analysis()\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    summarize_center_analysis(analyzed_models)\n",
    "    \n",
    "    return results_df, analyzed_models\n",
    "\n",
    "# ================================================================================================\n",
    "# 9. ì‹¤í–‰ ê°€ì´ë“œ ë° ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "# ================================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== ì™„ì„±ëœ Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ ì‹¤í—˜ ===\")\n",
    "    \n",
    "    print(\"\\nðŸ“ ê²°ê³¼ ì €ìž¥ êµ¬ì¡°:\")\n",
    "    print(\"../data/results/\")\n",
    "    print(\"â”œâ”€â”€ stratified_comparison/  # ë¶„í•  ë°©ë²• ë¹„êµ ê²°ê³¼\")\n",
    "    print(\"â”‚   â”œâ”€â”€ stratified_comparison_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"â”‚   â”œâ”€â”€ stratified_summary_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"â”‚   â””â”€â”€ stratified_best_models_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"â”œâ”€â”€ feature_importance/     # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„\")\n",
    "    print(\"â”‚   â””â”€â”€ importance_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"â”œâ”€â”€ shap_analysis/         # SHAP ë¶„ì„ ê²°ê³¼\")\n",
    "    print(\"â”‚   â”œâ”€â”€ shap_values_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.pkl\")\n",
    "    print(\"â”‚   â””â”€â”€ shap_summary_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"â”œâ”€â”€ model_performance/     # ëª¨ë¸ ì„±ëŠ¥ ìƒì„¸ ë¶„ì„\")\n",
    "    print(\"â”‚   â””â”€â”€ performance_YYYYMMDD_HHMMSS.csv\")\n",
    "    print(\"â””â”€â”€ visualizations/        # ìƒì„±ëœ ê·¸ëž˜í”„ ì´ë¯¸ì§€\")\n",
    "    print(\"    â”œâ”€â”€ stratified_comparison_plots_YYYYMMDD_HHMMSS.png\")\n",
    "    print(\"    â”œâ”€â”€ feature_importance_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.png\")\n",
    "    print(\"    â””â”€â”€ shap_ì„¼í„°ëª…_ëª¨ë¸ëª…_YYYYMMDD_HHMMSS.png\")\n",
    "    \n",
    "    print(\"\\nðŸš€ ì‹¤í–‰ ë°©ë²•:\")\n",
    "    print(\"1. ì „ì²´ ì‹¤í—˜ (ê¶Œìž¥): \")\n",
    "    print(\"   results_df = run_stratified_comparison()\")\n",
    "    print(\"\\n2. ë‹¨ì¼ ì„¼í„° í…ŒìŠ¤íŠ¸:\")\n",
    "    print(\"   results_df = quick_stratified_test('nanji')\")\n",
    "    print(\"\\n3. ê²°ê³¼ ë¶„ì„ë§Œ:\")\n",
    "    print(\"   analyze_stratified_comparison(results_df)\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ ì£¼ìš” ê°œì„ ì‚¬í•­:\")\n",
    "    print(\"- CatBoost íšŒê·€ ëª¨ë¸ ì˜¤ë¥˜ ìˆ˜ì •\")\n",
    "    print(\"- CatBoost ë¶„ë¥˜ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì˜¤ë¥˜ ìˆ˜ì •\")\n",
    "    print(\"- ì²´ê³„ì ì¸ í´ë” êµ¬ì¡°ë¡œ ê²°ê³¼ ì €ìž¥\")\n",
    "    print(\"- Feature Importance & SHAP ë¶„ì„ ê²°ê³¼ ì €ìž¥\")\n",
    "    print(\"- ì‹œê°í™” ì´ë¯¸ì§€ ìžë™ ì €ìž¥\")\n",
    "    print(\"- ìš”ì•½ í†µê³„ ë° ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ìž¥\")\n",
    "    print(\"- ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì¶”ì  ê°€ëŠ¥\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š ì‹¤í—˜ êµ¬ì„±:\")\n",
    "    print(\"- 4ê°œ ì„¼í„° (nanji, jungnang, seonam, tancheon)\")\n",
    "    print(\"- 2ê°€ì§€ ë¶„í• ë°©ë²• (temporal, stratified)\")\n",
    "    print(\"- 12ê°œ ëª¨ë¸ (íšŒê·€ 6ê°œ + ë¶„ë¥˜ 6ê°œ)\")\n",
    "    print(\"- ì´ 96ê°œ ì‹¤í—˜ (4Ã—2Ã—12)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ í‰ê°€ ì§€í‘œ:\")\n",
    "    print(\"íšŒê·€: RÂ², MAE, RMSE, MAPE\")\n",
    "    print(\"ë¶„ë¥˜: Accuracy, Macro F1, Weighted F1, Extreme F1\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸ ì‚¬ìš© ì „ í™•ì¸ì‚¬í•­:\")\n",
    "    print(\"1. ë°ì´í„° ì¤€ë¹„: nanji, jungnang, seonam, tancheon ë³€ìˆ˜ê°€ ë¡œë“œë˜ì–´ ìžˆì–´ì•¼ í•¨\")\n",
    "    print(\"2. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: pandas, numpy, matplotlib, sklearn ë“±\")\n",
    "    print(\"3. ì„ íƒ ë¼ì´ë¸ŒëŸ¬ë¦¬: xgboost, lightgbm, catboost, shap\")\n",
    "    print(\"4. ì‹¤í–‰ ê¶Œí•œ: ../data/results/ í´ë” ìƒì„± ê¶Œí•œ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7155fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ:\\n\\n# 1. ì „ì²´ ì‹¤í—˜ ì‹¤í–‰\\nresults_df = run_stratified_comparison()\\n\\n# 2. ê²°ê³¼ í™•ì¸\\nprint(f\"ì´ {len(results_df)}ê°œ ì‹¤í—˜ ì™„ë£Œ\")\\nsuccessful = results_df[results_df[\\'success\\'] == True]\\nprint(f\"ì„±ê³µ: {len(successful)}ê°œ\")\\n\\n# 3. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í™•ì¸\\nreg_best = successful[successful[\\'type\\'] == \\'regression\\'].nlargest(1, \\'r2\\')\\nclf_best = successful[successful[\\'type\\'] == \\'classification\\'].nlargest(1, \\'macro_f1\\')\\n\\nprint(\"ìµœê³  íšŒê·€ ì„±ëŠ¥:\", reg_best[[\\'center\\', \\'model\\', \\'split_method\\', \\'r2\\']].iloc[0])\\nprint(\"ìµœê³  ë¶„ë¥˜ ì„±ëŠ¥:\", clf_best[[\\'center\\', \\'model\\', \\'split_method\\', \\'macro_f1\\']].iloc[0])\\n\\n# 4. ì €ìž¥ëœ íŒŒì¼ í™•ì¸\\nimport os\\nfor root, dirs, files in os.walk(\\'../data/results\\'):\\n    level = root.replace(\\'../data/results\\', \\'\\').count(os.sep)\\n    indent = \\' \\' * 2 * level\\n    print(f\\'{indent}{os.path.basename(root)}/\\')\\n    subindent = \\' \\' * 2 * (level + 1)\\n    for file in files:\\n        print(f\\'{subindent}{file}\\')\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "\"\"\"\n",
    "# ì„¼í„°ë³„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¶„ì„ ì‹¤í–‰\n",
    "results_df, analyzed_models = run_stratified_comparison_with_center_analysis()\n",
    "\n",
    "# ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "summarize_center_analysis(analyzed_models)\n",
    "\n",
    "# ì €ìž¥ëœ ëª¨ë¸ ëª©ë¡ í™•ì¸\n",
    "models = list_saved_models()\n",
    "for model in models:\n",
    "    print(f\"{model['center']} - {model['model']} ({model['type']}): {model['performance']}\")\n",
    "\"\"\"\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì‹œ\n",
    "\"\"\"\n",
    "# 1. ì‹¤í—˜ ì‹¤í–‰ í›„ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤ ìžë™ ì €ìž¥\n",
    "results_df = run_stratified_comparison()\n",
    "saved_models = save_best_models_automatically(results_df, centers)\n",
    "\n",
    "# 2. ì €ìž¥ëœ ëª¨ë¸ í™•ì¸\n",
    "demo_model_usage()\n",
    "\n",
    "# 3. ìƒˆë¡œìš´ ë°ì´í„°ì— ì˜ˆì¸¡\n",
    "model_data = load_trained_model('nanji_XGBoost_Reg_temporal_20250826_143022')\n",
    "new_predictions = predict_with_saved_model(model_data, new_dataframe)\n",
    "\"\"\"\n",
    "\n",
    "# ================================================================================================\n",
    "# 10. ì‚¬ìš© ì˜ˆì‹œ\n",
    "# ================================================================================================\n",
    "\"\"\"\n",
    "ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ:\n",
    "\n",
    "# 1. ì „ì²´ ì‹¤í—˜ ì‹¤í–‰\n",
    "results_df = run_stratified_comparison()\n",
    "\n",
    "# 2. ê²°ê³¼ í™•ì¸\n",
    "print(f\"ì´ {len(results_df)}ê°œ ì‹¤í—˜ ì™„ë£Œ\")\n",
    "successful = results_df[results_df['success'] == True]\n",
    "print(f\"ì„±ê³µ: {len(successful)}ê°œ\")\n",
    "\n",
    "# 3. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í™•ì¸\n",
    "reg_best = successful[successful['type'] == 'regression'].nlargest(1, 'r2')\n",
    "clf_best = successful[successful['type'] == 'classification'].nlargest(1, 'macro_f1')\n",
    "\n",
    "print(\"ìµœê³  íšŒê·€ ì„±ëŠ¥:\", reg_best[['center', 'model', 'split_method', 'r2']].iloc[0])\n",
    "print(\"ìµœê³  ë¶„ë¥˜ ì„±ëŠ¥:\", clf_best[['center', 'model', 'split_method', 'macro_f1']].iloc[0])\n",
    "\n",
    "# 4. ì €ìž¥ëœ íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "for root, dirs, files in os.walk('../data/results'):\n",
    "    level = root.replace('../data/results', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f'{subindent}{file}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f63189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ===\n",
      "\n",
      "ì‚¬ìš©ë²•:\n",
      "results = run_complete_production_pipeline()\n",
      "\n",
      "ë˜ëŠ” cutoff_dateë¥¼ ë³€ê²½í•˜ì—¬:\n",
      "results = run_complete_production_pipeline(cutoff_date='2025-05-15')\n",
      "\n",
      "ë°˜í™˜ê°’:\n",
      "- results[0]: ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸”\n",
      "- results[1]: í•™ìŠµëœ ëª¨ë¸ ì •ë³´\n",
      "- results[2]: ì„±ëŠ¥ ìš”ì•½\n",
      "\n",
      "ìƒì„±ë˜ëŠ” íŒŒì¼:\n",
      "- production_simulation_YYYYMMDD_HHMMSS_predictions.csv\n",
      "- production_simulation_YYYYMMDD_HHMMSS_summary.csv\n",
      "- production_simulation_YYYYMMDD_HHMMSS_training.csv\n",
      "ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\n",
      "ì´ ê³¼ì •ì€ ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
      "================================================================================\n",
      "ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì‹œìž‘\n",
      "í•™ìŠµ ê¸°ê°„: ~ 2025-05-20\n",
      "ì˜ˆì¸¡ ê¸°ê°„: 2025-05-20 ì´í›„\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "1ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€ (~ 2025-05-20)\n",
      "============================================================\n",
      "\n",
      "[NANJI ì„¼í„° ì²˜ë¦¬ ì¤‘...]\n",
      "  í•™ìŠµ ë°ì´í„°: 3062í–‰\n",
      "  ì˜ˆì¸¡ ë°ì´í„°: 41í–‰\n",
      "\n",
      "======================================================================\n",
      "ì„¼í„°: nanji - Stratified vs ì‹œê³„ì—´ ë¶„í•  ë¹„êµ\n",
      "======================================================================\n",
      "ë°ì´í„° í¬ê¸°: 3062í–‰, 28ì»¬ëŸ¼\n",
      "\n",
      "==================================================\n",
      "ë¶„í•  ë°©ë²•: TEMPORAL\n",
      "==================================================\n",
      "\n",
      "--- íšŒê·€ ëª¨ë¸ í‰ê°€ (temporal) ---\n",
      "íšŒê·€ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ (temporal): 'í•©ê³„_1ì¼í›„'\n",
      "\n",
      "--- ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ (temporal) ---\n",
      "ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ (temporal): 'ë“±ê¸‰_1ì¼í›„'\n",
      "\n",
      "==================================================\n",
      "ë¶„í•  ë°©ë²•: STRATIFIED\n",
      "==================================================\n",
      "\n",
      "--- íšŒê·€ ëª¨ë¸ í‰ê°€ (random_shuffle) ---\n",
      "íšŒê·€ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ (random_shuffle): 'í•©ê³„_1ì¼í›„'\n",
      "\n",
      "--- ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ (stratified) ---\n",
      "ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨ (stratified): 'ë“±ê¸‰_1ì¼í›„'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'success'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 588\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- production_simulation_YYYYMMDD_HHMMSS_training.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_complete_production_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcutoff_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2025-05-20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# ê²°ê³¼ í™•ì¸\u001b[39;00m\n\u001b[1;32m    591\u001b[0m final_table, trained_models, performance_summary \u001b[38;5;241m=\u001b[39m results\n",
      "Cell \u001b[0;32mIn[59], line 552\u001b[0m, in \u001b[0;36mrun_complete_production_pipeline\u001b[0;34m(cutoff_date)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# í•µì‹¬ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ í˜¸ì¶œ (ìžê¸° ìžì‹ ì´ ì•„ë‹Œ!)\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcomplete_production_simulation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    555\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[59], line 84\u001b[0m, in \u001b[0;36mcomplete_production_simulation_pipeline\u001b[0;34m(centers, cutoff_date)\u001b[0m\n\u001b[1;32m     81\u001b[0m all_training_results\u001b[38;5;241m.\u001b[39mextend(center_results)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m center_best_models \u001b[38;5;241m=\u001b[39m \u001b[43mselect_and_train_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center_best_models:\n\u001b[1;32m     86\u001b[0m     best_models_by_center[center_name] \u001b[38;5;241m=\u001b[39m center_best_models\n",
      "Cell \u001b[0;32mIn[59], line 164\u001b[0m, in \u001b[0;36mselect_and_train_best_models\u001b[0;34m(center_name, train_data, evaluation_results)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(evaluation_results)\n\u001b[0;32m--> 164\u001b[0m successful_results \u001b[38;5;241m=\u001b[39m results_df[\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuccess\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(successful_results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'success'"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "# ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸\n",
    "# 1ë‹¨ê³„: 5ì›” 20ì¼ê¹Œì§€ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€\n",
    "# 2ë‹¨ê³„: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ë° ì €ìž¥\n",
    "# 3ë‹¨ê³„: 5ì›” 21ì¼~31ì¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "# 4ë‹¨ê³„: ê²°ê³¼ í…Œì´ë¸” ìƒì„± ë° ì„±ëŠ¥ í‰ê°€\n",
    "# ================================================================================================\n",
    "\n",
    "# ê¸°ì¡´ í•¨ìˆ˜ë“¤ í™œìš©\n",
    "def complete_production_simulation_pipeline(centers=None, cutoff_date='2025-05-20'):\n",
    "    \"\"\"\n",
    "    ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸\n",
    "    \n",
    "    Parameters:\n",
    "    - centers: ì„¼í„°ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬\n",
    "    - cutoff_date: í•™ìŠµ/ì˜ˆì¸¡ ë¶„í•  ê¸°ì¤€ì¼\n",
    "    \n",
    "    Returns:\n",
    "    - final_results_table: ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸”\n",
    "    - trained_models_info: í•™ìŠµëœ ëª¨ë¸ ì •ë³´\n",
    "    - performance_summary: ì„±ëŠ¥ ìš”ì•½\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ì‹œìž‘\")\n",
    "    print(f\"í•™ìŠµ ê¸°ê°„: ~ {cutoff_date}\")\n",
    "    print(f\"ì˜ˆì¸¡ ê¸°ê°„: {cutoff_date} ì´í›„\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ í™•ì¸\n",
    "    if centers is None:\n",
    "        try:\n",
    "            centers = {\n",
    "                \"nanji\": nanji,\n",
    "                \"jungnang\": jungnang,  \n",
    "                \"seonam\": seonam,\n",
    "                \"tancheon\": tancheon\n",
    "            }\n",
    "            print(f\"ë°ì´í„° ë¡œë“œ ì™„ë£Œ:\")\n",
    "            for name, df in centers.items():\n",
    "                print(f\"  {name}: {len(df)}í–‰\")\n",
    "        except NameError:\n",
    "            print(\"ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.\")\n",
    "            return None\n",
    "    \n",
    "    cutoff = pd.to_datetime(cutoff_date)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 1ë‹¨ê³„: ê° ì„¼í„°ë³„ë¡œ 5ì›” 20ì¼ê¹Œì§€ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"1ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€ (~ {cutoff_date})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_training_results = []\n",
    "    best_models_by_center = {}\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        print(f\"\\n[{center_name.upper()} ì„¼í„° ì²˜ë¦¬ ì¤‘...]\")\n",
    "        \n",
    "        # ë‚ ì§œ ë³€í™˜ ë° ë°ì´í„° ë¶„í• \n",
    "        df_work = df.copy()\n",
    "        df_work['ë‚ ì§œ'] = pd.to_datetime(df_work['ë‚ ì§œ'])\n",
    "        \n",
    "        train_data = df_work[df_work['ë‚ ì§œ'] <= cutoff].copy()\n",
    "        future_data = df_work[df_work['ë‚ ì§œ'] > cutoff].copy()\n",
    "        \n",
    "        print(f\"  í•™ìŠµ ë°ì´í„°: {len(train_data)}í–‰\")\n",
    "        print(f\"  ì˜ˆì¸¡ ë°ì´í„°: {len(future_data)}í–‰\")\n",
    "        \n",
    "        if len(train_data) < 50:\n",
    "            print(f\"  í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "            \n",
    "        if len(future_data) == 0:\n",
    "            print(f\"  ì˜ˆì¸¡í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "        \n",
    "        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (ê¸°ì¡´ í•¨ìˆ˜ í™œìš©)\n",
    "        center_results = comprehensive_evaluation_comparison(center_name, train_data)\n",
    "        all_training_results.extend(center_results)\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\n",
    "        center_best_models = select_and_train_best_models(center_name, train_data, center_results)\n",
    "        if center_best_models:\n",
    "            best_models_by_center[center_name] = center_best_models\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 2ë‹¨ê³„: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ê²°ê³¼ ìš”ì•½\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"2ë‹¨ê³„: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ì™„ë£Œ\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    training_results_df = pd.DataFrame(all_training_results)\n",
    "    \n",
    "    for center, models in best_models_by_center.items():\n",
    "        print(f\"\\n[{center.upper()} ì„¼í„° ìµœê³  ì„±ëŠ¥ ëª¨ë¸]\")\n",
    "        if 'regression' in models:\n",
    "            reg_info = models['regression']\n",
    "            print(f\"  íšŒê·€: {reg_info['model_name']} (RÂ²={reg_info['performance']['r2']:.3f})\")\n",
    "        if 'classification' in models:\n",
    "            clf_info = models['classification']\n",
    "            print(f\"  ë¶„ë¥˜: {clf_info['model_name']} (F1={clf_info['performance']['macro_f1']:.3f})\")\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 3ë‹¨ê³„: 5ì›” 21ì¼~31ì¼ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"3ë‹¨ê³„: ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ ìˆ˜í–‰ ({cutoff_date} ì´í›„)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for center_name, df in centers.items():\n",
    "        if center_name not in best_models_by_center:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n[{center_name.upper()} ì„¼í„° ì˜ˆì¸¡ ì¤‘...]\")\n",
    "        \n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        df_work = df.copy()\n",
    "        df_work['ë‚ ì§œ'] = pd.to_datetime(df_work['ë‚ ì§œ'])\n",
    "        future_data = df_work[df_work['ë‚ ì§œ'] > cutoff].copy()\n",
    "        \n",
    "        if len(future_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "        center_predictions = make_predictions_for_center(\n",
    "            center_name, future_data, best_models_by_center[center_name]\n",
    "        )\n",
    "        all_predictions.extend(center_predictions)\n",
    "    \n",
    "    # ========================================================================================\n",
    "    # 4ë‹¨ê³„: ê²°ê³¼ í…Œì´ë¸” ìƒì„± ë° ì„±ëŠ¥ í‰ê°€\n",
    "    # ========================================================================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"4ë‹¨ê³„: ê²°ê³¼ í…Œì´ë¸” ìƒì„± ë° ì„±ëŠ¥ í‰ê°€\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if not all_predictions:\n",
    "        print(\"ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ í…Œì´ë¸” ìƒì„±\n",
    "    final_results_table = create_final_results_table(all_predictions)\n",
    "    \n",
    "    # ì„±ëŠ¥ ìš”ì•½ ìƒì„±\n",
    "    performance_summary = create_performance_summary(final_results_table)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print_final_results(final_results_table, performance_summary)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ìž¥\n",
    "    save_final_results(final_results_table, performance_summary, training_results_df)\n",
    "    \n",
    "    return final_results_table, best_models_by_center, performance_summary\n",
    "\n",
    "def select_and_train_best_models(center_name, train_data, evaluation_results):\n",
    "    \"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    successful_results = results_df[results_df['success'] == True]\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(f\"    ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    # íšŒê·€ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"    ìµœê³  íšŒê·€ ëª¨ë¸: {best_reg['model']} (RÂ²={best_reg['r2']:.3f})\")\n",
    "        \n",
    "        # ëª¨ë¸ ìž¬í•™ìŠµ\n",
    "        reg_pipeline = retrain_best_model(\n",
    "            train_data, best_reg['model'], 'regression', best_reg['split_method']\n",
    "        )\n",
    "        \n",
    "        if reg_pipeline:\n",
    "            best_models['regression'] = {\n",
    "                'model_name': best_reg['model'],\n",
    "                'pipeline': reg_pipeline['pipeline'],\n",
    "                'feature_names': reg_pipeline['feature_names'],\n",
    "                'performance': dict(best_reg),\n",
    "                'split_method': best_reg['split_method']\n",
    "            }\n",
    "    \n",
    "    # ë¶„ë¥˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"    ìµœê³  ë¶„ë¥˜ ëª¨ë¸: {best_clf['model']} (F1={best_clf['macro_f1']:.3f})\")\n",
    "        \n",
    "        # ëª¨ë¸ ìž¬í•™ìŠµ\n",
    "        clf_pipeline = retrain_best_model(\n",
    "            train_data, best_clf['model'], 'classification', best_clf['split_method']\n",
    "        )\n",
    "        \n",
    "        if clf_pipeline:\n",
    "            best_models['classification'] = {\n",
    "                'model_name': best_clf['model'],\n",
    "                'pipeline': clf_pipeline['pipeline'],\n",
    "                'feature_names': clf_pipeline['feature_names'],\n",
    "                'performance': dict(best_clf),\n",
    "                'split_method': best_clf['split_method']\n",
    "            }\n",
    "    \n",
    "    return best_models if best_models else None\n",
    "\n",
    "def retrain_best_model(train_data, model_name, model_type, split_method):\n",
    "    \"\"\"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìž¬í•™ìŠµ\"\"\"\n",
    "    \n",
    "    try:\n",
    "        target_col = \"í•©ê³„_1ì¼í›„\" if model_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "        \n",
    "        # ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ìž¬í•™ìŠµ (test_sizeë¥¼ ë§¤ìš° ìž‘ê²Œ ì„¤ì •)\n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            train_data, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.05, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # ì „ì²´ ë°ì´í„° ì‚¬ìš© (X_train + X_test)\n",
    "        X_all = pd.concat([X_train, X_test], ignore_index=True)\n",
    "        y_all = pd.concat([y_train, y_test], ignore_index=True)\n",
    "        X_all = X_all[feature_names]  # âœ… í”¼ì²˜ ìˆœì„œ ê³ ì •\n",
    "        \n",
    "        # ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "        \n",
    "        model = models[model_name]\n",
    "        pipeline = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipeline.fit(X_all, y_all)\n",
    "        \n",
    "        return {\n",
    "            'pipeline': pipeline,\n",
    "            'feature_names': feature_names\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ëª¨ë¸ ìž¬í•™ìŠµ ì‹¤íŒ¨ ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def make_predictions_for_center(center_name, future_data, trained_models):\n",
    "    \"\"\"ì„¼í„°ë³„ ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "    predictions = []\n",
    "    future_data = future_data.reset_index(drop=True)  # make_predictions_for_center ì§„ìž… ì§í›„\n",
    "\n",
    "    for task_type, model_info in trained_models.items():\n",
    "        try:\n",
    "            pipeline = model_info['pipeline']\n",
    "            feature_names = model_info['feature_names']\n",
    "            model_name = model_info['model_name']\n",
    "            \n",
    "            # íƒ€ê²Ÿ ì»¬ëŸ¼ ì„¤ì •\n",
    "            target_col = \"í•©ê³„_1ì¼í›„\" if task_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "            \n",
    "            # ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„\n",
    "            X_future, y_true = prepare_prediction_data(future_data, feature_names, target_col)\n",
    "            \n",
    "            if X_future is None or len(X_future) == 0:\n",
    "                print(f\"    {task_type} ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨\")\n",
    "                continue\n",
    "            \n",
    "            # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            y_pred = pipeline.predict(X_future)\n",
    "            # íƒ€ìž… ë³´ì •\n",
    "            if task_type == \"classification\":\n",
    "                # numpy íƒ€ìž… í¬í•¨ -> íŒŒì´ì¬ intë¡œ\n",
    "                y_pred = [int(v) for v in y_pred]\n",
    "            \n",
    "            print(f\"    {task_type} ì˜ˆì¸¡ ì™„ë£Œ: {len(y_pred)}ê°œ\")\n",
    "            \n",
    "            # ê²°ê³¼ ì €ìž¥\n",
    "            for i in range(len(X_future)):\n",
    "                actual_val = (y_true.iloc[i] if (y_true is not None and i < len(y_true) and not pd.isna(y_true.iloc[i])) else None)\n",
    "                \n",
    "                pred_result = {\n",
    "                    'date': future_data.iloc[i]['ë‚ ì§œ'],\n",
    "                    'center': center_name,\n",
    "                    'task_type': task_type,\n",
    "                    'model_name': model_name,\n",
    "                    'target_column': target_col,\n",
    "                    # 'actual_value': y_true.iloc[i] if i < len(y_true) and not pd.isna(y_true.iloc[i]) else None,\n",
    "                    'actual_value': actual_val,\n",
    "                    # 'predicted_value': float(y_pred[i])\n",
    "                    'predicted_value': int(y_pred[i]) if task_type=='classification' else float(y_pred[i])\n",
    "                }\n",
    "                predictions.append(pred_result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    {task_type} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def prepare_prediction_data(future_data, expected_features, target_col):\n",
    "    \"\"\"ì˜ˆì¸¡ìš© ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "    \n",
    "    # ì œì™¸í•  ì»¬ëŸ¼ë“¤\n",
    "    not_use_col = [\n",
    "        'ë‚ ì§œ',\n",
    "        '1ì²˜ë¦¬ìž¥','2ì²˜ë¦¬ìž¥','ì •í™”ì¡°','ì¤‘ê³„íŽŒí”„ìž¥','í•©ê³„','ì‹œì„¤í˜„ëŒ€í™”',\n",
    "        '3ì²˜ë¦¬ìž¥','4ì²˜ë¦¬ìž¥','í•©ê³„', 'í•©ê³„_1ì¼í›„','í•©ê³„_2ì¼í›„',\n",
    "        'ë“±ê¸‰','ë“±ê¸‰_1ì¼í›„','ë“±ê¸‰_2ì¼í›„'\n",
    "    ]\n",
    "    \n",
    "    # í”¼ì²˜ ë°ì´í„° ì¤€ë¹„\n",
    "    drop_cols = [c for c in (set(not_use_col) | {target_col}) if c in future_data.columns]\n",
    "    X_future = future_data.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• ë³€í™˜\n",
    "    for c in X_future.columns:\n",
    "        X_future[c] = pd.to_numeric(X_future[c], errors=\"coerce\")\n",
    "    \n",
    "    # ì‹¤ì œê°’ ì¶”ì¶œ\n",
    "    y_true = None\n",
    "    if target_col in future_data.columns:\n",
    "        if target_col == \"ë“±ê¸‰_1ì¼í›„\":\n",
    "            y_true = pd.to_numeric(future_data[target_col], errors=\"coerce\").astype(\"Int64\")\n",
    "        else:\n",
    "            y_true = pd.to_numeric(future_data[target_col], errors=\"coerce\")\n",
    "    \n",
    "    # í”¼ì²˜ ìˆœì„œ ë§žì¶¤ ë° ëˆ„ë½ í”¼ì²˜ ì²˜ë¦¬\n",
    "    missing_features = set(expected_features) - set(X_future.columns)\n",
    "    if missing_features:\n",
    "        for feature in missing_features:\n",
    "            X_future[feature] = 0\n",
    "    \n",
    "    # í”¼ì²˜ ìˆœì„œ ë§žì¶¤\n",
    "    X_future = X_future[expected_features].copy()\n",
    "    \n",
    "    return X_future, y_true\n",
    "\n",
    "def create_final_results_table(all_predictions):\n",
    "    \"\"\"ìµœì¢… ê²°ê³¼ í…Œì´ë¸” ìƒì„±\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(all_predictions)\n",
    "    \n",
    "    # ë‚ ì§œ ì •ë ¬\n",
    "    results_df = results_df.sort_values(['date', 'center', 'task_type'])\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    results_df = calculate_prediction_metrics_enhanced(results_df)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def calculate_prediction_metrics_enhanced(results_df):\n",
    "    \"\"\"í–¥ìƒëœ ì˜ˆì¸¡ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    \n",
    "    results_df = results_df.copy()\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ì»¬ëŸ¼ ì´ˆê¸°í™”\n",
    "    results_df['absolute_error'] = None\n",
    "    results_df['squared_error'] = None\n",
    "    results_df['percentage_error'] = None\n",
    "    results_df['correct_prediction'] = None\n",
    "    results_df['residual'] = None\n",
    "    \n",
    "    for idx, row in results_df.iterrows():\n",
    "        if pd.isna(row['actual_value']) or pd.isna(row['predicted_value']):\n",
    "            continue\n",
    "            \n",
    "        actual = row['actual_value']\n",
    "        predicted = row['predicted_value']\n",
    "        \n",
    "        if row['task_type'] == 'regression':\n",
    "            # íšŒê·€ í‰ê°€ ì§€í‘œ\n",
    "            residual = actual - predicted\n",
    "            abs_error = abs(residual)\n",
    "            sq_error = residual ** 2\n",
    "            pct_error = abs(residual) / (abs(actual) + 1e-8) * 100\n",
    "            \n",
    "            results_df.at[idx, 'residual'] = residual\n",
    "            results_df.at[idx, 'absolute_error'] = abs_error\n",
    "            results_df.at[idx, 'squared_error'] = sq_error\n",
    "            results_df.at[idx, 'percentage_error'] = pct_error\n",
    "            \n",
    "        else:  # classification\n",
    "            # ë¶„ë¥˜ í‰ê°€ ì§€í‘œ\n",
    "            correct = 1 if int(actual) == int(predicted) else 0\n",
    "            results_df.at[idx, 'correct_prediction'] = correct\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def create_performance_summary(results_df):\n",
    "    \"\"\"ì„±ëŠ¥ ìš”ì•½ ìƒì„±\"\"\"\n",
    "    \n",
    "    summary = {}\n",
    "    \n",
    "    for center in results_df['center'].unique():\n",
    "        center_data = results_df[results_df['center'] == center]\n",
    "        summary[center] = {}\n",
    "        \n",
    "        for task_type in ['regression', 'classification']:\n",
    "            task_data = center_data[center_data['task_type'] == task_type]\n",
    "            task_data_clean = task_data.dropna(subset=['actual_value', 'predicted_value'])\n",
    "            \n",
    "            if len(task_data_clean) > 0:\n",
    "                if task_type == 'regression':\n",
    "                    summary[center]['regression'] = {\n",
    "                        'model_name': task_data_clean.iloc[0]['model_name'],\n",
    "                        'prediction_count': len(task_data_clean),\n",
    "                        'mae': task_data_clean['absolute_error'].mean(),\n",
    "                        'rmse': np.sqrt(task_data_clean['squared_error'].mean()),\n",
    "                        'mape': task_data_clean['percentage_error'].mean(),\n",
    "                        'r2_on_predictions': calculate_r2_on_predictions(\n",
    "                            task_data_clean['actual_value'], \n",
    "                            task_data_clean['predicted_value']\n",
    "                        )\n",
    "                    }\n",
    "                else:\n",
    "                    summary[center]['classification'] = {\n",
    "                        'model_name': task_data_clean.iloc[0]['model_name'],\n",
    "                        'prediction_count': len(task_data_clean),\n",
    "                        'accuracy': task_data_clean['correct_prediction'].mean(),\n",
    "                        'correct_count': int(task_data_clean['correct_prediction'].sum()),\n",
    "                        'total_count': len(task_data_clean)\n",
    "                    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def calculate_r2_on_predictions(y_true, y_pred):\n",
    "    \"\"\"ì˜ˆì¸¡ê°’ì— ëŒ€í•œ RÂ² ê³„ì‚°\"\"\"\n",
    "    from sklearn.metrics import r2_score\n",
    "    y_true = pd.Series(y_true).astype(float)\n",
    "    y_pred = pd.Series(y_pred).astype(float)\n",
    "    if len(y_true) < 2:\n",
    "        return None\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def print_final_results(results_df, performance_summary):\n",
    "    \"\"\"ìµœì¢… ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"=== ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ì „ì²´ ìš”ì•½\n",
    "    total_predictions = len(results_df)\n",
    "    date_range = f\"{results_df['date'].min()} ~ {results_df['date'].max()}\"\n",
    "    centers = results_df['center'].unique()\n",
    "    \n",
    "    print(f\"ì˜ˆì¸¡ ê¸°ê°„: {date_range}\")\n",
    "    print(f\"ì´ ì˜ˆì¸¡ ê±´ìˆ˜: {total_predictions}\")\n",
    "    print(f\"ì„¼í„° ìˆ˜: {len(centers)} ({', '.join(centers)})\")\n",
    "    \n",
    "    # ì„¼í„°ë³„ ì„±ëŠ¥ ìš”ì•½\n",
    "    for center, perf in performance_summary.items():\n",
    "        print(f\"\\n--- {center.upper()} ì„¼í„° ì„±ëŠ¥ ---\")\n",
    "        \n",
    "        if 'regression' in perf:\n",
    "            reg = perf['regression']\n",
    "            print(f\"  íšŒê·€ ({reg['model_name']}):\")\n",
    "            print(f\"    ì˜ˆì¸¡ ê±´ìˆ˜: {reg['prediction_count']}\")\n",
    "            print(f\"    MAE: {reg['mae']:.2f}\")\n",
    "            print(f\"    RMSE: {reg['rmse']:.2f}\")\n",
    "            print(f\"    MAPE: {reg['mape']:.1f}%\")\n",
    "            if reg['r2_on_predictions'] is not None:\n",
    "                print(f\"    RÂ²: {reg['r2_on_predictions']:.3f}\")\n",
    "        \n",
    "        if 'classification' in perf:\n",
    "            clf = perf['classification']\n",
    "            print(f\"  ë¶„ë¥˜ ({clf['model_name']}):\")\n",
    "            print(f\"    ì˜ˆì¸¡ ê±´ìˆ˜: {clf['prediction_count']}\")\n",
    "            print(f\"    ì •í™•ë„: {clf['accuracy']:.1%}\")\n",
    "            print(f\"    ì •ë‹µ ê°œìˆ˜: {clf['correct_count']}/{clf['total_count']}\")\n",
    "    \n",
    "    # ê²°ê³¼ í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°\n",
    "    print(f\"\\n--- ê²°ê³¼ í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸° ---\")\n",
    "    display_columns = ['date', 'center', 'task_type', 'model_name', 'actual_value', 'predicted_value']\n",
    "    if all(col in results_df.columns for col in display_columns):\n",
    "        print(results_df[display_columns].head(10).to_string(index=False))\n",
    "\n",
    "def save_final_results(results_df, performance_summary, training_results_df):\n",
    "    \"\"\"ìµœì¢… ê²°ê³¼ ì €ìž¥\"\"\"\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_filename = f\"production_simulation_{timestamp}\"\n",
    "    \n",
    "    try:\n",
    "        # 1. ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸” ì €ìž¥\n",
    "        results_filename = f\"{base_filename}_predictions.csv\"\n",
    "        results_df.to_csv(results_filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nì˜ˆì¸¡ ê²°ê³¼ ì €ìž¥: {results_filename}\")\n",
    "        \n",
    "        # 2. ì„±ëŠ¥ ìš”ì•½ ì €ìž¥\n",
    "        summary_data = []\n",
    "        for center, perf in performance_summary.items():\n",
    "            for task_type, metrics in perf.items():\n",
    "                summary_row = {'center': center, 'task_type': task_type}\n",
    "                summary_row.update(metrics)\n",
    "                summary_data.append(summary_row)\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_filename = f\"{base_filename}_summary.csv\"\n",
    "            summary_df.to_csv(summary_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"ì„±ëŠ¥ ìš”ì•½ ì €ìž¥: {summary_filename}\")\n",
    "        \n",
    "        # 3. í•™ìŠµ ê²°ê³¼ ì €ìž¥\n",
    "        if len(training_results_df) > 0:\n",
    "            training_filename = f\"{base_filename}_training.csv\"\n",
    "            training_results_df.to_csv(training_filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"í•™ìŠµ ê²°ê³¼ ì €ìž¥: {training_filename}\")\n",
    "        \n",
    "        print(f\"\\nëª¨ë“  ê²°ê³¼ê°€ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤. íŒŒì¼ëª… ì ‘ë‘ì‚¬: {base_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ê²°ê³¼ ì €ìž¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# ================================================================================================\n",
    "# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ================================================================================================\n",
    "\n",
    "# ================================================================================================\n",
    "# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (âœ… ìˆ˜ì •ëœ ë²„ì „)\n",
    "# ================================================================================================\n",
    "\n",
    "def run_complete_production_pipeline(cutoff_date='2025-05-20'):\n",
    "    \"\"\"ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
    "    print(\"ì´ ê³¼ì •ì€ ë‹¤ì†Œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ë°ì´í„° ë¡œë“œ (ì´ ë¶€ë¶„ì€ ì‹¤í–‰ê¸°ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ” ê²ƒì´ ë” ëª…í™•í•©ë‹ˆë‹¤)\n",
    "    try:\n",
    "        nanji_raw = pd.read_csv('../data/processed/center_season/nanji/ë‚œì§€_merged.csv', encoding='utf-8-sig')\n",
    "        jungnang_raw = pd.read_csv('../data/processed/center_season/jungnang/ì¤‘ëž‘_merged.csv', encoding='utf-8-sig')\n",
    "        seonam_raw = pd.read_csv('../data/processed/center_season/seonam/ì„œë‚¨_merged.csv', encoding='utf-8-sig')\n",
    "        tancheon_raw = pd.read_csv('../data/processed/center_season/tancheon/íƒ„ì²œ_merged.csv', encoding='utf-8-sig')\n",
    "        \n",
    "        centers = {\n",
    "            \"nanji\": nanji_raw,\n",
    "            \"jungnang\": jungnang_raw,\n",
    "            \"seonam\": seonam_raw,\n",
    "            \"tancheon\": tancheon_raw\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"ì›ë³¸ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "    # í•µì‹¬ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ í˜¸ì¶œ (ìžê¸° ìžì‹ ì´ ì•„ë‹Œ!)\n",
    "    results = complete_production_simulation_pipeline(centers=centers, cutoff_date=cutoff_date)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!\")\n",
    "    print(f\"ì´ ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ ({elapsed_time/60:.1f}ë¶„)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# ================================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== ì™„ì „í•œ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸ ===\")\n",
    "    print()\n",
    "    print(\"ì‚¬ìš©ë²•:\")\n",
    "    print(\"results = run_complete_production_pipeline()\")\n",
    "    print()\n",
    "    print(\"ë˜ëŠ” cutoff_dateë¥¼ ë³€ê²½í•˜ì—¬:\")\n",
    "    print(\"results = run_complete_production_pipeline(cutoff_date='2025-05-15')\")\n",
    "    print()\n",
    "    print(\"ë°˜í™˜ê°’:\")\n",
    "    print(\"- results[0]: ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸”\")\n",
    "    print(\"- results[1]: í•™ìŠµëœ ëª¨ë¸ ì •ë³´\")  \n",
    "    print(\"- results[2]: ì„±ëŠ¥ ìš”ì•½\")\n",
    "    print()\n",
    "    print(\"ìƒì„±ë˜ëŠ” íŒŒì¼:\")\n",
    "    print(\"- production_simulation_YYYYMMDD_HHMMSS_predictions.csv\")\n",
    "    print(\"- production_simulation_YYYYMMDD_HHMMSS_summary.csv\")\n",
    "    print(\"- production_simulation_YYYYMMDD_HHMMSS_training.csv\")\n",
    "\n",
    "# ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "results = run_complete_production_pipeline(cutoff_date='2025-05-20')\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "final_table, trained_models, performance_summary = results\n",
    "print(final_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================================\n",
    "# 1. ìˆ˜ì •ëœ make_features í•¨ìˆ˜\n",
    "# ================================================================================================\n",
    "\n",
    "def make_features(df, cutoff_date=None):\n",
    "    \"\"\"\n",
    "    íŒŒìƒë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ - Data Leakage ë°©ì§€ ë²„ì „\n",
    "    \n",
    "    Parameters:\n",
    "    - df: ì›ë³¸ ë°ì´í„°\n",
    "    - cutoff_date: íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì œí•œ ë‚ ì§œ (Noneì´ë©´ ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ë‚ ì§œ ì •ë¦¬ ë° ì •ë ¬\n",
    "    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])\n",
    "    df = df.sort_values('ë‚ ì§œ').reset_index(drop=True)\n",
    "\n",
    "    # ë‹¬/ìš”ì¼ ìˆ«ìž\n",
    "    df['ì›”'] = df['ë‚ ì§œ'].dt.month\n",
    "    df['ìš”ì¼'] = df['ë‚ ì§œ'].dt.weekday\n",
    "\n",
    "    # ê³„ì ˆ/ë¶ˆì¾Œì§€ìˆ˜ë“±ê¸‰ ìˆ«ìž ë§¤í•‘\n",
    "    season_map = {'ë´„': 0, 'ì—¬ë¦„': 1, 'ê°€ì„': 2, 'ê²¨ìš¸': 3}\n",
    "    discomfort_map = {'ì¾Œì ': 0, 'ì•½ê°„ ë¶ˆì¾Œ': 1, 'ë¶ˆì¾Œ': 2, 'ë§¤ìš° ë¶ˆì¾Œ': 3, 'ê·¹ì‹¬í•œ ë¶ˆì¾Œ': 4}\n",
    "    df['ê³„ì ˆ'] = df['ê³„ì ˆ'].map(season_map).astype('Int64')\n",
    "    df['ë¶ˆì¾Œì§€ìˆ˜ë“±ê¸‰'] = df['ë¶ˆì¾Œì§€ìˆ˜ë“±ê¸‰'].map(discomfort_map).astype('Int64')\n",
    "\n",
    "    # ê°•ìˆ˜ëŸ‰ ì‹œì°¨ í”¼ì²˜\n",
    "    df['ê°•ìˆ˜ëŸ‰_1ì¼ì „'] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].shift(1)\n",
    "    df['ê°•ìˆ˜ëŸ‰_2ì¼ì „'] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].shift(2)\n",
    "    df['ê°•ìˆ˜ëŸ‰_1ì¼_ëˆ„ì '] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(1, min_periods=1).sum()\n",
    "    df['ê°•ìˆ˜ëŸ‰_2ì¼_ëˆ„ì '] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(2, min_periods=1).sum()\n",
    "    df['ê°•ìˆ˜ëŸ‰_3ì¼_ëˆ„ì '] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(3, min_periods=1).sum()\n",
    "    df['ê°•ìˆ˜ëŸ‰_5ì¼_ëˆ„ì '] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(5, min_periods=1).sum()\n",
    "    df['ê°•ìˆ˜ëŸ‰_7ì¼_ëˆ„ì '] = df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(7, min_periods=1).sum()\n",
    "\n",
    "    df['ì¼êµì°¨'] = df['ì¼_ìµœê³ ê¸°ì˜¨(Â°C)'] - df['ì¼_ìµœì €ê¸°ì˜¨(Â°C)']\n",
    "    df['í­ìš°_ì—¬ë¶€'] = (df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'] >= 80).astype(int)\n",
    "    \n",
    "    # ì²´ê°ì˜¨ë„ ê³„ì‚°\n",
    "    if 'ì¼_í‰ê· ê¸°ì˜¨(Â°C)' in df.columns:\n",
    "        T = pd.to_numeric(df['ì¼_í‰ê· ê¸°ì˜¨(Â°C)'], errors='coerce')\n",
    "    else:\n",
    "        T = pd.Series(np.nan, index=df.index)\n",
    "    if 'ì¼_í‰ê· í’ì†(m/s)' in df.columns:\n",
    "        V_ms = pd.to_numeric(df['ì¼_í‰ê· í’ì†(m/s)'], errors='coerce')\n",
    "    else:\n",
    "        V_ms = pd.Series(np.nan, index=df.index)\n",
    "    if 'í‰ê· ìŠµë„(%)' in df.columns:\n",
    "        RH = pd.to_numeric(df['í‰ê· ìŠµë„(%)'], errors='coerce')\n",
    "    else:\n",
    "        RH = pd.Series(np.nan, index=df.index)\n",
    "\n",
    "    # ìœˆë“œì¹ \n",
    "    V_kmh = V_ms * 3.6\n",
    "    wct_raw = 13.12 + 0.6215*T - 11.37*np.power(V_kmh, 0.16) + 0.3965*T*np.power(V_kmh, 0.16)\n",
    "    wc_valid = (T <= 10.0) & (V_kmh >= 4.8)\n",
    "    wct = T.copy()\n",
    "    wct[wc_valid] = wct_raw[wc_valid]\n",
    "\n",
    "    # ì—´ì§€ìˆ˜\n",
    "    T_f = T * 9/5 + 32\n",
    "    HI_f = (-42.379 + 2.04901523*T_f + 10.14333127*RH\n",
    "            - 0.22475541*T_f*RH - 0.00683783*T_f**2 - 0.05481717*RH**2\n",
    "            + 0.00122874*T_f**2*RH + 0.00085282*T_f*RH**2\n",
    "            - 0.00000199*T_f**2*RH**2)\n",
    "    mask_low = (RH < 13) & (T_f >= 80) & (T_f <= 112)\n",
    "    adj_low = ((13 - RH)/4) * np.sqrt((17 - np.abs(T_f - 95))/17)\n",
    "    HI_f = HI_f.where(~mask_low, HI_f - adj_low)\n",
    "    mask_high = (RH > 85) & (T_f >= 80) & (T_f <= 87)\n",
    "    adj_high = ((RH - 85)/10) * ((87 - T_f)/5)\n",
    "    HI_f = HI_f.where(~mask_high, HI_f + adj_high)\n",
    "    hi_valid = (T_f >= 80) & (RH >= 40)\n",
    "    HI_c = (HI_f - 32) * 5/9\n",
    "    hi = T.copy()\n",
    "    hi[hi_valid] = HI_c[hi_valid]\n",
    "\n",
    "    # ìŠ¤í…Œë“œë¨¼ ì²´ê°ì˜¨ë„\n",
    "    e = (RH/100.0) * 6.105 * np.exp(17.27*T/(237.7 + T))\n",
    "    at = T + 0.33*e - 0.70*V_ms - 4.00\n",
    "\n",
    "    # ìµœì¢… ì²´ê°ì˜¨ë„\n",
    "    apparent = at.copy()\n",
    "    apparent[hi_valid] = hi[hi_valid]\n",
    "    apparent[wc_valid] = wct[wc_valid]\n",
    "    df['ì²´ê°ì˜¨ë„(Â°C)'] = apparent\n",
    "    \n",
    "    # ë¶„ë¥˜ìš© ë“±ê¸‰ ê³„ì‚°\n",
    "    q = df['í•©ê³„'].dropna().quantile([0.15, 0.70, 0.90])\n",
    "    q15, q70, q90 = float(q.loc[0.15]), float(q.loc[0.70]), float(q.loc[0.90])\n",
    "\n",
    "    def categorize(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        if x < q15:\n",
    "            return 0\n",
    "        elif x < q70:\n",
    "            return 1\n",
    "        elif x < q90:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    df['ë“±ê¸‰'] = df['í•©ê³„'].apply(categorize)\n",
    "    \n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)\n",
    "    if cutoff_date is not None:\n",
    "        cutoff = pd.to_datetime(cutoff_date)\n",
    "        \n",
    "        # íƒ€ê²Ÿ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "        df['í•©ê³„_1ì¼í›„'] = np.nan\n",
    "        df['í•©ê³„_2ì¼í›„'] = np.nan\n",
    "        df['ë“±ê¸‰_1ì¼í›„'] = np.nan\n",
    "        df['ë“±ê¸‰_2ì¼í›„'] = np.nan\n",
    "        \n",
    "        # cutoff_date ë‚´ì—ì„œë§Œ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±\n",
    "        for i in range(len(df)):\n",
    "            current_date = df.loc[i, 'ë‚ ì§œ']\n",
    "            \n",
    "            if i + 1 < len(df) and current_date <= cutoff:\n",
    "                next_date = df.loc[i+1, 'ë‚ ì§œ']\n",
    "                if next_date <= cutoff:\n",
    "                    df.loc[i, 'í•©ê³„_1ì¼í›„'] = df.loc[i+1, 'í•©ê³„']\n",
    "                    df.loc[i, 'ë“±ê¸‰_1ì¼í›„'] = df.loc[i+1, 'ë“±ê¸‰']\n",
    "            \n",
    "            if i + 2 < len(df) and current_date <= cutoff:\n",
    "                next2_date = df.loc[i+2, 'ë‚ ì§œ']\n",
    "                if next2_date <= cutoff:\n",
    "                    df.loc[i, 'í•©ê³„_2ì¼í›„'] = df.loc[i+2, 'í•©ê³„']\n",
    "                    df.loc[i, 'ë“±ê¸‰_2ì¼í›„'] = df.loc[i+2, 'ë“±ê¸‰']\n",
    "    else:\n",
    "        # ê¸°ì¡´ ë°©ì‹\n",
    "        df['í•©ê³„_1ì¼í›„'] = df['í•©ê³„'].shift(-1)\n",
    "        df['í•©ê³„_2ì¼í›„'] = df['í•©ê³„'].shift(-2)\n",
    "        df['ë“±ê¸‰_1ì¼í›„'] = df['ë“±ê¸‰'].shift(-1).astype('Int64')\n",
    "        df['ë“±ê¸‰_2ì¼í›„'] = df['ë“±ê¸‰'].shift(-2).astype('Int64')\n",
    "\n",
    "    # ì»· ê¸°ì¤€ ì €ìž¥\n",
    "    df.attrs['cutoffs'] = {\"q15\": q15, \"q70\": q70, \"q90\": q90}\n",
    "\n",
    "    # ê²°ì¸¡ ì œê±° ë° ë¦¬ì…‹\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # 6ì›” ë°ì´í„° ì œê±°\n",
    "    df = df[df[\"ë‚ ì§œ\"] < \"2025-06-01\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ================================================================================================\n",
    "# 2. ì˜ˆì¸¡ìš© íŒŒìƒë³€ìˆ˜ ìƒì„± í•¨ìˆ˜\n",
    "# ================================================================================================\n",
    "\n",
    "def make_features_for_prediction(historical_df, future_df):\n",
    "    \"\"\"ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ íŒŒìƒë³€ìˆ˜ ìƒì„± (ê³¼ê±° ë°ì´í„° í™œìš©)\"\"\"\n",
    "    \n",
    "    # ì „ì²´ ë°ì´í„° ê²°í•©\n",
    "    combined_df = pd.concat([historical_df, future_df], ignore_index=True)\n",
    "    combined_df['ë‚ ì§œ'] = pd.to_datetime(combined_df['ë‚ ì§œ'])\n",
    "    combined_df = combined_df.sort_values('ë‚ ì§œ').reset_index(drop=True)\n",
    "    \n",
    "    # ê¸°ë³¸ íŒŒìƒë³€ìˆ˜ë“¤ë§Œ ìƒì„± (lag ë³€ìˆ˜ ì¤‘ì‹¬)\n",
    "    combined_df['ì›”'] = combined_df['ë‚ ì§œ'].dt.month\n",
    "    combined_df['ìš”ì¼'] = combined_df['ë‚ ì§œ'].dt.weekday\n",
    "    \n",
    "    # ê³„ì ˆ/ë¶ˆì¾Œì§€ìˆ˜ ë§¤í•‘\n",
    "    season_map = {'ë´„': 0, 'ì—¬ë¦„': 1, 'ê°€ì„': 2, 'ê²¨ìš¸': 3}\n",
    "    discomfort_map = {'ì¾Œì ': 0, 'ì•½ê°„ ë¶ˆì¾Œ': 1, 'ë¶ˆì¾Œ': 2, 'ë§¤ìš° ë¶ˆì¾Œ': 3, 'ê·¹ì‹¬í•œ ë¶ˆì¾Œ': 4}\n",
    "    combined_df['ê³„ì ˆ'] = combined_df['ê³„ì ˆ'].map(season_map).astype('Int64')\n",
    "    combined_df['ë¶ˆì¾Œì§€ìˆ˜ë“±ê¸‰'] = combined_df['ë¶ˆì¾Œì§€ìˆ˜ë“±ê¸‰'].map(discomfort_map).astype('Int64')\n",
    "    \n",
    "    # ì‹œì°¨ ë³€ìˆ˜ë“¤\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_1ì¼ì „'] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].shift(1)\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_2ì¼ì „'] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].shift(2)\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_1ì¼_ëˆ„ì '] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(1, min_periods=1).sum()\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_2ì¼_ëˆ„ì '] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(2, min_periods=1).sum()\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_3ì¼_ëˆ„ì '] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(3, min_periods=1).sum()\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_5ì¼_ëˆ„ì '] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(5, min_periods=1).sum()\n",
    "    combined_df['ê°•ìˆ˜ëŸ‰_7ì¼_ëˆ„ì '] = combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'].rolling(7, min_periods=1).sum()\n",
    "    \n",
    "    combined_df['ì¼êµì°¨'] = combined_df['ì¼_ìµœê³ ê¸°ì˜¨(Â°C)'] - combined_df['ì¼_ìµœì €ê¸°ì˜¨(Â°C)']\n",
    "    combined_df['í­ìš°_ì—¬ë¶€'] = (combined_df['ì¼_ì¼ê°•ìˆ˜ëŸ‰(mm)'] >= 80).astype(int)\n",
    "    \n",
    "    # ì²´ê°ì˜¨ë„ ê³„ì‚° (ë™ì¼í•œ ë¡œì§)\n",
    "    T = pd.to_numeric(combined_df.get('ì¼_í‰ê· ê¸°ì˜¨(Â°C)', np.nan), errors='coerce')\n",
    "    V_ms = pd.to_numeric(combined_df.get('ì¼_í‰ê· í’ì†(m/s)', np.nan), errors='coerce')\n",
    "    RH = pd.to_numeric(combined_df.get('í‰ê· ìŠµë„(%)', np.nan), errors='coerce')\n",
    "    \n",
    "    # ì²´ê°ì˜¨ë„ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)\n",
    "    e = (RH/100.0) * 6.105 * np.exp(17.27*T/(237.7 + T))\n",
    "    combined_df['ì²´ê°ì˜¨ë„(Â°C)'] = T + 0.33*e - 0.70*V_ms - 4.00\n",
    "    \n",
    "    # ìƒˆ ë°ì´í„° ë¶€ë¶„ë§Œ ë°˜í™˜\n",
    "    historical_len = len(historical_df)\n",
    "    return combined_df.iloc[historical_len:].reset_index(drop=True)\n",
    "\n",
    "# ================================================================================================\n",
    "# 3. ìˆ˜ì •ëœ ë©”ì¸ íŒŒì´í”„ë¼ì¸\n",
    "# ================================================================================================\n",
    "\n",
    "def complete_production_simulation_safe(centers=None, cutoff_date='2025-05-20'):\n",
    "    \"\"\"Data Leakage ë°©ì§€ ì™„ì „ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Data Leakage ë°©ì§€ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜\")\n",
    "    print(f\"í•™ìŠµ ê¸°ê°„: ~ {cutoff_date}\")\n",
    "    print(f\"ì˜ˆì¸¡ ê¸°ê°„: {cutoff_date} ì´í›„\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if centers is None:\n",
    "        try:\n",
    "            centers = load_original_data()\n",
    "        except:\n",
    "            print(\"ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "    \n",
    "    cutoff = pd.to_datetime(cutoff_date)\n",
    "    all_training_results = []\n",
    "    best_models_by_center = {}\n",
    "    all_predictions = []\n",
    "    \n",
    "    # ê° ì„¼í„°ë³„ ì²˜ë¦¬\n",
    "    for center_name, df_raw in centers.items():\n",
    "        print(f\"\\n[{center_name.upper()} ì„¼í„° ì²˜ë¦¬]\")\n",
    "        \n",
    "        # ì›ë³¸ ë°ì´í„° ë‚ ì§œ ê¸°ì¤€ ë¶„í• \n",
    "        df_raw['ë‚ ì§œ'] = pd.to_datetime(df_raw['ë‚ ì§œ'])\n",
    "        df_raw = df_raw.sort_values('ë‚ ì§œ').reset_index(drop=True)\n",
    "        \n",
    "        raw_train_data = df_raw[df_raw['ë‚ ì§œ'] <= cutoff].copy()\n",
    "        raw_future_data = df_raw[df_raw['ë‚ ì§œ'] > cutoff].copy()\n",
    "        \n",
    "        print(f\"  ì›ë³¸ í•™ìŠµ ë°ì´í„°: {len(raw_train_data)}í–‰\")\n",
    "        print(f\"  ì›ë³¸ ì˜ˆì¸¡ ë°ì´í„°: {len(raw_future_data)}í–‰\")\n",
    "        \n",
    "        if len(raw_train_data) < 50 or len(raw_future_data) == 0:\n",
    "            print(f\"  ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€\")\n",
    "            continue\n",
    "        \n",
    "        # 1ë‹¨ê³„: í•™ìŠµìš© ë°ì´í„° ì•ˆì „í•˜ê²Œ ì¤€ë¹„\n",
    "        train_data_safe = make_features(raw_train_data, cutoff_date=cutoff_date)\n",
    "        print(f\"  ì²˜ë¦¬ëœ í•™ìŠµ ë°ì´í„°: {len(train_data_safe)}í–‰\")\n",
    "        \n",
    "        # 2ë‹¨ê³„: ëª¨ë¸ í‰ê°€ ë° ì„ íƒ\n",
    "        center_results = comprehensive_evaluation_comparison(center_name, train_data_safe)\n",
    "        all_training_results.extend(center_results)\n",
    "        \n",
    "        center_best_models = select_and_train_best_models_safe(center_name, train_data_safe, center_results)\n",
    "        if center_best_models:\n",
    "            best_models_by_center[center_name] = center_best_models\n",
    "        \n",
    "        # 3ë‹¨ê³„: ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„ (ê³¼ê±° ì •ë³´ë§Œ í™œìš©)\n",
    "        if len(raw_future_data) > 0 and center_name in best_models_by_center:\n",
    "            future_data_with_features = make_features_for_prediction(raw_train_data, raw_future_data)\n",
    "            \n",
    "            # 4ë‹¨ê³„: ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            center_predictions = make_predictions_safe(\n",
    "                center_name, future_data_with_features, best_models_by_center[center_name]\n",
    "            )\n",
    "            all_predictions.extend(center_predictions)\n",
    "    \n",
    "    # 5ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬\n",
    "    if not all_predictions:\n",
    "        print(\"ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    final_results_table = create_final_results_table(all_predictions)\n",
    "    performance_summary = create_performance_summary(final_results_table)\n",
    "    \n",
    "    print_final_results(final_results_table, performance_summary)\n",
    "    save_final_results(final_results_table, performance_summary, pd.DataFrame(all_training_results))\n",
    "    \n",
    "    return final_results_table, best_models_by_center, performance_summary\n",
    "\n",
    "def select_and_train_best_models_safe(center_name, train_data, evaluation_results):\n",
    "    \"\"\"ì•ˆì „í•œ ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ\"\"\"\n",
    "    \n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    successful_results = results_df[results_df['success'] == True]\n",
    "    \n",
    "    if len(successful_results) == 0:\n",
    "        print(f\"    ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    # íšŒê·€ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "    reg_results = successful_results[successful_results['type'] == 'regression']\n",
    "    if len(reg_results) > 0:\n",
    "        best_reg = reg_results.loc[reg_results['r2'].idxmax()]\n",
    "        print(f\"    ìµœê³  íšŒê·€ ëª¨ë¸: {best_reg['model']} (RÂ²={best_reg['r2']:.3f})\")\n",
    "        \n",
    "        reg_pipeline = retrain_on_full_safe_data(train_data, best_reg['model'], 'regression', best_reg['split_method'])\n",
    "        \n",
    "        if reg_pipeline:\n",
    "            best_models['regression'] = {\n",
    "                'model_name': best_reg['model'],\n",
    "                'pipeline': reg_pipeline['pipeline'],\n",
    "                'feature_names': reg_pipeline['feature_names'],\n",
    "                'performance': dict(best_reg),\n",
    "                'split_method': best_reg['split_method']\n",
    "            }\n",
    "    \n",
    "    # ë¶„ë¥˜ ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "    clf_results = successful_results[successful_results['type'] == 'classification']\n",
    "    if len(clf_results) > 0:\n",
    "        best_clf = clf_results.loc[clf_results['macro_f1'].idxmax()]\n",
    "        print(f\"    ìµœê³  ë¶„ë¥˜ ëª¨ë¸: {best_clf['model']} (F1={best_clf['macro_f1']:.3f})\")\n",
    "        \n",
    "        clf_pipeline = retrain_on_full_safe_data(train_data, best_clf['model'], 'classification', best_clf['split_method'])\n",
    "        \n",
    "        if clf_pipeline:\n",
    "            best_models['classification'] = {\n",
    "                'model_name': best_clf['model'],\n",
    "                'pipeline': clf_pipeline['pipeline'],\n",
    "                'feature_names': clf_pipeline['feature_names'],\n",
    "                'performance': dict(best_clf),\n",
    "                'split_method': best_clf['split_method']\n",
    "            }\n",
    "    \n",
    "    return best_models if best_models else None\n",
    "\n",
    "def retrain_on_full_safe_data(train_data, model_name, model_type, split_method):\n",
    "    \"\"\"ì•ˆì „í•œ ì „ì²´ ë°ì´í„° ìž¬í•™ìŠµ\"\"\"\n",
    "    \n",
    "    try:\n",
    "        target_col = \"í•©ê³„_1ì¼í›„\" if model_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\"\n",
    "        \n",
    "        # ì „ì²´ ë°ì´í„°ë¥¼ trainìœ¼ë¡œ ì‚¬ìš© (test_sizeë¥¼ ì•„ì£¼ ìž‘ê²Œ)\n",
    "        X_train, X_test, y_train, y_test, feature_names, _, _ = prepare_data_stratified(\n",
    "            train_data, target_col=target_col, model_type=model_type, \n",
    "            test_size=0.01, split_method=split_method\n",
    "        )\n",
    "        \n",
    "        # ì „ì²´ ê²°í•©\n",
    "        X_all = pd.concat([X_train, X_test], ignore_index=True)\n",
    "        y_all = pd.concat([y_train, y_test], ignore_index=True)\n",
    "        \n",
    "        # ëª¨ë¸ í•™ìŠµ\n",
    "        if model_type == \"regression\":\n",
    "            models = build_regression_models()\n",
    "        else:\n",
    "            models = build_classification_models()\n",
    "        \n",
    "        model = models[model_name]\n",
    "        pipeline = make_pipeline_unified(model, model_name, model_type)\n",
    "        pipeline.fit(X_all, y_all)\n",
    "        \n",
    "        return {'pipeline': pipeline, 'feature_names': feature_names}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ëª¨ë¸ ìž¬í•™ìŠµ ì‹¤íŒ¨ ({model_name}): {e}\")\n",
    "        return None\n",
    "\n",
    "def make_predictions_safe(center_name, future_data, trained_models):\n",
    "    \"\"\"ì•ˆì „í•œ ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for task_type, model_info in trained_models.items():\n",
    "        try:\n",
    "            pipeline = model_info['pipeline']\n",
    "            feature_names = model_info['feature_names']\n",
    "            model_name = model_info['model_name']\n",
    "            \n",
    "            # ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„\n",
    "            X_future = prepare_prediction_features(future_data, feature_names)\n",
    "            \n",
    "            if X_future is None or len(X_future) == 0:\n",
    "                continue\n",
    "            \n",
    "            # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            y_pred = pipeline.predict(X_future)\n",
    "            print(f\"    {task_type} ì˜ˆì¸¡ ì™„ë£Œ: {len(y_pred)}ê°œ\")\n",
    "            \n",
    "            # ê²°ê³¼ ì €ìž¥\n",
    "            for i in range(len(X_future)):\n",
    "                pred_result = {\n",
    "                    'date': future_data.iloc[i]['ë‚ ì§œ'],\n",
    "                    'center': center_name,\n",
    "                    'task_type': task_type,\n",
    "                    'model_name': model_name,\n",
    "                    'target_column': \"í•©ê³„_1ì¼í›„\" if task_type == \"regression\" else \"ë“±ê¸‰_1ì¼í›„\",\n",
    "                    'actual_value': None,  # ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ëª¨ë¦„\n",
    "                    'predicted_value': float(y_pred[i])\n",
    "                }\n",
    "                predictions.append(pred_result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    {task_type} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def prepare_prediction_features(future_data, expected_features):\n",
    "    \"\"\"ì˜ˆì¸¡ìš© í”¼ì²˜ ì¤€ë¹„\"\"\"\n",
    "    \n",
    "    not_use_col = [\n",
    "        'ë‚ ì§œ', '1ì²˜ë¦¬ìž¥','2ì²˜ë¦¬ìž¥','ì •í™”ì¡°','ì¤‘ê³„íŽŒí”„ìž¥','í•©ê³„','ì‹œì„¤í˜„ëŒ€í™”',\n",
    "        '3ì²˜ë¦¬ìž¥','4ì²˜ë¦¬ìž¥','í•©ê³„', 'í•©ê³„_1ì¼í›„','í•©ê³„_2ì¼í›„',\n",
    "        'ë“±ê¸‰','ë“±ê¸‰_1ì¼í›„','ë“±ê¸‰_2ì¼í›„'\n",
    "    ]\n",
    "    \n",
    "    # í”¼ì²˜ ì„ íƒ\n",
    "    available_cols = [col for col in future_data.columns if col not in not_use_col]\n",
    "    X_future = future_data[available_cols].copy()\n",
    "    \n",
    "    # ìˆ˜ì¹˜í˜• ë³€í™˜\n",
    "    for c in X_future.columns:\n",
    "        X_future[c] = pd.to_numeric(X_future[c], errors=\"coerce\")\n",
    "    \n",
    "    # ëˆ„ë½ëœ í”¼ì²˜ ì²˜ë¦¬\n",
    "    missing_features = set(expected_features) - set(X_future.columns)\n",
    "    if missing_features:\n",
    "        for feature in missing_features:\n",
    "            X_future[feature] = 0\n",
    "    \n",
    "    # í”¼ì²˜ ìˆœì„œ ë§žì¶¤\n",
    "    X_future = X_future[expected_features].copy()\n",
    "    \n",
    "    return X_future\n",
    "\n",
    "def load_original_data():\n",
    "    \"\"\"ì›ë³¸ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "    nanji_raw = pd.read_csv('../data/processed/center_season/nanji/ë‚œì§€_merged.csv', encoding='utf-8-sig')\n",
    "    jungnang_raw = pd.read_csv('../data/processed/center_season/jungnang/ì¤‘ëž‘_merged.csv', encoding='utf-8-sig')\n",
    "    seonam_raw = pd.read_csv('../data/processed/center_season/seonam/ì„œë‚¨_merged.csv', encoding='utf-8-sig')\n",
    "    tancheon_raw = pd.read_csv('../data/processed/center_season/tancheon/íƒ„ì²œ_merged.csv', encoding='utf-8-sig')\n",
    "    \n",
    "    return {\n",
    "        \"nanji\": nanji_raw,\n",
    "        \"jungnang\": jungnang_raw,\n",
    "        \"seonam\": seonam_raw,\n",
    "        \"tancheon\": tancheon_raw\n",
    "    }\n",
    "\n",
    "# ================================================================================================\n",
    "# 4. ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ================================================================================================\n",
    "\n",
    "def run_safe_production_pipeline(cutoff_date='2025-05-20'):\n",
    "    \"\"\"ì•ˆì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"Data Leakage ë°©ì§€ íŒŒì´í”„ë¼ì¸ì„ ì‹œìž‘í•©ë‹ˆë‹¤...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "    results = complete_production_simulation_safe(cutoff_date=cutoff_date)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\níŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================================================\n",
    "# 5. ì‚¬ìš© ë°©ë²•\n",
    "# ================================================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Data Leakage ë°©ì§€ ìš´ì˜ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜ ===\")\n",
    "    print()\n",
    "    print(\"ì‚¬ìš©ë²•:\")\n",
    "    print(\"results = run_safe_production_pipeline(cutoff_date='2025-05-20')\")\n",
    "    print()\n",
    "    print(\"íŠ¹ì§•:\")\n",
    "    print(\"- 5ì›” 20ì¼ê¹Œì§€ë§Œ í•™ìŠµìš© íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±\")\n",
    "    print(\"- 5ì›” 21ì¼ ì´í›„ëŠ” ì™„ì „ížˆ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì·¨ê¸‰\")\n",
    "    print(\"- íŒŒìƒë³€ìˆ˜ëŠ” ê³¼ê±° ì •ë³´ë§Œ í™œìš©í•´ì„œ ìƒì„±\")\n",
    "    print(\"- ëª¨ë¸ì€ ì ˆëŒ€ ìž¬í•™ìŠµí•˜ì§€ ì•ŠìŒ\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ ëª¨ë“  ì½”ë“œ ìœ„ì— ì´ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê³ \n",
    "results = run_safe_production_pipeline(cutoff_date='2025-05-20')\n",
    "\n",
    "# ================================================================================================\n",
    "# ìµœì¢… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "# ================================================================================================\n",
    "\n",
    "# ì´ í•¨ìˆ˜ í•˜ë‚˜ë§Œ í˜¸ì¶œí•˜ë©´ ìœ„ì—ì„œ ì •ì˜í•œ ëª¨ë“  ê³¼ì •ì´ ìžë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "results = run_safe_production_pipeline(cutoff_date='2025-05-20')\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ (ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰ ì™„ë£Œë˜ì—ˆì„ ê²½ìš°)\n",
    "if results:\n",
    "    final_table, trained_models, performance_summary = results\n",
    "    print(\"\\n--- ìµœì¢… ê²°ê³¼ í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸° ---\")\n",
    "    print(final_table.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
