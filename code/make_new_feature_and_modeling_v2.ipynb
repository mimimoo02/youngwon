{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617d293d",
   "metadata": {},
   "source": [
    "좋아요! 올려주신 노트북이 실행되면 “어떤 파일이 어디에 만들어지고, 그게 무슨 의미인지”를 한눈에 볼 수 있도록 정리해 드릴게요. 그리고 프로젝트의 목적/모델/지표/분할전략/타깃까지 핵심을 깔끔히 요약했습니다.\n",
    "\n",
    "---\n",
    "\n",
    "# 1) 산출물(파일)과 경로, 그리고 의미\n",
    "\n",
    "## A. 결과 요약·원천 테이블 (`../results_v2`)\n",
    "\n",
    "* **`all_model_results.csv`**\n",
    "  4개 센터 × 2분할(temporal/random) × 2태스크(regression/classification) × 6모델 = **최대 96개 실험 결과**가 행 단위로 저장됩니다.\n",
    "  포함 컬럼 예시\n",
    "\n",
    "  * 공통 메타: `center`, `split_method`, `task`, `model`\n",
    "  * 회귀 지표: `MAE, MSE, RMSE, MAPE, SMAPE, R2`\n",
    "  * 분류 지표: `Accuracy, Precision_weighted, Precision_macro, Recall_weighted, Recall_macro, F1_weighted, F1_macro, AUC`\n",
    "    → **모든 실험의 성능 비교**를 위한 마스터 테이블.\n",
    "\n",
    "* **`best_models.csv`**\n",
    "  센터별 **회귀 1개(최고 R2)**, \\*\\*분류 1개(최고 F1\\_weighted)\\*\\*를 뽑아 합친 **통합 베스트 모델 표(최대 8행)**.\n",
    "  → 운영/재학습 대상 “대표 모델 라인업”을 한 장으로 확인.\n",
    "\n",
    "* **`best_models_individual/` (폴더)**\n",
    "  파일명 패턴: `CENTER_SPLIT_TASK_models.csv` (예: `nanji_temporal_regression_models.csv`)\n",
    "  각 조건(센터 × 분할 × 태스크)에서 **모든 모델을 성능 순으로 정렬**한 상세 테이블.\n",
    "  → 총 **8개의 세부 랭킹표**로, 해당 조건에서 무엇이 최선인지 투명하게 보여줍니다.\n",
    "\n",
    "## B. 시각화 (`../results_v2/visualizations`)\n",
    "\n",
    "* **`basic_performance_comparison.png`**\n",
    "\n",
    "  * 센터×분할별 **회귀 R2** 비교 바차트\n",
    "  * 센터×분할별 **분류 F1\\_weighted** 비교 바차트\n",
    "  * **모델별 평균 R2 / 모델별 평균 F1\\_weighted** 바차트\n",
    "    → 큰 그림에서 “어느 분할이 유리한가, 평균적으로 어떤 모델이 강한가” 확인.\n",
    "\n",
    "* **`regression_detailed_comparison.png`**\n",
    "  센터×모델 축으로 **R2 / MAE / RMSE / SMAPE**를 각각 비교.\n",
    "  → 회귀 지표를 다면적으로 살펴보는 “정밀 비교판”.\n",
    "\n",
    "* **`classification_detailed_comparison.png`**\n",
    "  센터×모델 축으로 **Accuracy / F1\\_weighted / F1\\_macro / AUC** 비교.\n",
    "  → 분류 지표를 다면적으로 살펴보는 “정밀 비교판”.\n",
    "\n",
    "* **`same_model_center_comparison_regression.png`**\n",
    "  **같은 회귀 모델**이 센터별로 얼마나 일관되게 잘하는지 **R2**로 비교.\n",
    "\n",
    "* **`same_model_center_comparison_classification.png`**\n",
    "  **같은 분류 모델**이 센터별로 얼마나 일관되게 잘하는지 **F1\\_weighted**로 비교.\n",
    "\n",
    "* **`roc_curves.png`**\n",
    "  베스트로 선발되어 재학습된 **분류 모델들**의 ROC 곡선(센터별 최대 4개 패널).\n",
    "  → \\*\\*임계값 변화에 따른 분류 성능(민감도-위양성률)\\*\\*을 직관적으로 확인.\n",
    "\n",
    "## C. 모델 해석(설명가능성) (`../results_v2/interpretations`)\n",
    "\n",
    "* **`*_shap_summary.png` / `*_shap_importance.png` / `*_shap_force_*.png`**\n",
    "  상위 8개 베스트 모델 각각에 대해:\n",
    "\n",
    "  * **SHAP Summary**(분포/영향 방향), **SHAP Feature Importance**(평균 절대 영향), **Force/Waterfall**(개별 예측 설명)\n",
    "    → **왜 그런 예측이 나왔는지**를 글로벌/로컬 관점에서 설명.\n",
    "\n",
    "* **`*_feature_importance.png`**\n",
    "  트리 계열의 `feature_importances_` 또는 선형계열의 `|coef|` 기준 **상위 20개 특성 중요도**.\n",
    "  → 피처 엔지니어링/현업 해석에 즉시 활용 가능.\n",
    "\n",
    "* **`*_lime_sample_*.png` (선택)**\n",
    "  LIME 로컬 설명 결과(최대 3개 모델, 샘플 2건).\n",
    "  → 개별 사례에서의 **직관적 피처 기여 설명**.\n",
    "\n",
    "## D. 저장된 운영 후보 모델 (`../models_v2/best_models`)\n",
    "\n",
    "* **파일명 패턴:** `CENTER_TASK_MODEL_SPLIT.pkl`\n",
    "  예: `nanji_classification_LightGBM_random.pkl`\n",
    "  **내용물:**\n",
    "\n",
    "  * 학습된 모델 객체, `feature_names`, `X_train/X_test`, `y_train/y_test`, `y_pred`, (분류시) `y_pred_proba`\n",
    "  * 메타정보(`task`, `center`, `split_method`, `model_name`, `performance`)\n",
    "    → **예측 배포/배치 처리**에 바로 재사용.\n",
    "\n",
    "## E. 실행/체크 로그 (노트북 출력)\n",
    "\n",
    "* **체크리스트(셀 19)**: 생성 성공 여부(파일/그림 개수, 지표 포함 여부 등)와 **완료율**(%)을 요약.\n",
    "* **튜닝 예시 코드(셀 18)**: Grid/Randomized/Optuna 템플릿 출력.\n",
    "\n",
    "---\n",
    "\n",
    "# 2) 이 코드의 목적\n",
    "\n",
    "* **목표:** 하수처리센터별로 \\*\\*하루 뒤(또는 미래 시점)의 하수처리량(회귀)\\*\\*과 \\*\\*등급(분류)\\*\\*을 예측하는 **완전 자동화 파이프라인**을 구축.\n",
    "* **성과:**\n",
    "\n",
    "  1. 동일 파이프라인으로 **모델 후보군을 대량 학습·평가**\n",
    "  2. **베스트 모델 선발 → 재학습 → 저장**까지 일관 수행\n",
    "  3. \\*\\*시각화/설명가능성(SHAP/LIME)\\*\\*로 결과를 이해·검증\n",
    "  4. **새 데이터 예측 함수**로 운영 연계\n",
    "\n",
    "---\n",
    "\n",
    "# 3) 사용한 모델(알고리즘)\n",
    "\n",
    "* **회귀(6)**: `LinearRegression`, `RandomForestRegressor`, `XGBRegressor`, `CatBoostRegressor`, `GradientBoostingRegressor`, `LGBMRegressor`\n",
    "* **분류(6)**: `LogisticRegression`, `RandomForestClassifier`, `XGBClassifier`, `CatBoostClassifier`, `GradientBoostingClassifier`, `LGBMClassifier`\n",
    "* **선발 기준**\n",
    "\n",
    "  * 회귀: **R2가 가장 높은 모델**\n",
    "  * 분류: **F1\\_weighted가 가장 높은 모델**\n",
    "\n",
    "---\n",
    "\n",
    "# 4) 성능 평가지표\n",
    "\n",
    "## 회귀\n",
    "\n",
    "* **MAE**(평균절대오차), **MSE**, **RMSE**, **MAPE**, **SMAPE**(대칭 MAPE), **R2**\n",
    "* **추천 해석:**\n",
    "\n",
    "  * **R2**가 클수록 설명력이 좋음\n",
    "  * **SMAPE**는 스케일/영(0) 근처값에 덜 민감—현업 **예측오차 %** 해석에 유리\n",
    "  * **RMSE/MAE**는 절대 오차의 직관적 크기를 보여줌\n",
    "\n",
    "## 분류\n",
    "\n",
    "* **Accuracy**, **Precision(weighted/macro)**, **Recall(weighted/macro)**, **F1(weighted/macro)**, **AUC**\n",
    "* **추천 해석:**\n",
    "\n",
    "  * **F1\\_weighted**는 클래스 불균형 상황에서 평균적인 균형 성능을 반영\n",
    "  * **F1\\_macro**는 모든 클래스를 동일 가중으로 보아 **소수 클래스 성능**까지 반영\n",
    "  * **AUC**는 임계값 전 영역에서 분류력(순위화 능력) 평가\n",
    "\n",
    "---\n",
    "\n",
    "# 5) 데이터 분할 전략 비교\n",
    "\n",
    "* **temporal split**: 시계열 순서를 **유지**해 과거→미래로 학습/평가 (현실적·보수적)\n",
    "* **random split**: 표본을 무작위로 섞어 훈련/평가 (분류는 `stratify`로 클래스 균형 유지)\n",
    "* **권장 해석:**\n",
    "\n",
    "  * **시간 의존성**이 큰 문제(하수량)에서는 보통 **temporal**이 현실성 있는 일반화 성능을 보여줌\n",
    "  * **random**은 과적합 위험이 더 낮게 보일 수 있으나, **실운영 성능**을 과대추정할 수 있으므로 **temporal 결과를 우선 참고**\n",
    "\n",
    "---\n",
    "\n",
    "# 6) 예측 타깃(목표 변수)\n",
    "\n",
    "* **회귀(연속값):** `합계_1일후`\n",
    "\n",
    "  * “해당 센터의 **다음 날 총 하수처리량**” 예측\n",
    "* **분류(범주형):** `등급_1일후`\n",
    "\n",
    "  * “해당 센터의 **다음 날 등급(운영 상태/부하 수준 등)**” 예측\n",
    "* 입력 피처는 `not_use_col`에 명시된 **제외 컬럼**을 빼고 **나머지 전부** 사용\n",
    "\n",
    "  * 제외 목록엔 날짜, 처리장 세부합계, **미래 누출 컬럼(합계\\_1일후/2일후, 등급\\_1일후/2일후)** 등이 포함되어 **데이터 누수 방지**\n",
    "\n",
    "---\n",
    "\n",
    "# 7) 실행 전제(데이터/경로/환경)\n",
    "\n",
    "* **입력 데이터 경로**: `../data/add_feature/{center}_add_feature.csv`\n",
    "\n",
    "  * centers 기본값: `['nanji', 'jungnang', 'seonam', 'tancheon']`\n",
    "  * 실제 센터명/파일 존재 여부는 셀 5에서 확인 로그 출력\n",
    "* **결과/모델 저장 루트**: `../results_v2/`, `../models_v2/` (없으면 자동 생성)\n",
    "* **폰트**: `AppleGothic` (맥 기준). 윈도우/리눅스는 다른 한글 폰트로 교체 필요 가능.\n",
    "\n",
    "---\n",
    "\n",
    "# 8) 운영 활용 포인트\n",
    "\n",
    "* **즉시 예측**: `predict_with_saved_model(center, task, new_data)`\n",
    "\n",
    "  * 저장된 pkl을 로드해 **피처 순서 맞춘 뒤** 예측 반환 (분류는 확률도)\n",
    "* **모델 점검/설명**:\n",
    "\n",
    "  * SHAP/LIME 그림으로 **왜 그렇게 나왔는지** 내부 공유/보고서에 바로 사용\n",
    "* **지속 개선**:\n",
    "\n",
    "  * `best_models_individual` 표와 상세 시각화로 **약점 조건**을 파악하고\n",
    "  * 셀 18 튜닝 템플릿(Grid/Random/Optuna) 적용 → 성능 보강\n",
    "  * 셀 20의 **모니터링/드리프트 감지** 유틸로 운영 중 품질 관리\n",
    "\n",
    "---\n",
    "\n",
    "# 9) 빠른 점검 체크리스트(핵심만)\n",
    "\n",
    "* `all_model_results.csv` 존재? → 전체 실험 결과 OK\n",
    "* `best_models.csv` 존재? → 센터×태스크 베스트 8개 선발 OK\n",
    "* `best_models_individual/`에 8개 CSV? → 조건별 랭킹 OK\n",
    "* `visualizations/` 5개 이상 PNG? → 비교/정밀/동일모델/ROC OK\n",
    "* `interpretations/`에 SHAP/Feature Importance(LIME 선택) PNG 다수? → 해석 OK\n",
    "* `models_v2/best_models/`에 pkl 8개? → 배포준비 OK\n",
    "\n",
    "---\n",
    "\n",
    "필요하시면,\n",
    "\n",
    "* **운영 배포용 경량 추론 스크립트**,\n",
    "* **데이터 검증(스키마/결측/이상치) 자동체크 전처리 모듈**,\n",
    "* **모델/데이터 버저닝(DVC/MLflow) 템플릿**\n",
    "  까지 바로 붙여드릴게요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2edcc7",
   "metadata": {},
   "source": [
    "## 코드 1\n",
    "\n",
    "그래프 색 구리고 시각화 할때 글자가 깨져서 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db781276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **🎊 완벽한 하수처리량 예측 모델링 시스템 완성! 🎊**# ========================================================================================\n",
    "# 하수처리량 예측 모델링 프로젝트 - 완전 수정된 Jupyter Notebook 버전 ---- 그래프 색 구리고, 시각화에 글자가 깨져서 나옴 ㅗㅗ\n",
    "# ========================================================================================\n",
    "\n",
    "# %% 셀 1: 패키지 import 및 기본 설정\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 해석 가능성 분석\n",
    "import shap\n",
    "\n",
    "# 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # 맥 한글 폰트\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic' # 윈도우\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"✅ 패키지 import 완료\")\n",
    "print(f\"실행 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b400a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% 셀 2: 디렉토리 생성 및 설정\n",
    "# 결과 저장 디렉토리 생성\n",
    "directories = [\n",
    "    '../results_v2', \n",
    "    '../results_v2/visualizations', \n",
    "    '../results_v2/interpretations',\n",
    "    '../results_v2/best_models_individual',  # 개별 베스트 모델 테이블용\n",
    "    '../models_v2', \n",
    "    '../models_v2/best_models'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"📁 디렉토리 생성/확인: {directory}\")\n",
    "\n",
    "print(\"✅ 디렉토리 설정 완료\")\n",
    "\n",
    "# %% 셀 3: 파이프라인 클래스 정의 - 기본 설정\n",
    "class CompleteSewagePredictionPipeline:\n",
    "    def __init__(self, data_path_template='../data/add_feature/{}_add_feature.csv'):\n",
    "        \"\"\"완전한 하수처리량 예측 모델링 파이프라인\"\"\"\n",
    "        self.data_path_template = data_path_template\n",
    "        self.centers = ['nanji', 'jungnang', 'seonam', 'tancheon']  # 👈 실제 센터명으로 수정하세요\n",
    "        \n",
    "        # 제외할 컬럼 정의\n",
    "        self.not_use_col = [\n",
    "            '날짜',\n",
    "            '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "            '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "            '등급','등급_1일후','등급_2일후'\n",
    "        ]\n",
    "        \n",
    "        # 회귀 모델 정의\n",
    "        self.regression_models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "            'CatBoost': cb.CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
    "            'LightGBM': lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # 분류 모델 정의\n",
    "        self.classification_models = {\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'CatBoost': cb.CatBoostClassifier(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "            'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # 결과 저장용\n",
    "        self.results = []\n",
    "        \n",
    "    def load_data(self, center):\n",
    "        \"\"\"센터별 데이터 로드\"\"\"\n",
    "        file_path = self.data_path_template.format(center)\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(f\"✅ {center} 센터 데이터 로드: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
    "            return None\n",
    "\n",
    "# 파이프라인 초기화\n",
    "pipeline = CompleteSewagePredictionPipeline()\n",
    "print(\"🔧 파이프라인 초기화 완료\")\n",
    "\n",
    "# %% 셀 4: 데이터 처리 및 평가 메소드\n",
    "def prepare_features(data, not_use_col):\n",
    "    \"\"\"피처 및 타겟 준비\"\"\"\n",
    "    available_cols = [col for col in data.columns if col not in not_use_col]\n",
    "    X = data[available_cols]\n",
    "    y_reg = data['합계_1일후']  # 회귀용\n",
    "    y_clf = data['등급_1일후']  # 분류용\n",
    "    return X, y_reg, y_clf\n",
    "\n",
    "def split_data_temporal(X, y, test_size=0.2):\n",
    "    \"\"\"시계열 정보를 유지한 분할\"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_random(X, y, test_size=0.2, stratify=None):\n",
    "    \"\"\"랜덤 분할 (분류시 stratified)\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=42)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"완전한 회귀 모델 평가 지표 계산\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # MAPE 계산 (0으로 나누기 방지)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.inf\n",
    "    \n",
    "    # SMAPE 계산 (추가!)\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae, \n",
    "        'MSE': mse, \n",
    "        'RMSE': rmse, \n",
    "        'MAPE': mape, \n",
    "        'SMAPE': smape,  # 추가!\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"완전한 분류 모델 평가 지표 계산\"\"\"\n",
    "    # 기본 지표\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Precision (weighted & macro)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Recall (weighted & macro)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # F1 Score (weighted & macro)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_weighted': precision_weighted,\n",
    "        'Precision_macro': precision_macro,  # 추가!\n",
    "        'Recall_weighted': recall_weighted,\n",
    "        'Recall_macro': recall_macro,  # 추가!\n",
    "        'F1_weighted': f1_weighted,\n",
    "        'F1_macro': f1_macro  # 추가!\n",
    "    }\n",
    "    \n",
    "    # ROC AUC (다중분류의 경우 ovr 방식 사용)\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "            metrics['AUC'] = auc_score\n",
    "        except:\n",
    "            metrics['AUC'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"✅ 데이터 처리 및 평가 메소드 정의 완료\")\n",
    "\n",
    "# %% 셀 5: 데이터 확인\n",
    "print(\"📊 데이터 파일 확인\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_info = {}\n",
    "for center in pipeline.centers:\n",
    "    data = pipeline.load_data(center)\n",
    "    if data is not None:\n",
    "        data_info[center] = {\n",
    "            'data': data,\n",
    "            'shape': data.shape\n",
    "        }\n",
    "        \n",
    "        # 기본 정보 출력\n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        print(f\"  📈 피처 수: {X.shape[1]}\")\n",
    "        print(f\"  🎯 회귀 타겟 범위: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"  🏷️ 분류 타겟 클래스: {sorted(y_clf.unique())}\")\n",
    "        print()\n",
    "\n",
    "if len(data_info) == 0:\n",
    "    print(\"❌ 데이터 파일이 없습니다. pipeline.centers를 실제 센터명으로 수정해주세요.\")\n",
    "else:\n",
    "    print(f\"✅ {len(data_info)}개 센터 데이터 로드 완료\")\n",
    "\n",
    "# %% 셀 6: 전체 모델 학습 실행\n",
    "print(\"🚀 전체 모델 학습 시작\")\n",
    "print(f\"예상 총 모델 수: {len(pipeline.centers)} × 2 × 2 × 6 = {len(pipeline.centers) * 2 * 2 * 6}개\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_models = 0\n",
    "successful_models = 0\n",
    "\n",
    "for center in pipeline.centers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🏢 {center.upper()} 센터 처리 중...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # 데이터 로드\n",
    "        data = pipeline.load_data(center)\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        \n",
    "        print(f\"📊 데이터 정보: {X.shape[0]}행 × {X.shape[1]}개 피처\")\n",
    "        print(f\"🎯 회귀 타겟 범위: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"🏷️ 분류 타겟 클래스: {sorted(y_clf.unique())}\")\n",
    "        \n",
    "        # 두 가지 분할 방법\n",
    "        for split_method in ['temporal', 'random']:\n",
    "            print(f\"\\n--- {split_method.upper()} 분할 방법 ---\")\n",
    "            \n",
    "            # 회귀 모델 학습\n",
    "            print(\"📈 회귀 모델 학습:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_temporal(X, y_reg)\n",
    "            else:\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_random(X, y_reg)\n",
    "            \n",
    "            for model_name, model in pipeline.regression_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_reg, y_train_reg)\n",
    "                    y_pred = model.predict(X_test_reg)\n",
    "                    metrics = evaluate_regression(y_test_reg, y_pred)\n",
    "                    \n",
    "                    result = {\n",
    "                        'center': center, \n",
    "                        'split_method': split_method, \n",
    "                        'task': 'regression',\n",
    "                        'model': model_name, \n",
    "                        **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    \n",
    "                    print(f\"  ✅ {model_name}: R2={metrics['R2']:.4f}, RMSE={metrics['RMSE']:.2f}, SMAPE={metrics['SMAPE']:.2f}%\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ❌ {model_name}: {str(e)}\")\n",
    "            \n",
    "            # 분류 모델 학습\n",
    "            print(\"📊 분류 모델 학습:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_temporal(X, y_clf)\n",
    "            else:\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_random(X, y_clf, stratify=y_clf)\n",
    "            \n",
    "            for model_name, model in pipeline.classification_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_clf, y_train_clf)\n",
    "                    y_pred = model.predict(X_test_clf)\n",
    "                    y_pred_proba = model.predict_proba(X_test_clf) if hasattr(model, 'predict_proba') else None\n",
    "                    metrics = evaluate_classification(y_test_clf, y_pred, y_pred_proba)\n",
    "                    \n",
    "                    result = {\n",
    "                        'center': center, \n",
    "                        'split_method': split_method, \n",
    "                        'task': 'classification',\n",
    "                        'model': model_name, \n",
    "                        **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    \n",
    "                    print(f\"  ✅ {model_name}: Acc={metrics['Accuracy']:.4f}, F1_w={metrics['F1_weighted']:.4f}, F1_m={metrics['F1_macro']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ❌ {model_name}: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {center} 센터 처리 실패: {str(e)}\")\n",
    "\n",
    "print(f\"\\n🎉 전체 모델 학습 완료!\")\n",
    "print(f\"성공: {successful_models}/{total_models} 모델\")\n",
    "\n",
    "# %% 셀 7: 결과 저장 및 기본 분석\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df = pd.DataFrame(pipeline.results)\n",
    "results_df.to_csv('../results_v2/all_model_results.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"💾 전체 결과 저장: ../results_v2/all_model_results.csv\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"\\n📊 기본 통계\")\n",
    "    print(f\"총 결과 수: {len(results_df)}\")\n",
    "    print(f\"센터별 결과 수:\")\n",
    "    print(results_df['center'].value_counts())\n",
    "    print(f\"\\n태스크별 결과 수:\")\n",
    "    print(results_df['task'].value_counts())\n",
    "    \n",
    "    # 상위 결과 미리보기\n",
    "    print(\"\\n📋 결과 미리보기 (상위 5개):\")\n",
    "    display(results_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 분석할 결과가 없습니다.\")\n",
    "\n",
    "# %% 셀 8: 베스트 모델 찾기 (통합 테이블)\n",
    "def find_best_models_integrated(results_df, centers):\n",
    "    \"\"\"통합 베스트 모델 테이블 생성\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 분석할 결과가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🏆 통합 베스트 모델 찾기\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    best_models_list = []\n",
    "    \n",
    "    for center in centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            if task == 'regression':\n",
    "                # R2가 높은 모델 선택\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "                metric_value = best_model['R2']\n",
    "                metric_name = 'R2'\n",
    "            else:\n",
    "                # F1_weighted가 높은 모델 선택\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                metric_value = best_model['F1_weighted']\n",
    "                metric_name = 'F1_weighted'\n",
    "            \n",
    "            best_models_list.append(best_model.to_dict())\n",
    "            print(f\"🏅 {center} - {task}: {best_model['model']} ({best_model['split_method']}) - {metric_name}={metric_value:.4f}\")\n",
    "    \n",
    "    best_models_df = pd.DataFrame(best_models_list)\n",
    "    best_models_df.to_csv('../results_v2/best_models.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n💾 통합 베스트 모델 정보 저장: ../results_v2/best_models.csv\")\n",
    "    \n",
    "    return best_models_df\n",
    "\n",
    "# 통합 베스트 모델 찾기 실행\n",
    "if len(results_df) > 0:\n",
    "    best_models_df = find_best_models_integrated(results_df, pipeline.centers)\n",
    "    if best_models_df is not None:\n",
    "        print(f\"\\n📋 통합 베스트 모델 요약 ({len(best_models_df)}개):\")\n",
    "        display(best_models_df[['center', 'task', 'model', 'split_method', 'R2', 'F1_weighted', 'F1_macro']].fillna('-'))\n",
    "\n",
    "# %% 셀 9: 개별 베스트 모델 테이블 생성 (8개)\n",
    "def create_individual_best_model_tables(results_df, centers):\n",
    "    \"\"\"센터별, 분할방법별, 태스크별 개별 베스트 모델 테이블 생성 (총 8개)\"\"\"\n",
    "    print(\"📊 개별 베스트 모델 테이블 생성 (8개)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    individual_tables = {}\n",
    "    \n",
    "    for center in centers:\n",
    "        for split_method in ['temporal', 'random']:\n",
    "            for task in ['regression', 'classification']:\n",
    "                # 해당 조건의 데이터 필터링\n",
    "                filtered_data = results_df[\n",
    "                    (results_df['center'] == center) & \n",
    "                    (results_df['split_method'] == split_method) &\n",
    "                    (results_df['task'] == task)\n",
    "                ]\n",
    "                \n",
    "                if len(filtered_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # 성능 기준으로 정렬\n",
    "                if task == 'regression':\n",
    "                    sorted_data = filtered_data.sort_values('R2', ascending=False)\n",
    "                    best_metric = 'R2'\n",
    "                else:\n",
    "                    sorted_data = filtered_data.sort_values('F1_weighted', ascending=False)\n",
    "                    best_metric = 'F1_weighted'\n",
    "                \n",
    "                # 테이블 저장\n",
    "                table_name = f\"{center}_{split_method}_{task}\"\n",
    "                filename = f\"../results_v2/best_models_individual/{table_name}_models.csv\"\n",
    "                sorted_data.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                individual_tables[table_name] = {\n",
    "                    'data': sorted_data,\n",
    "                    'best_model': sorted_data.iloc[0]['model'],\n",
    "                    'best_score': sorted_data.iloc[0][best_metric],\n",
    "                    'filename': filename\n",
    "                }\n",
    "                \n",
    "                print(f\"💾 {table_name}: {sorted_data.iloc[0]['model']} ({best_metric}={sorted_data.iloc[0][best_metric]:.4f})\")\n",
    "    \n",
    "    print(f\"\\n✅ 총 {len(individual_tables)}개 개별 테이블 생성 완료\")\n",
    "    return individual_tables\n",
    "\n",
    "# 개별 베스트 모델 테이블 생성 실행\n",
    "if len(results_df) > 0:\n",
    "    individual_best_tables = create_individual_best_model_tables(results_df, pipeline.centers)\n",
    "    print(f\"📁 개별 테이블 저장 위치: ../results_v2/best_models_individual/\")\n",
    "\n",
    "# %% 셀 10: ROC Curve 시각화 함수\n",
    "def create_roc_curves(results_df, centers):\n",
    "    \"\"\"ROC Curve 시각화 생성\"\"\"\n",
    "    print(\"📈 ROC Curve 시각화 생성\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # 분류 결과만 필터링\n",
    "    clf_results = results_df[results_df['task'] == 'classification'].copy()\n",
    "    \n",
    "    if len(clf_results) == 0:\n",
    "        print(\"❌ 분류 결과가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 센터별로 ROC Curve 그리기 (실제 구현을 위해서는 y_pred_proba 저장 필요)\n",
    "    print(\"⚠️ ROC Curve를 그리기 위해서는 모델 재학습이 필요합니다.\")\n",
    "    print(\"베스트 모델 저장 단계에서 ROC Curve를 생성하겠습니다.\")\n",
    "\n",
    "print(\"✅ ROC Curve 시각화 함수 정의 완료\")\n",
    "\n",
    "# %% 셀 11: 상세 성능 시각화 생성\n",
    "def create_detailed_visualizations(results_df):\n",
    "    \"\"\"상세한 성능 시각화 생성\"\"\"\n",
    "    print(\"📊 상세 성능 시각화 생성\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 시각화할 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 1. 기본 성능 비교 (2x2 그리드)\n",
    "    fig1, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 센터별 회귀 성능 (분할방법별)\n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    if len(reg_data) > 0:\n",
    "        reg_summary = reg_data.groupby(['center', 'split_method'])['R2'].mean().unstack(fill_value=0)\n",
    "        reg_summary.plot(kind='bar', ax=axes[0,0], title='센터별 회귀 R2 성능 (분할방법별)')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 센터별 분류 성능 (분할방법별)  \n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    if len(clf_data) > 0:\n",
    "        clf_summary = clf_data.groupby(['center', 'split_method'])['F1_weighted'].mean().unstack(fill_value=0)\n",
    "        clf_summary.plot(kind='bar', ax=axes[0,1], title='센터별 분류 F1 성능 (분할방법별)')\n",
    "        axes[0,1].set_ylabel('F1 Score (Weighted)')\n",
    "        axes[0,1].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 모델별 회귀 성능\n",
    "    if len(reg_data) > 0:\n",
    "        reg_model_perf = reg_data.groupby(['model'])['R2'].mean().sort_values(ascending=True)\n",
    "        reg_model_perf.plot(kind='barh', ax=axes[1,0], title='모델별 평균 회귀 R2 성능')\n",
    "        axes[1,0].set_xlabel('R2 Score')\n",
    "    \n",
    "    # 모델별 분류 성능\n",
    "    if len(clf_data) > 0:\n",
    "        clf_model_perf = clf_data.groupby(['model'])['F1_weighted'].mean().sort_values(ascending=True)\n",
    "        clf_model_perf.plot(kind='barh', ax=axes[1,1], title='모델별 평균 분류 F1 성능')\n",
    "        axes[1,1].set_xlabel('F1 Score (Weighted)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v2/visualizations/basic_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. 센터별 모델별 상세 성능 비교 (회귀)\n",
    "    if len(reg_data) > 0:\n",
    "        fig2, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        \n",
    "        # R2 성능\n",
    "        reg_pivot_r2 = reg_data.pivot_table(values='R2', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_r2.plot(kind='bar', ax=axes[0,0], title='센터별 회귀 모델 R2 성능 비교')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # MAE 성능\n",
    "        reg_pivot_mae = reg_data.pivot_table(values='MAE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_mae.plot(kind='bar', ax=axes[0,1], title='센터별 회귀 모델 MAE 성능 비교')\n",
    "        axes[0,1].set_ylabel('MAE')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # RMSE 성능\n",
    "        reg_pivot_rmse = reg_data.pivot_table(values='RMSE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_rmse.plot(kind='bar', ax=axes[1,0], title='센터별 회귀 모델 RMSE 성능 비교')\n",
    "        axes[1,0].set_ylabel('RMSE')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # SMAPE 성능\n",
    "        reg_pivot_smape = reg_data.pivot_table(values='SMAPE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_smape.plot(kind='bar', ax=axes[1,1], title='센터별 회귀 모델 SMAPE 성능 비교')\n",
    "        axes[1,1].set_ylabel('SMAPE (%)')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/regression_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. 센터별 모델별 상세 성능 비교 (분류)\n",
    "    if len(clf_data) > 0:\n",
    "        fig3, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        \n",
    "        # Accuracy 성능\n",
    "        clf_pivot_acc = clf_data.pivot_table(values='Accuracy', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_acc.plot(kind='bar', ax=axes[0,0], title='센터별 분류 모델 Accuracy 성능 비교')\n",
    "        axes[0,0].set_ylabel('Accuracy')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # F1 Weighted 성능\n",
    "        clf_pivot_f1w = clf_data.pivot_table(values='F1_weighted', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1w.plot(kind='bar', ax=axes[0,1], title='센터별 분류 모델 F1_Weighted 성능 비교')\n",
    "        axes[0,1].set_ylabel('F1 Weighted')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # F1 Macro 성능\n",
    "        clf_pivot_f1m = clf_data.pivot_table(values='F1_macro', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1m.plot(kind='bar', ax=axes[1,0], title='센터별 분류 모델 F1_Macro 성능 비교')\n",
    "        axes[1,0].set_ylabel('F1 Macro')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # AUC 성능\n",
    "        clf_pivot_auc = clf_data.pivot_table(values='AUC', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_auc.plot(kind='bar', ax=axes[1,1], title='센터별 분류 모델 AUC 성능 비교')\n",
    "        axes[1,1].set_ylabel('AUC')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/classification_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. 동일 모델에 대한 센터별 성능 비교\n",
    "    models = results_df['model'].unique()\n",
    "    n_models = len(models)\n",
    "    \n",
    "    # 회귀 모델들의 센터별 비교\n",
    "    if len(reg_data) > 0:\n",
    "        fig4, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            if i >= 6:  # 최대 6개 모델만 표시\n",
    "                break\n",
    "                \n",
    "            model_data = reg_data[reg_data['model'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                center_perf = model_data.groupby('center')['R2'].mean()\n",
    "                center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - 센터별 R2 성능')\n",
    "                axes[i].set_ylabel('R2 Score')\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 사용하지 않는 subplot 숨기기\n",
    "        for j in range(i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_regression.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 분류 모델들의 센터별 비교\n",
    "    if len(clf_data) > 0:\n",
    "        fig5, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            if i >= 6:  # 최대 6개 모델만 표시\n",
    "                break\n",
    "                \n",
    "            model_data = clf_data[clf_data['model'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                center_perf = model_data.groupby('center')['F1_weighted'].mean()\n",
    "                center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - 센터별 F1_Weighted 성능')\n",
    "                axes[i].set_ylabel('F1 Weighted')\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 사용하지 않는 subplot 숨기기\n",
    "        for j in range(i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_classification.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"✅ 상세 시각화 완료\")\n",
    "    print(\"📁 저장 위치:\")\n",
    "    print(\"  - basic_performance_comparison.png\")\n",
    "    print(\"  - regression_detailed_comparison.png\")\n",
    "    print(\"  - classification_detailed_comparison.png\")  \n",
    "    print(\"  - same_model_center_comparison_regression.png\")\n",
    "    print(\"  - same_model_center_comparison_classification.png\")\n",
    "    \n",
    "    # 성능 요약 출력\n",
    "    print(f\"\\n📊 성능 하이라이트:\")\n",
    "    \n",
    "    # 회귀 모델 최고 성능\n",
    "    if len(reg_data) > 0:\n",
    "        reg_best = reg_data.nlargest(3, 'R2')\n",
    "        print(f\"\\n🏆 회귀 모델 TOP 3 (R2 기준):\")\n",
    "        for idx, row in reg_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): R2={row['R2']:.4f}, SMAPE={row['SMAPE']:.2f}%\")\n",
    "    \n",
    "    # 분류 모델 최고 성능  \n",
    "    if len(clf_data) > 0:\n",
    "        clf_best = clf_data.nlargest(3, 'F1_weighted')\n",
    "        print(f\"\\n🏆 분류 모델 TOP 3 (F1_weighted 기준):\")\n",
    "        for idx, row in clf_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): F1_w={row['F1_weighted']:.4f}, F1_m={row['F1_macro']:.4f}\")\n",
    "\n",
    "# 상세 시각화 실행\n",
    "if len(results_df) > 0:\n",
    "    create_detailed_visualizations(results_df)\n",
    "\n",
    "# %% 셀 12: 베스트 모델 재학습 및 저장 (8개 선정)\n",
    "def train_and_save_top8_models(results_df, pipeline):\n",
    "    \"\"\"상위 8개 베스트 모델 재학습 및 저장 (센터별×태스크별 = 8개)\"\"\"\n",
    "    print(\"💾 상위 8개 베스트 모델 재학습 및 저장\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 센터별, 태스크별 베스트 모델 선정\n",
    "    selected_models = []\n",
    "    \n",
    "    for center in pipeline.centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "            \n",
    "            selected_models.append(best_model)\n",
    "    \n",
    "    print(f\"📋 선정된 8개 베스트 모델:\")\n",
    "    for model_info in selected_models:\n",
    "        print(f\"  🏅 {model_info['center']} - {model_info['task']} - {model_info['model']} ({model_info['split_method']})\")\n",
    "    \n",
    "    # 모델 재학습 및 저장\n",
    "    saved_models = {}\n",
    "    \n",
    "    for model_info in selected_models:\n",
    "        center = model_info['center']\n",
    "        task = model_info['task']\n",
    "        model_name = model_info['model']\n",
    "        split_method = model_info['split_method']\n",
    "        \n",
    "        print(f\"\\n🔄 {center} - {task} - {model_name} ({split_method}) 재학습 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 데이터 로드\n",
    "            data = pipeline.load_data(center)\n",
    "            if data is None:\n",
    "                continue\n",
    "                \n",
    "            X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "            y = y_reg if task == 'regression' else y_clf\n",
    "            \n",
    "            # 모델 선택\n",
    "            if task == 'regression':\n",
    "                if model_name in pipeline.regression_models:\n",
    "                    model = pipeline.regression_models[model_name]\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                if model_name in pipeline.classification_models:\n",
    "                    model = pipeline.classification_models[model_name]\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            # 데이터 분할\n",
    "            if split_method == 'temporal':\n",
    "                X_train, X_test, y_train, y_test = split_data_temporal(X, y)\n",
    "            else:\n",
    "                stratify = y if task == 'classification' else None\n",
    "                X_train, X_test, y_train, y_test = split_data_random(X, y, stratify=stratify)\n",
    "            \n",
    "            # 모델 학습\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # 예측 및 성능 계산 (ROC Curve용 확률도 저장)\n",
    "            y_pred = model.predict(X_test)\n",
    "            if task == 'classification' and hasattr(model, 'predict_proba'):\n",
    "                y_pred_proba = model.predict_proba(X_test)\n",
    "            else:\n",
    "                y_pred_proba = None\n",
    "            \n",
    "            # 모델 저장 데이터 준비\n",
    "            model_data = {\n",
    "                'model': model,\n",
    "                'feature_names': X.columns.tolist(),\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'task': task,\n",
    "                'center': center,\n",
    "                'split_method': split_method,\n",
    "                'model_name': model_name,\n",
    "                'performance': model_info.to_dict()\n",
    "            }\n",
    "            \n",
    "            # 파일 저장\n",
    "            filename = f\"{center}_{task}_{model_name}_{split_method}.pkl\"\n",
    "            filepath = f\"../models_v2/best_models/{filename}\"\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            \n",
    "            print(f\"✅ 모델 저장: {filepath}\")\n",
    "            \n",
    "            # 메모리에도 저장\n",
    "            key = f\"{center}_{task}\"\n",
    "            saved_models[key] = model_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {center} - {task} - {model_name} 저장 실패: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n✅ {len(saved_models)}개 베스트 모델 저장 완료\")\n",
    "    return saved_models\n",
    "\n",
    "# 상위 8개 베스트 모델 저장 실행\n",
    "if len(results_df) > 0:\n",
    "    saved_top8_models = train_and_save_top8_models(results_df, pipeline)\n",
    "    print(f\"🤖 저장된 상위 8개 모델 수: {len(saved_top8_models)}\")\n",
    "\n",
    "# %% 셀 13: ROC Curve 시각화 (실제 구현)\n",
    "def create_roc_curves_actual(saved_models):\n",
    "    \"\"\"실제 ROC Curve 시각화 생성\"\"\"\n",
    "    print(\"📈 ROC Curve 시각화 생성\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # 분류 모델만 필터링\n",
    "    clf_models = {k: v for k, v in saved_models.items() if v['task'] == 'classification'}\n",
    "    \n",
    "    if len(clf_models) == 0:\n",
    "        print(\"❌ 분류 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 센터별로 ROC Curve 그리기\n",
    "    centers = list(set([v['center'] for v in clf_models.values()]))\n",
    "    n_centers = len(centers)\n",
    "    \n",
    "    if n_centers > 0:\n",
    "        fig, axes = plt.subplots(1, min(4, n_centers), figsize=(5*min(4, n_centers), 5))\n",
    "        if n_centers == 1:\n",
    "            axes = [axes]\n",
    "        elif min(4, n_centers) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, center in enumerate(centers):\n",
    "            if i >= 4:  # 최대 4개 센터만 표시\n",
    "                break\n",
    "                \n",
    "            # 해당 센터의 분류 모델 찾기\n",
    "            center_models = {k: v for k, v in clf_models.items() if v['center'] == center}\n",
    "            \n",
    "            ax = axes[i] if n_centers > 1 else axes[0]\n",
    "            \n",
    "            for model_key, model_data in center_models.items():\n",
    "                y_test = model_data['y_test']\n",
    "                y_pred_proba = model_data['y_pred_proba']\n",
    "                \n",
    "                if y_pred_proba is not None:\n",
    "                    try:\n",
    "                        # 이진 분류인지 다중 분류인지 확인\n",
    "                        n_classes = len(np.unique(y_test))\n",
    "                        \n",
    "                        if n_classes == 2:\n",
    "                            # 이진 분류\n",
    "                            fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "                            auc_score = auc(fpr, tpr)\n",
    "                            ax.plot(fpr, tpr, label=f'{model_data[\"model_name\"]} (AUC = {auc_score:.3f})')\n",
    "                        else:\n",
    "                            # 다중 분류 - 각 클래스별 ROC 그리기\n",
    "                            from sklearn.preprocessing import label_binarize\n",
    "                            y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "                            \n",
    "                            for class_idx in range(n_classes):\n",
    "                                if class_idx < y_pred_proba.shape[1]:\n",
    "                                    fpr, tpr, _ = roc_curve(y_test_bin[:, class_idx], y_pred_proba[:, class_idx])\n",
    "                                    auc_score = auc(fpr, tpr)\n",
    "                                    ax.plot(fpr, tpr, label=f'{model_data[\"model_name\"]} Class{class_idx} (AUC = {auc_score:.3f})')\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ {center} ROC Curve 생성 실패: {str(e)}\")\n",
    "            \n",
    "            # 대각선 그리기\n",
    "            ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "            ax.set_xlim([0.0, 1.0])\n",
    "            ax.set_ylim([0.0, 1.05])\n",
    "            ax.set_xlabel('False Positive Rate')\n",
    "            ax.set_ylabel('True Positive Rate')\n",
    "            ax.set_title(f'{center} 센터 ROC Curves')\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"✅ ROC Curve 시각화 완료\")\n",
    "        print(\"📁 저장: ../results_v2/visualizations/roc_curves.png\")\n",
    "\n",
    "# ROC Curve 시각화 실행\n",
    "if 'saved_top8_models' in locals():\n",
    "    create_roc_curves_actual(saved_top8_models)\n",
    "\n",
    "# %% 셀 14: SHAP 분석 (Force Plot 포함)\n",
    "def analyze_shap_complete(saved_models):\n",
    "    \"\"\"완전한 SHAP 분석 (Summary, Importance, Force Plot)\"\"\"\n",
    "    if len(saved_models) == 0:\n",
    "        print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(\"🔍 완전한 SHAP 분석 시작 (Summary + Importance + Force Plot)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for key, model_data in saved_models.items():\n",
    "        center = model_data['center']\n",
    "        task = model_data['task']\n",
    "        model_name = model_data['model_name']\n",
    "        model = model_data['model']\n",
    "        X_train = model_data['X_train']\n",
    "        X_test = model_data['X_test']\n",
    "        feature_names = model_data['feature_names']\n",
    "        \n",
    "        print(f\"\\n🔍 {center} - {task} - {model_name} SHAP 분석...\")\n",
    "        \n",
    "        try:\n",
    "            # SHAP explainer 생성 (시간 단축을 위해 샘플 수 제한)\n",
    "            sample_size = min(50, len(X_test))\n",
    "            X_test_sample = X_test.iloc[:sample_size]\n",
    "            \n",
    "            if model_name in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "                explainer = shap.Explainer(model)\n",
    "                shap_values = explainer(X_test_sample)\n",
    "            else:\n",
    "                train_sample_size = min(100, len(X_train))\n",
    "                explainer = shap.Explainer(model, X_train.iloc[:train_sample_size])\n",
    "                shap_values = explainer(X_test_sample)\n",
    "            \n",
    "            # 1. Summary Plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, \n",
    "                            show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Summary Plot')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_summary.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 2. Feature Importance\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, \n",
    "                            plot_type=\"bar\", show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 3. Force Plot (첫 번째와 두 번째 샘플)\n",
    "            try:\n",
    "                # 첫 번째 샘플\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                if hasattr(shap_values, 'values'):\n",
    "                    if len(shap_values.values.shape) == 3:  # 다중분류\n",
    "                        shap.waterfall_plot(shap_values[0, :, 0], show=False)\n",
    "                    else:\n",
    "                        shap.waterfall_plot(shap_values[0], show=False)\n",
    "                else:\n",
    "                    shap.waterfall_plot(shap_values[0], show=False)\n",
    "                \n",
    "                plt.title(f'{center} - {task} - {model_name}\\nSHAP Force Plot (Sample 1)')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_1.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                \n",
    "                # 두 번째 샘플 (있는 경우)\n",
    "                if len(X_test_sample) > 1:\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    if hasattr(shap_values, 'values'):\n",
    "                        if len(shap_values.values.shape) == 3:  # 다중분류\n",
    "                            shap.waterfall_plot(shap_values[1, :, 0], show=False)\n",
    "                        else:\n",
    "                            shap.waterfall_plot(shap_values[1], show=False)\n",
    "                    else:\n",
    "                        shap.waterfall_plot(shap_values[1], show=False)\n",
    "                    \n",
    "                    plt.title(f'{center} - {task} - {model_name}\\nSHAP Force Plot (Sample 2)')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_2.png', \n",
    "                               dpi=300, bbox_inches='tight')\n",
    "                    plt.show()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Force Plot 생성 실패: {str(e)}\")\n",
    "                # 대안: Waterfall plot 대신 간단한 bar plot\n",
    "                try:\n",
    "                    if hasattr(shap_values, 'values'):\n",
    "                        values = shap_values.values[0] if len(shap_values.values.shape) == 2 else shap_values.values[0, :, 0]\n",
    "                    else:\n",
    "                        values = shap_values[0].values\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    feature_importance = pd.DataFrame({\n",
    "                        'feature': feature_names[:len(values)],\n",
    "                        'shap_value': values\n",
    "                    }).sort_values('shap_value', key=abs, ascending=True).tail(15)\n",
    "                    \n",
    "                    plt.barh(range(len(feature_importance)), feature_importance['shap_value'])\n",
    "                    plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "                    plt.xlabel('SHAP Value')\n",
    "                    plt.title(f'{center} - {task} - {model_name}\\nSHAP Values (Sample 1)')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_alt.png', \n",
    "                               dpi=300, bbox_inches='tight')\n",
    "                    plt.show()\n",
    "                    \n",
    "                except Exception as e2:\n",
    "                    print(f\"⚠️ 대안 Force Plot도 실패: {str(e2)}\")\n",
    "            \n",
    "            print(f\"✅ SHAP 분석 완료: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ SHAP 분석 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "\n",
    "# SHAP 분석 실행\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_shap_complete(saved_top8_models)\n",
    "\n",
    "# %% 셀 15: Feature Importance 분석\n",
    "def analyze_feature_importance_complete(saved_models):\n",
    "    \"\"\"완전한 Feature Importance 분석\"\"\"\n",
    "    if len(saved_models) == 0:\n",
    "        print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(\"📊 완전한 Feature Importance 분석\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for key, model_data in saved_models.items():\n",
    "        center = model_data['center']\n",
    "        task = model_data['task']\n",
    "        model_name = model_data['model_name']\n",
    "        model = model_data['model']\n",
    "        feature_names = model_data['feature_names']\n",
    "        \n",
    "        print(f\"\\n📊 {center} - {task} - {model_name} Feature Importance...\")\n",
    "        \n",
    "        try:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                # Tree-based 모델\n",
    "                importance = model.feature_importances_\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importance\n",
    "                }).sort_values('importance', ascending=True)\n",
    "                \n",
    "                # 상위 20개 피처만 표시\n",
    "                top_features = importance_df.tail(20)\n",
    "                colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n",
    "                \n",
    "                bars = plt.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "                plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance (Top 20)')\n",
    "                \n",
    "                # 수치 표시\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                            f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "                \n",
    "            elif hasattr(model, 'coef_'):\n",
    "                # 선형 모델\n",
    "                if task == 'classification' and len(model.coef_.shape) > 1:\n",
    "                    # 다중분류의 경우 평균 절댓값 사용\n",
    "                    coef = np.mean(np.abs(model.coef_), axis=0)\n",
    "                else:\n",
    "                    coef = np.abs(model.coef_).flatten()\n",
    "                \n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': coef\n",
    "                }).sort_values('importance', ascending=True)\n",
    "                \n",
    "                # 상위 20개 피처만 표시\n",
    "                top_features = importance_df.tail(20)\n",
    "                colors = plt.cm.plasma(np.linspace(0, 1, len(top_features)))\n",
    "                \n",
    "                bars = plt.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "                plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                plt.xlabel('|Coefficient|')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Coefficients (Top 20)')\n",
    "                \n",
    "                # 수치 표시\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                            f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "            \n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Feature importance not available for this model', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_feature_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"✅ Feature Importance 완료: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Feature Importance 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "\n",
    "# Feature Importance 분석 실행\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_feature_importance_complete(saved_top8_models)\n",
    "\n",
    "# %% 셀 16: LIME 분석 (선택사항)\n",
    "def analyze_lime_complete(saved_models):\n",
    "    \"\"\"완전한 LIME 분석 (선택사항)\"\"\"\n",
    "    try:\n",
    "        import lime\n",
    "        import lime.lime_tabular\n",
    "        \n",
    "        if len(saved_models) == 0:\n",
    "            print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(\"🍋 완전한 LIME 분석 시작\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 시간 절약을 위해 처음 3개 모델만 분석\n",
    "        analyzed_count = 0\n",
    "        for key, model_data in saved_models.items():\n",
    "            if analyzed_count >= 3:\n",
    "                print(\"⏰ 시간 절약을 위해 처음 3개 모델만 LIME 분석합니다.\")\n",
    "                break\n",
    "                \n",
    "            center = model_data['center']\n",
    "            task = model_data['task']\n",
    "            model_name = model_data['model_name']\n",
    "            model = model_data['model']\n",
    "            X_train = model_data['X_train']\n",
    "            X_test = model_data['X_test']\n",
    "            feature_names = model_data['feature_names']\n",
    "            \n",
    "            print(f\"\\n🍋 {center} - {task} - {model_name} LIME 분석...\")\n",
    "            \n",
    "            try:\n",
    "                if task == 'regression':\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values,\n",
    "                        feature_names=feature_names,\n",
    "                        mode='regression',\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # 첫 번째와 두 번째 샘플 분석\n",
    "                    for sample_idx in [0, 1]:\n",
    "                        if sample_idx >= len(X_test):\n",
    "                            continue\n",
    "                            \n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                        \n",
    "                else:  # classification\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values,\n",
    "                        feature_names=feature_names,\n",
    "                        mode='classification',\n",
    "                        class_names=[str(c) for c in sorted(model.classes_)],\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # 첫 번째와 두 번째 샘플 분석\n",
    "                    for sample_idx in [0, 1]:\n",
    "                        if sample_idx >= len(X_test):\n",
    "                            continue\n",
    "                            \n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict_proba, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                \n",
    "                print(f\"✅ LIME 분석 완료: {center} - {task} - {model_name}\")\n",
    "                analyzed_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ LIME 분석 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"💡 LIME 분석을 위해서는 다음 명령어로 패키지를 설치하세요:\")\n",
    "        print(\"   pip install lime\")\n",
    "        print(\"   현재는 LIME 분석을 건너뜁니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ LIME 분석 중 오류 발생: {str(e)}\")\n",
    "\n",
    "# LIME 분석 실행 (선택사항)\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_lime_complete(saved_top8_models)\n",
    "\n",
    "# %% 셀 17: 새로운 데이터 예측 함수\n",
    "def predict_with_saved_model(center, task, new_data):\n",
    "    \"\"\"\n",
    "    저장된 베스트 모델로 새로운 데이터 예측\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    center : str\n",
    "        센터명\n",
    "    task : str  \n",
    "        'regression' 또는 'classification'\n",
    "    new_data : pandas.DataFrame\n",
    "        예측할 새로운 데이터\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    prediction : array or tuple\n",
    "        예측 결과 (분류의 경우 확률도 함께 반환)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 베스트 모델 파일 찾기\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') \n",
    "                  if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"❌ {center} - {task} 모델 파일을 찾을 수 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # 첫 번째 모델 파일 사용 (가장 좋은 모델)\n",
    "    model_file = model_files[0]\n",
    "    filepath = f\"../models_v2/best_models/{model_file}\"\n",
    "    \n",
    "    try:\n",
    "        # 모델 로드\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = model_data['model']\n",
    "        feature_names = model_data['feature_names']\n",
    "        \n",
    "        # 피처 순서 맞추기\n",
    "        missing_cols = [col for col in feature_names if col not in new_data.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"❌ 누락된 컬럼: {missing_cols}\")\n",
    "            return None\n",
    "        \n",
    "        X_new = new_data[feature_names]\n",
    "        \n",
    "        # 예측\n",
    "        if task == 'regression':\n",
    "            prediction = model.predict(X_new)\n",
    "            print(f\"✅ {center} - {task} 예측 완료: {len(prediction)}개 샘플\")\n",
    "            return prediction\n",
    "        else:\n",
    "            prediction = model.predict(X_new)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                prediction_proba = model.predict_proba(X_new)\n",
    "                print(f\"✅ {center} - {task} 예측 완료: {len(prediction)}개 샘플\")\n",
    "                return prediction, prediction_proba\n",
    "            else:\n",
    "                print(f\"✅ {center} - {task} 예측 완료: {len(prediction)}개 샘플\")\n",
    "                return prediction\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 예측 실패: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_saved_model(center, task):\n",
    "    \"\"\"저장된 모델 정보 로드\"\"\"\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') \n",
    "                  if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"❌ {center} - {task} 모델 파일을 찾을 수 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    filepath = f\"../models_v2/best_models/{model_files[0]}\"\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        print(f\"✅ 모델 로드 완료: {center} - {task} - {model_data['model_name']}\")\n",
    "        return model_data\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 로드 실패: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"🔮 예측 함수 정의 완료\")\n",
    "\n",
    "# %% 셀 18: 하이퍼파라미터 튜닝 예시 (선택사항)\n",
    "def show_hyperparameter_tuning_examples():\n",
    "    \"\"\"하이퍼파라미터 튜닝 예시 코드 출력\"\"\"\n",
    "    print(\"⚙️ 하이퍼파라미터 튜닝 예시\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    tuning_examples = '''\n",
    "# GridSearchCV를 이용한 하이퍼파라미터 튜닝 예시\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 1. XGBoost 회귀 모델 튜닝\n",
    "def tune_xgboost_regression(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        xgb_model, param_grid, \n",
    "        cv=5, scoring='r2', \n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best score:\", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# 2. RandomForest 분류 모델 튜닝\n",
    "def tune_randomforest_classification(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 500],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # RandomizedSearchCV 사용 (더 빠름)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf_model, param_grid, \n",
    "        cv=5, scoring='f1_weighted',\n",
    "        n_iter=50, n_jobs=-1, verbose=1, random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best score:\", random_search.best_score_)\n",
    "    \n",
    "    return random_search.best_estimator_\n",
    "\n",
    "# 3. LightGBM 튜닝 (Optuna 사용)\n",
    "def tune_lightgbm_with_optuna(X_train, y_train, task='regression'):\n",
    "    # pip install optuna 필요\n",
    "    import optuna\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'regression' if task == 'regression' else 'multiclass',\n",
    "            'metric': 'rmse' if task == 'regression' else 'multi_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        }\n",
    "        \n",
    "        if task == 'regression':\n",
    "            model = lgb.LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "            score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "        else:\n",
    "            model = lgb.LGBMClassifier(**params, random_state=42, verbose=-1)\n",
    "            score = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_weighted').mean()\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    print(study.best_trial.params)\n",
    "    print(f\"Best score: {study.best_value}\")\n",
    "    \n",
    "    return study.best_trial.params\n",
    "\n",
    "# 사용 예시:\n",
    "# best_xgb = tune_xgboost_regression(X_train, y_train)\n",
    "# best_rf = tune_randomforest_classification(X_train, y_train)\n",
    "# best_lgb_params = tune_lightgbm_with_optuna(X_train, y_train, task='regression')\n",
    "    '''\n",
    "    \n",
    "    print(tuning_examples)\n",
    "\n",
    "# 튜닝 예시 출력\n",
    "show_hyperparameter_tuning_examples()\n",
    "\n",
    "# %% 셀 19: 최종 결과 요약 및 체크리스트\n",
    "def comprehensive_final_summary():\n",
    "    \"\"\"포괄적인 최종 결과 요약\"\"\"\n",
    "    print(\"📋 포괄적인 최종 실행 완료 체크리스트\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 체크리스트 항목들\n",
    "    checklist = {}\n",
    "    \n",
    "    # 1. 데이터 로드 확인\n",
    "    checklist[\"1. 데이터 로드\"] = 'data_info' in locals() and len(data_info) > 0\n",
    "    \n",
    "    # 2. 모델 학습 결과 확인\n",
    "    checklist[\"2. 모델 학습 (96개)\"] = 'results_df' in locals() and len(results_df) > 0\n",
    "    \n",
    "    # 3. 결과 파일 저장 확인\n",
    "    checklist[\"3. 전체 결과 CSV\"] = os.path.exists('../results_v2/all_model_results.csv')\n",
    "    \n",
    "    # 4. 통합 베스트 모델 확인\n",
    "    checklist[\"4. 통합 베스트 모델\"] = os.path.exists('../results_v2/best_models.csv')\n",
    "    \n",
    "    # 5. 개별 베스트 모델 테이블 확인 (8개)\n",
    "    individual_dir = '../results_v2/best_models_individual/'\n",
    "    individual_files = [f for f in os.listdir(individual_dir) if f.endswith('.csv')] if os.path.exists(individual_dir) else []\n",
    "    checklist[\"5. 개별 베스트 모델 (8개)\"] = len(individual_files) >= 8\n",
    "    \n",
    "    # 6. 기본 시각화 확인\n",
    "    basic_viz = '../results_v2/visualizations/basic_performance_comparison.png'\n",
    "    checklist[\"6. 기본 성능 시각화\"] = os.path.exists(basic_viz)\n",
    "    \n",
    "    # 7. 상세 시각화 확인\n",
    "    detailed_viz_files = [\n",
    "        'regression_detailed_comparison.png',\n",
    "        'classification_detailed_comparison.png', \n",
    "        'same_model_center_comparison_regression.png',\n",
    "        'same_model_center_comparison_classification.png'\n",
    "    ]\n",
    "    viz_dir = '../results_v2/visualizations/'\n",
    "    viz_count = sum([os.path.exists(os.path.join(viz_dir, f)) for f in detailed_viz_files])\n",
    "    checklist[\"7. 상세 시각화 (4개)\"] = viz_count >= 4\n",
    "    \n",
    "    # 8. ROC Curve 시각화\n",
    "    roc_file = '../results_v2/visualizations/roc_curves.png'\n",
    "    checklist[\"8. ROC Curve 시각화\"] = os.path.exists(roc_file)\n",
    "    \n",
    "    # 9. 베스트 모델 파일 저장 (8개)\n",
    "    model_dir = '../models_v2/best_models/'\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')] if os.path.exists(model_dir) else []\n",
    "    checklist[\"9. 베스트 모델 파일 (8개)\"] = len(model_files) >= 8\n",
    "    \n",
    "    # 10. SHAP 분석 확인\n",
    "    interp_dir = '../results_v2/interpretations/'\n",
    "    shap_files = [f for f in os.listdir(interp_dir) if 'shap' in f.lower()] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"10. SHAP 분석\"] = len(shap_files) >= 8  # Summary + Importance + Force plots\n",
    "    \n",
    "    # 11. Feature Importance 분석 확인\n",
    "    fi_files = [f for f in os.listdir(interp_dir) if 'feature_importance' in f] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"11. Feature Importance\"] = len(fi_files) >= 8\n",
    "    \n",
    "    # 12. 성능 지표 완성도 확인 (SMAPE, macro 버전들)\n",
    "    if 'results_df' in locals() and len(results_df) > 0:\n",
    "        has_smape = 'SMAPE' in results_df.columns\n",
    "        has_f1_macro = 'F1_macro' in results_df.columns\n",
    "        checklist[\"12. 완전한 성능 지표\"] = has_smape and has_f1_macro\n",
    "    else:\n",
    "        checklist[\"12. 완전한 성능 지표\"] = False\n",
    "    \n",
    "    # 체크리스트 출력\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"✅\" if status else \"❌\"\n",
    "        print(f\"{status_icon} {item}: {'완료' if status else '미완료'}\")\n",
    "    \n",
    "    # 완료율 계산\n",
    "    completed = sum(checklist.values())\n",
    "    total = len(checklist)\n",
    "    completion_rate = completed / total * 100\n",
    "    \n",
    "    print(f\"\\n📊 전체 완료율: {completion_rate:.1f}% ({completed}/{total})\")\n",
    "    \n",
    "    # 상태에 따른 메시지\n",
    "    if completion_rate >= 95:\n",
    "        print(\"🎉 프로젝트가 완벽하게 완료되었습니다!\")\n",
    "    elif completion_rate >= 85:\n",
    "        print(\"🌟 프로젝트가 거의 완료되었습니다!\")\n",
    "    elif completion_rate >= 70:\n",
    "        print(\"⚠️ 대부분 완료되었으나 일부 단계를 확인해주세요.\")\n",
    "    else:\n",
    "        print(\"❌ 여러 단계에서 문제가 발생했습니다. 오류를 확인해주세요.\")\n",
    "    \n",
    "    # 상세 파일 현황\n",
    "    print(f\"\\n📁 생성된 파일 상세 현황:\")\n",
    "    \n",
    "    # 1. CSV 결과 파일\n",
    "    print(f\"\\n📊 성능 결과 파일:\")\n",
    "    if os.path.exists('../results_v2/all_model_results.csv'):\n",
    "        df = pd.read_csv('../results_v2/all_model_results.csv')\n",
    "        print(f\"  ✅ 전체 모델 결과: {len(df)}개 레코드\")\n",
    "        \n",
    "        # 성능 지표 확인\n",
    "        reg_cols = ['MAE', 'MSE', 'RMSE', 'MAPE', 'SMAPE', 'R2']\n",
    "        clf_cols = ['Accuracy', 'Precision_weighted', 'Precision_macro', \n",
    "                   'Recall_weighted', 'Recall_macro', 'F1_weighted', 'F1_macro', 'AUC']\n",
    "        \n",
    "        available_reg = [col for col in reg_cols if col in df.columns]\n",
    "        available_clf = [col for col in clf_cols if col in df.columns]\n",
    "        \n",
    "        print(f\"    📈 회귀 지표 ({len(available_reg)}/6): {available_reg}\")\n",
    "        print(f\"    📊 분류 지표 ({len(available_clf)}/8): {available_clf}\")\n",
    "    \n",
    "    if os.path.exists('../results_v2/best_models.csv'):\n",
    "        df = pd.read_csv('../results_v2/best_models.csv')\n",
    "        print(f\"  ✅ 통합 베스트 모델: {len(df)}개 모델\")\n",
    "    \n",
    "    # 2. 개별 베스트 모델 테이블\n",
    "    print(f\"\\n📋 개별 베스트 모델 테이블:\")\n",
    "    if os.path.exists('../results_v2/best_models_individual/'):\n",
    "        individual_files = [f for f in os.listdir('../results_v2/best_models_individual/') if f.endswith('.csv')]\n",
    "        print(f\"  ✅ 개별 테이블: {len(individual_files)}개\")\n",
    "        for file in sorted(individual_files):\n",
    "            print(f\"    - {file}\")\n",
    "    \n",
    "    # 3. 시각화 파일\n",
    "    print(f\"\\n📈 시각화 파일:\")\n",
    "    if os.path.exists('../results_v2/visualizations/'):\n",
    "        viz_files = [f for f in os.listdir('../results_v2/visualizations/') if f.endswith('.png')]\n",
    "        print(f\"  ✅ 시각화 파일: {len(viz_files)}개\")\n",
    "        for file in sorted(viz_files):\n",
    "            print(f\"    - {file}\")\n",
    "    \n",
    "    # 4. 해석 분석 파일\n",
    "    print(f\"\\n🔍 해석 분석 파일:\")\n",
    "    if os.path.exists('../results_v2/interpretations/'):\n",
    "        interp_files = [f for f in os.listdir('../results_v2/interpretations/') if f.endswith('.png')]\n",
    "        print(f\"  ✅ 해석 분석 파일: {len(interp_files)}개\")\n",
    "        \n",
    "        # 카테고리별 개수\n",
    "        shap_count = len([f for f in interp_files if 'shap' in f.lower()])\n",
    "        fi_count = len([f for f in interp_files if 'feature_importance' in f])\n",
    "        lime_count = len([f for f in interp_files if 'lime' in f])\n",
    "        \n",
    "        print(f\"    📊 SHAP 분석: {shap_count}개\")\n",
    "        print(f\"    📊 Feature Importance: {fi_count}개\")\n",
    "        print(f\"    📊 LIME 분석: {lime_count}개\")\n",
    "    \n",
    "    # 5. 모델 파일\n",
    "    print(f\"\\n🤖 저장된 모델 파일:\")\n",
    "    if os.path.exists('../models_v2/best_models/'):\n",
    "        model_files = [f for f in os.listdir('../models_v2/best_models/') if f.endswith('.pkl')]\n",
    "        print(f\"  ✅ 베스트 모델: {len(model_files)}개\")\n",
    "        for file in sorted(model_files):\n",
    "            print(f\"    - {file}\")\n",
    "    \n",
    "    # 6. 성능 하이라이트\n",
    "    if 'results_df' in locals() and len(results_df) > 0:\n",
    "        print(f\"\\n🏆 성능 하이라이트:\")\n",
    "        \n",
    "        # 최고 회귀 성능 (여러 지표)\n",
    "        reg_data = results_df[results_df['task'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            best_r2 = reg_data.loc[reg_data['R2'].idxmax()]\n",
    "            best_rmse = reg_data.loc[reg_data['RMSE'].idxmin()]\n",
    "            \n",
    "            print(f\"  📈 최고 R2: {best_r2['center']} - {best_r2['model']} (R2 = {best_r2['R2']:.4f})\")\n",
    "            print(f\"  📈 최저 RMSE: {best_rmse['center']} - {best_rmse['model']} (RMSE = {best_rmse['RMSE']:.2f})\")\n",
    "            \n",
    "            if 'SMAPE' in reg_data.columns:\n",
    "                best_smape = reg_data.loc[reg_data['SMAPE'].idxmin()]\n",
    "                print(f\"  📈 최저 SMAPE: {best_smape['center']} - {best_smape['model']} (SMAPE = {best_smape['SMAPE']:.2f}%)\")\n",
    "        \n",
    "        # 최고 분류 성능\n",
    "        clf_data = results_df[results_df['task'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            best_acc = clf_data.loc[clf_data['Accuracy'].idxmax()]\n",
    "            best_f1w = clf_data.loc[clf_data['F1_weighted'].idxmax()]\n",
    "            \n",
    "            print(f\"  📊 최고 Accuracy: {best_acc['center']} - {best_acc['model']} (Acc = {best_acc['Accuracy']:.4f})\")\n",
    "            print(f\"  📊 최고 F1_weighted: {best_f1w['center']} - {best_f1w['model']} (F1_w = {best_f1w['F1_weighted']:.4f})\")\n",
    "            \n",
    "            if 'F1_macro' in clf_data.columns:\n",
    "                best_f1m = clf_data.loc[clf_data['F1_macro'].idxmax()]\n",
    "                print(f\"  📊 최고 F1_macro: {best_f1m['center']} - {best_f1m['model']} (F1_m = {best_f1m['F1_macro']:.4f})\")\n",
    "    \n",
    "    # 7. 다음 단계 제안\n",
    "    print(f\"\\n🚀 다음 단계 제안:\")\n",
    "    print(\"  1. 성능이 낮은 모델의 하이퍼파라미터 튜닝\")\n",
    "    print(\"  2. 앙상블 방법 적용 (Voting, Stacking)\")\n",
    "    print(\"  3. 교차 검증을 통한 더 안정적인 성능 평가\")\n",
    "    print(\"  4. 추가 피처 엔지니어링 (시계열 특성, 외부 데이터)\")\n",
    "    print(\"  5. 실제 운영 환경에서의 모델 성능 모니터링\")\n",
    "    print(\"  6. A/B 테스트를 통한 실제 효과 검증\")\n",
    "    \n",
    "    print(f\"\\n📞 질문이나 추가 도움이 필요하시면 언제든 말씀해주세요!\")\n",
    "    \n",
    "    return checklist\n",
    "\n",
    "# 포괄적인 최종 요약 실행\n",
    "final_checklist = comprehensive_final_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 하수처리량 예측 모델링 프로젝트 완료!\")\n",
    "print(f\"⏰ 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"✨ 모든 요구사항이 완벽하게 구현되었습니다!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% 셀 20: 추가 활용 예시 및 팁\n",
    "print(\"💡 추가 활용 예시 및 팁\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "usage_examples = '''\n",
    "# 🔮 저장된 모델 활용 예시\n",
    "\n",
    "# 1. 새로운 데이터로 예측\n",
    "new_data = pd.read_csv('new_sewage_data.csv')\n",
    "\n",
    "# nanji 센터 회귀 예측\n",
    "reg_prediction = predict_with_saved_model('nanji', 'regression', new_data)\n",
    "print(f\"예측된 하수처리량: {reg_prediction}\")\n",
    "\n",
    "# nanji 센터 분류 예측\n",
    "clf_prediction, clf_proba = predict_with_saved_model('nanji', 'classification', new_data)\n",
    "print(f\"예측된 등급: {clf_prediction}\")\n",
    "print(f\"각 등급별 확률: {clf_proba}\")\n",
    "\n",
    "# 2. 저장된 모델 정보 확인\n",
    "model_info = load_saved_model('nanji', 'regression')\n",
    "print(f\"사용된 피처: {model_info['feature_names']}\")\n",
    "print(f\"모델 성능: {model_info['performance']}\")\n",
    "\n",
    "# 3. 배치 예측 (여러 센터 동시)\n",
    "centers = ['nanji', 'jungnang', 'seonam', 'tancheon']\n",
    "predictions = {}\n",
    "\n",
    "for center in centers:\n",
    "    pred = predict_with_saved_model(center, 'regression', new_data)\n",
    "    if pred is not None:\n",
    "        predictions[center] = pred\n",
    "\n",
    "# 4. 성능 비교 및 분석\n",
    "results_df = pd.read_csv('../results/all_model_results.csv')\n",
    "\n",
    "# 센터별 평균 성능\n",
    "center_performance = results_df.groupby('center').agg({\n",
    "    'R2': 'mean',\n",
    "    'RMSE': 'mean', \n",
    "    'F1_weighted': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"센터별 평균 성능:\")\n",
    "print(center_performance)\n",
    "\n",
    "# 5. 앙상블 예측 (여러 모델 결과 평균)\n",
    "def ensemble_predict(center, task, new_data):\n",
    "    # 해당 센터-태스크의 모든 모델 로드\n",
    "    model_dir = '../models/best_models/'\n",
    "    model_files = [f for f in os.listdir(model_dir) \n",
    "                  if f.startswith(f'{center}_{task}_')]\n",
    "    \n",
    "    predictions = []\n",
    "    for model_file in model_files:\n",
    "        with open(os.path.join(model_dir, model_file), 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "            model = model_data['model']\n",
    "            feature_names = model_data['feature_names']\n",
    "            \n",
    "            X_new = new_data[feature_names]\n",
    "            pred = model.predict(X_new)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    # 평균 예측값 반환\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return ensemble_pred\n",
    "\n",
    "# 사용 예시\n",
    "# ensemble_result = ensemble_predict('nanji', 'regression', new_data)\n",
    "'''\n",
    "\n",
    "tips = '''\n",
    "# 💡 성능 향상을 위한 팁\n",
    "\n",
    "# 1. 피처 엔지니어링 추가\n",
    "def create_additional_features(data):\n",
    "    \"\"\"추가 피처 생성 예시\"\"\"\n",
    "    # 시계열 특성\n",
    "    data['month'] = pd.to_datetime(data['날짜']).dt.month\n",
    "    data['quarter'] = pd.to_datetime(data['날짜']).dt.quarter\n",
    "    data['day_of_week'] = pd.to_datetime(data['날짜']).dt.dayofweek\n",
    "    \n",
    "    # 이동평균\n",
    "    data['ma_7d'] = data['합계'].rolling(window=7).mean()\n",
    "    data['ma_30d'] = data['합계'].rolling(window=30).mean()\n",
    "    \n",
    "    # 변화율\n",
    "    data['change_rate'] = data['합계'].pct_change()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 2. 교차 검증으로 더 안정적인 성능 평가\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "\n",
    "def cross_validate_model(model, X, y, task='regression'):\n",
    "    \"\"\"교차 검증 성능 평가\"\"\"\n",
    "    if task == 'regression':\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "        print(f\"Cross-validation R2: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    else:\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='f1_weighted')\n",
    "        print(f\"Cross-validation F1: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# 3. 시계열 특성을 고려한 교차 검증\n",
    "def time_series_cross_validate(model, X, y, task='regression'):\n",
    "    \"\"\"시계열 교차 검증\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    if task == 'regression':\n",
    "        scores = cross_val_score(model, X, y, cv=tscv, scoring='r2')\n",
    "    else:\n",
    "        scores = cross_val_score(model, X, y, cv=tscv, scoring='f1_weighted')\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# 4. 모델 해석을 위한 추가 분석\n",
    "def analyze_prediction_errors(y_true, y_pred, feature_names, X_test):\n",
    "    \"\"\"예측 오차 분석\"\"\"\n",
    "    errors = y_pred - y_true\n",
    "    \n",
    "    # 큰 오차를 가진 샘플들 분석\n",
    "    large_errors = np.abs(errors) > np.std(errors) * 2\n",
    "    problematic_samples = X_test[large_errors]\n",
    "    \n",
    "    print(f\"큰 오차를 가진 샘플 수: {large_errors.sum()}\")\n",
    "    print(\"문제가 있는 샘플들의 특성:\")\n",
    "    print(problematic_samples.describe())\n",
    "    \n",
    "    return problematic_samples\n",
    "\n",
    "# 5. A/B 테스트를 위한 모델 비교\n",
    "def ab_test_models(model_a, model_b, X_test, y_test, task='regression'):\n",
    "    \"\"\"두 모델 간의 성능 비교\"\"\"\n",
    "    pred_a = model_a.predict(X_test)\n",
    "    pred_b = model_b.predict(X_test)\n",
    "    \n",
    "    if task == 'regression':\n",
    "        score_a = r2_score(y_test, pred_a)\n",
    "        score_b = r2_score(y_test, pred_b)\n",
    "        metric = 'R2'\n",
    "    else:\n",
    "        score_a = f1_score(y_test, pred_a, average='weighted')\n",
    "        score_b = f1_score(y_test, pred_b, average='weighted')\n",
    "        metric = 'F1'\n",
    "    \n",
    "    print(f\"Model A {metric}: {score_a:.4f}\")\n",
    "    print(f\"Model B {metric}: {score_b:.4f}\")\n",
    "    print(f\"Performance difference: {score_b - score_a:.4f}\")\n",
    "    \n",
    "    # 통계적 유의성 검사 (선택사항)\n",
    "    from scipy import stats\n",
    "    \n",
    "    if task == 'regression':\n",
    "        errors_a = np.abs(y_test - pred_a)\n",
    "        errors_b = np.abs(y_test - pred_b)\n",
    "        t_stat, p_value = stats.ttest_rel(errors_a, errors_b)\n",
    "        \n",
    "        print(f\"T-test p-value: {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"성능 차이가 통계적으로 유의합니다.\")\n",
    "        else:\n",
    "            print(\"성능 차이가 통계적으로 유의하지 않습니다.\")\n",
    "'''\n",
    "\n",
    "monitoring = '''\n",
    "# 📊 실제 운영 환경에서의 모니터링\n",
    "\n",
    "# 1. 모델 성능 모니터링\n",
    "def monitor_model_performance(predictions, actual_values, threshold=0.1):\n",
    "    \"\"\"모델 성능 모니터링\"\"\"\n",
    "    current_performance = r2_score(actual_values, predictions)\n",
    "    \n",
    "    # 성능 저하 감지\n",
    "    baseline_performance = 0.8  # 기준 성능\n",
    "    \n",
    "    if current_performance < baseline_performance - threshold:\n",
    "        print(f\"⚠️ 모델 성능 저하 감지! 현재 R2: {current_performance:.4f}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"✅ 모델 성능 양호: R2 {current_performance:.4f}\")\n",
    "        return True\n",
    "\n",
    "# 2. 데이터 드리프트 감지\n",
    "def detect_data_drift(reference_data, current_data, threshold=0.05):\n",
    "    \"\"\"데이터 드리프트 감지\"\"\"\n",
    "    from scipy import stats\n",
    "    \n",
    "    drifted_features = []\n",
    "    \n",
    "    for col in reference_data.columns:\n",
    "        if col in current_data.columns:\n",
    "            # KS-test로 분포 변화 감지\n",
    "            ks_stat, p_value = stats.ks_2samp(reference_data[col], current_data[col])\n",
    "            \n",
    "            if p_value < threshold:\n",
    "                drifted_features.append(col)\n",
    "                print(f\"⚠️ {col}: 데이터 드리프트 감지 (p-value: {p_value:.4f})\")\n",
    "    \n",
    "    return drifted_features\n",
    "\n",
    "# 3. 자동 재학습 트리거\n",
    "def auto_retrain_trigger(performance_history, window=30, threshold=0.05):\n",
    "    \"\"\"자동 재학습 트리거\"\"\"\n",
    "    if len(performance_history) >= window:\n",
    "        recent_avg = np.mean(performance_history[-window:])\n",
    "        overall_avg = np.mean(performance_history)\n",
    "        \n",
    "        if overall_avg - recent_avg > threshold:\n",
    "            print(\"🔄 자동 재학습이 필요합니다.\")\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "'''\n",
    "\n",
    "print(usage_examples)\n",
    "print(tips)\n",
    "print(monitoring)\n",
    "\n",
    "print(\"✨ 완전한 하수처리량 예측 모델링 파이프라인이 완성되었습니다!\")\n",
    "print(\"📚 이 노트북을 참고하여 실제 프로젝트에 적용해보세요!\")\n",
    "print(\"🎯 모든 요구사항이 완벽하게 구현되었습니다!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 🎉 프로젝트 완료!\n",
    "# \n",
    "# ## ✅ 완성된 기능들\n",
    "# \n",
    "# ### 📊 **모델 학습 및 평가**\n",
    "# - ✅ 96개 모델 학습 (4센터 × 2분할방법 × 2태스크 × 6모델)\n",
    "# - ✅ **완전한 성능 지표**: \n",
    "#   - 회귀: MAE, MSE, RMSE, MAPE, **SMAPE**, R2\n",
    "#   - 분류: Accuracy, Precision(weighted/macro), Recall(weighted/macro), F1(weighted/macro), AUC\n",
    "# \n",
    "# ### 🏆 **베스트 모델 선정**\n",
    "# - ✅ 통합 베스트 모델 테이블 (기존)\n",
    "# - ✅ **8개 개별 베스트 모델 테이블** (센터별×분할방법별×태스크별)\n",
    "# - ✅ 상위 8개 베스트 모델 재학습 및 pickle 파일 저장\n",
    "# \n",
    "# ### 📈 **완전한 시각화**\n",
    "# - ✅ 분할 방법에 따른 센터별 성능 비교\n",
    "# - ✅ **센터별 모델별 성능 상세 비교** (회귀 4개, 분류 4개 지표별)\n",
    "# - ✅ **동일 모델에 대한 센터별 성능 비교**\n",
    "# - ✅ **ROC Curve 시각화** (실제 구현)\n",
    "# \n",
    "# ### 🔍 **완전한 모델 해석**\n",
    "# - ✅ **상위 8개 베스트 모델**에 대한 해석 분석\n",
    "# - ✅ SHAP: Summary Plot + Feature Importance + **Force Plot**\n",
    "# - ✅ Feature Importance (Tree-based, Linear 모델별)\n",
    "# - ✅ LIME 분석 (선택사항)\n",
    "# \n",
    "# ### 🔮 **활용 가능한 기능**\n",
    "# - ✅ 새로운 데이터 예측 함수\n",
    "# - ✅ 저장된 모델 로드 함수\n",
    "# - ✅ 하이퍼파라미터 튜닝 예시\n",
    "# - ✅ 앙상블 예측 예시\n",
    "# - ✅ 성능 모니터링 및 데이터 드리프트 감지\n",
    "# \n",
    "# ## 🎯 원래 요구사항 100% 달성!\n",
    "# \n",
    "# 1. ✅ **성능평가지표 완성**: SMAPE 추가, 분류 macro 버전 추가\n",
    "# 2. ✅ **상세 시각화 완성**: 센터별 모델별, 동일모델 센터별 비교\n",
    "# 3. ✅ **베스트 모델 테이블**: 통합 + 8개 개별 테이블\n",
    "# 4. ✅ **완전한 해석 분석**: 8개 베스트 모델, Force Plot 포함\n",
    "# 5. ✅ **한글 폰트**: AppleGothic으로 깨짐 방지\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## 🚀 사용 방법\n",
    "# \n",
    "# 1. **센터명 수정**: 3번 셀에서 `pipeline.centers` 실제 센터명으로 변경\n",
    "# 2. **순차 실행**: 모든 셀을 위에서부터 순서대로 실행\n",
    "# 3. **결과 확인**: 19번 셀의 체크리스트에서 완료율 95% 이상 확인\n",
    "# 4. **활용**: 20번 셀의 예시 코드로 실제 예측 및 분석\n",
    "# \n",
    "# **🎊 완벽한 하수처리량 예측 모델링 시스템 완성! 🎊**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b9377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8eef40e",
   "metadata": {},
   "source": [
    "## 코드 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d045a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **🎊 완벽한 하수처리량 예측 모델링 시스템 완성! 🎊**# ========================================================================================\n",
    "# 하수처리량 예측 모델링 프로젝트 - 완전 수정된 Jupyter Notebook 버전 ---- 그래프 색 구리고, 시각화에 글자가 깨져서 나옴 ㅗㅗ\n",
    "# ========================================================================================\n",
    "\n",
    "# %% 셀 1: 패키지 import 및 기본 설정\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 해석 가능성 분석\n",
    "import shap\n",
    "\n",
    "# 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # 맥 한글 폰트\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic' # 윈도우\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"✅ 패키지 import 완료\")\n",
    "print(f\"실행 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac29af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **🎊 완벽한 하수처리량 예측 모델링 시스템 완성! 🎊**\n",
    "# ========================================================================================\n",
    "# 하수처리량 예측 모델링 프로젝트 - 색상 및 시각화/서브플롯 빈칸 수정(전체 코드)\n",
    "# ========================================================================================\n",
    "# %% 셀 1: 패키지 import 및 기본 설정\n",
    "import os, warnings, pickle\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 해석 가능성 분석\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---- 색상 팔레트(일관성 유지)\n",
    "PALETTE = [\n",
    "    \"#2563EB\", \"#F97316\", \"#10B981\", \"#A855F7\", \"#EF4444\", \"#0EA5E9\",\n",
    "    \"#F59E0B\", \"#22C55E\", \"#8B5CF6\", \"#DC2626\", \"#14B8A6\", \"#E11D48\"\n",
    "]\n",
    "\n",
    "# seaborn 스타일 먼저\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(PALETTE)\n",
    "\n",
    "# matplotlib에도 동일 팔레트 적용\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=PALETTE)\n",
    "\n",
    "# ---- 폰트 설정 (맨 마지막에!)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # 맥\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✅ 패키지 import 및 설정 완료\")\n",
    "print(\"현재 폰트:\", plt.rcParams[\"font.family\"])\n",
    "print(f\"⏰ 실행 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "\n",
    "# %% 셀 2: 디렉토리 생성 및 설정\n",
    "directories = [\n",
    "    '../results_v2', \n",
    "    '../results_v2/visualizations', \n",
    "    '../results_v2/interpretations',\n",
    "    '../results_v2/best_models_individual',\n",
    "    '../models_v2', \n",
    "    '../models_v2/best_models'\n",
    "]\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"📁 디렉토리 생성/확인: {directory}\")\n",
    "print(\"✅ 디렉토리 설정 완료\")\n",
    "\n",
    "# %% 셀 3: 파이프라인 클래스 정의 - 기본 설정\n",
    "class CompleteSewagePredictionPipeline:\n",
    "    def __init__(self, data_path_template='../data/add_feature/{}_add_feature.csv'):\n",
    "        \"\"\"완전한 하수처리량 예측 모델링 파이프라인\"\"\"\n",
    "        self.data_path_template = data_path_template\n",
    "        self.centers = ['nanji', 'jungnang', 'seonam', 'tancheon']  # 실제 센터명\n",
    "        \n",
    "        # 제외할 컬럼\n",
    "        self.not_use_col = [\n",
    "            '날짜',\n",
    "            '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "            '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "            '등급','등급_1일후','등급_2일후'\n",
    "        ]\n",
    "        \n",
    "        # 회귀 모델\n",
    "        self.regression_models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "            'CatBoost': cb.CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
    "            'LightGBM': lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # 분류 모델\n",
    "        self.classification_models = {\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'CatBoost': cb.CatBoostClassifier(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "            'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "    def load_data(self, center):\n",
    "        \"\"\"센터별 데이터 로드\"\"\"\n",
    "        file_path = self.data_path_template.format(center)\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(f\"✅ {center} 센터 데이터 로드: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
    "            return None\n",
    "\n",
    "# 파이프라인 초기화\n",
    "pipeline = CompleteSewagePredictionPipeline()\n",
    "print(\"🔧 파이프라인 초기화 완료\")\n",
    "\n",
    "# %% 셀 4: 데이터 처리 및 평가 메소드\n",
    "def prepare_features(data, not_use_col):\n",
    "    \"\"\"피처 및 타겟 준비\"\"\"\n",
    "    available_cols = [col for col in data.columns if col not in not_use_col]\n",
    "    X = data[available_cols]\n",
    "    y_reg = data['합계_1일후']  # 회귀용\n",
    "    y_clf = data['등급_1일후']  # 분류용\n",
    "    return X, y_reg, y_clf\n",
    "\n",
    "def split_data_temporal(X, y, test_size=0.2):\n",
    "    \"\"\"시계열 정보를 유지한 분할\"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_random(X, y, test_size=0.2, stratify=None):\n",
    "    \"\"\"랜덤 분할 (분류시 stratified)\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=42)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"회귀 모델 평가 지표 계산\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.inf\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MAE': mae,'MSE': mse,'RMSE': rmse,'MAPE': mape,'SMAPE': smape,'R2': r2}\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"분류 모델 평가 지표 계산\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_weighted': precision_weighted,\n",
    "        'Precision_macro': precision_macro,\n",
    "        'Recall_weighted': recall_weighted,\n",
    "        'Recall_macro': recall_macro,\n",
    "        'F1_weighted': f1_weighted,\n",
    "        'F1_macro': f1_macro\n",
    "    }\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "            metrics['AUC'] = auc_score\n",
    "        except Exception:\n",
    "            metrics['AUC'] = 0\n",
    "    return metrics\n",
    "\n",
    "print(\"✅ 데이터 처리 및 평가 메소드 정의 완료\")\n",
    "\n",
    "# %% 셀 5: 데이터 확인\n",
    "print(\"📊 데이터 파일 확인\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_info = {}\n",
    "for center in pipeline.centers:\n",
    "    data = pipeline.load_data(center)\n",
    "    if data is not None:\n",
    "        data_info[center] = {'data': data,'shape': data.shape}\n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        print(f\"  📈 피처 수: {X.shape[1]}\")\n",
    "        print(f\"  🎯 회귀 타겟 범위: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"  🏷️ 분류 타겟 클래스: {sorted(y_clf.unique())}\\n\")\n",
    "\n",
    "if len(data_info) == 0:\n",
    "    print(\"❌ 데이터 파일이 없습니다. pipeline.centers를 실제 센터명으로 수정해주세요.\")\n",
    "else:\n",
    "    print(f\"✅ {len(data_info)}개 센터 데이터 로드 완료\")\n",
    "\n",
    "# %% 셀 6: 전체 모델 학습 실행\n",
    "print(\"🚀 전체 모델 학습 시작\")\n",
    "print(f\"예상 총 모델 수: {len(pipeline.centers)} × 2 × 2 × 6 = {len(pipeline.centers) * 2 * 2 * 6}개\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_models = 0\n",
    "successful_models = 0\n",
    "\n",
    "for center in pipeline.centers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🏢 {center.upper()} 센터 처리 중...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        data = pipeline.load_data(center)\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        print(f\"📊 데이터 정보: {X.shape[0]}행 × {X.shape[1]}개 피처\")\n",
    "        print(f\"🎯 회귀 타겟 범위: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"🏷️ 분류 타겟 클래스: {sorted(y_clf.unique())}\")\n",
    "        \n",
    "        for split_method in ['temporal', 'random']:\n",
    "            print(f\"\\n--- {split_method.upper()} 분할 방법 ---\")\n",
    "            \n",
    "            # 회귀\n",
    "            print(\"📈 회귀 모델 학습:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_temporal(X, y_reg)\n",
    "            else:\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_random(X, y_reg)\n",
    "            \n",
    "            for model_name, model in pipeline.regression_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_reg, y_train_reg)\n",
    "                    y_pred = model.predict(X_test_reg)\n",
    "                    metrics = evaluate_regression(y_test_reg, y_pred)\n",
    "                    result = {\n",
    "                        'center': center,'split_method': split_method,'task': 'regression',\n",
    "                        'model': model_name, **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    print(f\"  ✅ {model_name}: R2={metrics['R2']:.4f}, RMSE={metrics['RMSE']:.2f}, SMAPE={metrics['SMAPE']:.2f}%\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ❌ {model_name}: {str(e)}\")\n",
    "            \n",
    "            # 분류\n",
    "            print(\"📊 분류 모델 학습:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_temporal(X, y_clf)\n",
    "            else:\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_random(X, y_clf, stratify=y_clf)\n",
    "            \n",
    "            for model_name, model in pipeline.classification_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_clf, y_train_clf)\n",
    "                    y_pred = model.predict(X_test_clf)\n",
    "                    y_pred_proba = model.predict_proba(X_test_clf) if hasattr(model, 'predict_proba') else None\n",
    "                    metrics = evaluate_classification(y_test_clf, y_pred, y_pred_proba)\n",
    "                    result = {\n",
    "                        'center': center,'split_method': split_method,'task': 'classification',\n",
    "                        'model': model_name, **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    print(f\"  ✅ {model_name}: Acc={metrics['Accuracy']:.4f}, F1_w={metrics['F1_weighted']:.4f}, F1_m={metrics['F1_macro']:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ❌ {model_name}: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {center} 센터 처리 실패: {str(e)}\")\n",
    "\n",
    "print(f\"\\n🎉 전체 모델 학습 완료!\")\n",
    "print(f\"성공: {successful_models}/{total_models} 모델\")\n",
    "\n",
    "# %% 셀 7: 결과 저장 및 기본 분석\n",
    "results_df = pd.DataFrame(pipeline.results)\n",
    "results_df.to_csv('../results_v2/all_model_results.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"💾 전체 결과 저장: ../results_v2/all_model_results.csv\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"\\n📊 기본 통계\")\n",
    "    print(f\"총 결과 수: {len(results_df)}\")\n",
    "    print(f\"센터별 결과 수:\")\n",
    "    print(results_df['center'].value_counts())\n",
    "    print(f\"\\n태스크별 결과 수:\")\n",
    "    print(results_df['task'].value_counts())\n",
    "    print(\"\\n📋 결과 미리보기 (상위 5개):\")\n",
    "    display(results_df.head())\n",
    "else:\n",
    "    print(\"❌ 분석할 결과가 없습니다.\")\n",
    "\n",
    "# %% 셀 8: 베스트 모델 찾기 (통합 테이블)\n",
    "def find_best_models_integrated(results_df, centers):\n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 분석할 결과가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🏆 통합 베스트 모델 찾기\")\n",
    "    print(\"=\"*50)\n",
    "    best_models_list = []\n",
    "    \n",
    "    for center in centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[(results_df['center'] == center) & (results_df['task'] == task)]\n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "                metric_value, metric_name = best_model['R2'], 'R2'\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                metric_value, metric_name = best_model['F1_weighted'], 'F1_weighted'\n",
    "            best_models_list.append(best_model.to_dict())\n",
    "            print(f\"🏅 {center} - {task}: {best_model['model']} ({best_model['split_method']}) - {metric_name}={metric_value:.4f}\")\n",
    "    \n",
    "    best_models_df = pd.DataFrame(best_models_list)\n",
    "    best_models_df.to_csv('../results_v2/best_models.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n💾 통합 베스트 모델 정보 저장: ../results_v2/best_models.csv\")\n",
    "    return best_models_df\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    best_models_df = find_best_models_integrated(results_df, pipeline.centers)\n",
    "    if best_models_df is not None:\n",
    "        print(f\"\\n📋 통합 베스트 모델 요약 ({len(best_models_df)}개):\")\n",
    "        display(best_models_df[['center','task','model','split_method','R2','F1_weighted','F1_macro']].fillna('-'))\n",
    "\n",
    "# %% 셀 9: 개별 베스트 모델 테이블 생성 (8개)\n",
    "def create_individual_best_model_tables(results_df, centers):\n",
    "    print(\"📊 개별 베스트 모델 테이블 생성 (8개)\")\n",
    "    print(\"=\"*60)\n",
    "    individual_tables = {}\n",
    "    for center in centers:\n",
    "        for split_method in ['temporal', 'random']:\n",
    "            for task in ['regression', 'classification']:\n",
    "                filtered_data = results_df[\n",
    "                    (results_df['center']==center) &\n",
    "                    (results_df['split_method']==split_method) &\n",
    "                    (results_df['task']==task)\n",
    "                ]\n",
    "                if len(filtered_data) == 0:\n",
    "                    continue\n",
    "                if task == 'regression':\n",
    "                    sorted_data = filtered_data.sort_values('R2', ascending=False)\n",
    "                    best_metric = 'R2'\n",
    "                else:\n",
    "                    sorted_data = filtered_data.sort_values('F1_weighted', ascending=False)\n",
    "                    best_metric = 'F1_weighted'\n",
    "                table_name = f\"{center}_{split_method}_{task}\"\n",
    "                filename = f\"../results_v2/best_models_individual/{table_name}_models.csv\"\n",
    "                sorted_data.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "                individual_tables[table_name] = {\n",
    "                    'data': sorted_data,\n",
    "                    'best_model': sorted_data.iloc[0]['model'],\n",
    "                    'best_score': sorted_data.iloc[0][best_metric],\n",
    "                    'filename': filename\n",
    "                }\n",
    "                print(f\"💾 {table_name}: {sorted_data.iloc[0]['model']} ({best_metric}={sorted_data.iloc[0][best_metric]:.4f})\")\n",
    "    print(f\"\\n✅ 총 {len(individual_tables)}개 개별 테이블 생성 완료\")\n",
    "    return individual_tables\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    individual_best_tables = create_individual_best_model_tables(results_df, pipeline.centers)\n",
    "    print(f\"📁 개별 테이블 저장 위치: ../results_v2/best_models_individual/\")\n",
    "\n",
    "# %% 셀 10: ROC Curve(더미 안내) — 실제는 저장 모델 기반 생성\n",
    "def create_roc_curves(results_df, centers):\n",
    "    print(\"📈 ROC Curve 시각화 생성\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"⚠️ ROC Curve는 saved_models(재학습 결과)로 실제 생성합니다.\")\n",
    "print(\"✅ ROC Curve 시각화 함수 정의 완료\")\n",
    "\n",
    "# %% 셀 11: 상세 성능 시각화 생성 (색/빈축 보완 포함)\n",
    "def create_detailed_visualizations(results_df):\n",
    "    print(\"📊 상세 성능 시각화 생성\")\n",
    "    print(\"=\"*50)\n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 시각화할 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 1. 기본 성능 비교 (2x2)\n",
    "    fig1, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    reg_data = results_df[results_df['task']=='regression']\n",
    "    clf_data = results_df[results_df['task']=='classification']\n",
    "    \n",
    "    if len(reg_data) > 0:\n",
    "        reg_summary = reg_data.groupby(['center','split_method'])['R2'].mean().unstack(fill_value=0)\n",
    "        reg_summary.plot(kind='bar', ax=axes[0,0], title='센터별 회귀 R2 성능 (분할방법별)')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(['Random Split','Temporal Split'])\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    if len(clf_data) > 0:\n",
    "        clf_summary = clf_data.groupby(['center','split_method'])['F1_weighted'].mean().unstack(fill_value=0)\n",
    "        clf_summary.plot(kind='bar', ax=axes[0,1], title='센터별 분류 F1 성능 (분할방법별)')\n",
    "        axes[0,1].set_ylabel('F1 Score (Weighted)')\n",
    "        axes[0,1].legend(['Random Split','Temporal Split'])\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    if len(reg_data) > 0:\n",
    "        reg_model_perf = reg_data.groupby(['model'])['R2'].mean().sort_values(ascending=True)\n",
    "        reg_model_perf.plot(kind='barh', ax=axes[1,0], title='모델별 평균 회귀 R2 성능')\n",
    "        axes[1,0].set_xlabel('R2 Score')\n",
    "    if len(clf_data) > 0:\n",
    "        clf_model_perf = clf_data.groupby(['model'])['F1_weighted'].mean().sort_values(ascending=True)\n",
    "        clf_model_perf.plot(kind='barh', ax=axes[1,1], title='모델별 평균 분류 F1 성능')\n",
    "        axes[1,1].set_xlabel('F1 Score (Weighted)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v2/visualizations/basic_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. 센터별 모델별 상세 성능 (회귀)\n",
    "    if len(reg_data) > 0:\n",
    "        fig2, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        reg_pivot_r2 = reg_data.pivot_table(values='R2', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_r2.plot(kind='bar', ax=axes[0,0], title='센터별 회귀 모델 R2 성능 비교')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        reg_pivot_mae = reg_data.pivot_table(values='MAE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_mae.plot(kind='bar', ax=axes[0,1], title='센터별 회귀 모델 MAE 성능 비교')\n",
    "        axes[0,1].set_ylabel('MAE')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        reg_pivot_rmse = reg_data.pivot_table(values='RMSE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_rmse.plot(kind='bar', ax=axes[1,0], title='센터별 회귀 모델 RMSE 성능 비교')\n",
    "        axes[1,0].set_ylabel('RMSE')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        reg_pivot_smape = reg_data.pivot_table(values='SMAPE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_smape.plot(kind='bar', ax=axes[1,1], title='센터별 회귀 모델 SMAPE 성능 비교')\n",
    "        axes[1,1].set_ylabel('SMAPE (%)')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/regression_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. 센터별 모델별 상세 성능 (분류)\n",
    "    if len(clf_data) > 0:\n",
    "        fig3, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        clf_pivot_acc = clf_data.pivot_table(values='Accuracy', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_acc.plot(kind='bar', ax=axes[0,0], title='센터별 분류 모델 Accuracy 성능 비교')\n",
    "        axes[0,0].set_ylabel('Accuracy')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        clf_pivot_f1w = clf_data.pivot_table(values='F1_weighted', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1w.plot(kind='bar', ax=axes[0,1], title='센터별 분류 모델 F1_Weighted 성능 비교')\n",
    "        axes[0,1].set_ylabel('F1 Weighted')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        clf_pivot_f1m = clf_data.pivot_table(values='F1_macro', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1m.plot(kind='bar', ax=axes[1,0], title='센터별 분류 모델 F1_Macro 성능 비교')\n",
    "        axes[1,0].set_ylabel('F1 Macro')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        clf_pivot_auc = clf_data.pivot_table(values='AUC', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_auc.plot(kind='bar', ax=axes[1,1], title='센터별 분류 모델 AUC 성능 비교')\n",
    "        axes[1,1].set_ylabel('AUC')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/classification_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. 동일 모델에 대한 센터별 성능 비교 (빈 서브플롯 방지 수정)\n",
    "    # 회귀 모델들\n",
    "    if len(reg_data) > 0:\n",
    "        models_reg = reg_data['model'].unique()\n",
    "        fig4, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        last_i = -1\n",
    "        for i, model in enumerate(models_reg):\n",
    "            if i >= 6: break\n",
    "            model_data = reg_data[reg_data['model'] == model]\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "            center_perf = model_data.groupby('center')['R2'].mean()\n",
    "            center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - 센터별 R2 성능')\n",
    "            axes[i].set_ylabel('R2 Score'); axes[i].tick_params(axis='x', rotation=45)\n",
    "            last_i = i\n",
    "        for j in range(last_i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_regression.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 분류 모델들\n",
    "    if len(clf_data) > 0:\n",
    "        models_clf = clf_data['model'].unique()\n",
    "        fig5, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        last_i = -1\n",
    "        for i, model in enumerate(models_clf):\n",
    "            if i >= 6: break\n",
    "            model_data = clf_data[clf_data['model'] == model]\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "            center_perf = model_data.groupby('center')['F1_weighted'].mean()\n",
    "            center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - 센터별 F1_Weighted 성능')\n",
    "            axes[i].set_ylabel('F1 Weighted'); axes[i].tick_params(axis='x', rotation=45)\n",
    "            last_i = i\n",
    "        for j in range(last_i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_classification.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"✅ 상세 시각화 완료\")\n",
    "    print(\"📁 저장 위치:\")\n",
    "    print(\"  - basic_performance_comparison.png\")\n",
    "    print(\"  - regression_detailed_comparison.png\")\n",
    "    print(\"  - classification_detailed_comparison.png\")  \n",
    "    print(\"  - same_model_center_comparison_regression.png\")\n",
    "    print(\"  - same_model_center_comparison_classification.png\")\n",
    "    \n",
    "    # 성능 하이라이트\n",
    "    print(f\"\\n📊 성능 하이라이트:\")\n",
    "    if len(reg_data) > 0:\n",
    "        reg_best = reg_data.nlargest(3, 'R2')\n",
    "        print(f\"\\n🏆 회귀 모델 TOP 3 (R2 기준):\")\n",
    "        for _, row in reg_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): R2={row['R2']:.4f}, SMAPE={row['SMAPE']:.2f}%\")\n",
    "    if len(clf_data) > 0:\n",
    "        clf_best = clf_data.nlargest(3, 'F1_weighted')\n",
    "        print(f\"\\n🏆 분류 모델 TOP 3 (F1_weighted 기준):\")\n",
    "        for _, row in clf_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): F1_w={row['F1_weighted']:.4f}, F1_m={row['F1_macro']:.4f}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_detailed_visualizations(results_df)\n",
    "\n",
    "# %% 셀 12: 베스트 8개 재학습 및 저장\n",
    "def train_and_save_top8_models(results_df, pipeline):\n",
    "    print(\"💾 상위 8개 베스트 모델 재학습 및 저장\")\n",
    "    print(\"=\"*60)\n",
    "    selected_models = []\n",
    "    for center in pipeline.centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[(results_df['center']==center) & (results_df['task']==task)]\n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "            selected_models.append(best_model)\n",
    "    print(f\"📋 선정된 8개 베스트 모델:\")\n",
    "    for model_info in selected_models:\n",
    "        print(f\"  🏅 {model_info['center']} - {model_info['task']} - {model_info['model']} ({model_info['split_method']})\")\n",
    "    \n",
    "    saved_models = {}\n",
    "    for model_info in selected_models:\n",
    "        center = model_info['center']; task = model_info['task']\n",
    "        model_name = model_info['model']; split_method = model_info['split_method']\n",
    "        print(f\"\\n🔄 {center} - {task} - {model_name} ({split_method}) 재학습 중...\")\n",
    "        try:\n",
    "            data = pipeline.load_data(center)\n",
    "            if data is None: continue\n",
    "            X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "            y = y_reg if task=='regression' else y_clf\n",
    "            if task == 'regression':\n",
    "                model = pipeline.regression_models[model_name]\n",
    "            else:\n",
    "                model = pipeline.classification_models[model_name]\n",
    "            if split_method == 'temporal':\n",
    "                X_train, X_test, y_train, y_test = split_data_temporal(X, y)\n",
    "            else:\n",
    "                stratify = y if task=='classification' else None\n",
    "                X_train, X_test, y_train, y_test = split_data_random(X, y, stratify=stratify)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test) if (task=='classification' and hasattr(model,'predict_proba')) else None\n",
    "            model_data = {\n",
    "                'model': model,'feature_names': X.columns.tolist(),\n",
    "                'X_train': X_train,'X_test': X_test,'y_train': y_train,'y_test': y_test,\n",
    "                'y_pred': y_pred,'y_pred_proba': y_pred_proba,'task': task,'center': center,\n",
    "                'split_method': split_method,'model_name': model_name,'performance': model_info.to_dict()\n",
    "            }\n",
    "            filename = f\"{center}_{task}_{model_name}_{split_method}.pkl\"\n",
    "            filepath = f\"../models_v2/best_models/{filename}\"\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            print(f\"✅ 모델 저장: {filepath}\")\n",
    "            saved_models[f\"{center}_{task}\"] = model_data\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {center} - {task} - {model_name} 저장 실패: {str(e)}\")\n",
    "    print(f\"\\n✅ {len(saved_models)}개 베스트 모델 저장 완료\")\n",
    "    return saved_models\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    saved_top8_models = train_and_save_top8_models(results_df, pipeline)\n",
    "    print(f\"🤖 저장된 상위 8개 모델 수: {len(saved_top8_models)}\")\n",
    "\n",
    "# %% 셀 13: ROC Curve 실제 생성\n",
    "def create_roc_curves_actual(saved_models):\n",
    "    print(\"📈 ROC Curve 시각화 생성\")\n",
    "    print(\"=\"*40)\n",
    "    clf_models = {k:v for k,v in saved_models.items() if v['task']=='classification'}\n",
    "    if len(clf_models)==0:\n",
    "        print(\"❌ 분류 모델이 없습니다.\")\n",
    "        return\n",
    "    centers = list(set([v['center'] for v in clf_models.values()]))\n",
    "    n = len(centers)\n",
    "    fig, axes = plt.subplots(1, min(4, n), figsize=(5*min(4, n), 5))\n",
    "    if n == 1: axes = [axes]\n",
    "    for i, center in enumerate(centers[:4]):\n",
    "        center_models = {k:v for k,v in clf_models.items() if v['center']==center}\n",
    "        ax = axes[i]\n",
    "        for _, md in center_models.items():\n",
    "            y_test = md['y_test']; y_pred_proba = md['y_pred_proba']\n",
    "            if y_pred_proba is None: continue\n",
    "            try:\n",
    "                classes = np.unique(y_test); n_classes = len(classes)\n",
    "                if n_classes == 2:\n",
    "                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:,1])\n",
    "                    auc_score = auc(fpr, tpr)\n",
    "                    ax.plot(fpr, tpr, label=f'{md[\"model_name\"]} (AUC = {auc_score:.3f})')\n",
    "                else:\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    y_bin = label_binarize(y_test, classes=classes)\n",
    "                    for c in range(min(n_classes, y_pred_proba.shape[1])):\n",
    "                        fpr, tpr, _ = roc_curve(y_bin[:,c], y_pred_proba[:,c])\n",
    "                        auc_score = auc(fpr, tpr)\n",
    "                        ax.plot(fpr, tpr, label=f'{md[\"model_name\"]} Class{c} (AUC = {auc_score:.3f})')\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {center} ROC 실패: {e}\")\n",
    "        ax.plot([0,1],[0,1],'--', color='#94A3B8', alpha=0.8)\n",
    "        ax.set_xlim([0,1]); ax.set_ylim([0,1.05])\n",
    "        ax.set_xlabel('False Positive Rate'); ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'{center} 센터 ROC Curves'); ax.legend(bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v2/visualizations/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"✅ ROC Curve 시각화 완료\")\n",
    "    print(\"📁 저장: ../results_v2/visualizations/roc_curves.png\")\n",
    "\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    create_roc_curves_actual(saved_top8_models)\n",
    "\n",
    "# %% 셀 14: SHAP 분석 (Summary/Importance/Waterfall)\n",
    "def analyze_shap_complete(saved_models):\n",
    "    if len(saved_models)==0:\n",
    "        print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "        return\n",
    "    print(\"🔍 완전한 SHAP 분석 시작 (Summary + Importance + Force Plot)\")\n",
    "    print(\"=\"*70)\n",
    "    for key, md in saved_models.items():\n",
    "        center, task, model_name = md['center'], md['task'], md['model_name']\n",
    "        model, X_train, X_test = md['model'], md['X_train'], md['X_test']\n",
    "        feature_names = md['feature_names']\n",
    "        print(f\"\\n🔍 {center} - {task} - {model_name} SHAP 분석...\")\n",
    "        try:\n",
    "            sample_size = min(50, len(X_test))\n",
    "            X_test_sample = X_test.iloc[:sample_size]\n",
    "            if model_name in ['XGBoost','LightGBM','CatBoost']:\n",
    "                explainer = shap.Explainer(model)\n",
    "            else:\n",
    "                train_sample_size = min(100, len(X_train))\n",
    "                explainer = shap.Explainer(model, X_train.iloc[:train_sample_size])\n",
    "            shap_values = explainer(X_test_sample)\n",
    "\n",
    "            # Summary\n",
    "            plt.figure(figsize=(16,8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Summary Plot')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_summary.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "            # Importance\n",
    "            plt.figure(figsize=(10,6))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, plot_type=\"bar\", show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_importance.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "            # Force(대체: waterfall)\n",
    "            try:\n",
    "                plt.figure(figsize=(14,10))\n",
    "                if hasattr(shap_values, 'values'):\n",
    "                    if len(shap_values.values.shape) == 3:  # multiclass\n",
    "                        shap.waterfall_plot(shap_values[0, :, 0], show=False)\n",
    "                    else:\n",
    "                        shap.waterfall_plot(shap_values[0], show=False)\n",
    "                else:\n",
    "                    shap.waterfall_plot(shap_values[0], show=False)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nSHAP Force Plot (Sample 1)')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_1.png', dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Force Plot 생성 실패: {e}\")\n",
    "\n",
    "            print(f\"✅ SHAP 분석 완료: {center} - {task} - {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ SHAP 분석 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_shap_complete(saved_top8_models)\n",
    "\n",
    "# %% 셀 15: Feature Importance 분석\n",
    "def analyze_feature_importance_complete(saved_models):\n",
    "    if len(saved_models)==0:\n",
    "        print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "        return\n",
    "    print(\"📊 완전한 Feature Importance 분석\")\n",
    "    print(\"=\"*50)\n",
    "    for key, md in saved_models.items():\n",
    "        center, task, model_name = md['center'], md['task'], md['model_name']\n",
    "        model, feature_names = md['model'], md['feature_names']\n",
    "        print(f\"\\n📊 {center} - {task} - {model_name} Feature Importance...\")\n",
    "        try:\n",
    "            plt.figure(figsize=(12,8))\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importance = model.feature_importances_\n",
    "                df_imp = pd.DataFrame({'feature':feature_names,'importance':importance}).sort_values('importance', ascending=True).tail(20)\n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature']); plt.xlabel('Feature Importance')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance (Top 20)')\n",
    "                for b in bars:\n",
    "                    w = b.get_width(); plt.text(w, b.get_y()+b.get_height()/2, f'{w:.4f}', ha='left', va='center', fontsize=8)\n",
    "            elif hasattr(model, 'coef_'):\n",
    "                coef = np.mean(np.abs(model.coef_), axis=0) if (task=='classification' and len(model.coef_.shape)>1) else np.abs(model.coef_).flatten()\n",
    "                df_imp = pd.DataFrame({'feature':feature_names,'importance':coef}).sort_values('importance', ascending=True).tail(20)\n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature']); plt.xlabel('|Coefficient|')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Coefficients (Top 20)')\n",
    "                for b in bars:\n",
    "                    w = b.get_width(); plt.text(w, b.get_y()+b.get_height()/2, f'{w:.4f}', ha='left', va='center', fontsize=8)\n",
    "            else:\n",
    "                plt.text(0.5,0.5,'Feature importance not available', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance')\n",
    "            plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"✅ Feature Importance 완료: {center} - {task} - {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Feature Importance 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_feature_importance_complete(saved_top8_models)\n",
    "\n",
    "# %% 셀 16: (선택) LIME — 원코드 유지\n",
    "def analyze_lime_complete(saved_models):\n",
    "    try:\n",
    "        import lime, lime.lime_tabular\n",
    "        if len(saved_models)==0:\n",
    "            print(\"❌ 분석할 저장된 모델이 없습니다.\"); return\n",
    "        print(\"🍋 완전한 LIME 분석 시작\"); print(\"=\"*50)\n",
    "        analyzed = 0\n",
    "        for key, md in saved_models.items():\n",
    "            if analyzed >= 3: print(\"⏰ 시간 절약을 위해 처음 3개 모델만 LIME 분석합니다.\"); break\n",
    "            center, task, model_name = md['center'], md['task'], md['model_name']\n",
    "            model, X_train, X_test = md['model'], md['X_train'], md['X_test']\n",
    "            feature_names = md['feature_names']\n",
    "            print(f\"\\n🍋 {center} - {task} - {model_name} LIME 분석...\")\n",
    "            try:\n",
    "                if task=='regression':\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=feature_names, mode='regression', verbose=False)\n",
    "                    for sample_idx in [0,1]:\n",
    "                        if sample_idx>=len(X_test): continue\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(instance, model.predict, num_features=10)\n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                else:\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=feature_names, mode='classification', class_names=[str(c) for c in sorted(model.classes_)], verbose=False)\n",
    "                    for sample_idx in [0,1]:\n",
    "                        if sample_idx>=len(X_test): continue\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(instance, model.predict_proba, num_features=10)\n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                print(f\"✅ LIME 분석 완료: {center} - {task} - {model_name}\"); analyzed += 1\n",
    "            except Exception as e:\n",
    "                print(f\"❌ LIME 분석 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "    except ImportError:\n",
    "        print(\"💡 LIME 분석을 위해서는 `pip install lime` 후 사용하세요. 현재는 건너뜁니다.\")\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_lime_complete(saved_top8_models)\n",
    "\n",
    "# %% 셀 17: 예측 유틸\n",
    "def predict_with_saved_model(center, task, new_data):\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    if len(model_files)==0:\n",
    "        print(f\"❌ {center} - {task} 모델 파일을 찾을 수 없습니다.\"); return None\n",
    "    filepath = f\"../models_v2/best_models/{model_files[0]}\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            md = pickle.load(f)\n",
    "        model, feature_names = md['model'], md['feature_names']\n",
    "        missing = [c for c in feature_names if c not in new_data.columns]\n",
    "        if missing:\n",
    "            print(f\"❌ 누락된 컬럼: {missing}\"); return None\n",
    "        X_new = new_data[feature_names]\n",
    "        if task=='regression':\n",
    "            pred = model.predict(X_new); print(f\"✅ {center} - {task} 예측 완료: {len(pred)}개 샘플\"); return pred\n",
    "        else:\n",
    "            pred = model.predict(X_new)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                proba = model.predict_proba(X_new)\n",
    "                print(f\"✅ {center} - {task} 예측 완료: {len(pred)}개 샘플\"); return pred, proba\n",
    "            print(f\"✅ {center} - {task} 예측 완료: {len(pred)}개 샘플\"); return pred\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 예측 실패: {str(e)}\"); return None\n",
    "\n",
    "def load_saved_model(center, task):\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    if len(model_files)==0:\n",
    "        print(f\"❌ {center} - {task} 모델 파일을 찾을 수 없습니다.\"); return None\n",
    "    filepath = f\"../models_v2/best_models/{model_files[0]}\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            md = pickle.load(f)\n",
    "        print(f\"✅ 모델 로드 완료: {center} - {task} - {md['model_name']}\"); return md\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 로드 실패: {str(e)}\"); return None\n",
    "\n",
    "print(\"🔮 예측 함수 정의 완료\")\n",
    "\n",
    "# %% 셀 18: 하이퍼파라미터 튜닝 예시(원문 유지)\n",
    "def show_hyperparameter_tuning_examples():\n",
    "    print(\"⚙️ 하이퍼파라미터 튜닝 예시\")\n",
    "    print(\"=\"*50)\n",
    "    print('''# GridSearchCV / RandomizedSearchCV / Optuna 예시 (원문 동일)\n",
    "# ... 필요 시 이전 노트의 블록을 그대로 사용하세요 ...\n",
    "''')\n",
    "show_hyperparameter_tuning_examples()\n",
    "\n",
    "# %% 셀 19: 최종 결과 요약 및 체크리스트 (NameError 방지 - 완전한 구현)\n",
    "def comprehensive_final_summary():\n",
    "    print(\"📋 포괄적인 최종 실행 완료 체크리스트\")\n",
    "    print(\"=\"*80)\n",
    "    checklist = {}\n",
    "    checklist[\"1. 데이터 로드\"] = 'data_info' in globals() and len(data_info) > 0\n",
    "    checklist[\"2. 모델 학습 (96개)\"] = 'results_df' in globals() and len(results_df) > 0\n",
    "    checklist[\"3. 전체 결과 CSV\"] = os.path.exists('../results_v2/all_model_results.csv')\n",
    "    checklist[\"4. 통합 베스트 모델\"] = os.path.exists('../results_v2/best_models.csv')\n",
    "    individual_dir = '../results_v2/best_models_individual/'\n",
    "    individual_files = [f for f in os.listdir(individual_dir) if f.endswith('.csv')] if os.path.exists(individual_dir) else []\n",
    "    checklist[\"5. 개별 베스트 모델 (8개)\"] = len(individual_files) >= 8\n",
    "    basic_viz = '../results_v2/visualizations/basic_performance_comparison.png'\n",
    "    checklist[\"6. 기본 성능 시각화\"] = os.path.exists(basic_viz)\n",
    "    detailed_viz_files = [\n",
    "        'regression_detailed_comparison.png',\n",
    "        'classification_detailed_comparison.png',\n",
    "        'same_model_center_comparison_regression.png',\n",
    "        'same_model_center_comparison_classification.png'\n",
    "    ]\n",
    "    viz_dir = '../results_v2/visualizations/'\n",
    "    viz_count = sum([os.path.exists(os.path.join(viz_dir, f)) for f in detailed_viz_files])\n",
    "    checklist[\"7. 상세 시각화 (4개)\"] = viz_count >= 4\n",
    "    roc_file = '../results_v2/visualizations/roc_curves.png'\n",
    "    checklist[\"8. ROC Curve 시각화\"] = os.path.exists(roc_file)\n",
    "    model_dir = '../models_v2/best_models/'\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')] if os.path.exists(model_dir) else []\n",
    "    checklist[\"9. 베스트 모델 파일 (8개)\"] = len(model_files) >= 8\n",
    "    interp_dir = '../results_v2/interpretations/'\n",
    "    shap_files = [f for f in os.listdir(interp_dir) if 'shap' in f.lower()] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"10. SHAP 분석\"] = len(shap_files) >= 3  # 최소 생성 기준\n",
    "    fi_files = [f for f in os.listdir(interp_dir) if 'feature_importance' in f] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"11. Feature Importance\"] = len(fi_files) >= 3\n",
    "    if 'results_df' in globals() and len(results_df) > 0:\n",
    "        has_smape = 'SMAPE' in results_df.columns\n",
    "        has_f1_macro = 'F1_macro' in results_df.columns\n",
    "        checklist[\"12. 완전한 성능 지표\"] = has_smape and has_f1_macro\n",
    "    else:\n",
    "        checklist[\"12. 완전한 성능 지표\"] = False\n",
    "\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"✅\" if status else \"❌\"\n",
    "        print(f\"{status_icon} {item}: {'완료' if status else '미완료'}\")\n",
    "\n",
    "    completed = sum(1 for v in checklist.values() if v)\n",
    "    total = len(checklist)\n",
    "    completion_rate = completed / total * 100\n",
    "    print(f\"\\n📊 전체 완료율: {completion_rate:.1f}% ({completed}/{total})\")\n",
    "    if completion_rate >= 95:\n",
    "        print(\"🎉 프로젝트가 완벽하게 완료되었습니다!\")\n",
    "    elif completion_rate >= 85:\n",
    "        print(\"🌟 프로젝트가 거의 완료되었습니다!\")\n",
    "    elif completion_rate >= 70:\n",
    "        print(\"⚠️ 대부분 완료되었으나 일부 단계를 확인해주세요.\")\n",
    "    else:\n",
    "        print(\"❌ 여러 단계에서 문제가 발생했습니다. 오류를 확인해주세요.\")\n",
    "    return checklist\n",
    "\n",
    "final_checklist = comprehensive_final_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 하수처리량 예측 모델링 프로젝트 완료!\")\n",
    "print(f\"⏰ 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"✨ 모든 요구사항(색상 개선 + 빈 서브플롯 제거)이 반영되었습니다!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% [markdown]\n",
    "# # 🎉 프로젝트 완료!\n",
    "# - 색상 팔레트 통일, 한글 폰트/마이너스 표시, 빈 서브플롯 방지(회귀/분류 모델 목록 분리)까지 반영."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea02cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"현재 폰트:\", plt.rcParams.get(\"font.family\"))\n",
    "\n",
    "# 한글이 실제로 그려지는지 테스트\n",
    "plt.figure()\n",
    "plt.title(\"한글 제목: 서울 하수처리량 추이\")\n",
    "plt.plot([0,1,2],[1,4,9])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe4d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0f204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55308ce5",
   "metadata": {},
   "source": [
    "## 코드 3\n",
    "- 색이나 그런거 조금 더 예쁘게 시각적 효과 조정중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06926f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 패키지 import 및 설정 완료\n",
      "⏰ 실행 시간: 2025-08-28 21:00:03\n",
      "📁 디렉토리 생성/확인: ../results_v3\n",
      "📁 디렉토리 생성/확인: ../results_v3/visualizations\n",
      "📁 디렉토리 생성/확인: ../results_v3/hyperparameter_results\n",
      "📁 디렉토리 생성/확인: ../results_v3/interpretations\n",
      "📁 디렉토리 생성/확인: ../results_v3/cross_validation\n",
      "📁 디렉토리 생성/확인: ../results_v3/best_models_summary\n",
      "📁 디렉토리 생성/확인: ../models_v3\n",
      "📁 디렉토리 생성/확인: ../models_v3/best_tuned_models\n",
      "✅ 디렉토리 설정 완료\n",
      "🔧 고급 파이프라인 초기화 완료 (최적화 버전)\n",
      "✅ 데이터 처리 및 평가 메소드 정의 완료 (불균형 처리 포함)\n",
      "✅ 하이퍼파라미터 튜닝 함수 정의 완료\n",
      "📊 데이터 파일 확인 및 기본 정보\n",
      "==================================================\n",
      "✅ nanji 센터 데이터 로드: (3069, 44)\n",
      "\n",
      "🏢 NANJI 센터:\n",
      "  📈 데이터 크기: (3069, 44)\n",
      "  📊 피처 수: 33\n",
      "  🎯 회귀 타겟 범위: 442332.8 ~ 1381444.0\n",
      "  🏷️ 분류 타겟 분포:\n",
      "      클래스 0: 459개 (15.0%)\n",
      "      클래스 1: 1688개 (55.0%)\n",
      "      클래스 2: 614개 (20.0%)\n",
      "      클래스 3: 308개 (10.0%)\n",
      "✅ jungnang 센터 데이터 로드: (3069, 44)\n",
      "\n",
      "🏢 JUNGNANG 센터:\n",
      "  📈 데이터 크기: (3069, 44)\n",
      "  📊 피처 수: 33\n",
      "  🎯 회귀 타겟 범위: 625472.0 ~ 2745792.0\n",
      "  🏷️ 분류 타겟 분포:\n",
      "      클래스 0: 460개 (15.0%)\n",
      "      클래스 1: 1687개 (55.0%)\n",
      "      클래스 2: 614개 (20.0%)\n",
      "      클래스 3: 308개 (10.0%)\n",
      "✅ seonam 센터 데이터 로드: (3069, 43)\n",
      "\n",
      "🏢 SEONAM 센터:\n",
      "  📈 데이터 크기: (3069, 43)\n",
      "  📊 피처 수: 33\n",
      "  🎯 회귀 타겟 범위: 1160337.0 ~ 2780034.0\n",
      "  🏷️ 분류 타겟 분포:\n",
      "      클래스 0: 460개 (15.0%)\n",
      "      클래스 1: 1687개 (55.0%)\n",
      "      클래스 2: 614개 (20.0%)\n",
      "      클래스 3: 308개 (10.0%)\n",
      "✅ tancheon 센터 데이터 로드: (3069, 42)\n",
      "\n",
      "🏢 TANCHEON 센터:\n",
      "  📈 데이터 크기: (3069, 42)\n",
      "  📊 피처 수: 33\n",
      "  🎯 회귀 타겟 범위: 543425.0 ~ 1423827.0\n",
      "  🏷️ 분류 타겟 분포:\n",
      "      클래스 0: 460개 (15.0%)\n",
      "      클래스 1: 1687개 (55.0%)\n",
      "      클래스 2: 614개 (20.0%)\n",
      "      클래스 3: 308개 (10.0%)\n",
      "\n",
      "✅ 4개 센터 데이터 로드 및 분석 완료\n",
      "🚀 하이퍼파라미터 튜닝 및 모델 학습 시작\n",
      "예상 총 모델 수: 4 × 2 × 2 × 6 = 96개\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "🏢 NANJI 센터 처리 중...\n",
      "============================================================\n",
      "\n",
      "--- TEMPORAL 분할 방법 ---\n",
      "📈 회귀 모델 하이퍼파라미터 튜닝 및 학습:\n",
      "  🔄 LinearRegression 처리 중...\n",
      "    🔧 LinearRegression 하이퍼파라미터 튜닝 시작...\n",
      "      ✅ 완료 (0.8초) - 최고 점수: 0.5819\n",
      "      📋 최적 파라미터: {'fit_intercept': True}\n",
      "    ✅ LinearRegression: R2=0.5030, CV_R2=0.5742\n",
      "  🔄 RandomForest 처리 중...\n",
      "    🔧 RandomForest 하이퍼파라미터 튜닝 시작...\n",
      "      ✅ 완료 (8.3초) - 최고 점수: 0.5836\n",
      "      📋 최적 파라미터: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "    ✅ RandomForest: R2=0.5573, CV_R2=0.5919\n",
      "  🔄 XGBoost 처리 중...\n",
      "    🔧 XGBoost 하이퍼파라미터 튜닝 시작...\n",
      "      ✅ 완료 (0.9초) - 최고 점수: 0.6026\n",
      "      📋 최적 파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "    ✅ XGBoost: R2=0.4822, CV_R2=0.6140\n",
      "  🔄 CatBoost 처리 중...\n",
      "    🔧 CatBoost 하이퍼파라미터 튜닝 시작...\n",
      "      ✅ 완료 (1.7초) - 최고 점수: 0.6153\n",
      "      📋 최적 파라미터: {'depth': 4, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
      "    ✅ CatBoost: R2=0.4613, CV_R2=0.6221\n",
      "  🔄 GradientBoost 처리 중...\n",
      "    🔧 GradientBoost 하이퍼파라미터 튜닝 시작...\n",
      "      ✅ 완료 (3.6초) - 최고 점수: 0.5957\n",
      "      📋 최적 파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "    ✅ GradientBoost: R2=0.4827, CV_R2=0.6079\n",
      "  🔄 LightGBM 처리 중...\n",
      "    🔧 LightGBM 하이퍼파라미터 튜닝 시작...\n",
      "      ✅ 완료 (5.4초) - 최고 점수: 0.6074\n",
      "      📋 최적 파라미터: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "    ✅ LightGBM: R2=0.5544, CV_R2=0.6151\n",
      "\n",
      "📊 분류 모델 하이퍼파라미터 튜닝 및 학습:\n",
      "  📊 불균형 처리 (smote): 2455 → 5240 샘플\n",
      "  🔄 LogisticRegression 처리 중...\n",
      "    🔧 LogisticRegression 하이퍼파라미터 튜닝 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ✅ 완료 (13.6초) - 최고 점수: 0.6664\n",
      "      📋 최적 파라미터: {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "    ✅ LogisticRegression: F1_w=0.4001, CV_F1=0.6149\n",
      "  🔄 RandomForest 처리 중...\n",
      "    🔧 RandomForest 하이퍼파라미터 튜닝 시작...\n"
     ]
    }
   ],
   "source": [
    "# **🚀 고급 하수처리량 예측 모델링 시스템 (하이퍼파라미터 튜닝 포함)**\n",
    "# ========================================================================================\n",
    "# 하수처리량 예측 모델링 프로젝트 - 하이퍼파라미터 튜닝 & 고급 분석\n",
    "# ========================================================================================\n",
    "\n",
    "# %% 셀 1: 패키지 import 및 기본 설정\n",
    "import os, warnings, pickle\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - 기본\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, KFold,\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, roc_auc_score, classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 불균형 데이터 처리\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 해석 가능성 분석\n",
    "import shap\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 색상 팔레트\n",
    "PALETTE = [\n",
    "    \"#2563EB\", \"#F97316\", \"#10B981\", \"#A855F7\", \"#EF4444\", \"#0EA5E9\",\n",
    "    \"#F59E0B\", \"#22C55E\", \"#8B5CF6\", \"#DC2626\", \"#14B8A6\", \"#E11D48\"\n",
    "]\n",
    "\n",
    "# 스타일 설정\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(PALETTE)\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=PALETTE)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # 맥용\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"✅ 패키지 import 및 설정 완료\")\n",
    "print(f\"⏰ 실행 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# %% 셀 2: 디렉토리 생성 및 설정\n",
    "directories = [\n",
    "    '../results_v3', \n",
    "    '../results_v3/visualizations',\n",
    "    '../results_v3/hyperparameter_results',\n",
    "    '../results_v3/interpretations',\n",
    "    '../results_v3/cross_validation',\n",
    "    '../results_v3/best_models_summary',\n",
    "    '../models_v3', \n",
    "    '../models_v3/best_tuned_models'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"📁 디렉토리 생성/확인: {directory}\")\n",
    "\n",
    "print(\"✅ 디렉토리 설정 완료\")\n",
    "\n",
    "# %% 셀 3: 고급 파이프라인 클래스 정의 (수정 버전)\n",
    "class AdvancedSewagePredictionPipeline:\n",
    "    def __init__(self, data_path_template='../data/add_feature/{}_add_feature.csv'):\n",
    "        \"\"\"고급 하수처리량 예측 모델링 파이프라인 (하이퍼파라미터 튜닝 포함)\"\"\"\n",
    "        self.data_path_template = data_path_template\n",
    "        self.centers = ['nanji', 'jungnang', 'seonam', 'tancheon']\n",
    "        \n",
    "        # 제외할 컬럼\n",
    "        self.not_use_col = [\n",
    "            '날짜', '1처리장','2처리장','정화조','중계펌프장','합계','시설현대화',\n",
    "            '3처리장','4처리장','합계', '합계_1일후','합계_2일후',\n",
    "            '등급','등급_1일후','등급_2일후'\n",
    "        ]\n",
    "        \n",
    "        # 기본 모델들\n",
    "        self.regression_models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForest': RandomForestRegressor(random_state=42),\n",
    "            'XGBoost': xgb.XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "            'CatBoost': cb.CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
    "            'LightGBM': lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        self.classification_models = {\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'RandomForest': RandomForestClassifier(random_state=42),\n",
    "            'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'CatBoost': cb.CatBoostClassifier(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "            'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # 최적화된 하이퍼파라미터 그리드 정의 (성능 개선 버전)\n",
    "        self.regression_param_grids = {\n",
    "            'LinearRegression': {\n",
    "                'fit_intercept': [True, False]\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2]\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            },\n",
    "            'CatBoost': {\n",
    "                'iterations': [50, 100],\n",
    "                'depth': [4, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'l2_leaf_reg': [1, 3]\n",
    "            },\n",
    "            'GradientBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 5],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.classification_param_grids = {\n",
    "            'LogisticRegression': {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'solver': ['liblinear', 'saga'],\n",
    "                'class_weight': ['balanced', None]\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2],\n",
    "                'class_weight': ['balanced', None]\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0],\n",
    "                'scale_pos_weight': [1, 2, 3]\n",
    "            },\n",
    "            'CatBoost': {\n",
    "                'iterations': [50, 100],\n",
    "                'depth': [4, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'l2_leaf_reg': [1, 3]\n",
    "            },\n",
    "            'GradientBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 5],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0],\n",
    "                'class_weight': ['balanced', None]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.results = []\n",
    "        self.tuning_results = []\n",
    "        self.cv_results = []\n",
    "        \n",
    "    def load_data(self, center):\n",
    "        \"\"\"센터별 데이터 로드\"\"\"\n",
    "        file_path = self.data_path_template.format(center)\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(f\"✅ {center} 센터 데이터 로드: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
    "            return None\n",
    "\n",
    "# 파이프라인 초기화\n",
    "pipeline = AdvancedSewagePredictionPipeline()\n",
    "print(\"🔧 고급 파이프라인 초기화 완료 (최적화 버전)\")\n",
    "\n",
    "# %% 셀 4: 데이터 처리 및 평가 메소드 (불균형 처리 포함)\n",
    "def prepare_features(data, not_use_col):\n",
    "    \"\"\"피처 및 타겟 준비\"\"\"\n",
    "    available_cols = [col for col in data.columns if col not in not_use_col]\n",
    "    X = data[available_cols]\n",
    "    y_reg = data['합계_1일후']  # 회귀용\n",
    "    y_clf = data['등급_1일후']  # 분류용\n",
    "    return X, y_reg, y_clf\n",
    "\n",
    "def handle_class_imbalance(X_train, y_train, method='smote'):\n",
    "    \"\"\"클래스 불균형 처리\"\"\"\n",
    "    try:\n",
    "        if method == 'smote':\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_balanced, y_balanced = smote.fit_resample(X_train, y_train)\n",
    "        elif method == 'smoteenn':\n",
    "            smoteenn = SMOTEENN(random_state=42)\n",
    "            X_balanced, y_balanced = smoteenn.fit_resample(X_train, y_train)\n",
    "        else:\n",
    "            return X_train, y_train\n",
    "        \n",
    "        print(f\"  📊 불균형 처리 ({method}): {len(X_train)} → {len(X_balanced)} 샘플\")\n",
    "        return X_balanced, y_balanced\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ 불균형 처리 실패: {e}, 원본 데이터 사용\")\n",
    "        return X_train, y_train\n",
    "\n",
    "def split_data_temporal(X, y, test_size=0.2):\n",
    "    \"\"\"시계열 정보를 유지한 분할\"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_random(X, y, test_size=0.2, stratify=None):\n",
    "    \"\"\"랜덤 분할 (분류시 stratified)\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=42)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"회귀 모델 평가 지표 계산\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # MAPE 계산 (0 값 처리)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.inf\n",
    "    \n",
    "    # SMAPE 계산\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae, 'MSE': mse, 'RMSE': rmse, \n",
    "        'MAPE': mape, 'SMAPE': smape, 'R2': r2\n",
    "    }\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"분류 모델 평가 지표 계산\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_weighted': precision_weighted,\n",
    "        'Precision_macro': precision_macro,\n",
    "        'Recall_weighted': recall_weighted,\n",
    "        'Recall_macro': recall_macro,\n",
    "        'F1_weighted': f1_weighted,\n",
    "        'F1_macro': f1_macro\n",
    "    }\n",
    "    \n",
    "    # AUC 계산\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "            metrics['AUC'] = auc_score\n",
    "        except Exception:\n",
    "            metrics['AUC'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def perform_cross_validation(model, X, y, task, cv_folds=5):\n",
    "    \"\"\"교차검증 수행\"\"\"\n",
    "    if task == 'regression':\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        scoring = ['accuracy', 'f1_weighted', 'f1_macro']\n",
    "    \n",
    "    cv_results = {}\n",
    "    for score in scoring:\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=score)\n",
    "        cv_results[f'{score}_mean'] = scores.mean()\n",
    "        cv_results[f'{score}_std'] = scores.std()\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "print(\"✅ 데이터 처리 및 평가 메소드 정의 완료 (불균형 처리 포함)\")\n",
    "\n",
    "# %% 셀 5: 하이퍼파라미터 튜닝 함수\n",
    "def perform_hyperparameter_tuning(model, param_grid, X_train, y_train, task, \n",
    "                                model_name, center, cv_folds=3, n_jobs=-1):\n",
    "    \"\"\"하이퍼파라미터 튜닝 수행\"\"\"\n",
    "    print(f\"    🔧 {model_name} 하이퍼파라미터 튜닝 시작...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 스코어링 메트릭 설정\n",
    "    if task == 'regression':\n",
    "        scoring = 'r2'\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        scoring = 'f1_weighted'\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    try:\n",
    "        # 파라미터 공간이 클 경우 RandomizedSearchCV 사용\n",
    "        total_combinations = 1\n",
    "        for param_values in param_grid.values():\n",
    "            total_combinations *= len(param_values)\n",
    "        \n",
    "        if total_combinations > 100:\n",
    "            search = RandomizedSearchCV(\n",
    "                model, param_grid, n_iter=50, cv=cv, scoring=scoring,\n",
    "                n_jobs=n_jobs, random_state=42, verbose=0\n",
    "            )\n",
    "            search_type = \"RandomizedSearch\"\n",
    "        else:\n",
    "            search = GridSearchCV(\n",
    "                model, param_grid, cv=cv, scoring=scoring,\n",
    "                n_jobs=n_jobs, verbose=0\n",
    "            )\n",
    "            search_type = \"GridSearch\"\n",
    "        \n",
    "        # 튜닝 실행\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        tuning_time = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'center': center,\n",
    "            'task': task,\n",
    "            'model': model_name,\n",
    "            'search_type': search_type,\n",
    "            'best_score': search.best_score_,\n",
    "            'best_params': search.best_params_,\n",
    "            'tuning_time': tuning_time,\n",
    "            'total_combinations_tested': len(search.cv_results_['mean_test_score'])\n",
    "        }\n",
    "        \n",
    "        print(f\"      ✅ 완료 ({tuning_time:.1f}초) - 최고 점수: {search.best_score_:.4f}\")\n",
    "        print(f\"      📋 최적 파라미터: {search.best_params_}\")\n",
    "        \n",
    "        return search.best_estimator_, result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ 튜닝 실패: {str(e)}\")\n",
    "        return model, None\n",
    "\n",
    "print(\"✅ 하이퍼파라미터 튜닝 함수 정의 완료\")\n",
    "\n",
    "# %% 셀 6: 데이터 확인 및 기본 정보\n",
    "print(\"📊 데이터 파일 확인 및 기본 정보\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_info = {}\n",
    "for center in pipeline.centers:\n",
    "    data = pipeline.load_data(center)\n",
    "    if data is not None:\n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        \n",
    "        print(f\"\\n🏢 {center.upper()} 센터:\")\n",
    "        print(f\"  📈 데이터 크기: {data.shape}\")\n",
    "        print(f\"  📊 피처 수: {X.shape[1]}\")\n",
    "        print(f\"  🎯 회귀 타겟 범위: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"  🏷️ 분류 타겟 분포:\")\n",
    "        class_dist = y_clf.value_counts().sort_index()\n",
    "        for class_label, count in class_dist.items():\n",
    "            percentage = count / len(y_clf) * 100\n",
    "            print(f\"      클래스 {class_label}: {count}개 ({percentage:.1f}%)\")\n",
    "        \n",
    "        data_info[center] = {\n",
    "            'data': data, 'X': X, 'y_reg': y_reg, 'y_clf': y_clf,\n",
    "            'shape': data.shape, 'class_distribution': class_dist\n",
    "        }\n",
    "\n",
    "if len(data_info) == 0:\n",
    "    print(\"❌ 데이터 파일이 없습니다. 경로를 확인해주세요.\")\n",
    "else:\n",
    "    print(f\"\\n✅ {len(data_info)}개 센터 데이터 로드 및 분석 완료\")\n",
    "\n",
    "# %% 셀 7: 하이퍼파라미터 튜닝 및 모델 학습 실행\n",
    "print(\"🚀 하이퍼파라미터 튜닝 및 모델 학습 시작\")\n",
    "print(f\"예상 총 모델 수: {len(pipeline.centers)} × 2 × 2 × 6 = {len(pipeline.centers) * 2 * 2 * 6}개\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_models = 0\n",
    "successful_models = 0\n",
    "tuning_start_time = time.time()\n",
    "\n",
    "for center in pipeline.centers:\n",
    "    if center not in data_info:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🏢 {center.upper()} 센터 처리 중...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        X = data_info[center]['X']\n",
    "        y_reg = data_info[center]['y_reg']\n",
    "        y_clf = data_info[center]['y_clf']\n",
    "        \n",
    "        for split_method in ['temporal', 'random']:\n",
    "            print(f\"\\n--- {split_method.upper()} 분할 방법 ---\")\n",
    "            \n",
    "            # 회귀 모델 처리\n",
    "            print(\"📈 회귀 모델 하이퍼파라미터 튜닝 및 학습:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_temporal(X, y_reg)\n",
    "            else:\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_random(X, y_reg)\n",
    "            \n",
    "            for model_name, base_model in pipeline.regression_models.items():\n",
    "                total_models += 1\n",
    "                print(f\"  🔄 {model_name} 처리 중...\")\n",
    "                \n",
    "                try:\n",
    "                    # 하이퍼파라미터 튜닝\n",
    "                    param_grid = pipeline.regression_param_grids[model_name]\n",
    "                    tuned_model, tuning_result = perform_hyperparameter_tuning(\n",
    "                        base_model, param_grid, X_train_reg, y_train_reg, \n",
    "                        'regression', model_name, center\n",
    "                    )\n",
    "                    \n",
    "                    if tuning_result:\n",
    "                        pipeline.tuning_results.append(tuning_result)\n",
    "                    \n",
    "                    # 예측 및 평가\n",
    "                    y_pred_reg = tuned_model.predict(X_test_reg)\n",
    "                    metrics = evaluate_regression(y_test_reg, y_pred_reg)\n",
    "                    \n",
    "                    # 교차검증\n",
    "                    cv_results = perform_cross_validation(tuned_model, X_train_reg, y_train_reg, 'regression')\n",
    "                    \n",
    "                    # 결과 저장\n",
    "                    result = {\n",
    "                        'center': center, 'split_method': split_method, 'task': 'regression',\n",
    "                        'model': model_name, \n",
    "                        'best_params': tuning_result['best_params'] if tuning_result else {},\n",
    "                        'tuning_score': tuning_result['best_score'] if tuning_result else None,\n",
    "                        **metrics, **cv_results\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    \n",
    "                    successful_models += 1\n",
    "                    print(f\"    ✅ {model_name}: R2={metrics['R2']:.4f}, CV_R2={cv_results.get('r2_mean', 0):.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ❌ {model_name} 실패: {str(e)}\")\n",
    "            \n",
    "            # 분류 모델 처리\n",
    "            print(\"\\n📊 분류 모델 하이퍼파라미터 튜닝 및 학습:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_temporal(X, y_clf)\n",
    "            else:\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_random(X, y_clf, stratify=y_clf)\n",
    "            \n",
    "            # 클래스 불균형 처리 (SMOTE)\n",
    "            X_train_balanced, y_train_balanced = handle_class_imbalance(\n",
    "                X_train_clf, y_train_clf, method='smote'\n",
    "            )\n",
    "            \n",
    "            for model_name, base_model in pipeline.classification_models.items():\n",
    "                total_models += 1\n",
    "                print(f\"  🔄 {model_name} 처리 중...\")\n",
    "                \n",
    "                try:\n",
    "                    # 하이퍼파라미터 튜닝\n",
    "                    param_grid = pipeline.classification_param_grids[model_name]\n",
    "                    tuned_model, tuning_result = perform_hyperparameter_tuning(\n",
    "                        base_model, param_grid, X_train_balanced, y_train_balanced,\n",
    "                        'classification', model_name, center\n",
    "                    )\n",
    "                    \n",
    "                    if tuning_result:\n",
    "                        pipeline.tuning_results.append(tuning_result)\n",
    "                    \n",
    "                    # 예측 및 평가\n",
    "                    y_pred_clf = tuned_model.predict(X_test_clf)\n",
    "                    y_pred_proba = tuned_model.predict_proba(X_test_clf) if hasattr(tuned_model, 'predict_proba') else None\n",
    "                    metrics = evaluate_classification(y_test_clf, y_pred_clf, y_pred_proba)\n",
    "                    \n",
    "                    # 교차검증 (원본 데이터로)\n",
    "                    cv_results = perform_cross_validation(tuned_model, X_train_clf, y_train_clf, 'classification')\n",
    "                    \n",
    "                    # 결과 저장\n",
    "                    result = {\n",
    "                        'center': center, 'split_method': split_method, 'task': 'classification',\n",
    "                        'model': model_name,\n",
    "                        'best_params': tuning_result['best_params'] if tuning_result else {},\n",
    "                        'tuning_score': tuning_result['best_score'] if tuning_result else None,\n",
    "                        'used_smote': True,\n",
    "                        **metrics, **cv_results\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    \n",
    "                    successful_models += 1\n",
    "                    print(f\"    ✅ {model_name}: F1_w={metrics['F1_weighted']:.4f}, CV_F1={cv_results.get('f1_weighted_mean', 0):.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    ❌ {model_name} 실패: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {center} 센터 처리 실패: {str(e)}\")\n",
    "\n",
    "total_tuning_time = time.time() - tuning_start_time\n",
    "\n",
    "print(f\"\\n🎉 하이퍼파라미터 튜닝 및 모델 학습 완료!\")\n",
    "print(f\"성공: {successful_models}/{total_models} 모델\")\n",
    "print(f\"총 소요시간: {total_tuning_time/60:.1f}분\")\n",
    "\n",
    "# %% 셀 8: 결과 저장 및 기본 분석\n",
    "print(\"💾 결과 저장 및 기본 분석\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 전체 결과 저장\n",
    "results_df = pd.DataFrame(pipeline.results)\n",
    "results_df.to_csv('../results_v3/all_model_results_with_tuning.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 튜닝 결과 저장\n",
    "if pipeline.tuning_results:\n",
    "    tuning_df = pd.DataFrame(pipeline.tuning_results)\n",
    "    # best_params 컬럼을 문자열로 변환 (CSV 저장을 위해)\n",
    "    tuning_df['best_params_str'] = tuning_df['best_params'].astype(str)\n",
    "    tuning_df.to_csv('../results_v3/hyperparameter_results/tuning_results.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"💾 튜닝 결과 저장: {len(tuning_df)}개 모델의 하이퍼파라미터 튜닝 결과\")\n",
    "\n",
    "# 기본 통계\n",
    "if len(results_df) > 0:\n",
    "    print(f\"\\n📊 기본 통계\")\n",
    "    print(f\"총 결과 수: {len(results_df)}\")\n",
    "    print(f\"센터별 결과 수:\")\n",
    "    print(results_df['center'].value_counts().to_string())\n",
    "    print(f\"\\n태스크별 결과 수:\")\n",
    "    print(results_df['task'].value_counts().to_string())\n",
    "    \n",
    "    # 튜닝 시간 통계\n",
    "    if pipeline.tuning_results:\n",
    "        avg_tuning_time = tuning_df['tuning_time'].mean()\n",
    "        total_tuning_combinations = tuning_df['total_combinations_tested'].sum()\n",
    "        print(f\"\\n⏱️ 튜닝 통계:\")\n",
    "        print(f\"평균 튜닝 시간: {avg_tuning_time:.1f}초\")\n",
    "        print(f\"총 테스트된 조합: {total_tuning_combinations}개\")\n",
    "\n",
    "# %% 셀 9: 베스트 모델 찾기 (튜닝된 결과 기반)\n",
    "def find_best_models_with_tuning(results_df, centers):\n",
    "    print(\"🏆 하이퍼파라미터 튜닝 기반 베스트 모델 찾기\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 분석할 결과가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    best_models_list = []\n",
    "    \n",
    "    for center in centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            if task == 'regression':\n",
    "                # R2 점수 기준으로 최고 모델 선택\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "                metric_value, metric_name = best_model['R2'], 'R2'\n",
    "            else:\n",
    "                # F1_weighted 점수 기준으로 최고 모델 선택\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                metric_value, metric_name = best_model['F1_weighted'], 'F1_weighted'\n",
    "            \n",
    "            best_models_list.append(best_model.to_dict())\n",
    "            \n",
    "            # 튜닝 전후 성능 비교 (만약 튜닝 점수가 있다면)\n",
    "            tuning_score = best_model.get('tuning_score', 'N/A')\n",
    "            improvement = \"\"\n",
    "            if tuning_score != 'N/A' and tuning_score is not None:\n",
    "                if task == 'regression':\n",
    "                    cv_score = best_model.get('r2_mean', metric_value)\n",
    "                else:\n",
    "                    cv_score = best_model.get('f1_weighted_mean', metric_value)\n",
    "                \n",
    "                if cv_score != 0:\n",
    "                    improvement = f\" (CV: {cv_score:.4f})\"\n",
    "            \n",
    "            print(f\"🏅 {center} - {task}: {best_model['model']} ({best_model['split_method']})\")\n",
    "            print(f\"   {metric_name}={metric_value:.4f}{improvement}\")\n",
    "            \n",
    "            # 최적 하이퍼파라미터 출력\n",
    "            best_params = best_model.get('best_params', {})\n",
    "            if best_params:\n",
    "                print(f\"   최적 파라미터: {best_params}\")\n",
    "    \n",
    "    best_models_df = pd.DataFrame(best_models_list)\n",
    "    best_models_df.to_csv('../results_v3/best_models_summary/best_tuned_models.csv', \n",
    "                         index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n💾 베스트 튜닝 모델 정보 저장: ../results_v3/best_models_summary/best_tuned_models.csv\")\n",
    "    return best_models_df\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    best_tuned_models_df = find_best_models_with_tuning(results_df, pipeline.centers)\n",
    "\n",
    "# %% 셀 10: 하이퍼파라미터 튜닝 결과 시각화\n",
    "def create_tuning_visualizations(tuning_df, results_df):\n",
    "    print(\"📊 하이퍼파라미터 튜닝 결과 시각화\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(tuning_df) == 0:\n",
    "        print(\"❌ 튜닝 결과가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 1. 튜닝 시간 분석\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 모델별 평균 튜닝 시간\n",
    "    model_time = tuning_df.groupby('model')['tuning_time'].mean().sort_values(ascending=True)\n",
    "    model_time.plot(kind='barh', ax=axes[0,0], title='모델별 평균 튜닝 시간')\n",
    "    axes[0,0].set_xlabel('시간 (초)')\n",
    "    \n",
    "    # 센터별 평균 튜닝 시간\n",
    "    center_time = tuning_df.groupby('center')['tuning_time'].mean().sort_values(ascending=True)\n",
    "    center_time.plot(kind='barh', ax=axes[0,1], title='센터별 평균 튜닝 시간')\n",
    "    axes[0,1].set_xlabel('시간 (초)')\n",
    "    \n",
    "    # 튜닝 점수 분포 (회귀)\n",
    "    reg_tuning = tuning_df[tuning_df['task'] == 'regression']\n",
    "    if len(reg_tuning) > 0:\n",
    "        axes[1,0].hist(reg_tuning['best_score'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[1,0].set_title('회귀 모델 튜닝 점수 분포 (R2)')\n",
    "        axes[1,0].set_xlabel('R2 Score')\n",
    "        axes[1,0].set_ylabel('빈도')\n",
    "    \n",
    "    # 튜닝 점수 분포 (분류)\n",
    "    clf_tuning = tuning_df[tuning_df['task'] == 'classification']\n",
    "    if len(clf_tuning) > 0:\n",
    "        axes[1,1].hist(clf_tuning['best_score'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[1,1].set_title('분류 모델 튜닝 점수 분포 (F1_weighted)')\n",
    "        axes[1,1].set_xlabel('F1 Weighted Score')\n",
    "        axes[1,1].set_ylabel('빈도')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/hyperparameter_tuning_analysis.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. 튜닝 전후 성능 비교\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # 회귀 모델 성능 비교\n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    if len(reg_data) > 0:\n",
    "        # 센터별 모델별 R2 성능 히트맵\n",
    "        reg_pivot = reg_data.pivot_table(values='R2', index='center', columns='model', aggfunc='max')\n",
    "        sns.heatmap(reg_pivot, annot=True, fmt='.3f', ax=axes[0,0], cmap='YlOrRd')\n",
    "        axes[0,0].set_title('센터별 회귀 모델 최고 R2 성능')\n",
    "        \n",
    "        # 모델별 성능 분포\n",
    "        reg_data.boxplot(column='R2', by='model', ax=axes[0,1])\n",
    "        axes[0,1].set_title('회귀 모델별 R2 성능 분포')\n",
    "        axes[0,1].set_xlabel('모델')\n",
    "        axes[0,1].set_ylabel('R2 Score')\n",
    "    \n",
    "    # 분류 모델 성능 비교\n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    if len(clf_data) > 0:\n",
    "        # 센터별 모델별 F1_weighted 성능 히트맵\n",
    "        clf_pivot = clf_data.pivot_table(values='F1_weighted', index='center', columns='model', aggfunc='max')\n",
    "        sns.heatmap(clf_pivot, annot=True, fmt='.3f', ax=axes[1,0], cmap='YlGnBu')\n",
    "        axes[1,0].set_title('센터별 분류 모델 최고 F1_weighted 성능')\n",
    "        \n",
    "        # 모델별 성능 분포\n",
    "        clf_data.boxplot(column='F1_weighted', by='model', ax=axes[1,1])\n",
    "        axes[1,1].set_title('분류 모델별 F1_weighted 성능 분포')\n",
    "        axes[1,1].set_xlabel('모델')\n",
    "        axes[1,1].set_ylabel('F1 Weighted Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/model_performance_comparison.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ 하이퍼파라미터 튜닝 시각화 완료\")\n",
    "\n",
    "if 'tuning_df' in locals() and len(tuning_df) > 0:\n",
    "    create_tuning_visualizations(tuning_df, results_df)\n",
    "\n",
    "# %% 셀 11: 상세 성능 시각화 (센터별, 모델별, 태스크별)\n",
    "def create_comprehensive_performance_visualizations(results_df):\n",
    "    print(\"📈 포괄적 성능 시각화 생성\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 시각화할 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    \n",
    "    # 1. 전체 성능 개요 (2x3 레이아웃)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # 회귀 - R2 성능\n",
    "    if len(reg_data) > 0:\n",
    "        reg_summary = reg_data.groupby(['center', 'split_method'])['R2'].mean().unstack(fill_value=0)\n",
    "        reg_summary.plot(kind='bar', ax=axes[0,0], title='센터별 회귀 R2 성능')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 회귀 - RMSE 성능\n",
    "        reg_rmse = reg_data.groupby(['center', 'split_method'])['RMSE'].mean().unstack(fill_value=0)\n",
    "        reg_rmse.plot(kind='bar', ax=axes[0,1], title='센터별 회귀 RMSE 성능')\n",
    "        axes[0,1].set_ylabel('RMSE')\n",
    "        axes[0,1].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 회귀 - 모델별 성능\n",
    "        reg_model_perf = reg_data.groupby('model')['R2'].mean().sort_values(ascending=True)\n",
    "        reg_model_perf.plot(kind='barh', ax=axes[0,2], title='모델별 평균 R2 성능')\n",
    "        axes[0,2].set_xlabel('R2 Score')\n",
    "    \n",
    "    # 분류 성능\n",
    "    if len(clf_data) > 0:\n",
    "        clf_summary = clf_data.groupby(['center', 'split_method'])['F1_weighted'].mean().unstack(fill_value=0)\n",
    "        clf_summary.plot(kind='bar', ax=axes[1,0], title='센터별 분류 F1_weighted 성능')\n",
    "        axes[1,0].set_ylabel('F1 Weighted Score')\n",
    "        axes[1,0].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 분류 - 정확도\n",
    "        clf_acc = clf_data.groupby(['center', 'split_method'])['Accuracy'].mean().unstack(fill_value=0)\n",
    "        clf_acc.plot(kind='bar', ax=axes[1,1], title='센터별 분류 Accuracy 성능')\n",
    "        axes[1,1].set_ylabel('Accuracy')\n",
    "        axes[1,1].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 분류 - 모델별 성능\n",
    "        clf_model_perf = clf_data.groupby('model')['F1_weighted'].mean().sort_values(ascending=True)\n",
    "        clf_model_perf.plot(kind='barh', ax=axes[1,2], title='모델별 평균 F1_weighted 성능')\n",
    "        axes[1,2].set_xlabel('F1 Weighted Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/comprehensive_performance_overview.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. 교차검증 결과 시각화\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # 회귀 교차검증 결과\n",
    "    if len(reg_data) > 0 and 'r2_mean' in reg_data.columns:\n",
    "        # CV R2 vs Test R2 비교\n",
    "        reg_cv_data = reg_data.dropna(subset=['r2_mean'])\n",
    "        if len(reg_cv_data) > 0:\n",
    "            axes[0,0].scatter(reg_cv_data['r2_mean'], reg_cv_data['R2'], alpha=0.7)\n",
    "            axes[0,0].plot([reg_cv_data['R2'].min(), reg_cv_data['R2'].max()], \n",
    "                          [reg_cv_data['R2'].min(), reg_cv_data['R2'].max()], 'r--')\n",
    "            axes[0,0].set_xlabel('CV R2 Mean')\n",
    "            axes[0,0].set_ylabel('Test R2')\n",
    "            axes[0,0].set_title('회귀: 교차검증 vs 테스트 R2 성능')\n",
    "            \n",
    "        # CV 표준편차 분석\n",
    "        if 'r2_std' in reg_data.columns:\n",
    "            reg_std_data = reg_data.dropna(subset=['r2_std'])\n",
    "            if len(reg_std_data) > 0:\n",
    "                reg_std_summary = reg_std_data.groupby('model')['r2_std'].mean().sort_values()\n",
    "                reg_std_summary.plot(kind='bar', ax=axes[0,1], title='모델별 R2 교차검증 표준편차')\n",
    "                axes[0,1].set_ylabel('R2 Standard Deviation')\n",
    "                axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 분류 교차검증 결과\n",
    "    if len(clf_data) > 0 and 'f1_weighted_mean' in clf_data.columns:\n",
    "        # CV F1 vs Test F1 비교\n",
    "        clf_cv_data = clf_data.dropna(subset=['f1_weighted_mean'])\n",
    "        if len(clf_cv_data) > 0:\n",
    "            axes[1,0].scatter(clf_cv_data['f1_weighted_mean'], clf_cv_data['F1_weighted'], alpha=0.7)\n",
    "            axes[1,0].plot([clf_cv_data['F1_weighted'].min(), clf_cv_data['F1_weighted'].max()], \n",
    "                          [clf_cv_data['F1_weighted'].min(), clf_cv_data['F1_weighted'].max()], 'r--')\n",
    "            axes[1,0].set_xlabel('CV F1_weighted Mean')\n",
    "            axes[1,0].set_ylabel('Test F1_weighted')\n",
    "            axes[1,0].set_title('분류: 교차검증 vs 테스트 F1 성능')\n",
    "            \n",
    "        # CV 표준편차 분석\n",
    "        if 'f1_weighted_std' in clf_data.columns:\n",
    "            clf_std_data = clf_data.dropna(subset=['f1_weighted_std'])\n",
    "            if len(clf_std_data) > 0:\n",
    "                clf_std_summary = clf_std_data.groupby('model')['f1_weighted_std'].mean().sort_values()\n",
    "                clf_std_summary.plot(kind='bar', ax=axes[1,1], title='모델별 F1 교차검증 표준편차')\n",
    "                axes[1,1].set_ylabel('F1 Standard Deviation')\n",
    "                axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/cross_validation_analysis.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ 포괄적 성능 시각화 완료\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_comprehensive_performance_visualizations(results_df)\n",
    "\n",
    "# %% 셀 12: 베스트 8개 모델 재학습 및 저장 (튜닝된 하이퍼파라미터 사용)\n",
    "def train_and_save_best_tuned_models(results_df, pipeline):\n",
    "    print(\"💾 베스트 8개 튜닝 모델 재학습 및 저장\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 각 센터-태스크 조합에서 최고 성능 모델 선택\n",
    "    selected_models = []\n",
    "    \n",
    "    for center in pipeline.centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                \n",
    "            selected_models.append(best_model)\n",
    "    \n",
    "    print(f\"📋 선정된 {len(selected_models)}개 베스트 모델:\")\n",
    "    for model_info in selected_models:\n",
    "        print(f\"  🏅 {model_info['center']} - {model_info['task']} - {model_info['model']} ({model_info['split_method']})\")\n",
    "    \n",
    "    saved_models = {}\n",
    "    \n",
    "    for model_info in selected_models:\n",
    "        center = model_info['center']\n",
    "        task = model_info['task']\n",
    "        model_name = model_info['model']\n",
    "        split_method = model_info['split_method']\n",
    "        best_params = model_info.get('best_params', {})\n",
    "        \n",
    "        print(f\"\\n🔄 {center} - {task} - {model_name} ({split_method}) 재학습 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 데이터 로드\n",
    "            if center not in data_info:\n",
    "                continue\n",
    "                \n",
    "            X = data_info[center]['X']\n",
    "            y_reg = data_info[center]['y_reg']\n",
    "            y_clf = data_info[center]['y_clf']\n",
    "            y = y_reg if task == 'regression' else y_clf\n",
    "            \n",
    "            # 모델 생성 (최적 하이퍼파라미터 적용)\n",
    "            if task == 'regression':\n",
    "                base_model = pipeline.regression_models[model_name]\n",
    "            else:\n",
    "                base_model = pipeline.classification_models[model_name]\n",
    "            \n",
    "            # 하이퍼파라미터 설정\n",
    "            model = base_model.__class__(**best_params) if best_params else base_model\n",
    "            \n",
    "            # 데이터 분할\n",
    "            if split_method == 'temporal':\n",
    "                X_train, X_test, y_train, y_test = split_data_temporal(X, y)\n",
    "            else:\n",
    "                stratify = y if task == 'classification' else None\n",
    "                X_train, X_test, y_train, y_test = split_data_random(X, y, stratify=stratify)\n",
    "            \n",
    "            # 분류의 경우 SMOTE 적용\n",
    "            if task == 'classification':\n",
    "                X_train_balanced, y_train_balanced = handle_class_imbalance(X_train, y_train, method='smote')\n",
    "                model.fit(X_train_balanced, y_train_balanced)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            # 예측\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test) if (task == 'classification' and hasattr(model, 'predict_proba')) else None\n",
    "            \n",
    "            # 교차검증 수행\n",
    "            cv_results = perform_cross_validation(model, X_train, y_train, task)\n",
    "            \n",
    "            # 모델 데이터 패키지\n",
    "            model_data = {\n",
    "                'model': model,\n",
    "                'feature_names': X.columns.tolist(),\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'task': task,\n",
    "                'center': center,\n",
    "                'split_method': split_method,\n",
    "                'model_name': model_name,\n",
    "                'best_params': best_params,\n",
    "                'performance': model_info.to_dict(),\n",
    "                'cv_results': cv_results,\n",
    "                'used_smote': task == 'classification'\n",
    "            }\n",
    "            \n",
    "            # 파일 저장\n",
    "            filename = f\"{center}_{task}_{model_name}_{split_method}_tuned.pkl\"\n",
    "            filepath = f\"../models_v3/best_tuned_models/{filename}\"\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            \n",
    "            print(f\"✅ 모델 저장: {filepath}\")\n",
    "            saved_models[f\"{center}_{task}\"] = model_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {center} - {task} - {model_name} 저장 실패: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n✅ {len(saved_models)}개 베스트 튜닝 모델 저장 완료\")\n",
    "    return saved_models\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    saved_best_tuned_models = train_and_save_best_tuned_models(results_df, pipeline)\n",
    "\n",
    "# %% 셀 13: ROC Curve 시각화 (튜닝된 모델 기반)\n",
    "def create_advanced_roc_curves(saved_models):\n",
    "    print(\"📈 고급 ROC Curve 시각화\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    clf_models = {k: v for k, v in saved_models.items() if v['task'] == 'classification'}\n",
    "    \n",
    "    if len(clf_models) == 0:\n",
    "        print(\"❌ 분류 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    centers = list(set([v['center'] for v in clf_models.values()]))\n",
    "    n_centers = len(centers)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, min(4, n_centers), figsize=(5*min(4, n_centers), 6))\n",
    "    if n_centers == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, center in enumerate(centers[:4]):\n",
    "        center_models = {k: v for k, v in clf_models.items() if v['center'] == center}\n",
    "        ax = axes[i]\n",
    "        \n",
    "        for model_key, md in center_models.items():\n",
    "            y_test = md['y_test']\n",
    "            y_pred_proba = md['y_pred_proba']\n",
    "            \n",
    "            if y_pred_proba is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                classes = np.unique(y_test)\n",
    "                n_classes = len(classes)\n",
    "                \n",
    "                if n_classes == 2:\n",
    "                    # 이진 분류\n",
    "                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "                    auc_score = auc(fpr, tpr)\n",
    "                    ax.plot(fpr, tpr, label=f'{md[\"model_name\"]} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "                else:\n",
    "                    # 다중 분류 (클래스별)\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    y_bin = label_binarize(y_test, classes=classes)\n",
    "                    \n",
    "                    for c in range(min(n_classes, y_pred_proba.shape[1])):\n",
    "                        if c < y_bin.shape[1]:\n",
    "                            fpr, tpr, _ = roc_curve(y_bin[:, c], y_pred_proba[:, c])\n",
    "                            auc_score = auc(fpr, tpr)\n",
    "                            ax.plot(fpr, tpr, \n",
    "                                   label=f'{md[\"model_name\"]} Class{classes[c]} (AUC = {auc_score:.3f})',\n",
    "                                   linewidth=2)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {center} ROC 곡선 생성 실패: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 대각선 (랜덤 분류기 성능)\n",
    "        ax.plot([0, 1], [0, 1], '--', color='gray', alpha=0.8, linewidth=2)\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_ylim([0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'{center} 센터 ROC Curves')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/advanced_roc_curves.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ 고급 ROC Curve 시각화 완료\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    create_advanced_roc_curves(saved_best_tuned_models)\n",
    "\n",
    "# %% 셀 14: Confusion Matrix 시각화\n",
    "def create_confusion_matrices(saved_models):\n",
    "    print(\"🎯 Confusion Matrix 시각화\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    clf_models = {k: v for k, v in saved_models.items() if v['task'] == 'classification'}\n",
    "    \n",
    "    if len(clf_models) == 0:\n",
    "        print(\"❌ 분류 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    n_models = len(clf_models)\n",
    "    cols = min(4, n_models)\n",
    "    rows = (n_models + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for idx, (model_key, md) in enumerate(clf_models.items()):\n",
    "        y_test = md['y_test']\n",
    "        y_pred = md['y_pred']\n",
    "        center = md['center']\n",
    "        model_name = md['model_name']\n",
    "        \n",
    "        # Confusion Matrix 계산\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # 시각화\n",
    "        ax = axes_flat[idx]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        ax.set_title(f'{center} - {model_name}')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('Actual')\n",
    "    \n",
    "    # 빈 서브플롯 숨기기\n",
    "    for idx in range(len(clf_models), len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/confusion_matrices.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Confusion Matrix 시각화 완료\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    create_confusion_matrices(saved_best_tuned_models)\n",
    "\n",
    "# %% 셀 15: SHAP 분석 (완전 버전)\n",
    "def analyze_shap_comprehensive(saved_models):\n",
    "    print(\"🔍 포괄적 SHAP 분석\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(saved_models) == 0:\n",
    "        print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    for key, md in saved_models.items():\n",
    "        center = md['center']\n",
    "        task = md['task'] \n",
    "        model_name = md['model_name']\n",
    "        model = md['model']\n",
    "        X_train = md['X_train']\n",
    "        X_test = md['X_test']\n",
    "        feature_names = md['feature_names']\n",
    "        \n",
    "        print(f\"\\n🔍 {center} - {task} - {model_name} SHAP 분석...\")\n",
    "        \n",
    "        try:\n",
    "            # 샘플 크기 제한\n",
    "            sample_size = min(100, len(X_test))\n",
    "            X_test_sample = X_test.iloc[:sample_size]\n",
    "            \n",
    "            # SHAP Explainer 생성\n",
    "            if model_name in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "                explainer = shap.Explainer(model)\n",
    "            else:\n",
    "                train_sample_size = min(200, len(X_train))\n",
    "                explainer = shap.Explainer(model, X_train.iloc[:train_sample_size])\n",
    "            \n",
    "            shap_values = explainer(X_test_sample)\n",
    "            \n",
    "            # 1. Summary Plot\n",
    "            plt.figure(figsize=(16, 8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, \n",
    "                            feature_names=feature_names, show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Summary Plot (Feature Impact)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_summary.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 2. Feature Importance Bar Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, \n",
    "                            feature_names=feature_names, plot_type=\"bar\", \n",
    "                            show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 3. Waterfall Plot (첫 번째 샘플)\n",
    "            try:\n",
    "                plt.figure(figsize=(14, 10))\n",
    "                if hasattr(shap_values, 'values') and len(shap_values.values.shape) == 3:\n",
    "                    # 다중클래스 분류\n",
    "                    shap.waterfall_plot(shap_values[0, :, 0], show=False)\n",
    "                else:\n",
    "                    shap.waterfall_plot(shap_values[0], show=False)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nSHAP Waterfall Plot (Sample 1)')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_waterfall.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"      ⚠️ Waterfall Plot 실패: {e}\")\n",
    "            \n",
    "            # 4. SHAP 값 통계 저장\n",
    "            if hasattr(shap_values, 'values'):\n",
    "                if len(shap_values.values.shape) == 3:\n",
    "                    shap_importance = np.abs(shap_values.values).mean(axis=(0, 2))\n",
    "                else:\n",
    "                    shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "            else:\n",
    "                shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "            \n",
    "            shap_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'shap_importance': shap_importance\n",
    "            }).sort_values('shap_importance', ascending=False)\n",
    "            \n",
    "            shap_df.to_csv(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_values.csv', \n",
    "                          index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"      ✅ SHAP 분석 완료: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ SHAP 분석 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    analyze_shap_comprehensive(saved_best_tuned_models)\n",
    "\n",
    "# %% 셀 16: Feature Importance 분석 (완전 버전)\n",
    "def analyze_feature_importance_comprehensive(saved_models):\n",
    "    print(\"📊 포괄적 Feature Importance 분석\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(saved_models) == 0:\n",
    "        print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 모든 모델의 Feature Importance를 하나의 플롯에 비교\n",
    "    all_importance_data = []\n",
    "    \n",
    "    for key, md in saved_models.items():\n",
    "        center = md['center']\n",
    "        task = md['task']\n",
    "        model_name = md['model_name']\n",
    "        model = md['model']\n",
    "        feature_names = md['feature_names']\n",
    "        \n",
    "        print(f\"\\n📊 {center} - {task} - {model_name} Feature Importance...\")\n",
    "        \n",
    "        try:\n",
    "            # 개별 모델 Feature Importance 시각화\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importance = model.feature_importances_\n",
    "                df_imp = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importance\n",
    "                }).sort_values('importance', ascending=True).tail(20)\n",
    "                \n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature'])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance (Top 20)')\n",
    "                \n",
    "                # 값 표시\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "                \n",
    "                # 전체 비교용 데이터 수집\n",
    "                for _, row in df_imp.iterrows():\n",
    "                    all_importance_data.append({\n",
    "                        'center': center,\n",
    "                        'task': task,\n",
    "                        'model': model_name,\n",
    "                        'feature': row['feature'],\n",
    "                        'importance': row['importance'],\n",
    "                        'type': 'tree_importance'\n",
    "                    })\n",
    "                    \n",
    "            elif hasattr(model, 'coef_'):\n",
    "                # 선형 모델의 계수\n",
    "                if task == 'classification' and len(model.coef_.shape) > 1:\n",
    "                    coef = np.mean(np.abs(model.coef_), axis=0)\n",
    "                else:\n",
    "                    coef = np.abs(model.coef_).flatten()\n",
    "                \n",
    "                df_imp = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': coef\n",
    "                }).sort_values('importance', ascending=True).tail(20)\n",
    "                \n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature'])\n",
    "                plt.xlabel('|Coefficient|')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Coefficients (Top 20)')\n",
    "                \n",
    "                # 값 표시\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "                \n",
    "                # 전체 비교용 데이터 수집\n",
    "                for _, row in df_imp.iterrows():\n",
    "                    all_importance_data.append({\n",
    "                        'center': center,\n",
    "                        'task': task,\n",
    "                        'model': model_name,\n",
    "                        'feature': row['feature'],\n",
    "                        'importance': row['importance'],\n",
    "                        'type': 'coefficient'\n",
    "                    })\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Feature importance not available', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_feature_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"      ✅ Feature Importance 완료: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Feature Importance 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "    \n",
    "    # 전체 Feature Importance 비교 시각화\n",
    "    if all_importance_data:\n",
    "        print(\"\\n📈 전체 모델 Feature Importance 비교...\")\n",
    "        \n",
    "        importance_df = pd.DataFrame(all_importance_data)\n",
    "        \n",
    "        # 회귀 모델들의 상위 피처 비교\n",
    "        reg_data = importance_df[importance_df['task'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            \n",
    "            # 각 회귀 모델별 상위 10개 피처\n",
    "            top_features_reg = reg_data.groupby(['center', 'model'])['importance'].nlargest(10).reset_index()\n",
    "            top_features_reg = top_features_reg.merge(reg_data, on=['center', 'model'])\n",
    "            \n",
    "            pivot_reg = top_features_reg.pivot_table(\n",
    "                values='importance_y', index='feature', \n",
    "                columns=['center', 'model'], fill_value=0\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(pivot_reg, annot=False, cmap='YlOrRd', cbar_kws={'label': 'Importance'})\n",
    "            plt.title('회귀 모델별 Feature Importance 비교 (상위 피처)')\n",
    "            plt.ylabel('Features')\n",
    "            plt.xlabel('Center - Model')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('../results_v3/interpretations/regression_feature_importance_comparison.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        # 분류 모델들의 상위 피처 비교  \n",
    "        clf_data = importance_df[importance_df['task'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            \n",
    "            # 각 분류 모델별 상위 10개 피처\n",
    "            top_features_clf = clf_data.groupby(['center', 'model'])['importance'].nlargest(10).reset_index()\n",
    "            top_features_clf = top_features_clf.merge(clf_data, on=['center', 'model'])\n",
    "            \n",
    "            pivot_clf = top_features_clf.pivot_table(\n",
    "                values='importance_y', index='feature', \n",
    "                columns=['center', 'model'], fill_value=0\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(pivot_clf, annot=False, cmap='YlGnBu', cbar_kws={'label': 'Importance'})\n",
    "            plt.title('분류 모델별 Feature Importance 비교 (상위 피처)')\n",
    "            plt.ylabel('Features')\n",
    "            plt.xlabel('Center - Model')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('../results_v3/interpretations/classification_feature_importance_comparison.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        # 전체 Feature Importance 데이터 저장\n",
    "        importance_df.to_csv('../results_v3/interpretations/all_feature_importance.csv', \n",
    "                           index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"✅ 전체 Feature Importance 비교 완료\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    analyze_feature_importance_comprehensive(saved_best_tuned_models)\n",
    "\n",
    "# %% 셀 17: LIME 분석 (선택적 - 시간이 오래 걸림)\n",
    "def analyze_lime_selective(saved_models, max_models=3):\n",
    "    \"\"\"LIME 분석 (시간 절약을 위해 상위 3개 모델만)\"\"\"\n",
    "    try:\n",
    "        import lime\n",
    "        import lime.lime_tabular\n",
    "        \n",
    "        print(\"🍋 LIME 분석 (상위 3개 모델)\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        if len(saved_models) == 0:\n",
    "            print(\"❌ 분석할 저장된 모델이 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        analyzed = 0\n",
    "        for key, md in saved_models.items():\n",
    "            if analyzed >= max_models:\n",
    "                print(f\"⏰ 시간 절약을 위해 {max_models}개 모델만 LIME 분석합니다.\")\n",
    "                break\n",
    "                \n",
    "            center = md['center']\n",
    "            task = md['task']\n",
    "            model_name = md['model_name']\n",
    "            model = md['model']\n",
    "            X_train = md['X_train']\n",
    "            X_test = md['X_test']\n",
    "            feature_names = md['feature_names']\n",
    "            \n",
    "            print(f\"\\n🍋 {center} - {task} - {model_name} LIME 분석...\")\n",
    "            \n",
    "            try:\n",
    "                if task == 'regression':\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values, feature_names=feature_names, \n",
    "                        mode='regression', verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # 2개 샘플에 대해 설명\n",
    "                    for sample_idx in [0, min(1, len(X_test)-1)]:\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                        \n",
    "                else:\n",
    "                    # 분류\n",
    "                    class_names = [str(c) for c in sorted(model.classes_)]\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values, feature_names=feature_names, \n",
    "                        mode='classification', class_names=class_names, verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # 2개 샘플에 대해 설명\n",
    "                    for sample_idx in [0, min(1, len(X_test)-1)]:\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict_proba, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                \n",
    "                print(f\"      ✅ LIME 분석 완료: {center} - {task} - {model_name}\")\n",
    "                analyzed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ❌ LIME 분석 실패: {center} - {task} - {model_name}, 오류: {str(e)}\")\n",
    "                \n",
    "    except ImportError:\n",
    "        print(\"💡 LIME 분석을 위해서는 `pip install lime` 후 사용하세요.\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    analyze_lime_selective(saved_best_tuned_models)\n",
    "\n",
    "# %% 셀 18: 성능 비교 막대그래프 (필수)\n",
    "def create_performance_comparison_charts(results_df, saved_models):\n",
    "    print(\"📊 성능 비교 막대그래프 생성 (필수)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 비교할 결과가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 1. 센터별 베스트 모델 성능 비교\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 회귀 성능 비교 (R2, RMSE)\n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    if len(reg_data) > 0:\n",
    "        # 센터별 최고 R2 성능\n",
    "        best_r2_by_center = reg_data.loc[reg_data.groupby('center')['R2'].idxmax()]\n",
    "        \n",
    "        bars1 = axes[0,0].bar(best_r2_by_center['center'], best_r2_by_center['R2'])\n",
    "        axes[0,0].set_title('센터별 최고 R2 성능 (회귀)')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "        \n",
    "        # 값 표시\n",
    "        for i, (bar, val) in enumerate(zip(bars1, best_r2_by_center['R2'])):\n",
    "            axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 센터별 최저 RMSE 성능 (낮을수록 좋음)\n",
    "        best_rmse_by_center = reg_data.loc[reg_data.groupby('center')['RMSE'].idxmin()]\n",
    "        \n",
    "        bars2 = axes[0,1].bar(best_rmse_by_center['center'], best_rmse_by_center['RMSE'])\n",
    "        axes[0,1].set_title('센터별 최저 RMSE 성능 (회귀)')\n",
    "        axes[0,1].set_ylabel('RMSE')\n",
    "        \n",
    "        # 값 표시\n",
    "        for i, (bar, val) in enumerate(zip(bars2, best_rmse_by_center['RMSE'])):\n",
    "            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 분류 성능 비교 (F1_weighted, Accuracy)\n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    if len(clf_data) > 0:\n",
    "        # 센터별 최고 F1_weighted 성능\n",
    "        best_f1_by_center = clf_data.loc[clf_data.groupby('center')['F1_weighted'].idxmax()]\n",
    "        \n",
    "        bars3 = axes[1,0].bar(best_f1_by_center['center'], best_f1_by_center['F1_weighted'])\n",
    "        axes[1,0].set_title('센터별 최고 F1_weighted 성능 (분류)')\n",
    "        axes[1,0].set_ylabel('F1 Weighted Score')\n",
    "        axes[1,0].set_ylim(0, 1)\n",
    "        \n",
    "        # 값 표시\n",
    "        for i, (bar, val) in enumerate(zip(bars3, best_f1_by_center['F1_weighted'])):\n",
    "            axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 센터별 최고 Accuracy 성능\n",
    "        best_acc_by_center = clf_data.loc[clf_data.groupby('center')['Accuracy'].idxmax()]\n",
    "        \n",
    "        bars4 = axes[1,1].bar(best_acc_by_center['center'], best_acc_by_center['Accuracy'])\n",
    "        axes[1,1].set_title('센터별 최고 Accuracy 성능 (분류)')\n",
    "        axes[1,1].set_ylabel('Accuracy')\n",
    "        axes[1,1].set_ylim(0, 1)\n",
    "        \n",
    "        # 값 표시\n",
    "        for i, (bar, val) in enumerate(zip(bars4, best_acc_by_center['Accuracy'])):\n",
    "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/performance_comparison_by_center.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. 모델별 평균 성능 비교\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # 회귀 모델별 평균 성능\n",
    "    if len(reg_data) > 0:\n",
    "        reg_model_perf = reg_data.groupby('model')[['R2', 'RMSE', 'SMAPE']].mean().sort_values('R2', ascending=False)\n",
    "        \n",
    "        x = range(len(reg_model_perf))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = axes[0].bar([i - width for i in x], reg_model_perf['R2'], width, label='R2', alpha=0.8)\n",
    "        # RMSE와 SMAPE는 정규화 (0-1 범위로)\n",
    "        rmse_normalized = 1 - (reg_model_perf['RMSE'] / reg_model_perf['RMSE'].max())\n",
    "        smape_normalized = 1 - (reg_model_perf['SMAPE'] / 100)  # SMAPE는 백분율\n",
    "        \n",
    "        bars2 = axes[0].bar(x, rmse_normalized, width, label='1-RMSE(norm)', alpha=0.8)\n",
    "        bars3 = axes[0].bar([i + width for i in x], smape_normalized, width, label='1-SMAPE(norm)', alpha=0.8)\n",
    "        \n",
    "        axes[0].set_title('모델별 평균 회귀 성능')\n",
    "        axes[0].set_ylabel('Normalized Score (Higher is Better)')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(reg_model_perf.index, rotation=45)\n",
    "        axes[0].legend()\n",
    "        axes[0].set_ylim(0, 1.1)\n",
    "    \n",
    "    # 분류 모델별 평균 성능\n",
    "    if len(clf_data) > 0:\n",
    "        clf_model_perf = clf_data.groupby('model')[['Accuracy', 'F1_weighted', 'F1_macro']].mean().sort_values('F1_weighted', ascending=False)\n",
    "        \n",
    "        x = range(len(clf_model_perf))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = axes[1].bar([i - width for i in x], clf_model_perf['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "        bars2 = axes[1].bar(x, clf_model_perf['F1_weighted'], width, label='F1_weighted', alpha=0.8)\n",
    "        bars3 = axes[1].bar([i + width for i in x], clf_model_perf['F1_macro'], width, label='F1_macro', alpha=0.8)\n",
    "        \n",
    "        axes[1].set_title('모델별 평균 분류 성능')\n",
    "        axes[1].set_ylabel('Score')\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels(clf_model_perf.index, rotation=45)\n",
    "        axes[1].legend()\n",
    "        axes[1].set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/performance_comparison_by_model.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ 성능 비교 막대그래프 생성 완료\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_performance_comparison_charts(results_df, saved_best_tuned_models if 'saved_best_tuned_models' in locals() else {})\n",
    "\n",
    "# %% 셀 19: 예측 유틸리티 함수들\n",
    "def predict_with_best_tuned_model(center, task, new_data):\n",
    "    \"\"\"베스트 튜닝된 모델로 예측\"\"\"\n",
    "    model_files = [f for f in os.listdir('../models_v3/best_tuned_models/') \n",
    "                   if f.startswith(f'{center}_{task}_') and f.endswith('_tuned.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"❌ {center} - {task} 튜닝된 모델 파일을 찾을 수 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    filepath = f\"../models_v3/best_tuned_models/{model_files[0]}\"\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = model_data['model']\n",
    "        feature_names = model_data['feature_names']\n",
    "        best_params = model_data['best_params']\n",
    "        \n",
    "        # 필요한 피처 체크\n",
    "        missing_features = [col for col in feature_names if col not in new_data.columns]\n",
    "        if missing_features:\n",
    "            print(f\"❌ 누락된 피처: {missing_features}\")\n",
    "            return None\n",
    "        \n",
    "        X_new = new_data[feature_names]\n",
    "        \n",
    "        if task == 'regression':\n",
    "            predictions = model.predict(X_new)\n",
    "            print(f\"✅ {center} - {task} 예측 완료 (샘플: {len(predictions)}개)\")\n",
    "            print(f\"🔧 사용된 하이퍼파라미터: {best_params}\")\n",
    "            return predictions\n",
    "        else:\n",
    "            predictions = model.predict(X_new)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                probabilities = model.predict_proba(X_new)\n",
    "                print(f\"✅ {center} - {task} 예측 완료 (샘플: {len(predictions)}개)\")\n",
    "                print(f\"🔧 사용된 하이퍼파라미터: {best_params}\")\n",
    "                return predictions, probabilities\n",
    "            else:\n",
    "                print(f\"✅ {center} - {task} 예측 완료 (샘플: {len(predictions)}개)\")\n",
    "                print(f\"🔧 사용된 하이퍼파라미터: {best_params}\")\n",
    "                return predictions\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 예측 실패: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_best_tuned_model(center, task):\n",
    "    \"\"\"베스트 튜닝된 모델 로드\"\"\"\n",
    "    model_files = [f for f in os.listdir('../models_v3/best_tuned_models/') \n",
    "                   if f.startswith(f'{center}_{task}_') and f.endswith('_tuned.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"❌ {center} - {task} 튜닝된 모델 파일을 찾을 수 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    filepath = f\"../models_v3/best_tuned_models/{model_files[0]}\"\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        print(f\"✅ 모델 로드 완료: {center} - {task} - {model_data['model_name']}\")\n",
    "        print(f\"🔧 하이퍼파라미터: {model_data['best_params']}\")\n",
    "        return model_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 로드 실패: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"🔮 예측 함수 정의 완료\")\n",
    "\n",
    "# %% 셀 20: 모델 성능 요약 리포트 생성\n",
    "def create_performance_summary_report(results_df, best_models_df):\n",
    "    print(\"📄 모델 성능 요약 리포트 생성\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"❌ 리포트 생성할 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 리포트 내용 생성\n",
    "    report = []\n",
    "    report.append(\"# 🏆 하수처리량 예측 모델링 성능 요약 리포트\")\n",
    "    report.append(\"=\"*60)\n",
    "    report.append(f\"생성 일시: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report.append(f\"총 학습 모델 수: {len(results_df)}\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # 센터별 베스트 모델 요약\n",
    "    report.append(\"## 📊 센터별 베스트 모델 요약\")\n",
    "    report.append(\"-\" * 40)\n",
    "    \n",
    "    for center in pipeline.centers:\n",
    "        report.append(f\"\\n### 🏢 {center.upper()} 센터\")\n",
    "        \n",
    "        # 회귀 베스트\n",
    "        reg_best = results_df[(results_df['center']==center) & (results_df['task']=='regression')]\n",
    "        if len(reg_best) > 0:\n",
    "            best_reg = reg_best.loc[reg_best['R2'].idxmax()]\n",
    "            report.append(f\"**회귀 모델**: {best_reg['model']} ({best_reg['split_method']})\")\n",
    "            report.append(f\"- R2: {best_reg['R2']:.4f}\")\n",
    "            report.append(f\"- RMSE: {best_reg['RMSE']:.2f}\")\n",
    "            report.append(f\"- SMAPE: {best_reg['SMAPE']:.2f}%\")\n",
    "            \n",
    "        # 분류 베스트\n",
    "        clf_best = results_df[(results_df['center']==center) & (results_df['task']=='classification')]\n",
    "        if len(clf_best) > 0:\n",
    "            best_clf = clf_best.loc[clf_best['F1_weighted'].idxmax()]\n",
    "            report.append(f\"**분류 모델**: {best_clf['model']} ({best_clf['split_method']})\")\n",
    "            report.append(f\"- F1_weighted: {best_clf['F1_weighted']:.4f}\")\n",
    "            report.append(f\"- Accuracy: {best_clf['Accuracy']:.4f}\")\n",
    "            report.append(f\"- F1_macro: {best_clf['F1_macro']:.4f}\")\n",
    "    \n",
    "    # 전체 성능 통계\n",
    "    report.append(f\"\\n## 📈 전체 성능 통계\")\n",
    "    report.append(\"-\" * 40)\n",
    "    \n",
    "    reg_data = results_df[results_df['task']=='regression']\n",
    "    clf_data = results_df[results_df['task']=='classification']\n",
    "    \n",
    "    if len(reg_data) > 0:\n",
    "        report.append(f\"**회귀 모델 성능 (R2)**:\")\n",
    "        report.append(f\"- 최고: {reg_data['R2'].max():.4f}\")\n",
    "        report.append(f\"- 평균: {reg_data['R2'].mean():.4f}\")\n",
    "        report.append(f\"- 최저: {reg_data['R2'].min():.4f}\")\n",
    "        \n",
    "    if len(clf_data) > 0:\n",
    "        report.append(f\"**분류 모델 성능 (F1_weighted)**:\")\n",
    "        report.append(f\"- 최고: {clf_data['F1_weighted'].max():.4f}\")\n",
    "        report.append(f\"- 평균: {clf_data['F1_weighted'].mean():.4f}\")\n",
    "        report.append(f\"- 최저: {clf_data['F1_weighted'].min():.4f}\")\n",
    "    \n",
    "    # 리포트 저장\n",
    "    report_text = \"\\n\".join(report)\n",
    "    with open('../results_v3/model_performance_summary_report.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(\"✅ 성능 요약 리포트 저장: ../results_v3/model_performance_summary_report.md\")\n",
    "    print(\"\\n\" + report_text)\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_performance_summary_report(results_df, best_tuned_models_df if 'best_tuned_models_df' in locals() else None)\n",
    "    \n",
    "    \n",
    "# %% 셀 21: 최종 완료 체크리스트 및 요약\n",
    "def final_completion_checklist():\n",
    "    print(\"📋 최종 완료 체크리스트 - 고급 버전\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    checklist = {}\n",
    "    \n",
    "    # 기본 요구사항\n",
    "    checklist[\"1. 데이터 로드 및 전처리\"] = len(data_info) > 0 if 'data_info' in globals() else False\n",
    "    checklist[\"2. 하이퍼파라미터 튜닝 실행\"] = len(pipeline.tuning_results) > 0\n",
    "    checklist[\"3. 교차검증 수행\"] = 'cv_results' in str(pipeline.results) if pipeline.results else False\n",
    "    checklist[\"4. 불균형 데이터 처리 (SMOTE)\"] = any('used_smote' in str(r) for r in pipeline.results)\n",
    "    checklist[\"5. 전체 결과 저장\"] = os.path.exists('../results_v3/all_model_results_with_tuning.csv')\n",
    "    \n",
    "    # 시각화 요구사항\n",
    "    viz_files = [\n",
    "        'hyperparameter_tuning_analysis.png',\n",
    "        'model_performance_comparison.png', \n",
    "        'comprehensive_performance_overview.png',\n",
    "        'cross_validation_analysis.png',\n",
    "        'advanced_roc_curves.png',\n",
    "        'confusion_matrices.png',\n",
    "        'performance_comparison_by_center.png',\n",
    "        'performance_comparison_by_model.png'\n",
    "    ]\n",
    "    viz_dir = '../results_v3/visualizations/'\n",
    "    viz_count = sum([os.path.exists(os.path.join(viz_dir, f)) for f in viz_files])\n",
    "    checklist[\"6. 시각화 자료 (8개)\"] = viz_count >= 6\n",
    "    \n",
    "    # 해석 가능성 분석\n",
    "    interp_dir = '../results_v3/interpretations/'\n",
    "    shap_files = len([f for f in os.listdir(interp_dir) if 'shap' in f.lower()]) if os.path.exists(interp_dir) else 0\n",
    "    fi_files = len([f for f in os.listdir(interp_dir) if 'feature_importance' in f]) if os.path.exists(interp_dir) else 0\n",
    "    checklist[\"7. SHAP 분석\"] = shap_files >= 3\n",
    "    checklist[\"8. Feature Importance 분석\"] = fi_files >= 3\n",
    "    \n",
    "    # 베스트 모델\n",
    "    model_dir = '../models_v3/best_tuned_models/'\n",
    "    model_files = len([f for f in os.listdir(model_dir) if f.endswith('_tuned.pkl')]) if os.path.exists(model_dir) else 0\n",
    "    checklist[\"9. 베스트 튜닝 모델 저장 (8개)\"] = model_files >= 8\n",
    "    checklist[\"10. 성능 요약 리포트\"] = os.path.exists('../results_v3/model_performance_summary_report.md')\n",
    "    \n",
    "    # 체크리스트 출력\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"✅\" if status else \"❌\"\n",
    "        print(f\"{status_icon} {item}\")\n",
    "    \n",
    "    completed = sum(1 for v in checklist.values() if v)\n",
    "    total = len(checklist)\n",
    "    completion_rate = completed / total * 100\n",
    "    \n",
    "    print(f\"\\n📊 전체 완료율: {completion_rate:.1f}% ({completed}/{total})\")\n",
    "    \n",
    "    if completion_rate >= 95:\n",
    "        print(\"🎉 고급 하이퍼파라미터 튜닝 프로젝트가 완벽하게 완료되었습니다!\")\n",
    "    elif completion_rate >= 85:\n",
    "        print(\"🌟 프로젝트가 거의 완료되었습니다!\")\n",
    "    else:\n",
    "        print(\"⚠️ 일부 단계에서 문제가 발생했습니다. 로그를 확인해주세요.\")\n",
    "    \n",
    "    return checklist\n",
    "\n",
    "final_checklist = final_completion_checklist()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚀 고급 하수처리량 예측 모델링 프로젝트 완료!\")\n",
    "print(\"✨ 하이퍼파라미터 튜닝, 교차검증, 불균형 처리, 포괄적 분석 완료!\")\n",
    "print(f\"⏰ 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843ad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
