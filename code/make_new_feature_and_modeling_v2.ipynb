{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617d293d",
   "metadata": {},
   "source": [
    "ì¢‹ì•„ìš”! ì˜¬ë ¤ì£¼ì‹  ë…¸íŠ¸ë¶ì´ ì‹¤í–‰ë˜ë©´ â€œì–´ë–¤ íŒŒì¼ì´ ì–´ë””ì— ë§Œë“¤ì–´ì§€ê³ , ê·¸ê²Œ ë¬´ìŠ¨ ì˜ë¯¸ì¸ì§€â€ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•´ ë“œë¦´ê²Œìš”. ê·¸ë¦¬ê³  í”„ë¡œì íŠ¸ì˜ ëª©ì /ëª¨ë¸/ì§€í‘œ/ë¶„í• ì „ëµ/íƒ€ê¹ƒê¹Œì§€ í•µì‹¬ì„ ê¹”ë”íˆ ìš”ì•½í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "# 1) ì‚°ì¶œë¬¼(íŒŒì¼)ê³¼ ê²½ë¡œ, ê·¸ë¦¬ê³  ì˜ë¯¸\n",
    "\n",
    "## A. ê²°ê³¼ ìš”ì•½Â·ì›ì²œ í…Œì´ë¸” (`../results_v2`)\n",
    "\n",
    "* **`all_model_results.csv`**\n",
    "  4ê°œ ì„¼í„° Ã— 2ë¶„í• (temporal/random) Ã— 2íƒœìŠ¤í¬(regression/classification) Ã— 6ëª¨ë¸ = **ìµœëŒ€ 96ê°œ ì‹¤í—˜ ê²°ê³¼**ê°€ í–‰ ë‹¨ìœ„ë¡œ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "  í¬í•¨ ì»¬ëŸ¼ ì˜ˆì‹œ\n",
    "\n",
    "  * ê³µí†µ ë©”íƒ€: `center`, `split_method`, `task`, `model`\n",
    "  * íšŒê·€ ì§€í‘œ: `MAE, MSE, RMSE, MAPE, SMAPE, R2`\n",
    "  * ë¶„ë¥˜ ì§€í‘œ: `Accuracy, Precision_weighted, Precision_macro, Recall_weighted, Recall_macro, F1_weighted, F1_macro, AUC`\n",
    "    â†’ **ëª¨ë“  ì‹¤í—˜ì˜ ì„±ëŠ¥ ë¹„êµ**ë¥¼ ìœ„í•œ ë§ˆìŠ¤í„° í…Œì´ë¸”.\n",
    "\n",
    "* **`best_models.csv`**\n",
    "  ì„¼í„°ë³„ **íšŒê·€ 1ê°œ(ìµœê³  R2)**, \\*\\*ë¶„ë¥˜ 1ê°œ(ìµœê³  F1\\_weighted)\\*\\*ë¥¼ ë½‘ì•„ í•©ì¹œ **í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ í‘œ(ìµœëŒ€ 8í–‰)**.\n",
    "  â†’ ìš´ì˜/ì¬í•™ìŠµ ëŒ€ìƒ â€œëŒ€í‘œ ëª¨ë¸ ë¼ì¸ì—…â€ì„ í•œ ì¥ìœ¼ë¡œ í™•ì¸.\n",
    "\n",
    "* **`best_models_individual/` (í´ë”)**\n",
    "  íŒŒì¼ëª… íŒ¨í„´: `CENTER_SPLIT_TASK_models.csv` (ì˜ˆ: `nanji_temporal_regression_models.csv`)\n",
    "  ê° ì¡°ê±´(ì„¼í„° Ã— ë¶„í•  Ã— íƒœìŠ¤í¬)ì—ì„œ **ëª¨ë“  ëª¨ë¸ì„ ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬**í•œ ìƒì„¸ í…Œì´ë¸”.\n",
    "  â†’ ì´ **8ê°œì˜ ì„¸ë¶€ ë­í‚¹í‘œ**ë¡œ, í•´ë‹¹ ì¡°ê±´ì—ì„œ ë¬´ì—‡ì´ ìµœì„ ì¸ì§€ íˆ¬ëª…í•˜ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "## B. ì‹œê°í™” (`../results_v2/visualizations`)\n",
    "\n",
    "* **`basic_performance_comparison.png`**\n",
    "\n",
    "  * ì„¼í„°Ã—ë¶„í• ë³„ **íšŒê·€ R2** ë¹„êµ ë°”ì°¨íŠ¸\n",
    "  * ì„¼í„°Ã—ë¶„í• ë³„ **ë¶„ë¥˜ F1\\_weighted** ë¹„êµ ë°”ì°¨íŠ¸\n",
    "  * **ëª¨ë¸ë³„ í‰ê·  R2 / ëª¨ë¸ë³„ í‰ê·  F1\\_weighted** ë°”ì°¨íŠ¸\n",
    "    â†’ í° ê·¸ë¦¼ì—ì„œ â€œì–´ëŠ ë¶„í• ì´ ìœ ë¦¬í•œê°€, í‰ê· ì ìœ¼ë¡œ ì–´ë–¤ ëª¨ë¸ì´ ê°•í•œê°€â€ í™•ì¸.\n",
    "\n",
    "* **`regression_detailed_comparison.png`**\n",
    "  ì„¼í„°Ã—ëª¨ë¸ ì¶•ìœ¼ë¡œ **R2 / MAE / RMSE / SMAPE**ë¥¼ ê°ê° ë¹„êµ.\n",
    "  â†’ íšŒê·€ ì§€í‘œë¥¼ ë‹¤ë©´ì ìœ¼ë¡œ ì‚´í´ë³´ëŠ” â€œì •ë°€ ë¹„êµíŒâ€.\n",
    "\n",
    "* **`classification_detailed_comparison.png`**\n",
    "  ì„¼í„°Ã—ëª¨ë¸ ì¶•ìœ¼ë¡œ **Accuracy / F1\\_weighted / F1\\_macro / AUC** ë¹„êµ.\n",
    "  â†’ ë¶„ë¥˜ ì§€í‘œë¥¼ ë‹¤ë©´ì ìœ¼ë¡œ ì‚´í´ë³´ëŠ” â€œì •ë°€ ë¹„êµíŒâ€.\n",
    "\n",
    "* **`same_model_center_comparison_regression.png`**\n",
    "  **ê°™ì€ íšŒê·€ ëª¨ë¸**ì´ ì„¼í„°ë³„ë¡œ ì–¼ë§ˆë‚˜ ì¼ê´€ë˜ê²Œ ì˜í•˜ëŠ”ì§€ **R2**ë¡œ ë¹„êµ.\n",
    "\n",
    "* **`same_model_center_comparison_classification.png`**\n",
    "  **ê°™ì€ ë¶„ë¥˜ ëª¨ë¸**ì´ ì„¼í„°ë³„ë¡œ ì–¼ë§ˆë‚˜ ì¼ê´€ë˜ê²Œ ì˜í•˜ëŠ”ì§€ **F1\\_weighted**ë¡œ ë¹„êµ.\n",
    "\n",
    "* **`roc_curves.png`**\n",
    "  ë² ìŠ¤íŠ¸ë¡œ ì„ ë°œë˜ì–´ ì¬í•™ìŠµëœ **ë¶„ë¥˜ ëª¨ë¸ë“¤**ì˜ ROC ê³¡ì„ (ì„¼í„°ë³„ ìµœëŒ€ 4ê°œ íŒ¨ë„).\n",
    "  â†’ \\*\\*ì„ê³„ê°’ ë³€í™”ì— ë”°ë¥¸ ë¶„ë¥˜ ì„±ëŠ¥(ë¯¼ê°ë„-ìœ„ì–‘ì„±ë¥ )\\*\\*ì„ ì§ê´€ì ìœ¼ë¡œ í™•ì¸.\n",
    "\n",
    "## C. ëª¨ë¸ í•´ì„(ì„¤ëª…ê°€ëŠ¥ì„±) (`../results_v2/interpretations`)\n",
    "\n",
    "* **`*_shap_summary.png` / `*_shap_importance.png` / `*_shap_force_*.png`**\n",
    "  ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ê°ê°ì— ëŒ€í•´:\n",
    "\n",
    "  * **SHAP Summary**(ë¶„í¬/ì˜í–¥ ë°©í–¥), **SHAP Feature Importance**(í‰ê·  ì ˆëŒ€ ì˜í–¥), **Force/Waterfall**(ê°œë³„ ì˜ˆì¸¡ ì„¤ëª…)\n",
    "    â†’ **ì™œ ê·¸ëŸ° ì˜ˆì¸¡ì´ ë‚˜ì™”ëŠ”ì§€**ë¥¼ ê¸€ë¡œë²Œ/ë¡œì»¬ ê´€ì ì—ì„œ ì„¤ëª….\n",
    "\n",
    "* **`*_feature_importance.png`**\n",
    "  íŠ¸ë¦¬ ê³„ì—´ì˜ `feature_importances_` ë˜ëŠ” ì„ í˜•ê³„ì—´ì˜ `|coef|` ê¸°ì¤€ **ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„**.\n",
    "  â†’ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§/í˜„ì—… í•´ì„ì— ì¦‰ì‹œ í™œìš© ê°€ëŠ¥.\n",
    "\n",
    "* **`*_lime_sample_*.png` (ì„ íƒ)**\n",
    "  LIME ë¡œì»¬ ì„¤ëª… ê²°ê³¼(ìµœëŒ€ 3ê°œ ëª¨ë¸, ìƒ˜í”Œ 2ê±´).\n",
    "  â†’ ê°œë³„ ì‚¬ë¡€ì—ì„œì˜ **ì§ê´€ì  í”¼ì²˜ ê¸°ì—¬ ì„¤ëª…**.\n",
    "\n",
    "## D. ì €ì¥ëœ ìš´ì˜ í›„ë³´ ëª¨ë¸ (`../models_v2/best_models`)\n",
    "\n",
    "* **íŒŒì¼ëª… íŒ¨í„´:** `CENTER_TASK_MODEL_SPLIT.pkl`\n",
    "  ì˜ˆ: `nanji_classification_LightGBM_random.pkl`\n",
    "  **ë‚´ìš©ë¬¼:**\n",
    "\n",
    "  * í•™ìŠµëœ ëª¨ë¸ ê°ì²´, `feature_names`, `X_train/X_test`, `y_train/y_test`, `y_pred`, (ë¶„ë¥˜ì‹œ) `y_pred_proba`\n",
    "  * ë©”íƒ€ì •ë³´(`task`, `center`, `split_method`, `model_name`, `performance`)\n",
    "    â†’ **ì˜ˆì¸¡ ë°°í¬/ë°°ì¹˜ ì²˜ë¦¬**ì— ë°”ë¡œ ì¬ì‚¬ìš©.\n",
    "\n",
    "## E. ì‹¤í–‰/ì²´í¬ ë¡œê·¸ (ë…¸íŠ¸ë¶ ì¶œë ¥)\n",
    "\n",
    "* **ì²´í¬ë¦¬ìŠ¤íŠ¸(ì…€ 19)**: ìƒì„± ì„±ê³µ ì—¬ë¶€(íŒŒì¼/ê·¸ë¦¼ ê°œìˆ˜, ì§€í‘œ í¬í•¨ ì—¬ë¶€ ë“±)ì™€ **ì™„ë£Œìœ¨**(%)ì„ ìš”ì•½.\n",
    "* **íŠœë‹ ì˜ˆì‹œ ì½”ë“œ(ì…€ 18)**: Grid/Randomized/Optuna í…œí”Œë¦¿ ì¶œë ¥.\n",
    "\n",
    "---\n",
    "\n",
    "# 2) ì´ ì½”ë“œì˜ ëª©ì \n",
    "\n",
    "* **ëª©í‘œ:** í•˜ìˆ˜ì²˜ë¦¬ì„¼í„°ë³„ë¡œ \\*\\*í•˜ë£¨ ë’¤(ë˜ëŠ” ë¯¸ë˜ ì‹œì )ì˜ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰(íšŒê·€)\\*\\*ê³¼ \\*\\*ë“±ê¸‰(ë¶„ë¥˜)\\*\\*ì„ ì˜ˆì¸¡í•˜ëŠ” **ì™„ì „ ìë™í™” íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•.\n",
    "* **ì„±ê³¼:**\n",
    "\n",
    "  1. ë™ì¼ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ **ëª¨ë¸ í›„ë³´êµ°ì„ ëŒ€ëŸ‰ í•™ìŠµÂ·í‰ê°€**\n",
    "  2. **ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ ë°œ â†’ ì¬í•™ìŠµ â†’ ì €ì¥**ê¹Œì§€ ì¼ê´€ ìˆ˜í–‰\n",
    "  3. \\*\\*ì‹œê°í™”/ì„¤ëª…ê°€ëŠ¥ì„±(SHAP/LIME)\\*\\*ë¡œ ê²°ê³¼ë¥¼ ì´í•´Â·ê²€ì¦\n",
    "  4. **ìƒˆ ë°ì´í„° ì˜ˆì¸¡ í•¨ìˆ˜**ë¡œ ìš´ì˜ ì—°ê³„\n",
    "\n",
    "---\n",
    "\n",
    "# 3) ì‚¬ìš©í•œ ëª¨ë¸(ì•Œê³ ë¦¬ì¦˜)\n",
    "\n",
    "* **íšŒê·€(6)**: `LinearRegression`, `RandomForestRegressor`, `XGBRegressor`, `CatBoostRegressor`, `GradientBoostingRegressor`, `LGBMRegressor`\n",
    "* **ë¶„ë¥˜(6)**: `LogisticRegression`, `RandomForestClassifier`, `XGBClassifier`, `CatBoostClassifier`, `GradientBoostingClassifier`, `LGBMClassifier`\n",
    "* **ì„ ë°œ ê¸°ì¤€**\n",
    "\n",
    "  * íšŒê·€: **R2ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸**\n",
    "  * ë¶„ë¥˜: **F1\\_weightedê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸**\n",
    "\n",
    "---\n",
    "\n",
    "# 4) ì„±ëŠ¥ í‰ê°€ì§€í‘œ\n",
    "\n",
    "## íšŒê·€\n",
    "\n",
    "* **MAE**(í‰ê· ì ˆëŒ€ì˜¤ì°¨), **MSE**, **RMSE**, **MAPE**, **SMAPE**(ëŒ€ì¹­ MAPE), **R2**\n",
    "* **ì¶”ì²œ í•´ì„:**\n",
    "\n",
    "  * **R2**ê°€ í´ìˆ˜ë¡ ì„¤ëª…ë ¥ì´ ì¢‹ìŒ\n",
    "  * **SMAPE**ëŠ” ìŠ¤ì¼€ì¼/ì˜(0) ê·¼ì²˜ê°’ì— ëœ ë¯¼ê°â€”í˜„ì—… **ì˜ˆì¸¡ì˜¤ì°¨ %** í•´ì„ì— ìœ ë¦¬\n",
    "  * **RMSE/MAE**ëŠ” ì ˆëŒ€ ì˜¤ì°¨ì˜ ì§ê´€ì  í¬ê¸°ë¥¼ ë³´ì—¬ì¤Œ\n",
    "\n",
    "## ë¶„ë¥˜\n",
    "\n",
    "* **Accuracy**, **Precision(weighted/macro)**, **Recall(weighted/macro)**, **F1(weighted/macro)**, **AUC**\n",
    "* **ì¶”ì²œ í•´ì„:**\n",
    "\n",
    "  * **F1\\_weighted**ëŠ” í´ë˜ìŠ¤ ë¶ˆê· í˜• ìƒí™©ì—ì„œ í‰ê· ì ì¸ ê· í˜• ì„±ëŠ¥ì„ ë°˜ì˜\n",
    "  * **F1\\_macro**ëŠ” ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ë™ì¼ ê°€ì¤‘ìœ¼ë¡œ ë³´ì•„ **ì†Œìˆ˜ í´ë˜ìŠ¤ ì„±ëŠ¥**ê¹Œì§€ ë°˜ì˜\n",
    "  * **AUC**ëŠ” ì„ê³„ê°’ ì „ ì˜ì—­ì—ì„œ ë¶„ë¥˜ë ¥(ìˆœìœ„í™” ëŠ¥ë ¥) í‰ê°€\n",
    "\n",
    "---\n",
    "\n",
    "# 5) ë°ì´í„° ë¶„í•  ì „ëµ ë¹„êµ\n",
    "\n",
    "* **temporal split**: ì‹œê³„ì—´ ìˆœì„œë¥¼ **ìœ ì§€**í•´ ê³¼ê±°â†’ë¯¸ë˜ë¡œ í•™ìŠµ/í‰ê°€ (í˜„ì‹¤ì Â·ë³´ìˆ˜ì )\n",
    "* **random split**: í‘œë³¸ì„ ë¬´ì‘ìœ„ë¡œ ì„ì–´ í›ˆë ¨/í‰ê°€ (ë¶„ë¥˜ëŠ” `stratify`ë¡œ í´ë˜ìŠ¤ ê· í˜• ìœ ì§€)\n",
    "* **ê¶Œì¥ í•´ì„:**\n",
    "\n",
    "  * **ì‹œê°„ ì˜ì¡´ì„±**ì´ í° ë¬¸ì œ(í•˜ìˆ˜ëŸ‰)ì—ì„œëŠ” ë³´í†µ **temporal**ì´ í˜„ì‹¤ì„± ìˆëŠ” ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œ\n",
    "  * **random**ì€ ê³¼ì í•© ìœ„í—˜ì´ ë” ë‚®ê²Œ ë³´ì¼ ìˆ˜ ìˆìœ¼ë‚˜, **ì‹¤ìš´ì˜ ì„±ëŠ¥**ì„ ê³¼ëŒ€ì¶”ì •í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ **temporal ê²°ê³¼ë¥¼ ìš°ì„  ì°¸ê³ **\n",
    "\n",
    "---\n",
    "\n",
    "# 6) ì˜ˆì¸¡ íƒ€ê¹ƒ(ëª©í‘œ ë³€ìˆ˜)\n",
    "\n",
    "* **íšŒê·€(ì—°ì†ê°’):** `í•©ê³„_1ì¼í›„`\n",
    "\n",
    "  * â€œí•´ë‹¹ ì„¼í„°ì˜ **ë‹¤ìŒ ë‚  ì´ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰**â€ ì˜ˆì¸¡\n",
    "* **ë¶„ë¥˜(ë²”ì£¼í˜•):** `ë“±ê¸‰_1ì¼í›„`\n",
    "\n",
    "  * â€œí•´ë‹¹ ì„¼í„°ì˜ **ë‹¤ìŒ ë‚  ë“±ê¸‰(ìš´ì˜ ìƒíƒœ/ë¶€í•˜ ìˆ˜ì¤€ ë“±)**â€ ì˜ˆì¸¡\n",
    "* ì…ë ¥ í”¼ì²˜ëŠ” `not_use_col`ì— ëª…ì‹œëœ **ì œì™¸ ì»¬ëŸ¼**ì„ ë¹¼ê³  **ë‚˜ë¨¸ì§€ ì „ë¶€** ì‚¬ìš©\n",
    "\n",
    "  * ì œì™¸ ëª©ë¡ì—” ë‚ ì§œ, ì²˜ë¦¬ì¥ ì„¸ë¶€í•©ê³„, **ë¯¸ë˜ ëˆ„ì¶œ ì»¬ëŸ¼(í•©ê³„\\_1ì¼í›„/2ì¼í›„, ë“±ê¸‰\\_1ì¼í›„/2ì¼í›„)** ë“±ì´ í¬í•¨ë˜ì–´ **ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€**\n",
    "\n",
    "---\n",
    "\n",
    "# 7) ì‹¤í–‰ ì „ì œ(ë°ì´í„°/ê²½ë¡œ/í™˜ê²½)\n",
    "\n",
    "* **ì…ë ¥ ë°ì´í„° ê²½ë¡œ**: `../data/add_feature/{center}_add_feature.csv`\n",
    "\n",
    "  * centers ê¸°ë³¸ê°’: `['nanji', 'jungnang', 'seonam', 'tancheon']`\n",
    "  * ì‹¤ì œ ì„¼í„°ëª…/íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ëŠ” ì…€ 5ì—ì„œ í™•ì¸ ë¡œê·¸ ì¶œë ¥\n",
    "* **ê²°ê³¼/ëª¨ë¸ ì €ì¥ ë£¨íŠ¸**: `../results_v2/`, `../models_v2/` (ì—†ìœ¼ë©´ ìë™ ìƒì„±)\n",
    "* **í°íŠ¸**: `AppleGothic` (ë§¥ ê¸°ì¤€). ìœˆë„ìš°/ë¦¬ëˆ…ìŠ¤ëŠ” ë‹¤ë¥¸ í•œê¸€ í°íŠ¸ë¡œ êµì²´ í•„ìš” ê°€ëŠ¥.\n",
    "\n",
    "---\n",
    "\n",
    "# 8) ìš´ì˜ í™œìš© í¬ì¸íŠ¸\n",
    "\n",
    "* **ì¦‰ì‹œ ì˜ˆì¸¡**: `predict_with_saved_model(center, task, new_data)`\n",
    "\n",
    "  * ì €ì¥ëœ pklì„ ë¡œë“œí•´ **í”¼ì²˜ ìˆœì„œ ë§ì¶˜ ë’¤** ì˜ˆì¸¡ ë°˜í™˜ (ë¶„ë¥˜ëŠ” í™•ë¥ ë„)\n",
    "* **ëª¨ë¸ ì ê²€/ì„¤ëª…**:\n",
    "\n",
    "  * SHAP/LIME ê·¸ë¦¼ìœ¼ë¡œ **ì™œ ê·¸ë ‡ê²Œ ë‚˜ì™”ëŠ”ì§€** ë‚´ë¶€ ê³µìœ /ë³´ê³ ì„œì— ë°”ë¡œ ì‚¬ìš©\n",
    "* **ì§€ì† ê°œì„ **:\n",
    "\n",
    "  * `best_models_individual` í‘œì™€ ìƒì„¸ ì‹œê°í™”ë¡œ **ì•½ì  ì¡°ê±´**ì„ íŒŒì•…í•˜ê³ \n",
    "  * ì…€ 18 íŠœë‹ í…œí”Œë¦¿(Grid/Random/Optuna) ì ìš© â†’ ì„±ëŠ¥ ë³´ê°•\n",
    "  * ì…€ 20ì˜ **ëª¨ë‹ˆí„°ë§/ë“œë¦¬í”„íŠ¸ ê°ì§€** ìœ í‹¸ë¡œ ìš´ì˜ ì¤‘ í’ˆì§ˆ ê´€ë¦¬\n",
    "\n",
    "---\n",
    "\n",
    "# 9) ë¹ ë¥¸ ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸(í•µì‹¬ë§Œ)\n",
    "\n",
    "* `all_model_results.csv` ì¡´ì¬? â†’ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ OK\n",
    "* `best_models.csv` ì¡´ì¬? â†’ ì„¼í„°Ã—íƒœìŠ¤í¬ ë² ìŠ¤íŠ¸ 8ê°œ ì„ ë°œ OK\n",
    "* `best_models_individual/`ì— 8ê°œ CSV? â†’ ì¡°ê±´ë³„ ë­í‚¹ OK\n",
    "* `visualizations/` 5ê°œ ì´ìƒ PNG? â†’ ë¹„êµ/ì •ë°€/ë™ì¼ëª¨ë¸/ROC OK\n",
    "* `interpretations/`ì— SHAP/Feature Importance(LIME ì„ íƒ) PNG ë‹¤ìˆ˜? â†’ í•´ì„ OK\n",
    "* `models_v2/best_models/`ì— pkl 8ê°œ? â†’ ë°°í¬ì¤€ë¹„ OK\n",
    "\n",
    "---\n",
    "\n",
    "í•„ìš”í•˜ì‹œë©´,\n",
    "\n",
    "* **ìš´ì˜ ë°°í¬ìš© ê²½ëŸ‰ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸**,\n",
    "* **ë°ì´í„° ê²€ì¦(ìŠ¤í‚¤ë§ˆ/ê²°ì¸¡/ì´ìƒì¹˜) ìë™ì²´í¬ ì „ì²˜ë¦¬ ëª¨ë“ˆ**,\n",
    "* **ëª¨ë¸/ë°ì´í„° ë²„ì €ë‹(DVC/MLflow) í…œí”Œë¦¿**\n",
    "  ê¹Œì§€ ë°”ë¡œ ë¶™ì—¬ë“œë¦´ê²Œìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2edcc7",
   "metadata": {},
   "source": [
    "## ì½”ë“œ 1\n",
    "\n",
    "ê·¸ë˜í”„ ìƒ‰ êµ¬ë¦¬ê³  ì‹œê°í™” í• ë•Œ ê¸€ìê°€ ê¹¨ì ¸ì„œ ë‚˜ì˜´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db781276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **ğŸŠ ì™„ë²½í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œìŠ¤í…œ ì™„ì„±! ğŸŠ**# ========================================================================================\n",
    "# í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ - ì™„ì „ ìˆ˜ì •ëœ Jupyter Notebook ë²„ì „ ---- ê·¸ë˜í”„ ìƒ‰ êµ¬ë¦¬ê³ , ì‹œê°í™”ì— ê¸€ìê°€ ê¹¨ì ¸ì„œ ë‚˜ì˜´ ã…—ã…—\n",
    "# ========================================================================================\n",
    "\n",
    "# %% ì…€ 1: íŒ¨í‚¤ì§€ import ë° ê¸°ë³¸ ì„¤ì •\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# í•´ì„ ê°€ëŠ¥ì„± ë¶„ì„\n",
    "import shap\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # ë§¥ í•œê¸€ í°íŠ¸\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic' # ìœˆë„ìš°\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ import ì™„ë£Œ\")\n",
    "print(f\"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b400a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% ì…€ 2: ë””ë ‰í† ë¦¬ ìƒì„± ë° ì„¤ì •\n",
    "# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "directories = [\n",
    "    '../results_v2', \n",
    "    '../results_v2/visualizations', \n",
    "    '../results_v2/interpretations',\n",
    "    '../results_v2/best_models_individual',  # ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸”ìš©\n",
    "    '../models_v2', \n",
    "    '../models_v2/best_models'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {directory}\")\n",
    "\n",
    "print(\"âœ… ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 3: íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ ì •ì˜ - ê¸°ë³¸ ì„¤ì •\n",
    "class CompleteSewagePredictionPipeline:\n",
    "    def __init__(self, data_path_template='../data/add_feature/{}_add_feature.csv'):\n",
    "        \"\"\"ì™„ì „í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "        self.data_path_template = data_path_template\n",
    "        self.centers = ['nanji', 'jungnang', 'seonam', 'tancheon']  # ğŸ‘ˆ ì‹¤ì œ ì„¼í„°ëª…ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "        \n",
    "        # ì œì™¸í•  ì»¬ëŸ¼ ì •ì˜\n",
    "        self.not_use_col = [\n",
    "            'ë‚ ì§œ',\n",
    "            '1ì²˜ë¦¬ì¥','2ì²˜ë¦¬ì¥','ì •í™”ì¡°','ì¤‘ê³„íŒí”„ì¥','í•©ê³„','ì‹œì„¤í˜„ëŒ€í™”',\n",
    "            '3ì²˜ë¦¬ì¥','4ì²˜ë¦¬ì¥','í•©ê³„', 'í•©ê³„_1ì¼í›„','í•©ê³„_2ì¼í›„',\n",
    "            'ë“±ê¸‰','ë“±ê¸‰_1ì¼í›„','ë“±ê¸‰_2ì¼í›„'\n",
    "        ]\n",
    "        \n",
    "        # íšŒê·€ ëª¨ë¸ ì •ì˜\n",
    "        self.regression_models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "            'CatBoost': cb.CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
    "            'LightGBM': lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # ë¶„ë¥˜ ëª¨ë¸ ì •ì˜\n",
    "        self.classification_models = {\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'CatBoost': cb.CatBoostClassifier(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "            'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥ìš©\n",
    "        self.results = []\n",
    "        \n",
    "    def load_data(self, center):\n",
    "        \"\"\"ì„¼í„°ë³„ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        file_path = self.data_path_template.format(center)\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(f\"âœ… {center} ì„¼í„° ë°ì´í„° ë¡œë“œ: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "pipeline = CompleteSewagePredictionPipeline()\n",
    "print(\"ğŸ”§ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 4: ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ\n",
    "def prepare_features(data, not_use_col):\n",
    "    \"\"\"í”¼ì²˜ ë° íƒ€ê²Ÿ ì¤€ë¹„\"\"\"\n",
    "    available_cols = [col for col in data.columns if col not in not_use_col]\n",
    "    X = data[available_cols]\n",
    "    y_reg = data['í•©ê³„_1ì¼í›„']  # íšŒê·€ìš©\n",
    "    y_clf = data['ë“±ê¸‰_1ì¼í›„']  # ë¶„ë¥˜ìš©\n",
    "    return X, y_reg, y_clf\n",
    "\n",
    "def split_data_temporal(X, y, test_size=0.2):\n",
    "    \"\"\"ì‹œê³„ì—´ ì •ë³´ë¥¼ ìœ ì§€í•œ ë¶„í• \"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_random(X, y, test_size=0.2, stratify=None):\n",
    "    \"\"\"ëœë¤ ë¶„í•  (ë¶„ë¥˜ì‹œ stratified)\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=42)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"ì™„ì „í•œ íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # MAPE ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.inf\n",
    "    \n",
    "    # SMAPE ê³„ì‚° (ì¶”ê°€!)\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae, \n",
    "        'MSE': mse, \n",
    "        'RMSE': rmse, \n",
    "        'MAPE': mape, \n",
    "        'SMAPE': smape,  # ì¶”ê°€!\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"ì™„ì „í•œ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    # ê¸°ë³¸ ì§€í‘œ\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Precision (weighted & macro)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Recall (weighted & macro)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # F1 Score (weighted & macro)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_weighted': precision_weighted,\n",
    "        'Precision_macro': precision_macro,  # ì¶”ê°€!\n",
    "        'Recall_weighted': recall_weighted,\n",
    "        'Recall_macro': recall_macro,  # ì¶”ê°€!\n",
    "        'F1_weighted': f1_weighted,\n",
    "        'F1_macro': f1_macro  # ì¶”ê°€!\n",
    "    }\n",
    "    \n",
    "    # ROC AUC (ë‹¤ì¤‘ë¶„ë¥˜ì˜ ê²½ìš° ovr ë°©ì‹ ì‚¬ìš©)\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "            metrics['AUC'] = auc_score\n",
    "        except:\n",
    "            metrics['AUC'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 5: ë°ì´í„° í™•ì¸\n",
    "print(\"ğŸ“Š ë°ì´í„° íŒŒì¼ í™•ì¸\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_info = {}\n",
    "for center in pipeline.centers:\n",
    "    data = pipeline.load_data(center)\n",
    "    if data is not None:\n",
    "        data_info[center] = {\n",
    "            'data': data,\n",
    "            'shape': data.shape\n",
    "        }\n",
    "        \n",
    "        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥\n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        print(f\"  ğŸ“ˆ í”¼ì²˜ ìˆ˜: {X.shape[1]}\")\n",
    "        print(f\"  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ í´ë˜ìŠ¤: {sorted(y_clf.unique())}\")\n",
    "        print()\n",
    "\n",
    "if len(data_info) == 0:\n",
    "    print(\"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. pipeline.centersë¥¼ ì‹¤ì œ ì„¼í„°ëª…ìœ¼ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"âœ… {len(data_info)}ê°œ ì„¼í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 6: ì „ì²´ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "print(\"ğŸš€ ì „ì²´ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "print(f\"ì˜ˆìƒ ì´ ëª¨ë¸ ìˆ˜: {len(pipeline.centers)} Ã— 2 Ã— 2 Ã— 6 = {len(pipeline.centers) * 2 * 2 * 6}ê°œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_models = 0\n",
    "successful_models = 0\n",
    "\n",
    "for center in pipeline.centers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ¢ {center.upper()} ì„¼í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        data = pipeline.load_data(center)\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        \n",
    "        print(f\"ğŸ“Š ë°ì´í„° ì •ë³´: {X.shape[0]}í–‰ Ã— {X.shape[1]}ê°œ í”¼ì²˜\")\n",
    "        print(f\"ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ í´ë˜ìŠ¤: {sorted(y_clf.unique())}\")\n",
    "        \n",
    "        # ë‘ ê°€ì§€ ë¶„í•  ë°©ë²•\n",
    "        for split_method in ['temporal', 'random']:\n",
    "            print(f\"\\n--- {split_method.upper()} ë¶„í•  ë°©ë²• ---\")\n",
    "            \n",
    "            # íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
    "            print(\"ğŸ“ˆ íšŒê·€ ëª¨ë¸ í•™ìŠµ:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_temporal(X, y_reg)\n",
    "            else:\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_random(X, y_reg)\n",
    "            \n",
    "            for model_name, model in pipeline.regression_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_reg, y_train_reg)\n",
    "                    y_pred = model.predict(X_test_reg)\n",
    "                    metrics = evaluate_regression(y_test_reg, y_pred)\n",
    "                    \n",
    "                    result = {\n",
    "                        'center': center, \n",
    "                        'split_method': split_method, \n",
    "                        'task': 'regression',\n",
    "                        'model': model_name, \n",
    "                        **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    \n",
    "                    print(f\"  âœ… {model_name}: R2={metrics['R2']:.4f}, RMSE={metrics['RMSE']:.2f}, SMAPE={metrics['SMAPE']:.2f}%\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ {model_name}: {str(e)}\")\n",
    "            \n",
    "            # ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ\n",
    "            print(\"ğŸ“Š ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_temporal(X, y_clf)\n",
    "            else:\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_random(X, y_clf, stratify=y_clf)\n",
    "            \n",
    "            for model_name, model in pipeline.classification_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_clf, y_train_clf)\n",
    "                    y_pred = model.predict(X_test_clf)\n",
    "                    y_pred_proba = model.predict_proba(X_test_clf) if hasattr(model, 'predict_proba') else None\n",
    "                    metrics = evaluate_classification(y_test_clf, y_pred, y_pred_proba)\n",
    "                    \n",
    "                    result = {\n",
    "                        'center': center, \n",
    "                        'split_method': split_method, \n",
    "                        'task': 'classification',\n",
    "                        'model': model_name, \n",
    "                        **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    \n",
    "                    print(f\"  âœ… {model_name}: Acc={metrics['Accuracy']:.4f}, F1_w={metrics['F1_weighted']:.4f}, F1_m={metrics['F1_macro']:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ {model_name}: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {center} ì„¼í„° ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì „ì²´ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ì„±ê³µ: {successful_models}/{total_models} ëª¨ë¸\")\n",
    "\n",
    "# %% ì…€ 7: ê²°ê³¼ ì €ì¥ ë° ê¸°ë³¸ ë¶„ì„\n",
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "results_df = pd.DataFrame(pipeline.results)\n",
    "results_df.to_csv('../results_v2/all_model_results.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: ../results_v2/all_model_results.csv\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"\\nğŸ“Š ê¸°ë³¸ í†µê³„\")\n",
    "    print(f\"ì´ ê²°ê³¼ ìˆ˜: {len(results_df)}\")\n",
    "    print(f\"ì„¼í„°ë³„ ê²°ê³¼ ìˆ˜:\")\n",
    "    print(results_df['center'].value_counts())\n",
    "    print(f\"\\níƒœìŠ¤í¬ë³„ ê²°ê³¼ ìˆ˜:\")\n",
    "    print(results_df['task'].value_counts())\n",
    "    \n",
    "    # ìƒìœ„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "    print(\"\\nğŸ“‹ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):\")\n",
    "    display(results_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# %% ì…€ 8: ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸° (í†µí•© í…Œì´ë¸”)\n",
    "def find_best_models_integrated(results_df, centers):\n",
    "    \"\"\"í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„±\"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ† í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸°\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    best_models_list = []\n",
    "    \n",
    "    for center in centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            if task == 'regression':\n",
    "                # R2ê°€ ë†’ì€ ëª¨ë¸ ì„ íƒ\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "                metric_value = best_model['R2']\n",
    "                metric_name = 'R2'\n",
    "            else:\n",
    "                # F1_weightedê°€ ë†’ì€ ëª¨ë¸ ì„ íƒ\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                metric_value = best_model['F1_weighted']\n",
    "                metric_name = 'F1_weighted'\n",
    "            \n",
    "            best_models_list.append(best_model.to_dict())\n",
    "            print(f\"ğŸ… {center} - {task}: {best_model['model']} ({best_model['split_method']}) - {metric_name}={metric_value:.4f}\")\n",
    "    \n",
    "    best_models_df = pd.DataFrame(best_models_list)\n",
    "    best_models_df.to_csv('../results_v2/best_models.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nğŸ’¾ í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ì •ë³´ ì €ì¥: ../results_v2/best_models.csv\")\n",
    "    \n",
    "    return best_models_df\n",
    "\n",
    "# í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸° ì‹¤í–‰\n",
    "if len(results_df) > 0:\n",
    "    best_models_df = find_best_models_integrated(results_df, pipeline.centers)\n",
    "    if best_models_df is not None:\n",
    "        print(f\"\\nğŸ“‹ í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ìš”ì•½ ({len(best_models_df)}ê°œ):\")\n",
    "        display(best_models_df[['center', 'task', 'model', 'split_method', 'R2', 'F1_weighted', 'F1_macro']].fillna('-'))\n",
    "\n",
    "# %% ì…€ 9: ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„± (8ê°œ)\n",
    "def create_individual_best_model_tables(results_df, centers):\n",
    "    \"\"\"ì„¼í„°ë³„, ë¶„í• ë°©ë²•ë³„, íƒœìŠ¤í¬ë³„ ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„± (ì´ 8ê°œ)\"\"\"\n",
    "    print(\"ğŸ“Š ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„± (8ê°œ)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    individual_tables = {}\n",
    "    \n",
    "    for center in centers:\n",
    "        for split_method in ['temporal', 'random']:\n",
    "            for task in ['regression', 'classification']:\n",
    "                # í•´ë‹¹ ì¡°ê±´ì˜ ë°ì´í„° í•„í„°ë§\n",
    "                filtered_data = results_df[\n",
    "                    (results_df['center'] == center) & \n",
    "                    (results_df['split_method'] == split_method) &\n",
    "                    (results_df['task'] == task)\n",
    "                ]\n",
    "                \n",
    "                if len(filtered_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # ì„±ëŠ¥ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "                if task == 'regression':\n",
    "                    sorted_data = filtered_data.sort_values('R2', ascending=False)\n",
    "                    best_metric = 'R2'\n",
    "                else:\n",
    "                    sorted_data = filtered_data.sort_values('F1_weighted', ascending=False)\n",
    "                    best_metric = 'F1_weighted'\n",
    "                \n",
    "                # í…Œì´ë¸” ì €ì¥\n",
    "                table_name = f\"{center}_{split_method}_{task}\"\n",
    "                filename = f\"../results_v2/best_models_individual/{table_name}_models.csv\"\n",
    "                sorted_data.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                individual_tables[table_name] = {\n",
    "                    'data': sorted_data,\n",
    "                    'best_model': sorted_data.iloc[0]['model'],\n",
    "                    'best_score': sorted_data.iloc[0][best_metric],\n",
    "                    'filename': filename\n",
    "                }\n",
    "                \n",
    "                print(f\"ğŸ’¾ {table_name}: {sorted_data.iloc[0]['model']} ({best_metric}={sorted_data.iloc[0][best_metric]:.4f})\")\n",
    "    \n",
    "    print(f\"\\nâœ… ì´ {len(individual_tables)}ê°œ ê°œë³„ í…Œì´ë¸” ìƒì„± ì™„ë£Œ\")\n",
    "    return individual_tables\n",
    "\n",
    "# ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„± ì‹¤í–‰\n",
    "if len(results_df) > 0:\n",
    "    individual_best_tables = create_individual_best_model_tables(results_df, pipeline.centers)\n",
    "    print(f\"ğŸ“ ê°œë³„ í…Œì´ë¸” ì €ì¥ ìœ„ì¹˜: ../results_v2/best_models_individual/\")\n",
    "\n",
    "# %% ì…€ 10: ROC Curve ì‹œê°í™” í•¨ìˆ˜\n",
    "def create_roc_curves(results_df, centers):\n",
    "    \"\"\"ROC Curve ì‹œê°í™” ìƒì„±\"\"\"\n",
    "    print(\"ğŸ“ˆ ROC Curve ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # ë¶„ë¥˜ ê²°ê³¼ë§Œ í•„í„°ë§\n",
    "    clf_results = results_df[results_df['task'] == 'classification'].copy()\n",
    "    \n",
    "    if len(clf_results) == 0:\n",
    "        print(\"âŒ ë¶„ë¥˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ì„¼í„°ë³„ë¡œ ROC Curve ê·¸ë¦¬ê¸° (ì‹¤ì œ êµ¬í˜„ì„ ìœ„í•´ì„œëŠ” y_pred_proba ì €ì¥ í•„ìš”)\n",
    "    print(\"âš ï¸ ROC Curveë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ì„œëŠ” ëª¨ë¸ ì¬í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    print(\"ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ë‹¨ê³„ì—ì„œ ROC Curveë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"âœ… ROC Curve ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 11: ìƒì„¸ ì„±ëŠ¥ ì‹œê°í™” ìƒì„±\n",
    "def create_detailed_visualizations(results_df):\n",
    "    \"\"\"ìƒì„¸í•œ ì„±ëŠ¥ ì‹œê°í™” ìƒì„±\"\"\"\n",
    "    print(\"ğŸ“Š ìƒì„¸ ì„±ëŠ¥ ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # 1. ê¸°ë³¸ ì„±ëŠ¥ ë¹„êµ (2x2 ê·¸ë¦¬ë“œ)\n",
    "    fig1, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # ì„¼í„°ë³„ íšŒê·€ ì„±ëŠ¥ (ë¶„í• ë°©ë²•ë³„)\n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    if len(reg_data) > 0:\n",
    "        reg_summary = reg_data.groupby(['center', 'split_method'])['R2'].mean().unstack(fill_value=0)\n",
    "        reg_summary.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ íšŒê·€ R2 ì„±ëŠ¥ (ë¶„í• ë°©ë²•ë³„)')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ì„¼í„°ë³„ ë¶„ë¥˜ ì„±ëŠ¥ (ë¶„í• ë°©ë²•ë³„)  \n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    if len(clf_data) > 0:\n",
    "        clf_summary = clf_data.groupby(['center', 'split_method'])['F1_weighted'].mean().unstack(fill_value=0)\n",
    "        clf_summary.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ F1 ì„±ëŠ¥ (ë¶„í• ë°©ë²•ë³„)')\n",
    "        axes[0,1].set_ylabel('F1 Score (Weighted)')\n",
    "        axes[0,1].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ëª¨ë¸ë³„ íšŒê·€ ì„±ëŠ¥\n",
    "    if len(reg_data) > 0:\n",
    "        reg_model_perf = reg_data.groupby(['model'])['R2'].mean().sort_values(ascending=True)\n",
    "        reg_model_perf.plot(kind='barh', ax=axes[1,0], title='ëª¨ë¸ë³„ í‰ê·  íšŒê·€ R2 ì„±ëŠ¥')\n",
    "        axes[1,0].set_xlabel('R2 Score')\n",
    "    \n",
    "    # ëª¨ë¸ë³„ ë¶„ë¥˜ ì„±ëŠ¥\n",
    "    if len(clf_data) > 0:\n",
    "        clf_model_perf = clf_data.groupby(['model'])['F1_weighted'].mean().sort_values(ascending=True)\n",
    "        clf_model_perf.plot(kind='barh', ax=axes[1,1], title='ëª¨ë¸ë³„ í‰ê·  ë¶„ë¥˜ F1 ì„±ëŠ¥')\n",
    "        axes[1,1].set_xlabel('F1 Score (Weighted)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v2/visualizations/basic_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. ì„¼í„°ë³„ ëª¨ë¸ë³„ ìƒì„¸ ì„±ëŠ¥ ë¹„êµ (íšŒê·€)\n",
    "    if len(reg_data) > 0:\n",
    "        fig2, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        \n",
    "        # R2 ì„±ëŠ¥\n",
    "        reg_pivot_r2 = reg_data.pivot_table(values='R2', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_r2.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ R2 ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # MAE ì„±ëŠ¥\n",
    "        reg_pivot_mae = reg_data.pivot_table(values='MAE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_mae.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ MAE ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,1].set_ylabel('MAE')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # RMSE ì„±ëŠ¥\n",
    "        reg_pivot_rmse = reg_data.pivot_table(values='RMSE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_rmse.plot(kind='bar', ax=axes[1,0], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ RMSE ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,0].set_ylabel('RMSE')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # SMAPE ì„±ëŠ¥\n",
    "        reg_pivot_smape = reg_data.pivot_table(values='SMAPE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_smape.plot(kind='bar', ax=axes[1,1], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ SMAPE ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,1].set_ylabel('SMAPE (%)')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/regression_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. ì„¼í„°ë³„ ëª¨ë¸ë³„ ìƒì„¸ ì„±ëŠ¥ ë¹„êµ (ë¶„ë¥˜)\n",
    "    if len(clf_data) > 0:\n",
    "        fig3, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        \n",
    "        # Accuracy ì„±ëŠ¥\n",
    "        clf_pivot_acc = clf_data.pivot_table(values='Accuracy', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_acc.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ Accuracy ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,0].set_ylabel('Accuracy')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # F1 Weighted ì„±ëŠ¥\n",
    "        clf_pivot_f1w = clf_data.pivot_table(values='F1_weighted', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1w.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ F1_Weighted ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,1].set_ylabel('F1 Weighted')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # F1 Macro ì„±ëŠ¥\n",
    "        clf_pivot_f1m = clf_data.pivot_table(values='F1_macro', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1m.plot(kind='bar', ax=axes[1,0], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ F1_Macro ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,0].set_ylabel('F1 Macro')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # AUC ì„±ëŠ¥\n",
    "        clf_pivot_auc = clf_data.pivot_table(values='AUC', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_auc.plot(kind='bar', ax=axes[1,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ AUC ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,1].set_ylabel('AUC')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/classification_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. ë™ì¼ ëª¨ë¸ì— ëŒ€í•œ ì„¼í„°ë³„ ì„±ëŠ¥ ë¹„êµ\n",
    "    models = results_df['model'].unique()\n",
    "    n_models = len(models)\n",
    "    \n",
    "    # íšŒê·€ ëª¨ë¸ë“¤ì˜ ì„¼í„°ë³„ ë¹„êµ\n",
    "    if len(reg_data) > 0:\n",
    "        fig4, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            if i >= 6:  # ìµœëŒ€ 6ê°œ ëª¨ë¸ë§Œ í‘œì‹œ\n",
    "                break\n",
    "                \n",
    "            model_data = reg_data[reg_data['model'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                center_perf = model_data.groupby('center')['R2'].mean()\n",
    "                center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - ì„¼í„°ë³„ R2 ì„±ëŠ¥')\n",
    "                axes[i].set_ylabel('R2 Score')\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” subplot ìˆ¨ê¸°ê¸°\n",
    "        for j in range(i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_regression.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸ë“¤ì˜ ì„¼í„°ë³„ ë¹„êµ\n",
    "    if len(clf_data) > 0:\n",
    "        fig5, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            if i >= 6:  # ìµœëŒ€ 6ê°œ ëª¨ë¸ë§Œ í‘œì‹œ\n",
    "                break\n",
    "                \n",
    "            model_data = clf_data[clf_data['model'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                center_perf = model_data.groupby('center')['F1_weighted'].mean()\n",
    "                center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - ì„¼í„°ë³„ F1_Weighted ì„±ëŠ¥')\n",
    "                axes[i].set_ylabel('F1 Weighted')\n",
    "                axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” subplot ìˆ¨ê¸°ê¸°\n",
    "        for j in range(i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_classification.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"âœ… ìƒì„¸ ì‹œê°í™” ì™„ë£Œ\")\n",
    "    print(\"ğŸ“ ì €ì¥ ìœ„ì¹˜:\")\n",
    "    print(\"  - basic_performance_comparison.png\")\n",
    "    print(\"  - regression_detailed_comparison.png\")\n",
    "    print(\"  - classification_detailed_comparison.png\")  \n",
    "    print(\"  - same_model_center_comparison_regression.png\")\n",
    "    print(\"  - same_model_center_comparison_classification.png\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥\n",
    "    print(f\"\\nğŸ“Š ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸:\")\n",
    "    \n",
    "    # íšŒê·€ ëª¨ë¸ ìµœê³  ì„±ëŠ¥\n",
    "    if len(reg_data) > 0:\n",
    "        reg_best = reg_data.nlargest(3, 'R2')\n",
    "        print(f\"\\nğŸ† íšŒê·€ ëª¨ë¸ TOP 3 (R2 ê¸°ì¤€):\")\n",
    "        for idx, row in reg_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): R2={row['R2']:.4f}, SMAPE={row['SMAPE']:.2f}%\")\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸ ìµœê³  ì„±ëŠ¥  \n",
    "    if len(clf_data) > 0:\n",
    "        clf_best = clf_data.nlargest(3, 'F1_weighted')\n",
    "        print(f\"\\nğŸ† ë¶„ë¥˜ ëª¨ë¸ TOP 3 (F1_weighted ê¸°ì¤€):\")\n",
    "        for idx, row in clf_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): F1_w={row['F1_weighted']:.4f}, F1_m={row['F1_macro']:.4f}\")\n",
    "\n",
    "# ìƒì„¸ ì‹œê°í™” ì‹¤í–‰\n",
    "if len(results_df) > 0:\n",
    "    create_detailed_visualizations(results_df)\n",
    "\n",
    "# %% ì…€ 12: ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥ (8ê°œ ì„ ì •)\n",
    "def train_and_save_top8_models(results_df, pipeline):\n",
    "    \"\"\"ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥ (ì„¼í„°ë³„Ã—íƒœìŠ¤í¬ë³„ = 8ê°œ)\"\"\"\n",
    "    print(\"ğŸ’¾ ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ì„¼í„°ë³„, íƒœìŠ¤í¬ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ ì •\n",
    "    selected_models = []\n",
    "    \n",
    "    for center in pipeline.centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "            \n",
    "            selected_models.append(best_model)\n",
    "    \n",
    "    print(f\"ğŸ“‹ ì„ ì •ëœ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸:\")\n",
    "    for model_info in selected_models:\n",
    "        print(f\"  ğŸ… {model_info['center']} - {model_info['task']} - {model_info['model']} ({model_info['split_method']})\")\n",
    "    \n",
    "    # ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥\n",
    "    saved_models = {}\n",
    "    \n",
    "    for model_info in selected_models:\n",
    "        center = model_info['center']\n",
    "        task = model_info['task']\n",
    "        model_name = model_info['model']\n",
    "        split_method = model_info['split_method']\n",
    "        \n",
    "        print(f\"\\nğŸ”„ {center} - {task} - {model_name} ({split_method}) ì¬í•™ìŠµ ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            # ë°ì´í„° ë¡œë“œ\n",
    "            data = pipeline.load_data(center)\n",
    "            if data is None:\n",
    "                continue\n",
    "                \n",
    "            X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "            y = y_reg if task == 'regression' else y_clf\n",
    "            \n",
    "            # ëª¨ë¸ ì„ íƒ\n",
    "            if task == 'regression':\n",
    "                if model_name in pipeline.regression_models:\n",
    "                    model = pipeline.regression_models[model_name]\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                if model_name in pipeline.classification_models:\n",
    "                    model = pipeline.classification_models[model_name]\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            # ë°ì´í„° ë¶„í• \n",
    "            if split_method == 'temporal':\n",
    "                X_train, X_test, y_train, y_test = split_data_temporal(X, y)\n",
    "            else:\n",
    "                stratify = y if task == 'classification' else None\n",
    "                X_train, X_test, y_train, y_test = split_data_random(X, y, stratify=stratify)\n",
    "            \n",
    "            # ëª¨ë¸ í•™ìŠµ\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # ì˜ˆì¸¡ ë° ì„±ëŠ¥ ê³„ì‚° (ROC Curveìš© í™•ë¥ ë„ ì €ì¥)\n",
    "            y_pred = model.predict(X_test)\n",
    "            if task == 'classification' and hasattr(model, 'predict_proba'):\n",
    "                y_pred_proba = model.predict_proba(X_test)\n",
    "            else:\n",
    "                y_pred_proba = None\n",
    "            \n",
    "            # ëª¨ë¸ ì €ì¥ ë°ì´í„° ì¤€ë¹„\n",
    "            model_data = {\n",
    "                'model': model,\n",
    "                'feature_names': X.columns.tolist(),\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'task': task,\n",
    "                'center': center,\n",
    "                'split_method': split_method,\n",
    "                'model_name': model_name,\n",
    "                'performance': model_info.to_dict()\n",
    "            }\n",
    "            \n",
    "            # íŒŒì¼ ì €ì¥\n",
    "            filename = f\"{center}_{task}_{model_name}_{split_method}.pkl\"\n",
    "            filepath = f\"../models_v2/best_models/{filename}\"\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            \n",
    "            print(f\"âœ… ëª¨ë¸ ì €ì¥: {filepath}\")\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥\n",
    "            key = f\"{center}_{task}\"\n",
    "            saved_models[key] = model_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {center} - {task} - {model_name} ì €ì¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nâœ… {len(saved_models)}ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ì™„ë£Œ\")\n",
    "    return saved_models\n",
    "\n",
    "# ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ì‹¤í–‰\n",
    "if len(results_df) > 0:\n",
    "    saved_top8_models = train_and_save_top8_models(results_df, pipeline)\n",
    "    print(f\"ğŸ¤– ì €ì¥ëœ ìƒìœ„ 8ê°œ ëª¨ë¸ ìˆ˜: {len(saved_top8_models)}\")\n",
    "\n",
    "# %% ì…€ 13: ROC Curve ì‹œê°í™” (ì‹¤ì œ êµ¬í˜„)\n",
    "def create_roc_curves_actual(saved_models):\n",
    "    \"\"\"ì‹¤ì œ ROC Curve ì‹œê°í™” ìƒì„±\"\"\"\n",
    "    print(\"ğŸ“ˆ ROC Curve ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸ë§Œ í•„í„°ë§\n",
    "    clf_models = {k: v for k, v in saved_models.items() if v['task'] == 'classification'}\n",
    "    \n",
    "    if len(clf_models) == 0:\n",
    "        print(\"âŒ ë¶„ë¥˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ì„¼í„°ë³„ë¡œ ROC Curve ê·¸ë¦¬ê¸°\n",
    "    centers = list(set([v['center'] for v in clf_models.values()]))\n",
    "    n_centers = len(centers)\n",
    "    \n",
    "    if n_centers > 0:\n",
    "        fig, axes = plt.subplots(1, min(4, n_centers), figsize=(5*min(4, n_centers), 5))\n",
    "        if n_centers == 1:\n",
    "            axes = [axes]\n",
    "        elif min(4, n_centers) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, center in enumerate(centers):\n",
    "            if i >= 4:  # ìµœëŒ€ 4ê°œ ì„¼í„°ë§Œ í‘œì‹œ\n",
    "                break\n",
    "                \n",
    "            # í•´ë‹¹ ì„¼í„°ì˜ ë¶„ë¥˜ ëª¨ë¸ ì°¾ê¸°\n",
    "            center_models = {k: v for k, v in clf_models.items() if v['center'] == center}\n",
    "            \n",
    "            ax = axes[i] if n_centers > 1 else axes[0]\n",
    "            \n",
    "            for model_key, model_data in center_models.items():\n",
    "                y_test = model_data['y_test']\n",
    "                y_pred_proba = model_data['y_pred_proba']\n",
    "                \n",
    "                if y_pred_proba is not None:\n",
    "                    try:\n",
    "                        # ì´ì§„ ë¶„ë¥˜ì¸ì§€ ë‹¤ì¤‘ ë¶„ë¥˜ì¸ì§€ í™•ì¸\n",
    "                        n_classes = len(np.unique(y_test))\n",
    "                        \n",
    "                        if n_classes == 2:\n",
    "                            # ì´ì§„ ë¶„ë¥˜\n",
    "                            fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "                            auc_score = auc(fpr, tpr)\n",
    "                            ax.plot(fpr, tpr, label=f'{model_data[\"model_name\"]} (AUC = {auc_score:.3f})')\n",
    "                        else:\n",
    "                            # ë‹¤ì¤‘ ë¶„ë¥˜ - ê° í´ë˜ìŠ¤ë³„ ROC ê·¸ë¦¬ê¸°\n",
    "                            from sklearn.preprocessing import label_binarize\n",
    "                            y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "                            \n",
    "                            for class_idx in range(n_classes):\n",
    "                                if class_idx < y_pred_proba.shape[1]:\n",
    "                                    fpr, tpr, _ = roc_curve(y_test_bin[:, class_idx], y_pred_proba[:, class_idx])\n",
    "                                    auc_score = auc(fpr, tpr)\n",
    "                                    ax.plot(fpr, tpr, label=f'{model_data[\"model_name\"]} Class{class_idx} (AUC = {auc_score:.3f})')\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ {center} ROC Curve ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            \n",
    "            # ëŒ€ê°ì„  ê·¸ë¦¬ê¸°\n",
    "            ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "            ax.set_xlim([0.0, 1.0])\n",
    "            ax.set_ylim([0.0, 1.05])\n",
    "            ax.set_xlabel('False Positive Rate')\n",
    "            ax.set_ylabel('True Positive Rate')\n",
    "            ax.set_title(f'{center} ì„¼í„° ROC Curves')\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"âœ… ROC Curve ì‹œê°í™” ì™„ë£Œ\")\n",
    "        print(\"ğŸ“ ì €ì¥: ../results_v2/visualizations/roc_curves.png\")\n",
    "\n",
    "# ROC Curve ì‹œê°í™” ì‹¤í–‰\n",
    "if 'saved_top8_models' in locals():\n",
    "    create_roc_curves_actual(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 14: SHAP ë¶„ì„ (Force Plot í¬í•¨)\n",
    "def analyze_shap_complete(saved_models):\n",
    "    \"\"\"ì™„ì „í•œ SHAP ë¶„ì„ (Summary, Importance, Force Plot)\"\"\"\n",
    "    if len(saved_models) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ” ì™„ì „í•œ SHAP ë¶„ì„ ì‹œì‘ (Summary + Importance + Force Plot)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for key, model_data in saved_models.items():\n",
    "        center = model_data['center']\n",
    "        task = model_data['task']\n",
    "        model_name = model_data['model_name']\n",
    "        model = model_data['model']\n",
    "        X_train = model_data['X_train']\n",
    "        X_test = model_data['X_test']\n",
    "        feature_names = model_data['feature_names']\n",
    "        \n",
    "        print(f\"\\nğŸ” {center} - {task} - {model_name} SHAP ë¶„ì„...\")\n",
    "        \n",
    "        try:\n",
    "            # SHAP explainer ìƒì„± (ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ ìƒ˜í”Œ ìˆ˜ ì œí•œ)\n",
    "            sample_size = min(50, len(X_test))\n",
    "            X_test_sample = X_test.iloc[:sample_size]\n",
    "            \n",
    "            if model_name in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "                explainer = shap.Explainer(model)\n",
    "                shap_values = explainer(X_test_sample)\n",
    "            else:\n",
    "                train_sample_size = min(100, len(X_train))\n",
    "                explainer = shap.Explainer(model, X_train.iloc[:train_sample_size])\n",
    "                shap_values = explainer(X_test_sample)\n",
    "            \n",
    "            # 1. Summary Plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, \n",
    "                            show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Summary Plot')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_summary.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 2. Feature Importance\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, \n",
    "                            plot_type=\"bar\", show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 3. Force Plot (ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ìƒ˜í”Œ)\n",
    "            try:\n",
    "                # ì²« ë²ˆì§¸ ìƒ˜í”Œ\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                if hasattr(shap_values, 'values'):\n",
    "                    if len(shap_values.values.shape) == 3:  # ë‹¤ì¤‘ë¶„ë¥˜\n",
    "                        shap.waterfall_plot(shap_values[0, :, 0], show=False)\n",
    "                    else:\n",
    "                        shap.waterfall_plot(shap_values[0], show=False)\n",
    "                else:\n",
    "                    shap.waterfall_plot(shap_values[0], show=False)\n",
    "                \n",
    "                plt.title(f'{center} - {task} - {model_name}\\nSHAP Force Plot (Sample 1)')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_1.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                \n",
    "                # ë‘ ë²ˆì§¸ ìƒ˜í”Œ (ìˆëŠ” ê²½ìš°)\n",
    "                if len(X_test_sample) > 1:\n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    if hasattr(shap_values, 'values'):\n",
    "                        if len(shap_values.values.shape) == 3:  # ë‹¤ì¤‘ë¶„ë¥˜\n",
    "                            shap.waterfall_plot(shap_values[1, :, 0], show=False)\n",
    "                        else:\n",
    "                            shap.waterfall_plot(shap_values[1], show=False)\n",
    "                    else:\n",
    "                        shap.waterfall_plot(shap_values[1], show=False)\n",
    "                    \n",
    "                    plt.title(f'{center} - {task} - {model_name}\\nSHAP Force Plot (Sample 2)')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_2.png', \n",
    "                               dpi=300, bbox_inches='tight')\n",
    "                    plt.show()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Force Plot ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "                # ëŒ€ì•ˆ: Waterfall plot ëŒ€ì‹  ê°„ë‹¨í•œ bar plot\n",
    "                try:\n",
    "                    if hasattr(shap_values, 'values'):\n",
    "                        values = shap_values.values[0] if len(shap_values.values.shape) == 2 else shap_values.values[0, :, 0]\n",
    "                    else:\n",
    "                        values = shap_values[0].values\n",
    "                    \n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    feature_importance = pd.DataFrame({\n",
    "                        'feature': feature_names[:len(values)],\n",
    "                        'shap_value': values\n",
    "                    }).sort_values('shap_value', key=abs, ascending=True).tail(15)\n",
    "                    \n",
    "                    plt.barh(range(len(feature_importance)), feature_importance['shap_value'])\n",
    "                    plt.yticks(range(len(feature_importance)), feature_importance['feature'])\n",
    "                    plt.xlabel('SHAP Value')\n",
    "                    plt.title(f'{center} - {task} - {model_name}\\nSHAP Values (Sample 1)')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_alt.png', \n",
    "                               dpi=300, bbox_inches='tight')\n",
    "                    plt.show()\n",
    "                    \n",
    "                except Exception as e2:\n",
    "                    print(f\"âš ï¸ ëŒ€ì•ˆ Force Plotë„ ì‹¤íŒ¨: {str(e2)}\")\n",
    "            \n",
    "            print(f\"âœ… SHAP ë¶„ì„ ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SHAP ë¶„ì„ ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "# SHAP ë¶„ì„ ì‹¤í–‰\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_shap_complete(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 15: Feature Importance ë¶„ì„\n",
    "def analyze_feature_importance_complete(saved_models):\n",
    "    \"\"\"ì™„ì „í•œ Feature Importance ë¶„ì„\"\"\"\n",
    "    if len(saved_models) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ“Š ì™„ì „í•œ Feature Importance ë¶„ì„\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for key, model_data in saved_models.items():\n",
    "        center = model_data['center']\n",
    "        task = model_data['task']\n",
    "        model_name = model_data['model_name']\n",
    "        model = model_data['model']\n",
    "        feature_names = model_data['feature_names']\n",
    "        \n",
    "        print(f\"\\nğŸ“Š {center} - {task} - {model_name} Feature Importance...\")\n",
    "        \n",
    "        try:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                # Tree-based ëª¨ë¸\n",
    "                importance = model.feature_importances_\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importance\n",
    "                }).sort_values('importance', ascending=True)\n",
    "                \n",
    "                # ìƒìœ„ 20ê°œ í”¼ì²˜ë§Œ í‘œì‹œ\n",
    "                top_features = importance_df.tail(20)\n",
    "                colors = plt.cm.viridis(np.linspace(0, 1, len(top_features)))\n",
    "                \n",
    "                bars = plt.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "                plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance (Top 20)')\n",
    "                \n",
    "                # ìˆ˜ì¹˜ í‘œì‹œ\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                            f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "                \n",
    "            elif hasattr(model, 'coef_'):\n",
    "                # ì„ í˜• ëª¨ë¸\n",
    "                if task == 'classification' and len(model.coef_.shape) > 1:\n",
    "                    # ë‹¤ì¤‘ë¶„ë¥˜ì˜ ê²½ìš° í‰ê·  ì ˆëŒ“ê°’ ì‚¬ìš©\n",
    "                    coef = np.mean(np.abs(model.coef_), axis=0)\n",
    "                else:\n",
    "                    coef = np.abs(model.coef_).flatten()\n",
    "                \n",
    "                importance_df = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': coef\n",
    "                }).sort_values('importance', ascending=True)\n",
    "                \n",
    "                # ìƒìœ„ 20ê°œ í”¼ì²˜ë§Œ í‘œì‹œ\n",
    "                top_features = importance_df.tail(20)\n",
    "                colors = plt.cm.plasma(np.linspace(0, 1, len(top_features)))\n",
    "                \n",
    "                bars = plt.barh(range(len(top_features)), top_features['importance'], color=colors)\n",
    "                plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                plt.xlabel('|Coefficient|')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Coefficients (Top 20)')\n",
    "                \n",
    "                # ìˆ˜ì¹˜ í‘œì‹œ\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                            f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "            \n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Feature importance not available for this model', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_feature_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"âœ… Feature Importance ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Feature Importance ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "# Feature Importance ë¶„ì„ ì‹¤í–‰\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_feature_importance_complete(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 16: LIME ë¶„ì„ (ì„ íƒì‚¬í•­)\n",
    "def analyze_lime_complete(saved_models):\n",
    "    \"\"\"ì™„ì „í•œ LIME ë¶„ì„ (ì„ íƒì‚¬í•­)\"\"\"\n",
    "    try:\n",
    "        import lime\n",
    "        import lime.lime_tabular\n",
    "        \n",
    "        if len(saved_models) == 0:\n",
    "            print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(\"ğŸ‹ ì™„ì „í•œ LIME ë¶„ì„ ì‹œì‘\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ì²˜ìŒ 3ê°œ ëª¨ë¸ë§Œ ë¶„ì„\n",
    "        analyzed_count = 0\n",
    "        for key, model_data in saved_models.items():\n",
    "            if analyzed_count >= 3:\n",
    "                print(\"â° ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ì²˜ìŒ 3ê°œ ëª¨ë¸ë§Œ LIME ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "                \n",
    "            center = model_data['center']\n",
    "            task = model_data['task']\n",
    "            model_name = model_data['model_name']\n",
    "            model = model_data['model']\n",
    "            X_train = model_data['X_train']\n",
    "            X_test = model_data['X_test']\n",
    "            feature_names = model_data['feature_names']\n",
    "            \n",
    "            print(f\"\\nğŸ‹ {center} - {task} - {model_name} LIME ë¶„ì„...\")\n",
    "            \n",
    "            try:\n",
    "                if task == 'regression':\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values,\n",
    "                        feature_names=feature_names,\n",
    "                        mode='regression',\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ìƒ˜í”Œ ë¶„ì„\n",
    "                    for sample_idx in [0, 1]:\n",
    "                        if sample_idx >= len(X_test):\n",
    "                            continue\n",
    "                            \n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                        \n",
    "                else:  # classification\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values,\n",
    "                        feature_names=feature_names,\n",
    "                        mode='classification',\n",
    "                        class_names=[str(c) for c in sorted(model.classes_)],\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ìƒ˜í”Œ ë¶„ì„\n",
    "                    for sample_idx in [0, 1]:\n",
    "                        if sample_idx >= len(X_test):\n",
    "                            continue\n",
    "                            \n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict_proba, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                \n",
    "                print(f\"âœ… LIME ë¶„ì„ ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "                analyzed_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ LIME ë¶„ì„ ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"ğŸ’¡ LIME ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:\")\n",
    "        print(\"   pip install lime\")\n",
    "        print(\"   í˜„ì¬ëŠ” LIME ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LIME ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "\n",
    "# LIME ë¶„ì„ ì‹¤í–‰ (ì„ íƒì‚¬í•­)\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_lime_complete(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 17: ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "def predict_with_saved_model(center, task, new_data):\n",
    "    \"\"\"\n",
    "    ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    center : str\n",
    "        ì„¼í„°ëª…\n",
    "    task : str  \n",
    "        'regression' ë˜ëŠ” 'classification'\n",
    "    new_data : pandas.DataFrame\n",
    "        ì˜ˆì¸¡í•  ìƒˆë¡œìš´ ë°ì´í„°\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    prediction : array or tuple\n",
    "        ì˜ˆì¸¡ ê²°ê³¼ (ë¶„ë¥˜ì˜ ê²½ìš° í™•ë¥ ë„ í•¨ê»˜ ë°˜í™˜)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ë² ìŠ¤íŠ¸ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') \n",
    "                  if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"âŒ {center} - {task} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ëª¨ë¸ íŒŒì¼ ì‚¬ìš© (ê°€ì¥ ì¢‹ì€ ëª¨ë¸)\n",
    "    model_file = model_files[0]\n",
    "    filepath = f\"../models_v2/best_models/{model_file}\"\n",
    "    \n",
    "    try:\n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = model_data['model']\n",
    "        feature_names = model_data['feature_names']\n",
    "        \n",
    "        # í”¼ì²˜ ìˆœì„œ ë§ì¶”ê¸°\n",
    "        missing_cols = [col for col in feature_names if col not in new_data.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"âŒ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_cols}\")\n",
    "            return None\n",
    "        \n",
    "        X_new = new_data[feature_names]\n",
    "        \n",
    "        # ì˜ˆì¸¡\n",
    "        if task == 'regression':\n",
    "            prediction = model.predict(X_new)\n",
    "            print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ: {len(prediction)}ê°œ ìƒ˜í”Œ\")\n",
    "            return prediction\n",
    "        else:\n",
    "            prediction = model.predict(X_new)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                prediction_proba = model.predict_proba(X_new)\n",
    "                print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ: {len(prediction)}ê°œ ìƒ˜í”Œ\")\n",
    "                return prediction, prediction_proba\n",
    "            else:\n",
    "                print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ: {len(prediction)}ê°œ ìƒ˜í”Œ\")\n",
    "                return prediction\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_saved_model(center, task):\n",
    "    \"\"\"ì €ì¥ëœ ëª¨ë¸ ì •ë³´ ë¡œë“œ\"\"\"\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') \n",
    "                  if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"âŒ {center} - {task} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    filepath = f\"../models_v2/best_models/{model_files[0]}\"\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {center} - {task} - {model_data['model_name']}\")\n",
    "        return model_data\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"ğŸ”® ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 18: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ (ì„ íƒì‚¬í•­)\n",
    "def show_hyperparameter_tuning_examples():\n",
    "    \"\"\"í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ ì½”ë“œ ì¶œë ¥\"\"\"\n",
    "    print(\"âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    tuning_examples = '''\n",
    "# GridSearchCVë¥¼ ì´ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 1. XGBoost íšŒê·€ ëª¨ë¸ íŠœë‹\n",
    "def tune_xgboost_regression(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        xgb_model, param_grid, \n",
    "        cv=5, scoring='r2', \n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best score:\", grid_search.best_score_)\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# 2. RandomForest ë¶„ë¥˜ ëª¨ë¸ íŠœë‹\n",
    "def tune_randomforest_classification(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 500],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # RandomizedSearchCV ì‚¬ìš© (ë” ë¹ ë¦„)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        rf_model, param_grid, \n",
    "        cv=5, scoring='f1_weighted',\n",
    "        n_iter=50, n_jobs=-1, verbose=1, random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best score:\", random_search.best_score_)\n",
    "    \n",
    "    return random_search.best_estimator_\n",
    "\n",
    "# 3. LightGBM íŠœë‹ (Optuna ì‚¬ìš©)\n",
    "def tune_lightgbm_with_optuna(X_train, y_train, task='regression'):\n",
    "    # pip install optuna í•„ìš”\n",
    "    import optuna\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'regression' if task == 'regression' else 'multiclass',\n",
    "            'metric': 'rmse' if task == 'regression' else 'multi_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        }\n",
    "        \n",
    "        if task == 'regression':\n",
    "            model = lgb.LGBMRegressor(**params, random_state=42, verbose=-1)\n",
    "            score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "        else:\n",
    "            model = lgb.LGBMClassifier(**params, random_state=42, verbose=-1)\n",
    "            score = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_weighted').mean()\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    print(study.best_trial.params)\n",
    "    print(f\"Best score: {study.best_value}\")\n",
    "    \n",
    "    return study.best_trial.params\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "# best_xgb = tune_xgboost_regression(X_train, y_train)\n",
    "# best_rf = tune_randomforest_classification(X_train, y_train)\n",
    "# best_lgb_params = tune_lightgbm_with_optuna(X_train, y_train, task='regression')\n",
    "    '''\n",
    "    \n",
    "    print(tuning_examples)\n",
    "\n",
    "# íŠœë‹ ì˜ˆì‹œ ì¶œë ¥\n",
    "show_hyperparameter_tuning_examples()\n",
    "\n",
    "# %% ì…€ 19: ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "def comprehensive_final_summary():\n",
    "    \"\"\"í¬ê´„ì ì¸ ìµœì¢… ê²°ê³¼ ìš”ì•½\"\"\"\n",
    "    print(\"ğŸ“‹ í¬ê´„ì ì¸ ìµœì¢… ì‹¤í–‰ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª©ë“¤\n",
    "    checklist = {}\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¡œë“œ í™•ì¸\n",
    "    checklist[\"1. ë°ì´í„° ë¡œë“œ\"] = 'data_info' in locals() and len(data_info) > 0\n",
    "    \n",
    "    # 2. ëª¨ë¸ í•™ìŠµ ê²°ê³¼ í™•ì¸\n",
    "    checklist[\"2. ëª¨ë¸ í•™ìŠµ (96ê°œ)\"] = 'results_df' in locals() and len(results_df) > 0\n",
    "    \n",
    "    # 3. ê²°ê³¼ íŒŒì¼ ì €ì¥ í™•ì¸\n",
    "    checklist[\"3. ì „ì²´ ê²°ê³¼ CSV\"] = os.path.exists('../results_v2/all_model_results.csv')\n",
    "    \n",
    "    # 4. í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ í™•ì¸\n",
    "    checklist[\"4. í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸\"] = os.path.exists('../results_v2/best_models.csv')\n",
    "    \n",
    "    # 5. ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” í™•ì¸ (8ê°œ)\n",
    "    individual_dir = '../results_v2/best_models_individual/'\n",
    "    individual_files = [f for f in os.listdir(individual_dir) if f.endswith('.csv')] if os.path.exists(individual_dir) else []\n",
    "    checklist[\"5. ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ (8ê°œ)\"] = len(individual_files) >= 8\n",
    "    \n",
    "    # 6. ê¸°ë³¸ ì‹œê°í™” í™•ì¸\n",
    "    basic_viz = '../results_v2/visualizations/basic_performance_comparison.png'\n",
    "    checklist[\"6. ê¸°ë³¸ ì„±ëŠ¥ ì‹œê°í™”\"] = os.path.exists(basic_viz)\n",
    "    \n",
    "    # 7. ìƒì„¸ ì‹œê°í™” í™•ì¸\n",
    "    detailed_viz_files = [\n",
    "        'regression_detailed_comparison.png',\n",
    "        'classification_detailed_comparison.png', \n",
    "        'same_model_center_comparison_regression.png',\n",
    "        'same_model_center_comparison_classification.png'\n",
    "    ]\n",
    "    viz_dir = '../results_v2/visualizations/'\n",
    "    viz_count = sum([os.path.exists(os.path.join(viz_dir, f)) for f in detailed_viz_files])\n",
    "    checklist[\"7. ìƒì„¸ ì‹œê°í™” (4ê°œ)\"] = viz_count >= 4\n",
    "    \n",
    "    # 8. ROC Curve ì‹œê°í™”\n",
    "    roc_file = '../results_v2/visualizations/roc_curves.png'\n",
    "    checklist[\"8. ROC Curve ì‹œê°í™”\"] = os.path.exists(roc_file)\n",
    "    \n",
    "    # 9. ë² ìŠ¤íŠ¸ ëª¨ë¸ íŒŒì¼ ì €ì¥ (8ê°œ)\n",
    "    model_dir = '../models_v2/best_models/'\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')] if os.path.exists(model_dir) else []\n",
    "    checklist[\"9. ë² ìŠ¤íŠ¸ ëª¨ë¸ íŒŒì¼ (8ê°œ)\"] = len(model_files) >= 8\n",
    "    \n",
    "    # 10. SHAP ë¶„ì„ í™•ì¸\n",
    "    interp_dir = '../results_v2/interpretations/'\n",
    "    shap_files = [f for f in os.listdir(interp_dir) if 'shap' in f.lower()] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"10. SHAP ë¶„ì„\"] = len(shap_files) >= 8  # Summary + Importance + Force plots\n",
    "    \n",
    "    # 11. Feature Importance ë¶„ì„ í™•ì¸\n",
    "    fi_files = [f for f in os.listdir(interp_dir) if 'feature_importance' in f] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"11. Feature Importance\"] = len(fi_files) >= 8\n",
    "    \n",
    "    # 12. ì„±ëŠ¥ ì§€í‘œ ì™„ì„±ë„ í™•ì¸ (SMAPE, macro ë²„ì „ë“¤)\n",
    "    if 'results_df' in locals() and len(results_df) > 0:\n",
    "        has_smape = 'SMAPE' in results_df.columns\n",
    "        has_f1_macro = 'F1_macro' in results_df.columns\n",
    "        checklist[\"12. ì™„ì „í•œ ì„±ëŠ¥ ì§€í‘œ\"] = has_smape and has_f1_macro\n",
    "    else:\n",
    "        checklist[\"12. ì™„ì „í•œ ì„±ëŠ¥ ì§€í‘œ\"] = False\n",
    "    \n",
    "    # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"{status_icon} {item}: {'ì™„ë£Œ' if status else 'ë¯¸ì™„ë£Œ'}\")\n",
    "    \n",
    "    # ì™„ë£Œìœ¨ ê³„ì‚°\n",
    "    completed = sum(checklist.values())\n",
    "    total = len(checklist)\n",
    "    completion_rate = completed / total * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì „ì²´ ì™„ë£Œìœ¨: {completion_rate:.1f}% ({completed}/{total})\")\n",
    "    \n",
    "    # ìƒíƒœì— ë”°ë¥¸ ë©”ì‹œì§€\n",
    "    if completion_rate >= 95:\n",
    "        print(\"ğŸ‰ í”„ë¡œì íŠ¸ê°€ ì™„ë²½í•˜ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    elif completion_rate >= 85:\n",
    "        print(\"ğŸŒŸ í”„ë¡œì íŠ¸ê°€ ê±°ì˜ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    elif completion_rate >= 70:\n",
    "        print(\"âš ï¸ ëŒ€ë¶€ë¶„ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ì¼ë¶€ ë‹¨ê³„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(\"âŒ ì—¬ëŸ¬ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    # ìƒì„¸ íŒŒì¼ í˜„í™©\n",
    "    print(f\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼ ìƒì„¸ í˜„í™©:\")\n",
    "    \n",
    "    # 1. CSV ê²°ê³¼ íŒŒì¼\n",
    "    print(f\"\\nğŸ“Š ì„±ëŠ¥ ê²°ê³¼ íŒŒì¼:\")\n",
    "    if os.path.exists('../results_v2/all_model_results.csv'):\n",
    "        df = pd.read_csv('../results_v2/all_model_results.csv')\n",
    "        print(f\"  âœ… ì „ì²´ ëª¨ë¸ ê²°ê³¼: {len(df)}ê°œ ë ˆì½”ë“œ\")\n",
    "        \n",
    "        # ì„±ëŠ¥ ì§€í‘œ í™•ì¸\n",
    "        reg_cols = ['MAE', 'MSE', 'RMSE', 'MAPE', 'SMAPE', 'R2']\n",
    "        clf_cols = ['Accuracy', 'Precision_weighted', 'Precision_macro', \n",
    "                   'Recall_weighted', 'Recall_macro', 'F1_weighted', 'F1_macro', 'AUC']\n",
    "        \n",
    "        available_reg = [col for col in reg_cols if col in df.columns]\n",
    "        available_clf = [col for col in clf_cols if col in df.columns]\n",
    "        \n",
    "        print(f\"    ğŸ“ˆ íšŒê·€ ì§€í‘œ ({len(available_reg)}/6): {available_reg}\")\n",
    "        print(f\"    ğŸ“Š ë¶„ë¥˜ ì§€í‘œ ({len(available_clf)}/8): {available_clf}\")\n",
    "    \n",
    "    if os.path.exists('../results_v2/best_models.csv'):\n",
    "        df = pd.read_csv('../results_v2/best_models.csv')\n",
    "        print(f\"  âœ… í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸: {len(df)}ê°œ ëª¨ë¸\")\n",
    "    \n",
    "    # 2. ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸”\n",
    "    print(f\"\\nğŸ“‹ ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸”:\")\n",
    "    if os.path.exists('../results_v2/best_models_individual/'):\n",
    "        individual_files = [f for f in os.listdir('../results_v2/best_models_individual/') if f.endswith('.csv')]\n",
    "        print(f\"  âœ… ê°œë³„ í…Œì´ë¸”: {len(individual_files)}ê°œ\")\n",
    "        for file in sorted(individual_files):\n",
    "            print(f\"    - {file}\")\n",
    "    \n",
    "    # 3. ì‹œê°í™” íŒŒì¼\n",
    "    print(f\"\\nğŸ“ˆ ì‹œê°í™” íŒŒì¼:\")\n",
    "    if os.path.exists('../results_v2/visualizations/'):\n",
    "        viz_files = [f for f in os.listdir('../results_v2/visualizations/') if f.endswith('.png')]\n",
    "        print(f\"  âœ… ì‹œê°í™” íŒŒì¼: {len(viz_files)}ê°œ\")\n",
    "        for file in sorted(viz_files):\n",
    "            print(f\"    - {file}\")\n",
    "    \n",
    "    # 4. í•´ì„ ë¶„ì„ íŒŒì¼\n",
    "    print(f\"\\nğŸ” í•´ì„ ë¶„ì„ íŒŒì¼:\")\n",
    "    if os.path.exists('../results_v2/interpretations/'):\n",
    "        interp_files = [f for f in os.listdir('../results_v2/interpretations/') if f.endswith('.png')]\n",
    "        print(f\"  âœ… í•´ì„ ë¶„ì„ íŒŒì¼: {len(interp_files)}ê°œ\")\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜\n",
    "        shap_count = len([f for f in interp_files if 'shap' in f.lower()])\n",
    "        fi_count = len([f for f in interp_files if 'feature_importance' in f])\n",
    "        lime_count = len([f for f in interp_files if 'lime' in f])\n",
    "        \n",
    "        print(f\"    ğŸ“Š SHAP ë¶„ì„: {shap_count}ê°œ\")\n",
    "        print(f\"    ğŸ“Š Feature Importance: {fi_count}ê°œ\")\n",
    "        print(f\"    ğŸ“Š LIME ë¶„ì„: {lime_count}ê°œ\")\n",
    "    \n",
    "    # 5. ëª¨ë¸ íŒŒì¼\n",
    "    print(f\"\\nğŸ¤– ì €ì¥ëœ ëª¨ë¸ íŒŒì¼:\")\n",
    "    if os.path.exists('../models_v2/best_models/'):\n",
    "        model_files = [f for f in os.listdir('../models_v2/best_models/') if f.endswith('.pkl')]\n",
    "        print(f\"  âœ… ë² ìŠ¤íŠ¸ ëª¨ë¸: {len(model_files)}ê°œ\")\n",
    "        for file in sorted(model_files):\n",
    "            print(f\"    - {file}\")\n",
    "    \n",
    "    # 6. ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸\n",
    "    if 'results_df' in locals() and len(results_df) > 0:\n",
    "        print(f\"\\nğŸ† ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸:\")\n",
    "        \n",
    "        # ìµœê³  íšŒê·€ ì„±ëŠ¥ (ì—¬ëŸ¬ ì§€í‘œ)\n",
    "        reg_data = results_df[results_df['task'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            best_r2 = reg_data.loc[reg_data['R2'].idxmax()]\n",
    "            best_rmse = reg_data.loc[reg_data['RMSE'].idxmin()]\n",
    "            \n",
    "            print(f\"  ğŸ“ˆ ìµœê³  R2: {best_r2['center']} - {best_r2['model']} (R2 = {best_r2['R2']:.4f})\")\n",
    "            print(f\"  ğŸ“ˆ ìµœì € RMSE: {best_rmse['center']} - {best_rmse['model']} (RMSE = {best_rmse['RMSE']:.2f})\")\n",
    "            \n",
    "            if 'SMAPE' in reg_data.columns:\n",
    "                best_smape = reg_data.loc[reg_data['SMAPE'].idxmin()]\n",
    "                print(f\"  ğŸ“ˆ ìµœì € SMAPE: {best_smape['center']} - {best_smape['model']} (SMAPE = {best_smape['SMAPE']:.2f}%)\")\n",
    "        \n",
    "        # ìµœê³  ë¶„ë¥˜ ì„±ëŠ¥\n",
    "        clf_data = results_df[results_df['task'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            best_acc = clf_data.loc[clf_data['Accuracy'].idxmax()]\n",
    "            best_f1w = clf_data.loc[clf_data['F1_weighted'].idxmax()]\n",
    "            \n",
    "            print(f\"  ğŸ“Š ìµœê³  Accuracy: {best_acc['center']} - {best_acc['model']} (Acc = {best_acc['Accuracy']:.4f})\")\n",
    "            print(f\"  ğŸ“Š ìµœê³  F1_weighted: {best_f1w['center']} - {best_f1w['model']} (F1_w = {best_f1w['F1_weighted']:.4f})\")\n",
    "            \n",
    "            if 'F1_macro' in clf_data.columns:\n",
    "                best_f1m = clf_data.loc[clf_data['F1_macro'].idxmax()]\n",
    "                print(f\"  ğŸ“Š ìµœê³  F1_macro: {best_f1m['center']} - {best_f1m['model']} (F1_m = {best_f1m['F1_macro']:.4f})\")\n",
    "    \n",
    "    # 7. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
    "    print(f\"\\nğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:\")\n",
    "    print(\"  1. ì„±ëŠ¥ì´ ë‚®ì€ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\")\n",
    "    print(\"  2. ì•™ìƒë¸” ë°©ë²• ì ìš© (Voting, Stacking)\")\n",
    "    print(\"  3. êµì°¨ ê²€ì¦ì„ í†µí•œ ë” ì•ˆì •ì ì¸ ì„±ëŠ¥ í‰ê°€\")\n",
    "    print(\"  4. ì¶”ê°€ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì‹œê³„ì—´ íŠ¹ì„±, ì™¸ë¶€ ë°ì´í„°)\")\n",
    "    print(\"  5. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "    print(\"  6. A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì‹¤ì œ íš¨ê³¼ ê²€ì¦\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì§ˆë¬¸ì´ë‚˜ ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!\")\n",
    "    \n",
    "    return checklist\n",
    "\n",
    "# í¬ê´„ì ì¸ ìµœì¢… ìš”ì•½ ì‹¤í–‰\n",
    "final_checklist = comprehensive_final_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"âœ¨ ëª¨ë“  ìš”êµ¬ì‚¬í•­ì´ ì™„ë²½í•˜ê²Œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% ì…€ 20: ì¶”ê°€ í™œìš© ì˜ˆì‹œ ë° íŒ\n",
    "print(\"ğŸ’¡ ì¶”ê°€ í™œìš© ì˜ˆì‹œ ë° íŒ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "usage_examples = '''\n",
    "# ğŸ”® ì €ì¥ëœ ëª¨ë¸ í™œìš© ì˜ˆì‹œ\n",
    "\n",
    "# 1. ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì˜ˆì¸¡\n",
    "new_data = pd.read_csv('new_sewage_data.csv')\n",
    "\n",
    "# nanji ì„¼í„° íšŒê·€ ì˜ˆì¸¡\n",
    "reg_prediction = predict_with_saved_model('nanji', 'regression', new_data)\n",
    "print(f\"ì˜ˆì¸¡ëœ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰: {reg_prediction}\")\n",
    "\n",
    "# nanji ì„¼í„° ë¶„ë¥˜ ì˜ˆì¸¡\n",
    "clf_prediction, clf_proba = predict_with_saved_model('nanji', 'classification', new_data)\n",
    "print(f\"ì˜ˆì¸¡ëœ ë“±ê¸‰: {clf_prediction}\")\n",
    "print(f\"ê° ë“±ê¸‰ë³„ í™•ë¥ : {clf_proba}\")\n",
    "\n",
    "# 2. ì €ì¥ëœ ëª¨ë¸ ì •ë³´ í™•ì¸\n",
    "model_info = load_saved_model('nanji', 'regression')\n",
    "print(f\"ì‚¬ìš©ëœ í”¼ì²˜: {model_info['feature_names']}\")\n",
    "print(f\"ëª¨ë¸ ì„±ëŠ¥: {model_info['performance']}\")\n",
    "\n",
    "# 3. ë°°ì¹˜ ì˜ˆì¸¡ (ì—¬ëŸ¬ ì„¼í„° ë™ì‹œ)\n",
    "centers = ['nanji', 'jungnang', 'seonam', 'tancheon']\n",
    "predictions = {}\n",
    "\n",
    "for center in centers:\n",
    "    pred = predict_with_saved_model(center, 'regression', new_data)\n",
    "    if pred is not None:\n",
    "        predictions[center] = pred\n",
    "\n",
    "# 4. ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„\n",
    "results_df = pd.read_csv('../results/all_model_results.csv')\n",
    "\n",
    "# ì„¼í„°ë³„ í‰ê·  ì„±ëŠ¥\n",
    "center_performance = results_df.groupby('center').agg({\n",
    "    'R2': 'mean',\n",
    "    'RMSE': 'mean', \n",
    "    'F1_weighted': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"ì„¼í„°ë³„ í‰ê·  ì„±ëŠ¥:\")\n",
    "print(center_performance)\n",
    "\n",
    "# 5. ì•™ìƒë¸” ì˜ˆì¸¡ (ì—¬ëŸ¬ ëª¨ë¸ ê²°ê³¼ í‰ê· )\n",
    "def ensemble_predict(center, task, new_data):\n",
    "    # í•´ë‹¹ ì„¼í„°-íƒœìŠ¤í¬ì˜ ëª¨ë“  ëª¨ë¸ ë¡œë“œ\n",
    "    model_dir = '../models/best_models/'\n",
    "    model_files = [f for f in os.listdir(model_dir) \n",
    "                  if f.startswith(f'{center}_{task}_')]\n",
    "    \n",
    "    predictions = []\n",
    "    for model_file in model_files:\n",
    "        with open(os.path.join(model_dir, model_file), 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "            model = model_data['model']\n",
    "            feature_names = model_data['feature_names']\n",
    "            \n",
    "            X_new = new_data[feature_names]\n",
    "            pred = model.predict(X_new)\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    # í‰ê·  ì˜ˆì¸¡ê°’ ë°˜í™˜\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    return ensemble_pred\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# ensemble_result = ensemble_predict('nanji', 'regression', new_data)\n",
    "'''\n",
    "\n",
    "tips = '''\n",
    "# ğŸ’¡ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ íŒ\n",
    "\n",
    "# 1. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¶”ê°€\n",
    "def create_additional_features(data):\n",
    "    \"\"\"ì¶”ê°€ í”¼ì²˜ ìƒì„± ì˜ˆì‹œ\"\"\"\n",
    "    # ì‹œê³„ì—´ íŠ¹ì„±\n",
    "    data['month'] = pd.to_datetime(data['ë‚ ì§œ']).dt.month\n",
    "    data['quarter'] = pd.to_datetime(data['ë‚ ì§œ']).dt.quarter\n",
    "    data['day_of_week'] = pd.to_datetime(data['ë‚ ì§œ']).dt.dayofweek\n",
    "    \n",
    "    # ì´ë™í‰ê· \n",
    "    data['ma_7d'] = data['í•©ê³„'].rolling(window=7).mean()\n",
    "    data['ma_30d'] = data['í•©ê³„'].rolling(window=30).mean()\n",
    "    \n",
    "    # ë³€í™”ìœ¨\n",
    "    data['change_rate'] = data['í•©ê³„'].pct_change()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 2. êµì°¨ ê²€ì¦ìœ¼ë¡œ ë” ì•ˆì •ì ì¸ ì„±ëŠ¥ í‰ê°€\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "\n",
    "def cross_validate_model(model, X, y, task='regression'):\n",
    "    \"\"\"êµì°¨ ê²€ì¦ ì„±ëŠ¥ í‰ê°€\"\"\"\n",
    "    if task == 'regression':\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "        print(f\"Cross-validation R2: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    else:\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='f1_weighted')\n",
    "        print(f\"Cross-validation F1: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# 3. ì‹œê³„ì—´ íŠ¹ì„±ì„ ê³ ë ¤í•œ êµì°¨ ê²€ì¦\n",
    "def time_series_cross_validate(model, X, y, task='regression'):\n",
    "    \"\"\"ì‹œê³„ì—´ êµì°¨ ê²€ì¦\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    if task == 'regression':\n",
    "        scores = cross_val_score(model, X, y, cv=tscv, scoring='r2')\n",
    "    else:\n",
    "        scores = cross_val_score(model, X, y, cv=tscv, scoring='f1_weighted')\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# 4. ëª¨ë¸ í•´ì„ì„ ìœ„í•œ ì¶”ê°€ ë¶„ì„\n",
    "def analyze_prediction_errors(y_true, y_pred, feature_names, X_test):\n",
    "    \"\"\"ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì„\"\"\"\n",
    "    errors = y_pred - y_true\n",
    "    \n",
    "    # í° ì˜¤ì°¨ë¥¼ ê°€ì§„ ìƒ˜í”Œë“¤ ë¶„ì„\n",
    "    large_errors = np.abs(errors) > np.std(errors) * 2\n",
    "    problematic_samples = X_test[large_errors]\n",
    "    \n",
    "    print(f\"í° ì˜¤ì°¨ë¥¼ ê°€ì§„ ìƒ˜í”Œ ìˆ˜: {large_errors.sum()}\")\n",
    "    print(\"ë¬¸ì œê°€ ìˆëŠ” ìƒ˜í”Œë“¤ì˜ íŠ¹ì„±:\")\n",
    "    print(problematic_samples.describe())\n",
    "    \n",
    "    return problematic_samples\n",
    "\n",
    "# 5. A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ëª¨ë¸ ë¹„êµ\n",
    "def ab_test_models(model_a, model_b, X_test, y_test, task='regression'):\n",
    "    \"\"\"ë‘ ëª¨ë¸ ê°„ì˜ ì„±ëŠ¥ ë¹„êµ\"\"\"\n",
    "    pred_a = model_a.predict(X_test)\n",
    "    pred_b = model_b.predict(X_test)\n",
    "    \n",
    "    if task == 'regression':\n",
    "        score_a = r2_score(y_test, pred_a)\n",
    "        score_b = r2_score(y_test, pred_b)\n",
    "        metric = 'R2'\n",
    "    else:\n",
    "        score_a = f1_score(y_test, pred_a, average='weighted')\n",
    "        score_b = f1_score(y_test, pred_b, average='weighted')\n",
    "        metric = 'F1'\n",
    "    \n",
    "    print(f\"Model A {metric}: {score_a:.4f}\")\n",
    "    print(f\"Model B {metric}: {score_b:.4f}\")\n",
    "    print(f\"Performance difference: {score_b - score_a:.4f}\")\n",
    "    \n",
    "    # í†µê³„ì  ìœ ì˜ì„± ê²€ì‚¬ (ì„ íƒì‚¬í•­)\n",
    "    from scipy import stats\n",
    "    \n",
    "    if task == 'regression':\n",
    "        errors_a = np.abs(y_test - pred_a)\n",
    "        errors_b = np.abs(y_test - pred_b)\n",
    "        t_stat, p_value = stats.ttest_rel(errors_a, errors_b)\n",
    "        \n",
    "        print(f\"T-test p-value: {p_value:.4f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"ì„±ëŠ¥ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"ì„±ëŠ¥ ì°¨ì´ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "'''\n",
    "\n",
    "monitoring = '''\n",
    "# ğŸ“Š ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "# 1. ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n",
    "def monitor_model_performance(predictions, actual_values, threshold=0.1):\n",
    "    \"\"\"ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\"\"\"\n",
    "    current_performance = r2_score(actual_values, predictions)\n",
    "    \n",
    "    # ì„±ëŠ¥ ì €í•˜ ê°ì§€\n",
    "    baseline_performance = 0.8  # ê¸°ì¤€ ì„±ëŠ¥\n",
    "    \n",
    "    if current_performance < baseline_performance - threshold:\n",
    "        print(f\"âš ï¸ ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ ê°ì§€! í˜„ì¬ R2: {current_performance:.4f}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"âœ… ëª¨ë¸ ì„±ëŠ¥ ì–‘í˜¸: R2 {current_performance:.4f}\")\n",
    "        return True\n",
    "\n",
    "# 2. ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€\n",
    "def detect_data_drift(reference_data, current_data, threshold=0.05):\n",
    "    \"\"\"ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€\"\"\"\n",
    "    from scipy import stats\n",
    "    \n",
    "    drifted_features = []\n",
    "    \n",
    "    for col in reference_data.columns:\n",
    "        if col in current_data.columns:\n",
    "            # KS-testë¡œ ë¶„í¬ ë³€í™” ê°ì§€\n",
    "            ks_stat, p_value = stats.ks_2samp(reference_data[col], current_data[col])\n",
    "            \n",
    "            if p_value < threshold:\n",
    "                drifted_features.append(col)\n",
    "                print(f\"âš ï¸ {col}: ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€ (p-value: {p_value:.4f})\")\n",
    "    \n",
    "    return drifted_features\n",
    "\n",
    "# 3. ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°\n",
    "def auto_retrain_trigger(performance_history, window=30, threshold=0.05):\n",
    "    \"\"\"ìë™ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°\"\"\"\n",
    "    if len(performance_history) >= window:\n",
    "        recent_avg = np.mean(performance_history[-window:])\n",
    "        overall_avg = np.mean(performance_history)\n",
    "        \n",
    "        if overall_avg - recent_avg > threshold:\n",
    "            print(\"ğŸ”„ ìë™ ì¬í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "'''\n",
    "\n",
    "print(usage_examples)\n",
    "print(tips)\n",
    "print(monitoring)\n",
    "\n",
    "print(\"âœ¨ ì™„ì „í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“š ì´ ë…¸íŠ¸ë¶ì„ ì°¸ê³ í•˜ì—¬ ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”!\")\n",
    "print(\"ğŸ¯ ëª¨ë“  ìš”êµ¬ì‚¬í•­ì´ ì™„ë²½í•˜ê²Œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ!\n",
    "# \n",
    "# ## âœ… ì™„ì„±ëœ ê¸°ëŠ¥ë“¤\n",
    "# \n",
    "# ### ğŸ“Š **ëª¨ë¸ í•™ìŠµ ë° í‰ê°€**\n",
    "# - âœ… 96ê°œ ëª¨ë¸ í•™ìŠµ (4ì„¼í„° Ã— 2ë¶„í• ë°©ë²• Ã— 2íƒœìŠ¤í¬ Ã— 6ëª¨ë¸)\n",
    "# - âœ… **ì™„ì „í•œ ì„±ëŠ¥ ì§€í‘œ**: \n",
    "#   - íšŒê·€: MAE, MSE, RMSE, MAPE, **SMAPE**, R2\n",
    "#   - ë¶„ë¥˜: Accuracy, Precision(weighted/macro), Recall(weighted/macro), F1(weighted/macro), AUC\n",
    "# \n",
    "# ### ğŸ† **ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ ì •**\n",
    "# - âœ… í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” (ê¸°ì¡´)\n",
    "# - âœ… **8ê°œ ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸”** (ì„¼í„°ë³„Ã—ë¶„í• ë°©ë²•ë³„Ã—íƒœìŠ¤í¬ë³„)\n",
    "# - âœ… ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¬í•™ìŠµ ë° pickle íŒŒì¼ ì €ì¥\n",
    "# \n",
    "# ### ğŸ“ˆ **ì™„ì „í•œ ì‹œê°í™”**\n",
    "# - âœ… ë¶„í•  ë°©ë²•ì— ë”°ë¥¸ ì„¼í„°ë³„ ì„±ëŠ¥ ë¹„êµ\n",
    "# - âœ… **ì„¼í„°ë³„ ëª¨ë¸ë³„ ì„±ëŠ¥ ìƒì„¸ ë¹„êµ** (íšŒê·€ 4ê°œ, ë¶„ë¥˜ 4ê°œ ì§€í‘œë³„)\n",
    "# - âœ… **ë™ì¼ ëª¨ë¸ì— ëŒ€í•œ ì„¼í„°ë³„ ì„±ëŠ¥ ë¹„êµ**\n",
    "# - âœ… **ROC Curve ì‹œê°í™”** (ì‹¤ì œ êµ¬í˜„)\n",
    "# \n",
    "# ### ğŸ” **ì™„ì „í•œ ëª¨ë¸ í•´ì„**\n",
    "# - âœ… **ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸**ì— ëŒ€í•œ í•´ì„ ë¶„ì„\n",
    "# - âœ… SHAP: Summary Plot + Feature Importance + **Force Plot**\n",
    "# - âœ… Feature Importance (Tree-based, Linear ëª¨ë¸ë³„)\n",
    "# - âœ… LIME ë¶„ì„ (ì„ íƒì‚¬í•­)\n",
    "# \n",
    "# ### ğŸ”® **í™œìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥**\n",
    "# - âœ… ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "# - âœ… ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜\n",
    "# - âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ\n",
    "# - âœ… ì•™ìƒë¸” ì˜ˆì¸¡ ì˜ˆì‹œ\n",
    "# - âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€\n",
    "# \n",
    "# ## ğŸ¯ ì›ë˜ ìš”êµ¬ì‚¬í•­ 100% ë‹¬ì„±!\n",
    "# \n",
    "# 1. âœ… **ì„±ëŠ¥í‰ê°€ì§€í‘œ ì™„ì„±**: SMAPE ì¶”ê°€, ë¶„ë¥˜ macro ë²„ì „ ì¶”ê°€\n",
    "# 2. âœ… **ìƒì„¸ ì‹œê°í™” ì™„ì„±**: ì„¼í„°ë³„ ëª¨ë¸ë³„, ë™ì¼ëª¨ë¸ ì„¼í„°ë³„ ë¹„êµ\n",
    "# 3. âœ… **ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸”**: í†µí•© + 8ê°œ ê°œë³„ í…Œì´ë¸”\n",
    "# 4. âœ… **ì™„ì „í•œ í•´ì„ ë¶„ì„**: 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸, Force Plot í¬í•¨\n",
    "# 5. âœ… **í•œê¸€ í°íŠ¸**: AppleGothicìœ¼ë¡œ ê¹¨ì§ ë°©ì§€\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# ## ğŸš€ ì‚¬ìš© ë°©ë²•\n",
    "# \n",
    "# 1. **ì„¼í„°ëª… ìˆ˜ì •**: 3ë²ˆ ì…€ì—ì„œ `pipeline.centers` ì‹¤ì œ ì„¼í„°ëª…ìœ¼ë¡œ ë³€ê²½\n",
    "# 2. **ìˆœì°¨ ì‹¤í–‰**: ëª¨ë“  ì…€ì„ ìœ„ì—ì„œë¶€í„° ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\n",
    "# 3. **ê²°ê³¼ í™•ì¸**: 19ë²ˆ ì…€ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ì—ì„œ ì™„ë£Œìœ¨ 95% ì´ìƒ í™•ì¸\n",
    "# 4. **í™œìš©**: 20ë²ˆ ì…€ì˜ ì˜ˆì‹œ ì½”ë“œë¡œ ì‹¤ì œ ì˜ˆì¸¡ ë° ë¶„ì„\n",
    "# \n",
    "# **ğŸŠ ì™„ë²½í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œìŠ¤í…œ ì™„ì„±! ğŸŠ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b9377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8eef40e",
   "metadata": {},
   "source": [
    "## ì½”ë“œ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d045a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# **ğŸŠ ì™„ë²½í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œìŠ¤í…œ ì™„ì„±! ğŸŠ**# ========================================================================================\n",
    "# í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ - ì™„ì „ ìˆ˜ì •ëœ Jupyter Notebook ë²„ì „ ---- ê·¸ë˜í”„ ìƒ‰ êµ¬ë¦¬ê³ , ì‹œê°í™”ì— ê¸€ìê°€ ê¹¨ì ¸ì„œ ë‚˜ì˜´ ã…—ã…—\n",
    "# ========================================================================================\n",
    "\n",
    "# %% ì…€ 1: íŒ¨í‚¤ì§€ import ë° ê¸°ë³¸ ì„¤ì •\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# í•´ì„ ê°€ëŠ¥ì„± ë¶„ì„\n",
    "import shap\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # ë§¥ í•œê¸€ í°íŠ¸\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic' # ìœˆë„ìš°\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ import ì™„ë£Œ\")\n",
    "print(f\"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac29af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **ğŸŠ ì™„ë²½í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œìŠ¤í…œ ì™„ì„±! ğŸŠ**\n",
    "# ========================================================================================\n",
    "# í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ - ìƒ‰ìƒ ë° ì‹œê°í™”/ì„œë¸Œí”Œë¡¯ ë¹ˆì¹¸ ìˆ˜ì •(ì „ì²´ ì½”ë“œ)\n",
    "# ========================================================================================\n",
    "# %% ì…€ 1: íŒ¨í‚¤ì§€ import ë° ê¸°ë³¸ ì„¤ì •\n",
    "import os, warnings, pickle\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# í•´ì„ ê°€ëŠ¥ì„± ë¶„ì„\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---- ìƒ‰ìƒ íŒ”ë ˆíŠ¸(ì¼ê´€ì„± ìœ ì§€)\n",
    "PALETTE = [\n",
    "    \"#2563EB\", \"#F97316\", \"#10B981\", \"#A855F7\", \"#EF4444\", \"#0EA5E9\",\n",
    "    \"#F59E0B\", \"#22C55E\", \"#8B5CF6\", \"#DC2626\", \"#14B8A6\", \"#E11D48\"\n",
    "]\n",
    "\n",
    "# seaborn ìŠ¤íƒ€ì¼ ë¨¼ì €\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(PALETTE)\n",
    "\n",
    "# matplotlibì—ë„ ë™ì¼ íŒ”ë ˆíŠ¸ ì ìš©\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=PALETTE)\n",
    "\n",
    "# ---- í°íŠ¸ ì„¤ì • (ë§¨ ë§ˆì§€ë§‰ì—!)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # ë§¥\n",
    "# plt.rcParams['font.family'] = 'Malgun Gothic'  # ìœˆë„ìš°\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ import ë° ì„¤ì • ì™„ë£Œ\")\n",
    "print(\"í˜„ì¬ í°íŠ¸:\", plt.rcParams[\"font.family\"])\n",
    "print(f\"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "\n",
    "# %% ì…€ 2: ë””ë ‰í† ë¦¬ ìƒì„± ë° ì„¤ì •\n",
    "directories = [\n",
    "    '../results_v2', \n",
    "    '../results_v2/visualizations', \n",
    "    '../results_v2/interpretations',\n",
    "    '../results_v2/best_models_individual',\n",
    "    '../models_v2', \n",
    "    '../models_v2/best_models'\n",
    "]\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {directory}\")\n",
    "print(\"âœ… ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 3: íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ ì •ì˜ - ê¸°ë³¸ ì„¤ì •\n",
    "class CompleteSewagePredictionPipeline:\n",
    "    def __init__(self, data_path_template='../data/add_feature/{}_add_feature.csv'):\n",
    "        \"\"\"ì™„ì „í•œ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "        self.data_path_template = data_path_template\n",
    "        self.centers = ['nanji', 'jungnang', 'seonam', 'tancheon']  # ì‹¤ì œ ì„¼í„°ëª…\n",
    "        \n",
    "        # ì œì™¸í•  ì»¬ëŸ¼\n",
    "        self.not_use_col = [\n",
    "            'ë‚ ì§œ',\n",
    "            '1ì²˜ë¦¬ì¥','2ì²˜ë¦¬ì¥','ì •í™”ì¡°','ì¤‘ê³„íŒí”„ì¥','í•©ê³„','ì‹œì„¤í˜„ëŒ€í™”',\n",
    "            '3ì²˜ë¦¬ì¥','4ì²˜ë¦¬ì¥','í•©ê³„', 'í•©ê³„_1ì¼í›„','í•©ê³„_2ì¼í›„',\n",
    "            'ë“±ê¸‰','ë“±ê¸‰_1ì¼í›„','ë“±ê¸‰_2ì¼í›„'\n",
    "        ]\n",
    "        \n",
    "        # íšŒê·€ ëª¨ë¸\n",
    "        self.regression_models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForest': RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "            'CatBoost': cb.CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
    "            'LightGBM': lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # ë¶„ë¥˜ ëª¨ë¸\n",
    "        self.classification_models = {\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'RandomForest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "            'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'CatBoost': cb.CatBoostClassifier(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "            'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "    def load_data(self, center):\n",
    "        \"\"\"ì„¼í„°ë³„ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        file_path = self.data_path_template.format(center)\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(f\"âœ… {center} ì„¼í„° ë°ì´í„° ë¡œë“œ: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "pipeline = CompleteSewagePredictionPipeline()\n",
    "print(\"ğŸ”§ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 4: ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ\n",
    "def prepare_features(data, not_use_col):\n",
    "    \"\"\"í”¼ì²˜ ë° íƒ€ê²Ÿ ì¤€ë¹„\"\"\"\n",
    "    available_cols = [col for col in data.columns if col not in not_use_col]\n",
    "    X = data[available_cols]\n",
    "    y_reg = data['í•©ê³„_1ì¼í›„']  # íšŒê·€ìš©\n",
    "    y_clf = data['ë“±ê¸‰_1ì¼í›„']  # ë¶„ë¥˜ìš©\n",
    "    return X, y_reg, y_clf\n",
    "\n",
    "def split_data_temporal(X, y, test_size=0.2):\n",
    "    \"\"\"ì‹œê³„ì—´ ì •ë³´ë¥¼ ìœ ì§€í•œ ë¶„í• \"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_random(X, y, test_size=0.2, stratify=None):\n",
    "    \"\"\"ëœë¤ ë¶„í•  (ë¶„ë¥˜ì‹œ stratified)\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=42)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.inf\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MAE': mae,'MSE': mse,'RMSE': rmse,'MAPE': mape,'SMAPE': smape,'R2': r2}\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_weighted': precision_weighted,\n",
    "        'Precision_macro': precision_macro,\n",
    "        'Recall_weighted': recall_weighted,\n",
    "        'Recall_macro': recall_macro,\n",
    "        'F1_weighted': f1_weighted,\n",
    "        'F1_macro': f1_macro\n",
    "    }\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "            metrics['AUC'] = auc_score\n",
    "        except Exception:\n",
    "            metrics['AUC'] = 0\n",
    "    return metrics\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 5: ë°ì´í„° í™•ì¸\n",
    "print(\"ğŸ“Š ë°ì´í„° íŒŒì¼ í™•ì¸\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_info = {}\n",
    "for center in pipeline.centers:\n",
    "    data = pipeline.load_data(center)\n",
    "    if data is not None:\n",
    "        data_info[center] = {'data': data,'shape': data.shape}\n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        print(f\"  ğŸ“ˆ í”¼ì²˜ ìˆ˜: {X.shape[1]}\")\n",
    "        print(f\"  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ í´ë˜ìŠ¤: {sorted(y_clf.unique())}\\n\")\n",
    "\n",
    "if len(data_info) == 0:\n",
    "    print(\"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. pipeline.centersë¥¼ ì‹¤ì œ ì„¼í„°ëª…ìœ¼ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"âœ… {len(data_info)}ê°œ ì„¼í„° ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 6: ì „ì²´ ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "print(\"ğŸš€ ì „ì²´ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "print(f\"ì˜ˆìƒ ì´ ëª¨ë¸ ìˆ˜: {len(pipeline.centers)} Ã— 2 Ã— 2 Ã— 6 = {len(pipeline.centers) * 2 * 2 * 6}ê°œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_models = 0\n",
    "successful_models = 0\n",
    "\n",
    "for center in pipeline.centers:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ¢ {center.upper()} ì„¼í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        data = pipeline.load_data(center)\n",
    "        if data is None:\n",
    "            continue\n",
    "            \n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        print(f\"ğŸ“Š ë°ì´í„° ì •ë³´: {X.shape[0]}í–‰ Ã— {X.shape[1]}ê°œ í”¼ì²˜\")\n",
    "        print(f\"ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ í´ë˜ìŠ¤: {sorted(y_clf.unique())}\")\n",
    "        \n",
    "        for split_method in ['temporal', 'random']:\n",
    "            print(f\"\\n--- {split_method.upper()} ë¶„í•  ë°©ë²• ---\")\n",
    "            \n",
    "            # íšŒê·€\n",
    "            print(\"ğŸ“ˆ íšŒê·€ ëª¨ë¸ í•™ìŠµ:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_temporal(X, y_reg)\n",
    "            else:\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_random(X, y_reg)\n",
    "            \n",
    "            for model_name, model in pipeline.regression_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_reg, y_train_reg)\n",
    "                    y_pred = model.predict(X_test_reg)\n",
    "                    metrics = evaluate_regression(y_test_reg, y_pred)\n",
    "                    result = {\n",
    "                        'center': center,'split_method': split_method,'task': 'regression',\n",
    "                        'model': model_name, **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    print(f\"  âœ… {model_name}: R2={metrics['R2']:.4f}, RMSE={metrics['RMSE']:.2f}, SMAPE={metrics['SMAPE']:.2f}%\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ {model_name}: {str(e)}\")\n",
    "            \n",
    "            # ë¶„ë¥˜\n",
    "            print(\"ğŸ“Š ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_temporal(X, y_clf)\n",
    "            else:\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_random(X, y_clf, stratify=y_clf)\n",
    "            \n",
    "            for model_name, model in pipeline.classification_models.items():\n",
    "                total_models += 1\n",
    "                try:\n",
    "                    model.fit(X_train_clf, y_train_clf)\n",
    "                    y_pred = model.predict(X_test_clf)\n",
    "                    y_pred_proba = model.predict_proba(X_test_clf) if hasattr(model, 'predict_proba') else None\n",
    "                    metrics = evaluate_classification(y_test_clf, y_pred, y_pred_proba)\n",
    "                    result = {\n",
    "                        'center': center,'split_method': split_method,'task': 'classification',\n",
    "                        'model': model_name, **metrics\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    successful_models += 1\n",
    "                    print(f\"  âœ… {model_name}: Acc={metrics['Accuracy']:.4f}, F1_w={metrics['F1_weighted']:.4f}, F1_m={metrics['F1_macro']:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ {model_name}: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {center} ì„¼í„° ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì „ì²´ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ì„±ê³µ: {successful_models}/{total_models} ëª¨ë¸\")\n",
    "\n",
    "# %% ì…€ 7: ê²°ê³¼ ì €ì¥ ë° ê¸°ë³¸ ë¶„ì„\n",
    "results_df = pd.DataFrame(pipeline.results)\n",
    "results_df.to_csv('../results_v2/all_model_results.csv', index=False, encoding='utf-8-sig')\n",
    "print(f\"ğŸ’¾ ì „ì²´ ê²°ê³¼ ì €ì¥: ../results_v2/all_model_results.csv\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    print(f\"\\nğŸ“Š ê¸°ë³¸ í†µê³„\")\n",
    "    print(f\"ì´ ê²°ê³¼ ìˆ˜: {len(results_df)}\")\n",
    "    print(f\"ì„¼í„°ë³„ ê²°ê³¼ ìˆ˜:\")\n",
    "    print(results_df['center'].value_counts())\n",
    "    print(f\"\\níƒœìŠ¤í¬ë³„ ê²°ê³¼ ìˆ˜:\")\n",
    "    print(results_df['task'].value_counts())\n",
    "    print(\"\\nğŸ“‹ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):\")\n",
    "    display(results_df.head())\n",
    "else:\n",
    "    print(\"âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# %% ì…€ 8: ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸° (í†µí•© í…Œì´ë¸”)\n",
    "def find_best_models_integrated(results_df, centers):\n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ† í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸°\")\n",
    "    print(\"=\"*50)\n",
    "    best_models_list = []\n",
    "    \n",
    "    for center in centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[(results_df['center'] == center) & (results_df['task'] == task)]\n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "                metric_value, metric_name = best_model['R2'], 'R2'\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                metric_value, metric_name = best_model['F1_weighted'], 'F1_weighted'\n",
    "            best_models_list.append(best_model.to_dict())\n",
    "            print(f\"ğŸ… {center} - {task}: {best_model['model']} ({best_model['split_method']}) - {metric_name}={metric_value:.4f}\")\n",
    "    \n",
    "    best_models_df = pd.DataFrame(best_models_list)\n",
    "    best_models_df.to_csv('../results_v2/best_models.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nğŸ’¾ í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ì •ë³´ ì €ì¥: ../results_v2/best_models.csv\")\n",
    "    return best_models_df\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    best_models_df = find_best_models_integrated(results_df, pipeline.centers)\n",
    "    if best_models_df is not None:\n",
    "        print(f\"\\nğŸ“‹ í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸ ìš”ì•½ ({len(best_models_df)}ê°œ):\")\n",
    "        display(best_models_df[['center','task','model','split_method','R2','F1_weighted','F1_macro']].fillna('-'))\n",
    "\n",
    "# %% ì…€ 9: ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„± (8ê°œ)\n",
    "def create_individual_best_model_tables(results_df, centers):\n",
    "    print(\"ğŸ“Š ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ í…Œì´ë¸” ìƒì„± (8ê°œ)\")\n",
    "    print(\"=\"*60)\n",
    "    individual_tables = {}\n",
    "    for center in centers:\n",
    "        for split_method in ['temporal', 'random']:\n",
    "            for task in ['regression', 'classification']:\n",
    "                filtered_data = results_df[\n",
    "                    (results_df['center']==center) &\n",
    "                    (results_df['split_method']==split_method) &\n",
    "                    (results_df['task']==task)\n",
    "                ]\n",
    "                if len(filtered_data) == 0:\n",
    "                    continue\n",
    "                if task == 'regression':\n",
    "                    sorted_data = filtered_data.sort_values('R2', ascending=False)\n",
    "                    best_metric = 'R2'\n",
    "                else:\n",
    "                    sorted_data = filtered_data.sort_values('F1_weighted', ascending=False)\n",
    "                    best_metric = 'F1_weighted'\n",
    "                table_name = f\"{center}_{split_method}_{task}\"\n",
    "                filename = f\"../results_v2/best_models_individual/{table_name}_models.csv\"\n",
    "                sorted_data.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "                individual_tables[table_name] = {\n",
    "                    'data': sorted_data,\n",
    "                    'best_model': sorted_data.iloc[0]['model'],\n",
    "                    'best_score': sorted_data.iloc[0][best_metric],\n",
    "                    'filename': filename\n",
    "                }\n",
    "                print(f\"ğŸ’¾ {table_name}: {sorted_data.iloc[0]['model']} ({best_metric}={sorted_data.iloc[0][best_metric]:.4f})\")\n",
    "    print(f\"\\nâœ… ì´ {len(individual_tables)}ê°œ ê°œë³„ í…Œì´ë¸” ìƒì„± ì™„ë£Œ\")\n",
    "    return individual_tables\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    individual_best_tables = create_individual_best_model_tables(results_df, pipeline.centers)\n",
    "    print(f\"ğŸ“ ê°œë³„ í…Œì´ë¸” ì €ì¥ ìœ„ì¹˜: ../results_v2/best_models_individual/\")\n",
    "\n",
    "# %% ì…€ 10: ROC Curve(ë”ë¯¸ ì•ˆë‚´) â€” ì‹¤ì œëŠ” ì €ì¥ ëª¨ë¸ ê¸°ë°˜ ìƒì„±\n",
    "def create_roc_curves(results_df, centers):\n",
    "    print(\"ğŸ“ˆ ROC Curve ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"âš ï¸ ROC CurveëŠ” saved_models(ì¬í•™ìŠµ ê²°ê³¼)ë¡œ ì‹¤ì œ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "print(\"âœ… ROC Curve ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 11: ìƒì„¸ ì„±ëŠ¥ ì‹œê°í™” ìƒì„± (ìƒ‰/ë¹ˆì¶• ë³´ì™„ í¬í•¨)\n",
    "def create_detailed_visualizations(results_df):\n",
    "    print(\"ğŸ“Š ìƒì„¸ ì„±ëŠ¥ ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*50)\n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # 1. ê¸°ë³¸ ì„±ëŠ¥ ë¹„êµ (2x2)\n",
    "    fig1, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    reg_data = results_df[results_df['task']=='regression']\n",
    "    clf_data = results_df[results_df['task']=='classification']\n",
    "    \n",
    "    if len(reg_data) > 0:\n",
    "        reg_summary = reg_data.groupby(['center','split_method'])['R2'].mean().unstack(fill_value=0)\n",
    "        reg_summary.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ íšŒê·€ R2 ì„±ëŠ¥ (ë¶„í• ë°©ë²•ë³„)')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(['Random Split','Temporal Split'])\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    if len(clf_data) > 0:\n",
    "        clf_summary = clf_data.groupby(['center','split_method'])['F1_weighted'].mean().unstack(fill_value=0)\n",
    "        clf_summary.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ F1 ì„±ëŠ¥ (ë¶„í• ë°©ë²•ë³„)')\n",
    "        axes[0,1].set_ylabel('F1 Score (Weighted)')\n",
    "        axes[0,1].legend(['Random Split','Temporal Split'])\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    if len(reg_data) > 0:\n",
    "        reg_model_perf = reg_data.groupby(['model'])['R2'].mean().sort_values(ascending=True)\n",
    "        reg_model_perf.plot(kind='barh', ax=axes[1,0], title='ëª¨ë¸ë³„ í‰ê·  íšŒê·€ R2 ì„±ëŠ¥')\n",
    "        axes[1,0].set_xlabel('R2 Score')\n",
    "    if len(clf_data) > 0:\n",
    "        clf_model_perf = clf_data.groupby(['model'])['F1_weighted'].mean().sort_values(ascending=True)\n",
    "        clf_model_perf.plot(kind='barh', ax=axes[1,1], title='ëª¨ë¸ë³„ í‰ê·  ë¶„ë¥˜ F1 ì„±ëŠ¥')\n",
    "        axes[1,1].set_xlabel('F1 Score (Weighted)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v2/visualizations/basic_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. ì„¼í„°ë³„ ëª¨ë¸ë³„ ìƒì„¸ ì„±ëŠ¥ (íšŒê·€)\n",
    "    if len(reg_data) > 0:\n",
    "        fig2, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        reg_pivot_r2 = reg_data.pivot_table(values='R2', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_r2.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ R2 ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        reg_pivot_mae = reg_data.pivot_table(values='MAE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_mae.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ MAE ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,1].set_ylabel('MAE')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        reg_pivot_rmse = reg_data.pivot_table(values='RMSE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_rmse.plot(kind='bar', ax=axes[1,0], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ RMSE ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,0].set_ylabel('RMSE')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        reg_pivot_smape = reg_data.pivot_table(values='SMAPE', index='center', columns='model', aggfunc='mean')\n",
    "        reg_pivot_smape.plot(kind='bar', ax=axes[1,1], title='ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ SMAPE ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,1].set_ylabel('SMAPE (%)')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/regression_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. ì„¼í„°ë³„ ëª¨ë¸ë³„ ìƒì„¸ ì„±ëŠ¥ (ë¶„ë¥˜)\n",
    "    if len(clf_data) > 0:\n",
    "        fig3, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        clf_pivot_acc = clf_data.pivot_table(values='Accuracy', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_acc.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ Accuracy ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,0].set_ylabel('Accuracy')\n",
    "        axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        clf_pivot_f1w = clf_data.pivot_table(values='F1_weighted', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1w.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ F1_Weighted ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[0,1].set_ylabel('F1 Weighted')\n",
    "        axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        clf_pivot_f1m = clf_data.pivot_table(values='F1_macro', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_f1m.plot(kind='bar', ax=axes[1,0], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ F1_Macro ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,0].set_ylabel('F1 Macro')\n",
    "        axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        clf_pivot_auc = clf_data.pivot_table(values='AUC', index='center', columns='model', aggfunc='mean')\n",
    "        clf_pivot_auc.plot(kind='bar', ax=axes[1,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ AUC ì„±ëŠ¥ ë¹„êµ')\n",
    "        axes[1,1].set_ylabel('AUC')\n",
    "        axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/classification_detailed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 4. ë™ì¼ ëª¨ë¸ì— ëŒ€í•œ ì„¼í„°ë³„ ì„±ëŠ¥ ë¹„êµ (ë¹ˆ ì„œë¸Œí”Œë¡¯ ë°©ì§€ ìˆ˜ì •)\n",
    "    # íšŒê·€ ëª¨ë¸ë“¤\n",
    "    if len(reg_data) > 0:\n",
    "        models_reg = reg_data['model'].unique()\n",
    "        fig4, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        last_i = -1\n",
    "        for i, model in enumerate(models_reg):\n",
    "            if i >= 6: break\n",
    "            model_data = reg_data[reg_data['model'] == model]\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "            center_perf = model_data.groupby('center')['R2'].mean()\n",
    "            center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - ì„¼í„°ë³„ R2 ì„±ëŠ¥')\n",
    "            axes[i].set_ylabel('R2 Score'); axes[i].tick_params(axis='x', rotation=45)\n",
    "            last_i = i\n",
    "        for j in range(last_i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_regression.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸ë“¤\n",
    "    if len(clf_data) > 0:\n",
    "        models_clf = clf_data['model'].unique()\n",
    "        fig5, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        last_i = -1\n",
    "        for i, model in enumerate(models_clf):\n",
    "            if i >= 6: break\n",
    "            model_data = clf_data[clf_data['model'] == model]\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "            center_perf = model_data.groupby('center')['F1_weighted'].mean()\n",
    "            center_perf.plot(kind='bar', ax=axes[i], title=f'{model} - ì„¼í„°ë³„ F1_Weighted ì„±ëŠ¥')\n",
    "            axes[i].set_ylabel('F1 Weighted'); axes[i].tick_params(axis='x', rotation=45)\n",
    "            last_i = i\n",
    "        for j in range(last_i+1, 6):\n",
    "            axes[j].set_visible(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../results_v2/visualizations/same_model_center_comparison_classification.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"âœ… ìƒì„¸ ì‹œê°í™” ì™„ë£Œ\")\n",
    "    print(\"ğŸ“ ì €ì¥ ìœ„ì¹˜:\")\n",
    "    print(\"  - basic_performance_comparison.png\")\n",
    "    print(\"  - regression_detailed_comparison.png\")\n",
    "    print(\"  - classification_detailed_comparison.png\")  \n",
    "    print(\"  - same_model_center_comparison_regression.png\")\n",
    "    print(\"  - same_model_center_comparison_classification.png\")\n",
    "    \n",
    "    # ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸\n",
    "    print(f\"\\nğŸ“Š ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸:\")\n",
    "    if len(reg_data) > 0:\n",
    "        reg_best = reg_data.nlargest(3, 'R2')\n",
    "        print(f\"\\nğŸ† íšŒê·€ ëª¨ë¸ TOP 3 (R2 ê¸°ì¤€):\")\n",
    "        for _, row in reg_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): R2={row['R2']:.4f}, SMAPE={row['SMAPE']:.2f}%\")\n",
    "    if len(clf_data) > 0:\n",
    "        clf_best = clf_data.nlargest(3, 'F1_weighted')\n",
    "        print(f\"\\nğŸ† ë¶„ë¥˜ ëª¨ë¸ TOP 3 (F1_weighted ê¸°ì¤€):\")\n",
    "        for _, row in clf_best.iterrows():\n",
    "            print(f\"  {row['center']} - {row['model']} ({row['split_method']}): F1_w={row['F1_weighted']:.4f}, F1_m={row['F1_macro']:.4f}\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_detailed_visualizations(results_df)\n",
    "\n",
    "# %% ì…€ 12: ë² ìŠ¤íŠ¸ 8ê°œ ì¬í•™ìŠµ ë° ì €ì¥\n",
    "def train_and_save_top8_models(results_df, pipeline):\n",
    "    print(\"ğŸ’¾ ìƒìœ„ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥\")\n",
    "    print(\"=\"*60)\n",
    "    selected_models = []\n",
    "    for center in pipeline.centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[(results_df['center']==center) & (results_df['task']==task)]\n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "            selected_models.append(best_model)\n",
    "    print(f\"ğŸ“‹ ì„ ì •ëœ 8ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸:\")\n",
    "    for model_info in selected_models:\n",
    "        print(f\"  ğŸ… {model_info['center']} - {model_info['task']} - {model_info['model']} ({model_info['split_method']})\")\n",
    "    \n",
    "    saved_models = {}\n",
    "    for model_info in selected_models:\n",
    "        center = model_info['center']; task = model_info['task']\n",
    "        model_name = model_info['model']; split_method = model_info['split_method']\n",
    "        print(f\"\\nğŸ”„ {center} - {task} - {model_name} ({split_method}) ì¬í•™ìŠµ ì¤‘...\")\n",
    "        try:\n",
    "            data = pipeline.load_data(center)\n",
    "            if data is None: continue\n",
    "            X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "            y = y_reg if task=='regression' else y_clf\n",
    "            if task == 'regression':\n",
    "                model = pipeline.regression_models[model_name]\n",
    "            else:\n",
    "                model = pipeline.classification_models[model_name]\n",
    "            if split_method == 'temporal':\n",
    "                X_train, X_test, y_train, y_test = split_data_temporal(X, y)\n",
    "            else:\n",
    "                stratify = y if task=='classification' else None\n",
    "                X_train, X_test, y_train, y_test = split_data_random(X, y, stratify=stratify)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test) if (task=='classification' and hasattr(model,'predict_proba')) else None\n",
    "            model_data = {\n",
    "                'model': model,'feature_names': X.columns.tolist(),\n",
    "                'X_train': X_train,'X_test': X_test,'y_train': y_train,'y_test': y_test,\n",
    "                'y_pred': y_pred,'y_pred_proba': y_pred_proba,'task': task,'center': center,\n",
    "                'split_method': split_method,'model_name': model_name,'performance': model_info.to_dict()\n",
    "            }\n",
    "            filename = f\"{center}_{task}_{model_name}_{split_method}.pkl\"\n",
    "            filepath = f\"../models_v2/best_models/{filename}\"\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            print(f\"âœ… ëª¨ë¸ ì €ì¥: {filepath}\")\n",
    "            saved_models[f\"{center}_{task}\"] = model_data\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {center} - {task} - {model_name} ì €ì¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "    print(f\"\\nâœ… {len(saved_models)}ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ì™„ë£Œ\")\n",
    "    return saved_models\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    saved_top8_models = train_and_save_top8_models(results_df, pipeline)\n",
    "    print(f\"ğŸ¤– ì €ì¥ëœ ìƒìœ„ 8ê°œ ëª¨ë¸ ìˆ˜: {len(saved_top8_models)}\")\n",
    "\n",
    "# %% ì…€ 13: ROC Curve ì‹¤ì œ ìƒì„±\n",
    "def create_roc_curves_actual(saved_models):\n",
    "    print(\"ğŸ“ˆ ROC Curve ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*40)\n",
    "    clf_models = {k:v for k,v in saved_models.items() if v['task']=='classification'}\n",
    "    if len(clf_models)==0:\n",
    "        print(\"âŒ ë¶„ë¥˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    centers = list(set([v['center'] for v in clf_models.values()]))\n",
    "    n = len(centers)\n",
    "    fig, axes = plt.subplots(1, min(4, n), figsize=(5*min(4, n), 5))\n",
    "    if n == 1: axes = [axes]\n",
    "    for i, center in enumerate(centers[:4]):\n",
    "        center_models = {k:v for k,v in clf_models.items() if v['center']==center}\n",
    "        ax = axes[i]\n",
    "        for _, md in center_models.items():\n",
    "            y_test = md['y_test']; y_pred_proba = md['y_pred_proba']\n",
    "            if y_pred_proba is None: continue\n",
    "            try:\n",
    "                classes = np.unique(y_test); n_classes = len(classes)\n",
    "                if n_classes == 2:\n",
    "                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:,1])\n",
    "                    auc_score = auc(fpr, tpr)\n",
    "                    ax.plot(fpr, tpr, label=f'{md[\"model_name\"]} (AUC = {auc_score:.3f})')\n",
    "                else:\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    y_bin = label_binarize(y_test, classes=classes)\n",
    "                    for c in range(min(n_classes, y_pred_proba.shape[1])):\n",
    "                        fpr, tpr, _ = roc_curve(y_bin[:,c], y_pred_proba[:,c])\n",
    "                        auc_score = auc(fpr, tpr)\n",
    "                        ax.plot(fpr, tpr, label=f'{md[\"model_name\"]} Class{c} (AUC = {auc_score:.3f})')\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {center} ROC ì‹¤íŒ¨: {e}\")\n",
    "        ax.plot([0,1],[0,1],'--', color='#94A3B8', alpha=0.8)\n",
    "        ax.set_xlim([0,1]); ax.set_ylim([0,1.05])\n",
    "        ax.set_xlabel('False Positive Rate'); ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'{center} ì„¼í„° ROC Curves'); ax.legend(bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v2/visualizations/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ… ROC Curve ì‹œê°í™” ì™„ë£Œ\")\n",
    "    print(\"ğŸ“ ì €ì¥: ../results_v2/visualizations/roc_curves.png\")\n",
    "\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    create_roc_curves_actual(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 14: SHAP ë¶„ì„ (Summary/Importance/Waterfall)\n",
    "def analyze_shap_complete(saved_models):\n",
    "    if len(saved_models)==0:\n",
    "        print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    print(\"ğŸ” ì™„ì „í•œ SHAP ë¶„ì„ ì‹œì‘ (Summary + Importance + Force Plot)\")\n",
    "    print(\"=\"*70)\n",
    "    for key, md in saved_models.items():\n",
    "        center, task, model_name = md['center'], md['task'], md['model_name']\n",
    "        model, X_train, X_test = md['model'], md['X_train'], md['X_test']\n",
    "        feature_names = md['feature_names']\n",
    "        print(f\"\\nğŸ” {center} - {task} - {model_name} SHAP ë¶„ì„...\")\n",
    "        try:\n",
    "            sample_size = min(50, len(X_test))\n",
    "            X_test_sample = X_test.iloc[:sample_size]\n",
    "            if model_name in ['XGBoost','LightGBM','CatBoost']:\n",
    "                explainer = shap.Explainer(model)\n",
    "            else:\n",
    "                train_sample_size = min(100, len(X_train))\n",
    "                explainer = shap.Explainer(model, X_train.iloc[:train_sample_size])\n",
    "            shap_values = explainer(X_test_sample)\n",
    "\n",
    "            # Summary\n",
    "            plt.figure(figsize=(16,8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Summary Plot')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_summary.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "            # Importance\n",
    "            plt.figure(figsize=(10,6))\n",
    "            shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, plot_type=\"bar\", show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_importance.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "            # Force(ëŒ€ì²´: waterfall)\n",
    "            try:\n",
    "                plt.figure(figsize=(14,10))\n",
    "                if hasattr(shap_values, 'values'):\n",
    "                    if len(shap_values.values.shape) == 3:  # multiclass\n",
    "                        shap.waterfall_plot(shap_values[0, :, 0], show=False)\n",
    "                    else:\n",
    "                        shap.waterfall_plot(shap_values[0], show=False)\n",
    "                else:\n",
    "                    shap.waterfall_plot(shap_values[0], show=False)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nSHAP Force Plot (Sample 1)')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_shap_force_1.png', dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Force Plot ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "            print(f\"âœ… SHAP ë¶„ì„ ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SHAP ë¶„ì„ ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_shap_complete(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 15: Feature Importance ë¶„ì„\n",
    "def analyze_feature_importance_complete(saved_models):\n",
    "    if len(saved_models)==0:\n",
    "        print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    print(\"ğŸ“Š ì™„ì „í•œ Feature Importance ë¶„ì„\")\n",
    "    print(\"=\"*50)\n",
    "    for key, md in saved_models.items():\n",
    "        center, task, model_name = md['center'], md['task'], md['model_name']\n",
    "        model, feature_names = md['model'], md['feature_names']\n",
    "        print(f\"\\nğŸ“Š {center} - {task} - {model_name} Feature Importance...\")\n",
    "        try:\n",
    "            plt.figure(figsize=(12,8))\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importance = model.feature_importances_\n",
    "                df_imp = pd.DataFrame({'feature':feature_names,'importance':importance}).sort_values('importance', ascending=True).tail(20)\n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature']); plt.xlabel('Feature Importance')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance (Top 20)')\n",
    "                for b in bars:\n",
    "                    w = b.get_width(); plt.text(w, b.get_y()+b.get_height()/2, f'{w:.4f}', ha='left', va='center', fontsize=8)\n",
    "            elif hasattr(model, 'coef_'):\n",
    "                coef = np.mean(np.abs(model.coef_), axis=0) if (task=='classification' and len(model.coef_.shape)>1) else np.abs(model.coef_).flatten()\n",
    "                df_imp = pd.DataFrame({'feature':feature_names,'importance':coef}).sort_values('importance', ascending=True).tail(20)\n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature']); plt.xlabel('|Coefficient|')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Coefficients (Top 20)')\n",
    "                for b in bars:\n",
    "                    w = b.get_width(); plt.text(w, b.get_y()+b.get_height()/2, f'{w:.4f}', ha='left', va='center', fontsize=8)\n",
    "            else:\n",
    "                plt.text(0.5,0.5,'Feature importance not available', ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance')\n",
    "            plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "            plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"âœ… Feature Importance ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Feature Importance ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_feature_importance_complete(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 16: (ì„ íƒ) LIME â€” ì›ì½”ë“œ ìœ ì§€\n",
    "def analyze_lime_complete(saved_models):\n",
    "    try:\n",
    "        import lime, lime.lime_tabular\n",
    "        if len(saved_models)==0:\n",
    "            print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\"); return\n",
    "        print(\"ğŸ‹ ì™„ì „í•œ LIME ë¶„ì„ ì‹œì‘\"); print(\"=\"*50)\n",
    "        analyzed = 0\n",
    "        for key, md in saved_models.items():\n",
    "            if analyzed >= 3: print(\"â° ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ì²˜ìŒ 3ê°œ ëª¨ë¸ë§Œ LIME ë¶„ì„í•©ë‹ˆë‹¤.\"); break\n",
    "            center, task, model_name = md['center'], md['task'], md['model_name']\n",
    "            model, X_train, X_test = md['model'], md['X_train'], md['X_test']\n",
    "            feature_names = md['feature_names']\n",
    "            print(f\"\\nğŸ‹ {center} - {task} - {model_name} LIME ë¶„ì„...\")\n",
    "            try:\n",
    "                if task=='regression':\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=feature_names, mode='regression', verbose=False)\n",
    "                    for sample_idx in [0,1]:\n",
    "                        if sample_idx>=len(X_test): continue\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(instance, model.predict, num_features=10)\n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                else:\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=feature_names, mode='classification', class_names=[str(c) for c in sorted(model.classes_)], verbose=False)\n",
    "                    for sample_idx in [0,1]:\n",
    "                        if sample_idx>=len(X_test): continue\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(instance, model.predict_proba, num_features=10)\n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v2/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                print(f\"âœ… LIME ë¶„ì„ ì™„ë£Œ: {center} - {task} - {model_name}\"); analyzed += 1\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ LIME ë¶„ì„ ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "    except ImportError:\n",
    "        print(\"ğŸ’¡ LIME ë¶„ì„ì„ ìœ„í•´ì„œëŠ” `pip install lime` í›„ ì‚¬ìš©í•˜ì„¸ìš”. í˜„ì¬ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "if 'saved_top8_models' in locals():\n",
    "    analyze_lime_complete(saved_top8_models)\n",
    "\n",
    "# %% ì…€ 17: ì˜ˆì¸¡ ìœ í‹¸\n",
    "def predict_with_saved_model(center, task, new_data):\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    if len(model_files)==0:\n",
    "        print(f\"âŒ {center} - {task} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"); return None\n",
    "    filepath = f\"../models_v2/best_models/{model_files[0]}\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            md = pickle.load(f)\n",
    "        model, feature_names = md['model'], md['feature_names']\n",
    "        missing = [c for c in feature_names if c not in new_data.columns]\n",
    "        if missing:\n",
    "            print(f\"âŒ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing}\"); return None\n",
    "        X_new = new_data[feature_names]\n",
    "        if task=='regression':\n",
    "            pred = model.predict(X_new); print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ: {len(pred)}ê°œ ìƒ˜í”Œ\"); return pred\n",
    "        else:\n",
    "            pred = model.predict(X_new)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                proba = model.predict_proba(X_new)\n",
    "                print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ: {len(pred)}ê°œ ìƒ˜í”Œ\"); return pred, proba\n",
    "            print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ: {len(pred)}ê°œ ìƒ˜í”Œ\"); return pred\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}\"); return None\n",
    "\n",
    "def load_saved_model(center, task):\n",
    "    model_files = [f for f in os.listdir('../models_v2/best_models/') if f.startswith(f'{center}_{task}_') and f.endswith('.pkl')]\n",
    "    if len(model_files)==0:\n",
    "        print(f\"âŒ {center} - {task} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"); return None\n",
    "    filepath = f\"../models_v2/best_models/{model_files[0]}\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            md = pickle.load(f)\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {center} - {task} - {md['model_name']}\"); return md\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\"); return None\n",
    "\n",
    "print(\"ğŸ”® ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 18: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ(ì›ë¬¸ ìœ ì§€)\n",
    "def show_hyperparameter_tuning_examples():\n",
    "    print(\"âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜ˆì‹œ\")\n",
    "    print(\"=\"*50)\n",
    "    print('''# GridSearchCV / RandomizedSearchCV / Optuna ì˜ˆì‹œ (ì›ë¬¸ ë™ì¼)\n",
    "# ... í•„ìš” ì‹œ ì´ì „ ë…¸íŠ¸ì˜ ë¸”ë¡ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš” ...\n",
    "''')\n",
    "show_hyperparameter_tuning_examples()\n",
    "\n",
    "# %% ì…€ 19: ìµœì¢… ê²°ê³¼ ìš”ì•½ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸ (NameError ë°©ì§€ - ì™„ì „í•œ êµ¬í˜„)\n",
    "def comprehensive_final_summary():\n",
    "    print(\"ğŸ“‹ í¬ê´„ì ì¸ ìµœì¢… ì‹¤í–‰ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\")\n",
    "    print(\"=\"*80)\n",
    "    checklist = {}\n",
    "    checklist[\"1. ë°ì´í„° ë¡œë“œ\"] = 'data_info' in globals() and len(data_info) > 0\n",
    "    checklist[\"2. ëª¨ë¸ í•™ìŠµ (96ê°œ)\"] = 'results_df' in globals() and len(results_df) > 0\n",
    "    checklist[\"3. ì „ì²´ ê²°ê³¼ CSV\"] = os.path.exists('../results_v2/all_model_results.csv')\n",
    "    checklist[\"4. í†µí•© ë² ìŠ¤íŠ¸ ëª¨ë¸\"] = os.path.exists('../results_v2/best_models.csv')\n",
    "    individual_dir = '../results_v2/best_models_individual/'\n",
    "    individual_files = [f for f in os.listdir(individual_dir) if f.endswith('.csv')] if os.path.exists(individual_dir) else []\n",
    "    checklist[\"5. ê°œë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ (8ê°œ)\"] = len(individual_files) >= 8\n",
    "    basic_viz = '../results_v2/visualizations/basic_performance_comparison.png'\n",
    "    checklist[\"6. ê¸°ë³¸ ì„±ëŠ¥ ì‹œê°í™”\"] = os.path.exists(basic_viz)\n",
    "    detailed_viz_files = [\n",
    "        'regression_detailed_comparison.png',\n",
    "        'classification_detailed_comparison.png',\n",
    "        'same_model_center_comparison_regression.png',\n",
    "        'same_model_center_comparison_classification.png'\n",
    "    ]\n",
    "    viz_dir = '../results_v2/visualizations/'\n",
    "    viz_count = sum([os.path.exists(os.path.join(viz_dir, f)) for f in detailed_viz_files])\n",
    "    checklist[\"7. ìƒì„¸ ì‹œê°í™” (4ê°œ)\"] = viz_count >= 4\n",
    "    roc_file = '../results_v2/visualizations/roc_curves.png'\n",
    "    checklist[\"8. ROC Curve ì‹œê°í™”\"] = os.path.exists(roc_file)\n",
    "    model_dir = '../models_v2/best_models/'\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')] if os.path.exists(model_dir) else []\n",
    "    checklist[\"9. ë² ìŠ¤íŠ¸ ëª¨ë¸ íŒŒì¼ (8ê°œ)\"] = len(model_files) >= 8\n",
    "    interp_dir = '../results_v2/interpretations/'\n",
    "    shap_files = [f for f in os.listdir(interp_dir) if 'shap' in f.lower()] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"10. SHAP ë¶„ì„\"] = len(shap_files) >= 3  # ìµœì†Œ ìƒì„± ê¸°ì¤€\n",
    "    fi_files = [f for f in os.listdir(interp_dir) if 'feature_importance' in f] if os.path.exists(interp_dir) else []\n",
    "    checklist[\"11. Feature Importance\"] = len(fi_files) >= 3\n",
    "    if 'results_df' in globals() and len(results_df) > 0:\n",
    "        has_smape = 'SMAPE' in results_df.columns\n",
    "        has_f1_macro = 'F1_macro' in results_df.columns\n",
    "        checklist[\"12. ì™„ì „í•œ ì„±ëŠ¥ ì§€í‘œ\"] = has_smape and has_f1_macro\n",
    "    else:\n",
    "        checklist[\"12. ì™„ì „í•œ ì„±ëŠ¥ ì§€í‘œ\"] = False\n",
    "\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"{status_icon} {item}: {'ì™„ë£Œ' if status else 'ë¯¸ì™„ë£Œ'}\")\n",
    "\n",
    "    completed = sum(1 for v in checklist.values() if v)\n",
    "    total = len(checklist)\n",
    "    completion_rate = completed / total * 100\n",
    "    print(f\"\\nğŸ“Š ì „ì²´ ì™„ë£Œìœ¨: {completion_rate:.1f}% ({completed}/{total})\")\n",
    "    if completion_rate >= 95:\n",
    "        print(\"ğŸ‰ í”„ë¡œì íŠ¸ê°€ ì™„ë²½í•˜ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    elif completion_rate >= 85:\n",
    "        print(\"ğŸŒŸ í”„ë¡œì íŠ¸ê°€ ê±°ì˜ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    elif completion_rate >= 70:\n",
    "        print(\"âš ï¸ ëŒ€ë¶€ë¶„ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ì¼ë¶€ ë‹¨ê³„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(\"âŒ ì—¬ëŸ¬ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    return checklist\n",
    "\n",
    "final_checklist = comprehensive_final_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"âœ¨ ëª¨ë“  ìš”êµ¬ì‚¬í•­(ìƒ‰ìƒ ê°œì„  + ë¹ˆ ì„œë¸Œí”Œë¡¯ ì œê±°)ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% [markdown]\n",
    "# # ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ!\n",
    "# - ìƒ‰ìƒ íŒ”ë ˆíŠ¸ í†µì¼, í•œê¸€ í°íŠ¸/ë§ˆì´ë„ˆìŠ¤ í‘œì‹œ, ë¹ˆ ì„œë¸Œí”Œë¡¯ ë°©ì§€(íšŒê·€/ë¶„ë¥˜ ëª¨ë¸ ëª©ë¡ ë¶„ë¦¬)ê¹Œì§€ ë°˜ì˜."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea02cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"í˜„ì¬ í°íŠ¸:\", plt.rcParams.get(\"font.family\"))\n",
    "\n",
    "# í•œê¸€ì´ ì‹¤ì œë¡œ ê·¸ë ¤ì§€ëŠ”ì§€ í…ŒìŠ¤íŠ¸\n",
    "plt.figure()\n",
    "plt.title(\"í•œê¸€ ì œëª©: ì„œìš¸ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì¶”ì´\")\n",
    "plt.plot([0,1,2],[1,4,9])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe4d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0f204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55308ce5",
   "metadata": {},
   "source": [
    "## ì½”ë“œ 3\n",
    "- ìƒ‰ì´ë‚˜ ê·¸ëŸ°ê±° ì¡°ê¸ˆ ë” ì˜ˆì˜ê²Œ ì‹œê°ì  íš¨ê³¼ ì¡°ì •ì¤‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06926f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒ¨í‚¤ì§€ import ë° ì„¤ì • ì™„ë£Œ\n",
      "â° ì‹¤í–‰ ì‹œê°„: 2025-08-28 21:00:03\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../results_v3\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../results_v3/visualizations\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../results_v3/hyperparameter_results\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../results_v3/interpretations\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../results_v3/cross_validation\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../results_v3/best_models_summary\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../models_v3\n",
      "ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: ../models_v3/best_tuned_models\n",
      "âœ… ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ\n",
      "ğŸ”§ ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ (ìµœì í™” ë²„ì „)\n",
      "âœ… ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ ì •ì˜ ì™„ë£Œ (ë¶ˆê· í˜• ì²˜ë¦¬ í¬í•¨)\n",
      "âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "ğŸ“Š ë°ì´í„° íŒŒì¼ í™•ì¸ ë° ê¸°ë³¸ ì •ë³´\n",
      "==================================================\n",
      "âœ… nanji ì„¼í„° ë°ì´í„° ë¡œë“œ: (3069, 44)\n",
      "\n",
      "ğŸ¢ NANJI ì„¼í„°:\n",
      "  ğŸ“ˆ ë°ì´í„° í¬ê¸°: (3069, 44)\n",
      "  ğŸ“Š í”¼ì²˜ ìˆ˜: 33\n",
      "  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: 442332.8 ~ 1381444.0\n",
      "  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ ë¶„í¬:\n",
      "      í´ë˜ìŠ¤ 0: 459ê°œ (15.0%)\n",
      "      í´ë˜ìŠ¤ 1: 1688ê°œ (55.0%)\n",
      "      í´ë˜ìŠ¤ 2: 614ê°œ (20.0%)\n",
      "      í´ë˜ìŠ¤ 3: 308ê°œ (10.0%)\n",
      "âœ… jungnang ì„¼í„° ë°ì´í„° ë¡œë“œ: (3069, 44)\n",
      "\n",
      "ğŸ¢ JUNGNANG ì„¼í„°:\n",
      "  ğŸ“ˆ ë°ì´í„° í¬ê¸°: (3069, 44)\n",
      "  ğŸ“Š í”¼ì²˜ ìˆ˜: 33\n",
      "  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: 625472.0 ~ 2745792.0\n",
      "  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ ë¶„í¬:\n",
      "      í´ë˜ìŠ¤ 0: 460ê°œ (15.0%)\n",
      "      í´ë˜ìŠ¤ 1: 1687ê°œ (55.0%)\n",
      "      í´ë˜ìŠ¤ 2: 614ê°œ (20.0%)\n",
      "      í´ë˜ìŠ¤ 3: 308ê°œ (10.0%)\n",
      "âœ… seonam ì„¼í„° ë°ì´í„° ë¡œë“œ: (3069, 43)\n",
      "\n",
      "ğŸ¢ SEONAM ì„¼í„°:\n",
      "  ğŸ“ˆ ë°ì´í„° í¬ê¸°: (3069, 43)\n",
      "  ğŸ“Š í”¼ì²˜ ìˆ˜: 33\n",
      "  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: 1160337.0 ~ 2780034.0\n",
      "  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ ë¶„í¬:\n",
      "      í´ë˜ìŠ¤ 0: 460ê°œ (15.0%)\n",
      "      í´ë˜ìŠ¤ 1: 1687ê°œ (55.0%)\n",
      "      í´ë˜ìŠ¤ 2: 614ê°œ (20.0%)\n",
      "      í´ë˜ìŠ¤ 3: 308ê°œ (10.0%)\n",
      "âœ… tancheon ì„¼í„° ë°ì´í„° ë¡œë“œ: (3069, 42)\n",
      "\n",
      "ğŸ¢ TANCHEON ì„¼í„°:\n",
      "  ğŸ“ˆ ë°ì´í„° í¬ê¸°: (3069, 42)\n",
      "  ğŸ“Š í”¼ì²˜ ìˆ˜: 33\n",
      "  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: 543425.0 ~ 1423827.0\n",
      "  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ ë¶„í¬:\n",
      "      í´ë˜ìŠ¤ 0: 460ê°œ (15.0%)\n",
      "      í´ë˜ìŠ¤ 1: 1687ê°œ (55.0%)\n",
      "      í´ë˜ìŠ¤ 2: 614ê°œ (20.0%)\n",
      "      í´ë˜ìŠ¤ 3: 308ê°œ (10.0%)\n",
      "\n",
      "âœ… 4ê°œ ì„¼í„° ë°ì´í„° ë¡œë“œ ë° ë¶„ì„ ì™„ë£Œ\n",
      "ğŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
      "ì˜ˆìƒ ì´ ëª¨ë¸ ìˆ˜: 4 Ã— 2 Ã— 2 Ã— 6 = 96ê°œ\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ¢ NANJI ì„¼í„° ì²˜ë¦¬ ì¤‘...\n",
      "============================================================\n",
      "\n",
      "--- TEMPORAL ë¶„í•  ë°©ë²• ---\n",
      "ğŸ“ˆ íšŒê·€ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° í•™ìŠµ:\n",
      "  ğŸ”„ LinearRegression ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ LinearRegression í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n",
      "      âœ… ì™„ë£Œ (0.8ì´ˆ) - ìµœê³  ì ìˆ˜: 0.5819\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'fit_intercept': True}\n",
      "    âœ… LinearRegression: R2=0.5030, CV_R2=0.5742\n",
      "  ğŸ”„ RandomForest ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ RandomForest í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n",
      "      âœ… ì™„ë£Œ (8.3ì´ˆ) - ìµœê³  ì ìˆ˜: 0.5836\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "    âœ… RandomForest: R2=0.5573, CV_R2=0.5919\n",
      "  ğŸ”„ XGBoost ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n",
      "      âœ… ì™„ë£Œ (0.9ì´ˆ) - ìµœê³  ì ìˆ˜: 0.6026\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "    âœ… XGBoost: R2=0.4822, CV_R2=0.6140\n",
      "  ğŸ”„ CatBoost ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ CatBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n",
      "      âœ… ì™„ë£Œ (1.7ì´ˆ) - ìµœê³  ì ìˆ˜: 0.6153\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'depth': 4, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
      "    âœ… CatBoost: R2=0.4613, CV_R2=0.6221\n",
      "  ğŸ”„ GradientBoost ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ GradientBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n",
      "      âœ… ì™„ë£Œ (3.6ì´ˆ) - ìµœê³  ì ìˆ˜: 0.5957\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "    âœ… GradientBoost: R2=0.4827, CV_R2=0.6079\n",
      "  ğŸ”„ LightGBM ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ LightGBM í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n",
      "      âœ… ì™„ë£Œ (5.4ì´ˆ) - ìµœê³  ì ìˆ˜: 0.6074\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "    âœ… LightGBM: R2=0.5544, CV_R2=0.6151\n",
      "\n",
      "ğŸ“Š ë¶„ë¥˜ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° í•™ìŠµ:\n",
      "  ğŸ“Š ë¶ˆê· í˜• ì²˜ë¦¬ (smote): 2455 â†’ 5240 ìƒ˜í”Œ\n",
      "  ğŸ”„ LogisticRegression ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ LogisticRegression í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/youngwon/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      âœ… ì™„ë£Œ (13.6ì´ˆ) - ìµœê³  ì ìˆ˜: 0.6664\n",
      "      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "    âœ… LogisticRegression: F1_w=0.4001, CV_F1=0.6149\n",
      "  ğŸ”„ RandomForest ì²˜ë¦¬ ì¤‘...\n",
      "    ğŸ”§ RandomForest í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\n"
     ]
    }
   ],
   "source": [
    "# **ğŸš€ ê³ ê¸‰ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œìŠ¤í…œ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í¬í•¨)**\n",
    "# ========================================================================================\n",
    "# í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ & ê³ ê¸‰ ë¶„ì„\n",
    "# ========================================================================================\n",
    "\n",
    "# %% ì…€ 1: íŒ¨í‚¤ì§€ import ë° ê¸°ë³¸ ì„¤ì •\n",
    "import os, warnings, pickle\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - ê¸°ë³¸\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, KFold,\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, auc, roc_auc_score, classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Advanced ML models\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# í•´ì„ ê°€ëŠ¥ì„± ë¶„ì„\n",
    "import shap\n",
    "\n",
    "# ê²½ê³  ë¬´ì‹œ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ìƒ‰ìƒ íŒ”ë ˆíŠ¸\n",
    "PALETTE = [\n",
    "    \"#2563EB\", \"#F97316\", \"#10B981\", \"#A855F7\", \"#EF4444\", \"#0EA5E9\",\n",
    "    \"#F59E0B\", \"#22C55E\", \"#8B5CF6\", \"#DC2626\", \"#14B8A6\", \"#E11D48\"\n",
    "]\n",
    "\n",
    "# ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(PALETTE)\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=PALETTE)\n",
    "plt.rcParams['font.family'] = 'AppleGothic'  # ë§¥ìš©\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ import ë° ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# %% ì…€ 2: ë””ë ‰í† ë¦¬ ìƒì„± ë° ì„¤ì •\n",
    "directories = [\n",
    "    '../results_v3', \n",
    "    '../results_v3/visualizations',\n",
    "    '../results_v3/hyperparameter_results',\n",
    "    '../results_v3/interpretations',\n",
    "    '../results_v3/cross_validation',\n",
    "    '../results_v3/best_models_summary',\n",
    "    '../models_v3', \n",
    "    '../models_v3/best_tuned_models'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {directory}\")\n",
    "\n",
    "print(\"âœ… ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 3: ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤ ì •ì˜ (ìˆ˜ì • ë²„ì „)\n",
    "class AdvancedSewagePredictionPipeline:\n",
    "    def __init__(self, data_path_template='../data/add_feature/{}_add_feature.csv'):\n",
    "        \"\"\"ê³ ê¸‰ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í¬í•¨)\"\"\"\n",
    "        self.data_path_template = data_path_template\n",
    "        self.centers = ['nanji', 'jungnang', 'seonam', 'tancheon']\n",
    "        \n",
    "        # ì œì™¸í•  ì»¬ëŸ¼\n",
    "        self.not_use_col = [\n",
    "            'ë‚ ì§œ', '1ì²˜ë¦¬ì¥','2ì²˜ë¦¬ì¥','ì •í™”ì¡°','ì¤‘ê³„íŒí”„ì¥','í•©ê³„','ì‹œì„¤í˜„ëŒ€í™”',\n",
    "            '3ì²˜ë¦¬ì¥','4ì²˜ë¦¬ì¥','í•©ê³„', 'í•©ê³„_1ì¼í›„','í•©ê³„_2ì¼í›„',\n",
    "            'ë“±ê¸‰','ë“±ê¸‰_1ì¼í›„','ë“±ê¸‰_2ì¼í›„'\n",
    "        ]\n",
    "        \n",
    "        # ê¸°ë³¸ ëª¨ë¸ë“¤\n",
    "        self.regression_models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'RandomForest': RandomForestRegressor(random_state=42),\n",
    "            'XGBoost': xgb.XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "            'CatBoost': cb.CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
    "            'LightGBM': lgb.LGBMRegressor(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        self.classification_models = {\n",
    "            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'RandomForest': RandomForestClassifier(random_state=42),\n",
    "            'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'CatBoost': cb.CatBoostClassifier(random_state=42, verbose=False),\n",
    "            'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "            'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        # ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜ (ì„±ëŠ¥ ê°œì„  ë²„ì „)\n",
    "        self.regression_param_grids = {\n",
    "            'LinearRegression': {\n",
    "                'fit_intercept': [True, False]\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2]\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            },\n",
    "            'CatBoost': {\n",
    "                'iterations': [50, 100],\n",
    "                'depth': [4, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'l2_leaf_reg': [1, 3]\n",
    "            },\n",
    "            'GradientBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 5],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.classification_param_grids = {\n",
    "            'LogisticRegression': {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'solver': ['liblinear', 'saga'],\n",
    "                'class_weight': ['balanced', None]\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [10, 20],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2],\n",
    "                'class_weight': ['balanced', None]\n",
    "            },\n",
    "            'XGBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0],\n",
    "                'scale_pos_weight': [1, 2, 3]\n",
    "            },\n",
    "            'CatBoost': {\n",
    "                'iterations': [50, 100],\n",
    "                'depth': [4, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'l2_leaf_reg': [1, 3]\n",
    "            },\n",
    "            'GradientBoost': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 5],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0]\n",
    "            },\n",
    "            'LightGBM': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [3, 6],\n",
    "                'learning_rate': [0.1, 0.2],\n",
    "                'subsample': [0.8, 1.0],\n",
    "                'class_weight': ['balanced', None]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.results = []\n",
    "        self.tuning_results = []\n",
    "        self.cv_results = []\n",
    "        \n",
    "    def load_data(self, center):\n",
    "        \"\"\"ì„¼í„°ë³„ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        file_path = self.data_path_template.format(center)\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(f\"âœ… {center} ì„¼í„° ë°ì´í„° ë¡œë“œ: {data.shape}\")\n",
    "            return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "pipeline = AdvancedSewagePredictionPipeline()\n",
    "print(\"ğŸ”§ ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ (ìµœì í™” ë²„ì „)\")\n",
    "\n",
    "# %% ì…€ 4: ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ (ë¶ˆê· í˜• ì²˜ë¦¬ í¬í•¨)\n",
    "def prepare_features(data, not_use_col):\n",
    "    \"\"\"í”¼ì²˜ ë° íƒ€ê²Ÿ ì¤€ë¹„\"\"\"\n",
    "    available_cols = [col for col in data.columns if col not in not_use_col]\n",
    "    X = data[available_cols]\n",
    "    y_reg = data['í•©ê³„_1ì¼í›„']  # íšŒê·€ìš©\n",
    "    y_clf = data['ë“±ê¸‰_1ì¼í›„']  # ë¶„ë¥˜ìš©\n",
    "    return X, y_reg, y_clf\n",
    "\n",
    "def handle_class_imbalance(X_train, y_train, method='smote'):\n",
    "    \"\"\"í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\"\"\"\n",
    "    try:\n",
    "        if method == 'smote':\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_balanced, y_balanced = smote.fit_resample(X_train, y_train)\n",
    "        elif method == 'smoteenn':\n",
    "            smoteenn = SMOTEENN(random_state=42)\n",
    "            X_balanced, y_balanced = smoteenn.fit_resample(X_train, y_train)\n",
    "        else:\n",
    "            return X_train, y_train\n",
    "        \n",
    "        print(f\"  ğŸ“Š ë¶ˆê· í˜• ì²˜ë¦¬ ({method}): {len(X_train)} â†’ {len(X_balanced)} ìƒ˜í”Œ\")\n",
    "        return X_balanced, y_balanced\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ ë¶ˆê· í˜• ì²˜ë¦¬ ì‹¤íŒ¨: {e}, ì›ë³¸ ë°ì´í„° ì‚¬ìš©\")\n",
    "        return X_train, y_train\n",
    "\n",
    "def split_data_temporal(X, y, test_size=0.2):\n",
    "    \"\"\"ì‹œê³„ì—´ ì •ë³´ë¥¼ ìœ ì§€í•œ ë¶„í• \"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_random(X, y, test_size=0.2, stratify=None):\n",
    "    \"\"\"ëœë¤ ë¶„í•  (ë¶„ë¥˜ì‹œ stratified)\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=stratify, random_state=42)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    \"\"\"íšŒê·€ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # MAPE ê³„ì‚° (0 ê°’ ì²˜ë¦¬)\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else np.inf\n",
    "    \n",
    "    # SMAPE ê³„ì‚°\n",
    "    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true))) * 100\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae, 'MSE': mse, 'RMSE': rmse, \n",
    "        'MAPE': mape, 'SMAPE': smape, 'R2': r2\n",
    "    }\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision_weighted': precision_weighted,\n",
    "        'Precision_macro': precision_macro,\n",
    "        'Recall_weighted': recall_weighted,\n",
    "        'Recall_macro': recall_macro,\n",
    "        'F1_weighted': f1_weighted,\n",
    "        'F1_macro': f1_macro\n",
    "    }\n",
    "    \n",
    "    # AUC ê³„ì‚°\n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "            else:\n",
    "                auc_score = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "            metrics['AUC'] = auc_score\n",
    "        except Exception:\n",
    "            metrics['AUC'] = 0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def perform_cross_validation(model, X, y, task, cv_folds=5):\n",
    "    \"\"\"êµì°¨ê²€ì¦ ìˆ˜í–‰\"\"\"\n",
    "    if task == 'regression':\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        scoring = ['accuracy', 'f1_weighted', 'f1_macro']\n",
    "    \n",
    "    cv_results = {}\n",
    "    for score in scoring:\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=score)\n",
    "        cv_results[f'{score}_mean'] = scores.mean()\n",
    "        cv_results[f'{score}_std'] = scores.std()\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ì²˜ë¦¬ ë° í‰ê°€ ë©”ì†Œë“œ ì •ì˜ ì™„ë£Œ (ë¶ˆê· í˜• ì²˜ë¦¬ í¬í•¨)\")\n",
    "\n",
    "# %% ì…€ 5: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•¨ìˆ˜\n",
    "def perform_hyperparameter_tuning(model, param_grid, X_train, y_train, task, \n",
    "                                model_name, center, cv_folds=3, n_jobs=-1):\n",
    "    \"\"\"í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìˆ˜í–‰\"\"\"\n",
    "    print(f\"    ğŸ”§ {model_name} í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ìŠ¤ì½”ì–´ë§ ë©”íŠ¸ë¦­ ì„¤ì •\n",
    "    if task == 'regression':\n",
    "        scoring = 'r2'\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        scoring = 'f1_weighted'\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    try:\n",
    "        # íŒŒë¼ë¯¸í„° ê³µê°„ì´ í´ ê²½ìš° RandomizedSearchCV ì‚¬ìš©\n",
    "        total_combinations = 1\n",
    "        for param_values in param_grid.values():\n",
    "            total_combinations *= len(param_values)\n",
    "        \n",
    "        if total_combinations > 100:\n",
    "            search = RandomizedSearchCV(\n",
    "                model, param_grid, n_iter=50, cv=cv, scoring=scoring,\n",
    "                n_jobs=n_jobs, random_state=42, verbose=0\n",
    "            )\n",
    "            search_type = \"RandomizedSearch\"\n",
    "        else:\n",
    "            search = GridSearchCV(\n",
    "                model, param_grid, cv=cv, scoring=scoring,\n",
    "                n_jobs=n_jobs, verbose=0\n",
    "            )\n",
    "            search_type = \"GridSearch\"\n",
    "        \n",
    "        # íŠœë‹ ì‹¤í–‰\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        tuning_time = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'center': center,\n",
    "            'task': task,\n",
    "            'model': model_name,\n",
    "            'search_type': search_type,\n",
    "            'best_score': search.best_score_,\n",
    "            'best_params': search.best_params_,\n",
    "            'tuning_time': tuning_time,\n",
    "            'total_combinations_tested': len(search.cv_results_['mean_test_score'])\n",
    "        }\n",
    "        \n",
    "        print(f\"      âœ… ì™„ë£Œ ({tuning_time:.1f}ì´ˆ) - ìµœê³  ì ìˆ˜: {search.best_score_:.4f}\")\n",
    "        print(f\"      ğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°: {search.best_params_}\")\n",
    "        \n",
    "        return search.best_estimator_, result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ íŠœë‹ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return model, None\n",
    "\n",
    "print(\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 6: ë°ì´í„° í™•ì¸ ë° ê¸°ë³¸ ì •ë³´\n",
    "print(\"ğŸ“Š ë°ì´í„° íŒŒì¼ í™•ì¸ ë° ê¸°ë³¸ ì •ë³´\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_info = {}\n",
    "for center in pipeline.centers:\n",
    "    data = pipeline.load_data(center)\n",
    "    if data is not None:\n",
    "        X, y_reg, y_clf = prepare_features(data, pipeline.not_use_col)\n",
    "        \n",
    "        print(f\"\\nğŸ¢ {center.upper()} ì„¼í„°:\")\n",
    "        print(f\"  ğŸ“ˆ ë°ì´í„° í¬ê¸°: {data.shape}\")\n",
    "        print(f\"  ğŸ“Š í”¼ì²˜ ìˆ˜: {X.shape[1]}\")\n",
    "        print(f\"  ğŸ¯ íšŒê·€ íƒ€ê²Ÿ ë²”ìœ„: {y_reg.min():.1f} ~ {y_reg.max():.1f}\")\n",
    "        print(f\"  ğŸ·ï¸ ë¶„ë¥˜ íƒ€ê²Ÿ ë¶„í¬:\")\n",
    "        class_dist = y_clf.value_counts().sort_index()\n",
    "        for class_label, count in class_dist.items():\n",
    "            percentage = count / len(y_clf) * 100\n",
    "            print(f\"      í´ë˜ìŠ¤ {class_label}: {count}ê°œ ({percentage:.1f}%)\")\n",
    "        \n",
    "        data_info[center] = {\n",
    "            'data': data, 'X': X, 'y_reg': y_reg, 'y_clf': y_clf,\n",
    "            'shape': data.shape, 'class_distribution': class_dist\n",
    "        }\n",
    "\n",
    "if len(data_info) == 0:\n",
    "    print(\"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"\\nâœ… {len(data_info)}ê°œ ì„¼í„° ë°ì´í„° ë¡œë“œ ë° ë¶„ì„ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 7: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "print(\"ğŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "print(f\"ì˜ˆìƒ ì´ ëª¨ë¸ ìˆ˜: {len(pipeline.centers)} Ã— 2 Ã— 2 Ã— 6 = {len(pipeline.centers) * 2 * 2 * 6}ê°œ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_models = 0\n",
    "successful_models = 0\n",
    "tuning_start_time = time.time()\n",
    "\n",
    "for center in pipeline.centers:\n",
    "    if center not in data_info:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ¢ {center.upper()} ì„¼í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        X = data_info[center]['X']\n",
    "        y_reg = data_info[center]['y_reg']\n",
    "        y_clf = data_info[center]['y_clf']\n",
    "        \n",
    "        for split_method in ['temporal', 'random']:\n",
    "            print(f\"\\n--- {split_method.upper()} ë¶„í•  ë°©ë²• ---\")\n",
    "            \n",
    "            # íšŒê·€ ëª¨ë¸ ì²˜ë¦¬\n",
    "            print(\"ğŸ“ˆ íšŒê·€ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° í•™ìŠµ:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_temporal(X, y_reg)\n",
    "            else:\n",
    "                X_train_reg, X_test_reg, y_train_reg, y_test_reg = split_data_random(X, y_reg)\n",
    "            \n",
    "            for model_name, base_model in pipeline.regression_models.items():\n",
    "                total_models += 1\n",
    "                print(f\"  ğŸ”„ {model_name} ì²˜ë¦¬ ì¤‘...\")\n",
    "                \n",
    "                try:\n",
    "                    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "                    param_grid = pipeline.regression_param_grids[model_name]\n",
    "                    tuned_model, tuning_result = perform_hyperparameter_tuning(\n",
    "                        base_model, param_grid, X_train_reg, y_train_reg, \n",
    "                        'regression', model_name, center\n",
    "                    )\n",
    "                    \n",
    "                    if tuning_result:\n",
    "                        pipeline.tuning_results.append(tuning_result)\n",
    "                    \n",
    "                    # ì˜ˆì¸¡ ë° í‰ê°€\n",
    "                    y_pred_reg = tuned_model.predict(X_test_reg)\n",
    "                    metrics = evaluate_regression(y_test_reg, y_pred_reg)\n",
    "                    \n",
    "                    # êµì°¨ê²€ì¦\n",
    "                    cv_results = perform_cross_validation(tuned_model, X_train_reg, y_train_reg, 'regression')\n",
    "                    \n",
    "                    # ê²°ê³¼ ì €ì¥\n",
    "                    result = {\n",
    "                        'center': center, 'split_method': split_method, 'task': 'regression',\n",
    "                        'model': model_name, \n",
    "                        'best_params': tuning_result['best_params'] if tuning_result else {},\n",
    "                        'tuning_score': tuning_result['best_score'] if tuning_result else None,\n",
    "                        **metrics, **cv_results\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    \n",
    "                    successful_models += 1\n",
    "                    print(f\"    âœ… {model_name}: R2={metrics['R2']:.4f}, CV_R2={cv_results.get('r2_mean', 0):.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ {model_name} ì‹¤íŒ¨: {str(e)}\")\n",
    "            \n",
    "            # ë¶„ë¥˜ ëª¨ë¸ ì²˜ë¦¬\n",
    "            print(\"\\nğŸ“Š ë¶„ë¥˜ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° í•™ìŠµ:\")\n",
    "            if split_method == 'temporal':\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_temporal(X, y_clf)\n",
    "            else:\n",
    "                X_train_clf, X_test_clf, y_train_clf, y_test_clf = split_data_random(X, y_clf, stratify=y_clf)\n",
    "            \n",
    "            # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (SMOTE)\n",
    "            X_train_balanced, y_train_balanced = handle_class_imbalance(\n",
    "                X_train_clf, y_train_clf, method='smote'\n",
    "            )\n",
    "            \n",
    "            for model_name, base_model in pipeline.classification_models.items():\n",
    "                total_models += 1\n",
    "                print(f\"  ğŸ”„ {model_name} ì²˜ë¦¬ ì¤‘...\")\n",
    "                \n",
    "                try:\n",
    "                    # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "                    param_grid = pipeline.classification_param_grids[model_name]\n",
    "                    tuned_model, tuning_result = perform_hyperparameter_tuning(\n",
    "                        base_model, param_grid, X_train_balanced, y_train_balanced,\n",
    "                        'classification', model_name, center\n",
    "                    )\n",
    "                    \n",
    "                    if tuning_result:\n",
    "                        pipeline.tuning_results.append(tuning_result)\n",
    "                    \n",
    "                    # ì˜ˆì¸¡ ë° í‰ê°€\n",
    "                    y_pred_clf = tuned_model.predict(X_test_clf)\n",
    "                    y_pred_proba = tuned_model.predict_proba(X_test_clf) if hasattr(tuned_model, 'predict_proba') else None\n",
    "                    metrics = evaluate_classification(y_test_clf, y_pred_clf, y_pred_proba)\n",
    "                    \n",
    "                    # êµì°¨ê²€ì¦ (ì›ë³¸ ë°ì´í„°ë¡œ)\n",
    "                    cv_results = perform_cross_validation(tuned_model, X_train_clf, y_train_clf, 'classification')\n",
    "                    \n",
    "                    # ê²°ê³¼ ì €ì¥\n",
    "                    result = {\n",
    "                        'center': center, 'split_method': split_method, 'task': 'classification',\n",
    "                        'model': model_name,\n",
    "                        'best_params': tuning_result['best_params'] if tuning_result else {},\n",
    "                        'tuning_score': tuning_result['best_score'] if tuning_result else None,\n",
    "                        'used_smote': True,\n",
    "                        **metrics, **cv_results\n",
    "                    }\n",
    "                    pipeline.results.append(result)\n",
    "                    \n",
    "                    successful_models += 1\n",
    "                    print(f\"    âœ… {model_name}: F1_w={metrics['F1_weighted']:.4f}, CV_F1={cv_results.get('f1_weighted_mean', 0):.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ {model_name} ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {center} ì„¼í„° ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "total_tuning_time = time.time() - tuning_start_time\n",
    "\n",
    "print(f\"\\nğŸ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ì„±ê³µ: {successful_models}/{total_models} ëª¨ë¸\")\n",
    "print(f\"ì´ ì†Œìš”ì‹œê°„: {total_tuning_time/60:.1f}ë¶„\")\n",
    "\n",
    "# %% ì…€ 8: ê²°ê³¼ ì €ì¥ ë° ê¸°ë³¸ ë¶„ì„\n",
    "print(\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ë° ê¸°ë³¸ ë¶„ì„\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "results_df = pd.DataFrame(pipeline.results)\n",
    "results_df.to_csv('../results_v3/all_model_results_with_tuning.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# íŠœë‹ ê²°ê³¼ ì €ì¥\n",
    "if pipeline.tuning_results:\n",
    "    tuning_df = pd.DataFrame(pipeline.tuning_results)\n",
    "    # best_params ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (CSV ì €ì¥ì„ ìœ„í•´)\n",
    "    tuning_df['best_params_str'] = tuning_df['best_params'].astype(str)\n",
    "    tuning_df.to_csv('../results_v3/hyperparameter_results/tuning_results.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"ğŸ’¾ íŠœë‹ ê²°ê³¼ ì €ì¥: {len(tuning_df)}ê°œ ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼\")\n",
    "\n",
    "# ê¸°ë³¸ í†µê³„\n",
    "if len(results_df) > 0:\n",
    "    print(f\"\\nğŸ“Š ê¸°ë³¸ í†µê³„\")\n",
    "    print(f\"ì´ ê²°ê³¼ ìˆ˜: {len(results_df)}\")\n",
    "    print(f\"ì„¼í„°ë³„ ê²°ê³¼ ìˆ˜:\")\n",
    "    print(results_df['center'].value_counts().to_string())\n",
    "    print(f\"\\níƒœìŠ¤í¬ë³„ ê²°ê³¼ ìˆ˜:\")\n",
    "    print(results_df['task'].value_counts().to_string())\n",
    "    \n",
    "    # íŠœë‹ ì‹œê°„ í†µê³„\n",
    "    if pipeline.tuning_results:\n",
    "        avg_tuning_time = tuning_df['tuning_time'].mean()\n",
    "        total_tuning_combinations = tuning_df['total_combinations_tested'].sum()\n",
    "        print(f\"\\nâ±ï¸ íŠœë‹ í†µê³„:\")\n",
    "        print(f\"í‰ê·  íŠœë‹ ì‹œê°„: {avg_tuning_time:.1f}ì´ˆ\")\n",
    "        print(f\"ì´ í…ŒìŠ¤íŠ¸ëœ ì¡°í•©: {total_tuning_combinations}ê°œ\")\n",
    "\n",
    "# %% ì…€ 9: ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸° (íŠœë‹ëœ ê²°ê³¼ ê¸°ë°˜)\n",
    "def find_best_models_with_tuning(results_df, centers):\n",
    "    print(\"ğŸ† í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê¸°ë°˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì°¾ê¸°\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    best_models_list = []\n",
    "    \n",
    "    for center in centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            if task == 'regression':\n",
    "                # R2 ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì„ íƒ\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "                metric_value, metric_name = best_model['R2'], 'R2'\n",
    "            else:\n",
    "                # F1_weighted ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìµœê³  ëª¨ë¸ ì„ íƒ\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                metric_value, metric_name = best_model['F1_weighted'], 'F1_weighted'\n",
    "            \n",
    "            best_models_list.append(best_model.to_dict())\n",
    "            \n",
    "            # íŠœë‹ ì „í›„ ì„±ëŠ¥ ë¹„êµ (ë§Œì•½ íŠœë‹ ì ìˆ˜ê°€ ìˆë‹¤ë©´)\n",
    "            tuning_score = best_model.get('tuning_score', 'N/A')\n",
    "            improvement = \"\"\n",
    "            if tuning_score != 'N/A' and tuning_score is not None:\n",
    "                if task == 'regression':\n",
    "                    cv_score = best_model.get('r2_mean', metric_value)\n",
    "                else:\n",
    "                    cv_score = best_model.get('f1_weighted_mean', metric_value)\n",
    "                \n",
    "                if cv_score != 0:\n",
    "                    improvement = f\" (CV: {cv_score:.4f})\"\n",
    "            \n",
    "            print(f\"ğŸ… {center} - {task}: {best_model['model']} ({best_model['split_method']})\")\n",
    "            print(f\"   {metric_name}={metric_value:.4f}{improvement}\")\n",
    "            \n",
    "            # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥\n",
    "            best_params = best_model.get('best_params', {})\n",
    "            if best_params:\n",
    "                print(f\"   ìµœì  íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "    \n",
    "    best_models_df = pd.DataFrame(best_models_list)\n",
    "    best_models_df.to_csv('../results_v3/best_models_summary/best_tuned_models.csv', \n",
    "                         index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ë² ìŠ¤íŠ¸ íŠœë‹ ëª¨ë¸ ì •ë³´ ì €ì¥: ../results_v3/best_models_summary/best_tuned_models.csv\")\n",
    "    return best_models_df\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    best_tuned_models_df = find_best_models_with_tuning(results_df, pipeline.centers)\n",
    "\n",
    "# %% ì…€ 10: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ ì‹œê°í™”\n",
    "def create_tuning_visualizations(tuning_df, results_df):\n",
    "    print(\"ğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ ì‹œê°í™”\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(tuning_df) == 0:\n",
    "        print(\"âŒ íŠœë‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # 1. íŠœë‹ ì‹œê°„ ë¶„ì„\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # ëª¨ë¸ë³„ í‰ê·  íŠœë‹ ì‹œê°„\n",
    "    model_time = tuning_df.groupby('model')['tuning_time'].mean().sort_values(ascending=True)\n",
    "    model_time.plot(kind='barh', ax=axes[0,0], title='ëª¨ë¸ë³„ í‰ê·  íŠœë‹ ì‹œê°„')\n",
    "    axes[0,0].set_xlabel('ì‹œê°„ (ì´ˆ)')\n",
    "    \n",
    "    # ì„¼í„°ë³„ í‰ê·  íŠœë‹ ì‹œê°„\n",
    "    center_time = tuning_df.groupby('center')['tuning_time'].mean().sort_values(ascending=True)\n",
    "    center_time.plot(kind='barh', ax=axes[0,1], title='ì„¼í„°ë³„ í‰ê·  íŠœë‹ ì‹œê°„')\n",
    "    axes[0,1].set_xlabel('ì‹œê°„ (ì´ˆ)')\n",
    "    \n",
    "    # íŠœë‹ ì ìˆ˜ ë¶„í¬ (íšŒê·€)\n",
    "    reg_tuning = tuning_df[tuning_df['task'] == 'regression']\n",
    "    if len(reg_tuning) > 0:\n",
    "        axes[1,0].hist(reg_tuning['best_score'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[1,0].set_title('íšŒê·€ ëª¨ë¸ íŠœë‹ ì ìˆ˜ ë¶„í¬ (R2)')\n",
    "        axes[1,0].set_xlabel('R2 Score')\n",
    "        axes[1,0].set_ylabel('ë¹ˆë„')\n",
    "    \n",
    "    # íŠœë‹ ì ìˆ˜ ë¶„í¬ (ë¶„ë¥˜)\n",
    "    clf_tuning = tuning_df[tuning_df['task'] == 'classification']\n",
    "    if len(clf_tuning) > 0:\n",
    "        axes[1,1].hist(clf_tuning['best_score'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[1,1].set_title('ë¶„ë¥˜ ëª¨ë¸ íŠœë‹ ì ìˆ˜ ë¶„í¬ (F1_weighted)')\n",
    "        axes[1,1].set_xlabel('F1 Weighted Score')\n",
    "        axes[1,1].set_ylabel('ë¹ˆë„')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/hyperparameter_tuning_analysis.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. íŠœë‹ ì „í›„ ì„±ëŠ¥ ë¹„êµ\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    \n",
    "    # íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    if len(reg_data) > 0:\n",
    "        # ì„¼í„°ë³„ ëª¨ë¸ë³„ R2 ì„±ëŠ¥ íˆíŠ¸ë§µ\n",
    "        reg_pivot = reg_data.pivot_table(values='R2', index='center', columns='model', aggfunc='max')\n",
    "        sns.heatmap(reg_pivot, annot=True, fmt='.3f', ax=axes[0,0], cmap='YlOrRd')\n",
    "        axes[0,0].set_title('ì„¼í„°ë³„ íšŒê·€ ëª¨ë¸ ìµœê³  R2 ì„±ëŠ¥')\n",
    "        \n",
    "        # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¶„í¬\n",
    "        reg_data.boxplot(column='R2', by='model', ax=axes[0,1])\n",
    "        axes[0,1].set_title('íšŒê·€ ëª¨ë¸ë³„ R2 ì„±ëŠ¥ ë¶„í¬')\n",
    "        axes[0,1].set_xlabel('ëª¨ë¸')\n",
    "        axes[0,1].set_ylabel('R2 Score')\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    if len(clf_data) > 0:\n",
    "        # ì„¼í„°ë³„ ëª¨ë¸ë³„ F1_weighted ì„±ëŠ¥ íˆíŠ¸ë§µ\n",
    "        clf_pivot = clf_data.pivot_table(values='F1_weighted', index='center', columns='model', aggfunc='max')\n",
    "        sns.heatmap(clf_pivot, annot=True, fmt='.3f', ax=axes[1,0], cmap='YlGnBu')\n",
    "        axes[1,0].set_title('ì„¼í„°ë³„ ë¶„ë¥˜ ëª¨ë¸ ìµœê³  F1_weighted ì„±ëŠ¥')\n",
    "        \n",
    "        # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¶„í¬\n",
    "        clf_data.boxplot(column='F1_weighted', by='model', ax=axes[1,1])\n",
    "        axes[1,1].set_title('ë¶„ë¥˜ ëª¨ë¸ë³„ F1_weighted ì„±ëŠ¥ ë¶„í¬')\n",
    "        axes[1,1].set_xlabel('ëª¨ë¸')\n",
    "        axes[1,1].set_ylabel('F1 Weighted Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/model_performance_comparison.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œê°í™” ì™„ë£Œ\")\n",
    "\n",
    "if 'tuning_df' in locals() and len(tuning_df) > 0:\n",
    "    create_tuning_visualizations(tuning_df, results_df)\n",
    "\n",
    "# %% ì…€ 11: ìƒì„¸ ì„±ëŠ¥ ì‹œê°í™” (ì„¼í„°ë³„, ëª¨ë¸ë³„, íƒœìŠ¤í¬ë³„)\n",
    "def create_comprehensive_performance_visualizations(results_df):\n",
    "    print(\"ğŸ“ˆ í¬ê´„ì  ì„±ëŠ¥ ì‹œê°í™” ìƒì„±\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    \n",
    "    # 1. ì „ì²´ ì„±ëŠ¥ ê°œìš” (2x3 ë ˆì´ì•„ì›ƒ)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # íšŒê·€ - R2 ì„±ëŠ¥\n",
    "    if len(reg_data) > 0:\n",
    "        reg_summary = reg_data.groupby(['center', 'split_method'])['R2'].mean().unstack(fill_value=0)\n",
    "        reg_summary.plot(kind='bar', ax=axes[0,0], title='ì„¼í„°ë³„ íšŒê·€ R2 ì„±ëŠ¥')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # íšŒê·€ - RMSE ì„±ëŠ¥\n",
    "        reg_rmse = reg_data.groupby(['center', 'split_method'])['RMSE'].mean().unstack(fill_value=0)\n",
    "        reg_rmse.plot(kind='bar', ax=axes[0,1], title='ì„¼í„°ë³„ íšŒê·€ RMSE ì„±ëŠ¥')\n",
    "        axes[0,1].set_ylabel('RMSE')\n",
    "        axes[0,1].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # íšŒê·€ - ëª¨ë¸ë³„ ì„±ëŠ¥\n",
    "        reg_model_perf = reg_data.groupby('model')['R2'].mean().sort_values(ascending=True)\n",
    "        reg_model_perf.plot(kind='barh', ax=axes[0,2], title='ëª¨ë¸ë³„ í‰ê·  R2 ì„±ëŠ¥')\n",
    "        axes[0,2].set_xlabel('R2 Score')\n",
    "    \n",
    "    # ë¶„ë¥˜ ì„±ëŠ¥\n",
    "    if len(clf_data) > 0:\n",
    "        clf_summary = clf_data.groupby(['center', 'split_method'])['F1_weighted'].mean().unstack(fill_value=0)\n",
    "        clf_summary.plot(kind='bar', ax=axes[1,0], title='ì„¼í„°ë³„ ë¶„ë¥˜ F1_weighted ì„±ëŠ¥')\n",
    "        axes[1,0].set_ylabel('F1 Weighted Score')\n",
    "        axes[1,0].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # ë¶„ë¥˜ - ì •í™•ë„\n",
    "        clf_acc = clf_data.groupby(['center', 'split_method'])['Accuracy'].mean().unstack(fill_value=0)\n",
    "        clf_acc.plot(kind='bar', ax=axes[1,1], title='ì„¼í„°ë³„ ë¶„ë¥˜ Accuracy ì„±ëŠ¥')\n",
    "        axes[1,1].set_ylabel('Accuracy')\n",
    "        axes[1,1].legend(['Random Split', 'Temporal Split'])\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # ë¶„ë¥˜ - ëª¨ë¸ë³„ ì„±ëŠ¥\n",
    "        clf_model_perf = clf_data.groupby('model')['F1_weighted'].mean().sort_values(ascending=True)\n",
    "        clf_model_perf.plot(kind='barh', ax=axes[1,2], title='ëª¨ë¸ë³„ í‰ê·  F1_weighted ì„±ëŠ¥')\n",
    "        axes[1,2].set_xlabel('F1 Weighted Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/comprehensive_performance_overview.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. êµì°¨ê²€ì¦ ê²°ê³¼ ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    # íšŒê·€ êµì°¨ê²€ì¦ ê²°ê³¼\n",
    "    if len(reg_data) > 0 and 'r2_mean' in reg_data.columns:\n",
    "        # CV R2 vs Test R2 ë¹„êµ\n",
    "        reg_cv_data = reg_data.dropna(subset=['r2_mean'])\n",
    "        if len(reg_cv_data) > 0:\n",
    "            axes[0,0].scatter(reg_cv_data['r2_mean'], reg_cv_data['R2'], alpha=0.7)\n",
    "            axes[0,0].plot([reg_cv_data['R2'].min(), reg_cv_data['R2'].max()], \n",
    "                          [reg_cv_data['R2'].min(), reg_cv_data['R2'].max()], 'r--')\n",
    "            axes[0,0].set_xlabel('CV R2 Mean')\n",
    "            axes[0,0].set_ylabel('Test R2')\n",
    "            axes[0,0].set_title('íšŒê·€: êµì°¨ê²€ì¦ vs í…ŒìŠ¤íŠ¸ R2 ì„±ëŠ¥')\n",
    "            \n",
    "        # CV í‘œì¤€í¸ì°¨ ë¶„ì„\n",
    "        if 'r2_std' in reg_data.columns:\n",
    "            reg_std_data = reg_data.dropna(subset=['r2_std'])\n",
    "            if len(reg_std_data) > 0:\n",
    "                reg_std_summary = reg_std_data.groupby('model')['r2_std'].mean().sort_values()\n",
    "                reg_std_summary.plot(kind='bar', ax=axes[0,1], title='ëª¨ë¸ë³„ R2 êµì°¨ê²€ì¦ í‘œì¤€í¸ì°¨')\n",
    "                axes[0,1].set_ylabel('R2 Standard Deviation')\n",
    "                axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ë¶„ë¥˜ êµì°¨ê²€ì¦ ê²°ê³¼\n",
    "    if len(clf_data) > 0 and 'f1_weighted_mean' in clf_data.columns:\n",
    "        # CV F1 vs Test F1 ë¹„êµ\n",
    "        clf_cv_data = clf_data.dropna(subset=['f1_weighted_mean'])\n",
    "        if len(clf_cv_data) > 0:\n",
    "            axes[1,0].scatter(clf_cv_data['f1_weighted_mean'], clf_cv_data['F1_weighted'], alpha=0.7)\n",
    "            axes[1,0].plot([clf_cv_data['F1_weighted'].min(), clf_cv_data['F1_weighted'].max()], \n",
    "                          [clf_cv_data['F1_weighted'].min(), clf_cv_data['F1_weighted'].max()], 'r--')\n",
    "            axes[1,0].set_xlabel('CV F1_weighted Mean')\n",
    "            axes[1,0].set_ylabel('Test F1_weighted')\n",
    "            axes[1,0].set_title('ë¶„ë¥˜: êµì°¨ê²€ì¦ vs í…ŒìŠ¤íŠ¸ F1 ì„±ëŠ¥')\n",
    "            \n",
    "        # CV í‘œì¤€í¸ì°¨ ë¶„ì„\n",
    "        if 'f1_weighted_std' in clf_data.columns:\n",
    "            clf_std_data = clf_data.dropna(subset=['f1_weighted_std'])\n",
    "            if len(clf_std_data) > 0:\n",
    "                clf_std_summary = clf_std_data.groupby('model')['f1_weighted_std'].mean().sort_values()\n",
    "                clf_std_summary.plot(kind='bar', ax=axes[1,1], title='ëª¨ë¸ë³„ F1 êµì°¨ê²€ì¦ í‘œì¤€í¸ì°¨')\n",
    "                axes[1,1].set_ylabel('F1 Standard Deviation')\n",
    "                axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/cross_validation_analysis.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… í¬ê´„ì  ì„±ëŠ¥ ì‹œê°í™” ì™„ë£Œ\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_comprehensive_performance_visualizations(results_df)\n",
    "\n",
    "# %% ì…€ 12: ë² ìŠ¤íŠ¸ 8ê°œ ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥ (íŠœë‹ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©)\n",
    "def train_and_save_best_tuned_models(results_df, pipeline):\n",
    "    print(\"ğŸ’¾ ë² ìŠ¤íŠ¸ 8ê°œ íŠœë‹ ëª¨ë¸ ì¬í•™ìŠµ ë° ì €ì¥\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ê° ì„¼í„°-íƒœìŠ¤í¬ ì¡°í•©ì—ì„œ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ\n",
    "    selected_models = []\n",
    "    \n",
    "    for center in pipeline.centers:\n",
    "        for task in ['regression', 'classification']:\n",
    "            center_task_data = results_df[\n",
    "                (results_df['center'] == center) & \n",
    "                (results_df['task'] == task)\n",
    "            ]\n",
    "            \n",
    "            if len(center_task_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            if task == 'regression':\n",
    "                best_model = center_task_data.loc[center_task_data['R2'].idxmax()]\n",
    "            else:\n",
    "                best_model = center_task_data.loc[center_task_data['F1_weighted'].idxmax()]\n",
    "                \n",
    "            selected_models.append(best_model)\n",
    "    \n",
    "    print(f\"ğŸ“‹ ì„ ì •ëœ {len(selected_models)}ê°œ ë² ìŠ¤íŠ¸ ëª¨ë¸:\")\n",
    "    for model_info in selected_models:\n",
    "        print(f\"  ğŸ… {model_info['center']} - {model_info['task']} - {model_info['model']} ({model_info['split_method']})\")\n",
    "    \n",
    "    saved_models = {}\n",
    "    \n",
    "    for model_info in selected_models:\n",
    "        center = model_info['center']\n",
    "        task = model_info['task']\n",
    "        model_name = model_info['model']\n",
    "        split_method = model_info['split_method']\n",
    "        best_params = model_info.get('best_params', {})\n",
    "        \n",
    "        print(f\"\\nğŸ”„ {center} - {task} - {model_name} ({split_method}) ì¬í•™ìŠµ ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            # ë°ì´í„° ë¡œë“œ\n",
    "            if center not in data_info:\n",
    "                continue\n",
    "                \n",
    "            X = data_info[center]['X']\n",
    "            y_reg = data_info[center]['y_reg']\n",
    "            y_clf = data_info[center]['y_clf']\n",
    "            y = y_reg if task == 'regression' else y_clf\n",
    "            \n",
    "            # ëª¨ë¸ ìƒì„± (ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©)\n",
    "            if task == 'regression':\n",
    "                base_model = pipeline.regression_models[model_name]\n",
    "            else:\n",
    "                base_model = pipeline.classification_models[model_name]\n",
    "            \n",
    "            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "            model = base_model.__class__(**best_params) if best_params else base_model\n",
    "            \n",
    "            # ë°ì´í„° ë¶„í• \n",
    "            if split_method == 'temporal':\n",
    "                X_train, X_test, y_train, y_test = split_data_temporal(X, y)\n",
    "            else:\n",
    "                stratify = y if task == 'classification' else None\n",
    "                X_train, X_test, y_train, y_test = split_data_random(X, y, stratify=stratify)\n",
    "            \n",
    "            # ë¶„ë¥˜ì˜ ê²½ìš° SMOTE ì ìš©\n",
    "            if task == 'classification':\n",
    "                X_train_balanced, y_train_balanced = handle_class_imbalance(X_train, y_train, method='smote')\n",
    "                model.fit(X_train_balanced, y_train_balanced)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            # ì˜ˆì¸¡\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test) if (task == 'classification' and hasattr(model, 'predict_proba')) else None\n",
    "            \n",
    "            # êµì°¨ê²€ì¦ ìˆ˜í–‰\n",
    "            cv_results = perform_cross_validation(model, X_train, y_train, task)\n",
    "            \n",
    "            # ëª¨ë¸ ë°ì´í„° íŒ¨í‚¤ì§€\n",
    "            model_data = {\n",
    "                'model': model,\n",
    "                'feature_names': X.columns.tolist(),\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'task': task,\n",
    "                'center': center,\n",
    "                'split_method': split_method,\n",
    "                'model_name': model_name,\n",
    "                'best_params': best_params,\n",
    "                'performance': model_info.to_dict(),\n",
    "                'cv_results': cv_results,\n",
    "                'used_smote': task == 'classification'\n",
    "            }\n",
    "            \n",
    "            # íŒŒì¼ ì €ì¥\n",
    "            filename = f\"{center}_{task}_{model_name}_{split_method}_tuned.pkl\"\n",
    "            filepath = f\"../models_v3/best_tuned_models/{filename}\"\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            \n",
    "            print(f\"âœ… ëª¨ë¸ ì €ì¥: {filepath}\")\n",
    "            saved_models[f\"{center}_{task}\"] = model_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {center} - {task} - {model_name} ì €ì¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nâœ… {len(saved_models)}ê°œ ë² ìŠ¤íŠ¸ íŠœë‹ ëª¨ë¸ ì €ì¥ ì™„ë£Œ\")\n",
    "    return saved_models\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    saved_best_tuned_models = train_and_save_best_tuned_models(results_df, pipeline)\n",
    "\n",
    "# %% ì…€ 13: ROC Curve ì‹œê°í™” (íŠœë‹ëœ ëª¨ë¸ ê¸°ë°˜)\n",
    "def create_advanced_roc_curves(saved_models):\n",
    "    print(\"ğŸ“ˆ ê³ ê¸‰ ROC Curve ì‹œê°í™”\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    clf_models = {k: v for k, v in saved_models.items() if v['task'] == 'classification'}\n",
    "    \n",
    "    if len(clf_models) == 0:\n",
    "        print(\"âŒ ë¶„ë¥˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    centers = list(set([v['center'] for v in clf_models.values()]))\n",
    "    n_centers = len(centers)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, min(4, n_centers), figsize=(5*min(4, n_centers), 6))\n",
    "    if n_centers == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, center in enumerate(centers[:4]):\n",
    "        center_models = {k: v for k, v in clf_models.items() if v['center'] == center}\n",
    "        ax = axes[i]\n",
    "        \n",
    "        for model_key, md in center_models.items():\n",
    "            y_test = md['y_test']\n",
    "            y_pred_proba = md['y_pred_proba']\n",
    "            \n",
    "            if y_pred_proba is None:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                classes = np.unique(y_test)\n",
    "                n_classes = len(classes)\n",
    "                \n",
    "                if n_classes == 2:\n",
    "                    # ì´ì§„ ë¶„ë¥˜\n",
    "                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "                    auc_score = auc(fpr, tpr)\n",
    "                    ax.plot(fpr, tpr, label=f'{md[\"model_name\"]} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "                else:\n",
    "                    # ë‹¤ì¤‘ ë¶„ë¥˜ (í´ë˜ìŠ¤ë³„)\n",
    "                    from sklearn.preprocessing import label_binarize\n",
    "                    y_bin = label_binarize(y_test, classes=classes)\n",
    "                    \n",
    "                    for c in range(min(n_classes, y_pred_proba.shape[1])):\n",
    "                        if c < y_bin.shape[1]:\n",
    "                            fpr, tpr, _ = roc_curve(y_bin[:, c], y_pred_proba[:, c])\n",
    "                            auc_score = auc(fpr, tpr)\n",
    "                            ax.plot(fpr, tpr, \n",
    "                                   label=f'{md[\"model_name\"]} Class{classes[c]} (AUC = {auc_score:.3f})',\n",
    "                                   linewidth=2)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {center} ROC ê³¡ì„  ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # ëŒ€ê°ì„  (ëœë¤ ë¶„ë¥˜ê¸° ì„±ëŠ¥)\n",
    "        ax.plot([0, 1], [0, 1], '--', color='gray', alpha=0.8, linewidth=2)\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_ylim([0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'{center} ì„¼í„° ROC Curves')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/advanced_roc_curves.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… ê³ ê¸‰ ROC Curve ì‹œê°í™” ì™„ë£Œ\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    create_advanced_roc_curves(saved_best_tuned_models)\n",
    "\n",
    "# %% ì…€ 14: Confusion Matrix ì‹œê°í™”\n",
    "def create_confusion_matrices(saved_models):\n",
    "    print(\"ğŸ¯ Confusion Matrix ì‹œê°í™”\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    clf_models = {k: v for k, v in saved_models.items() if v['task'] == 'classification'}\n",
    "    \n",
    "    if len(clf_models) == 0:\n",
    "        print(\"âŒ ë¶„ë¥˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    n_models = len(clf_models)\n",
    "    cols = min(4, n_models)\n",
    "    rows = (n_models + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for idx, (model_key, md) in enumerate(clf_models.items()):\n",
    "        y_test = md['y_test']\n",
    "        y_pred = md['y_pred']\n",
    "        center = md['center']\n",
    "        model_name = md['model_name']\n",
    "        \n",
    "        # Confusion Matrix ê³„ì‚°\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        ax = axes_flat[idx]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        ax.set_title(f'{center} - {model_name}')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('Actual')\n",
    "    \n",
    "    # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°\n",
    "    for idx in range(len(clf_models), len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/confusion_matrices.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Confusion Matrix ì‹œê°í™” ì™„ë£Œ\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    create_confusion_matrices(saved_best_tuned_models)\n",
    "\n",
    "# %% ì…€ 15: SHAP ë¶„ì„ (ì™„ì „ ë²„ì „)\n",
    "def analyze_shap_comprehensive(saved_models):\n",
    "    print(\"ğŸ” í¬ê´„ì  SHAP ë¶„ì„\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(saved_models) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    for key, md in saved_models.items():\n",
    "        center = md['center']\n",
    "        task = md['task'] \n",
    "        model_name = md['model_name']\n",
    "        model = md['model']\n",
    "        X_train = md['X_train']\n",
    "        X_test = md['X_test']\n",
    "        feature_names = md['feature_names']\n",
    "        \n",
    "        print(f\"\\nğŸ” {center} - {task} - {model_name} SHAP ë¶„ì„...\")\n",
    "        \n",
    "        try:\n",
    "            # ìƒ˜í”Œ í¬ê¸° ì œí•œ\n",
    "            sample_size = min(100, len(X_test))\n",
    "            X_test_sample = X_test.iloc[:sample_size]\n",
    "            \n",
    "            # SHAP Explainer ìƒì„±\n",
    "            if model_name in ['XGBoost', 'LightGBM', 'CatBoost']:\n",
    "                explainer = shap.Explainer(model)\n",
    "            else:\n",
    "                train_sample_size = min(200, len(X_train))\n",
    "                explainer = shap.Explainer(model, X_train.iloc[:train_sample_size])\n",
    "            \n",
    "            shap_values = explainer(X_test_sample)\n",
    "            \n",
    "            # 1. Summary Plot\n",
    "            plt.figure(figsize=(16, 8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, \n",
    "                            feature_names=feature_names, show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Summary Plot (Feature Impact)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_summary.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 2. Feature Importance Bar Plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X_test_sample, \n",
    "                            feature_names=feature_names, plot_type=\"bar\", \n",
    "                            show=False, max_display=15)\n",
    "            plt.title(f'{center} - {task} - {model_name}\\nSHAP Feature Importance')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # 3. Waterfall Plot (ì²« ë²ˆì§¸ ìƒ˜í”Œ)\n",
    "            try:\n",
    "                plt.figure(figsize=(14, 10))\n",
    "                if hasattr(shap_values, 'values') and len(shap_values.values.shape) == 3:\n",
    "                    # ë‹¤ì¤‘í´ë˜ìŠ¤ ë¶„ë¥˜\n",
    "                    shap.waterfall_plot(shap_values[0, :, 0], show=False)\n",
    "                else:\n",
    "                    shap.waterfall_plot(shap_values[0], show=False)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nSHAP Waterfall Plot (Sample 1)')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_waterfall.png', \n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"      âš ï¸ Waterfall Plot ì‹¤íŒ¨: {e}\")\n",
    "            \n",
    "            # 4. SHAP ê°’ í†µê³„ ì €ì¥\n",
    "            if hasattr(shap_values, 'values'):\n",
    "                if len(shap_values.values.shape) == 3:\n",
    "                    shap_importance = np.abs(shap_values.values).mean(axis=(0, 2))\n",
    "                else:\n",
    "                    shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "            else:\n",
    "                shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "            \n",
    "            shap_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'shap_importance': shap_importance\n",
    "            }).sort_values('shap_importance', ascending=False)\n",
    "            \n",
    "            shap_df.to_csv(f'../results_v3/interpretations/{center}_{task}_{model_name}_shap_values.csv', \n",
    "                          index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(f\"      âœ… SHAP ë¶„ì„ ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ SHAP ë¶„ì„ ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    analyze_shap_comprehensive(saved_best_tuned_models)\n",
    "\n",
    "# %% ì…€ 16: Feature Importance ë¶„ì„ (ì™„ì „ ë²„ì „)\n",
    "def analyze_feature_importance_comprehensive(saved_models):\n",
    "    print(\"ğŸ“Š í¬ê´„ì  Feature Importance ë¶„ì„\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(saved_models) == 0:\n",
    "        print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ëª¨ë“  ëª¨ë¸ì˜ Feature Importanceë¥¼ í•˜ë‚˜ì˜ í”Œë¡¯ì— ë¹„êµ\n",
    "    all_importance_data = []\n",
    "    \n",
    "    for key, md in saved_models.items():\n",
    "        center = md['center']\n",
    "        task = md['task']\n",
    "        model_name = md['model_name']\n",
    "        model = md['model']\n",
    "        feature_names = md['feature_names']\n",
    "        \n",
    "        print(f\"\\nğŸ“Š {center} - {task} - {model_name} Feature Importance...\")\n",
    "        \n",
    "        try:\n",
    "            # ê°œë³„ ëª¨ë¸ Feature Importance ì‹œê°í™”\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importance = model.feature_importances_\n",
    "                df_imp = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': importance\n",
    "                }).sort_values('importance', ascending=True).tail(20)\n",
    "                \n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature'])\n",
    "                plt.xlabel('Feature Importance')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance (Top 20)')\n",
    "                \n",
    "                # ê°’ í‘œì‹œ\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "                \n",
    "                # ì „ì²´ ë¹„êµìš© ë°ì´í„° ìˆ˜ì§‘\n",
    "                for _, row in df_imp.iterrows():\n",
    "                    all_importance_data.append({\n",
    "                        'center': center,\n",
    "                        'task': task,\n",
    "                        'model': model_name,\n",
    "                        'feature': row['feature'],\n",
    "                        'importance': row['importance'],\n",
    "                        'type': 'tree_importance'\n",
    "                    })\n",
    "                    \n",
    "            elif hasattr(model, 'coef_'):\n",
    "                # ì„ í˜• ëª¨ë¸ì˜ ê³„ìˆ˜\n",
    "                if task == 'classification' and len(model.coef_.shape) > 1:\n",
    "                    coef = np.mean(np.abs(model.coef_), axis=0)\n",
    "                else:\n",
    "                    coef = np.abs(model.coef_).flatten()\n",
    "                \n",
    "                df_imp = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': coef\n",
    "                }).sort_values('importance', ascending=True).tail(20)\n",
    "                \n",
    "                bars = plt.barh(range(len(df_imp)), df_imp['importance'])\n",
    "                plt.yticks(range(len(df_imp)), df_imp['feature'])\n",
    "                plt.xlabel('|Coefficient|')\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Coefficients (Top 20)')\n",
    "                \n",
    "                # ê°’ í‘œì‹œ\n",
    "                for i, bar in enumerate(bars):\n",
    "                    width = bar.get_width()\n",
    "                    plt.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{width:.4f}', ha='left', va='center', fontsize=8)\n",
    "                \n",
    "                # ì „ì²´ ë¹„êµìš© ë°ì´í„° ìˆ˜ì§‘\n",
    "                for _, row in df_imp.iterrows():\n",
    "                    all_importance_data.append({\n",
    "                        'center': center,\n",
    "                        'task': task,\n",
    "                        'model': model_name,\n",
    "                        'feature': row['feature'],\n",
    "                        'importance': row['importance'],\n",
    "                        'type': 'coefficient'\n",
    "                    })\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Feature importance not available', \n",
    "                        ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "                plt.title(f'{center} - {task} - {model_name}\\nFeature Importance')\n",
    "            \n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_feature_importance.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"      âœ… Feature Importance ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ Feature Importance ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "    \n",
    "    # ì „ì²´ Feature Importance ë¹„êµ ì‹œê°í™”\n",
    "    if all_importance_data:\n",
    "        print(\"\\nğŸ“ˆ ì „ì²´ ëª¨ë¸ Feature Importance ë¹„êµ...\")\n",
    "        \n",
    "        importance_df = pd.DataFrame(all_importance_data)\n",
    "        \n",
    "        # íšŒê·€ ëª¨ë¸ë“¤ì˜ ìƒìœ„ í”¼ì²˜ ë¹„êµ\n",
    "        reg_data = importance_df[importance_df['task'] == 'regression']\n",
    "        if len(reg_data) > 0:\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            \n",
    "            # ê° íšŒê·€ ëª¨ë¸ë³„ ìƒìœ„ 10ê°œ í”¼ì²˜\n",
    "            top_features_reg = reg_data.groupby(['center', 'model'])['importance'].nlargest(10).reset_index()\n",
    "            top_features_reg = top_features_reg.merge(reg_data, on=['center', 'model'])\n",
    "            \n",
    "            pivot_reg = top_features_reg.pivot_table(\n",
    "                values='importance_y', index='feature', \n",
    "                columns=['center', 'model'], fill_value=0\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(pivot_reg, annot=False, cmap='YlOrRd', cbar_kws={'label': 'Importance'})\n",
    "            plt.title('íšŒê·€ ëª¨ë¸ë³„ Feature Importance ë¹„êµ (ìƒìœ„ í”¼ì²˜)')\n",
    "            plt.ylabel('Features')\n",
    "            plt.xlabel('Center - Model')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('../results_v3/interpretations/regression_feature_importance_comparison.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        # ë¶„ë¥˜ ëª¨ë¸ë“¤ì˜ ìƒìœ„ í”¼ì²˜ ë¹„êµ  \n",
    "        clf_data = importance_df[importance_df['task'] == 'classification']\n",
    "        if len(clf_data) > 0:\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            \n",
    "            # ê° ë¶„ë¥˜ ëª¨ë¸ë³„ ìƒìœ„ 10ê°œ í”¼ì²˜\n",
    "            top_features_clf = clf_data.groupby(['center', 'model'])['importance'].nlargest(10).reset_index()\n",
    "            top_features_clf = top_features_clf.merge(clf_data, on=['center', 'model'])\n",
    "            \n",
    "            pivot_clf = top_features_clf.pivot_table(\n",
    "                values='importance_y', index='feature', \n",
    "                columns=['center', 'model'], fill_value=0\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(pivot_clf, annot=False, cmap='YlGnBu', cbar_kws={'label': 'Importance'})\n",
    "            plt.title('ë¶„ë¥˜ ëª¨ë¸ë³„ Feature Importance ë¹„êµ (ìƒìœ„ í”¼ì²˜)')\n",
    "            plt.ylabel('Features')\n",
    "            plt.xlabel('Center - Model')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('../results_v3/interpretations/classification_feature_importance_comparison.png', \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        # ì „ì²´ Feature Importance ë°ì´í„° ì €ì¥\n",
    "        importance_df.to_csv('../results_v3/interpretations/all_feature_importance.csv', \n",
    "                           index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"âœ… ì „ì²´ Feature Importance ë¹„êµ ì™„ë£Œ\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    analyze_feature_importance_comprehensive(saved_best_tuned_models)\n",
    "\n",
    "# %% ì…€ 17: LIME ë¶„ì„ (ì„ íƒì  - ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)\n",
    "def analyze_lime_selective(saved_models, max_models=3):\n",
    "    \"\"\"LIME ë¶„ì„ (ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ìƒìœ„ 3ê°œ ëª¨ë¸ë§Œ)\"\"\"\n",
    "    try:\n",
    "        import lime\n",
    "        import lime.lime_tabular\n",
    "        \n",
    "        print(\"ğŸ‹ LIME ë¶„ì„ (ìƒìœ„ 3ê°œ ëª¨ë¸)\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        if len(saved_models) == 0:\n",
    "            print(\"âŒ ë¶„ì„í•  ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        analyzed = 0\n",
    "        for key, md in saved_models.items():\n",
    "            if analyzed >= max_models:\n",
    "                print(f\"â° ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ {max_models}ê°œ ëª¨ë¸ë§Œ LIME ë¶„ì„í•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "                \n",
    "            center = md['center']\n",
    "            task = md['task']\n",
    "            model_name = md['model_name']\n",
    "            model = md['model']\n",
    "            X_train = md['X_train']\n",
    "            X_test = md['X_test']\n",
    "            feature_names = md['feature_names']\n",
    "            \n",
    "            print(f\"\\nğŸ‹ {center} - {task} - {model_name} LIME ë¶„ì„...\")\n",
    "            \n",
    "            try:\n",
    "                if task == 'regression':\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values, feature_names=feature_names, \n",
    "                        mode='regression', verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # 2ê°œ ìƒ˜í”Œì— ëŒ€í•´ ì„¤ëª…\n",
    "                    for sample_idx in [0, min(1, len(X_test)-1)]:\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                        \n",
    "                else:\n",
    "                    # ë¶„ë¥˜\n",
    "                    class_names = [str(c) for c in sorted(model.classes_)]\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "                        X_train.values, feature_names=feature_names, \n",
    "                        mode='classification', class_names=class_names, verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # 2ê°œ ìƒ˜í”Œì— ëŒ€í•´ ì„¤ëª…\n",
    "                    for sample_idx in [0, min(1, len(X_test)-1)]:\n",
    "                        instance = X_test.iloc[sample_idx].values\n",
    "                        explanation = explainer.explain_instance(\n",
    "                            instance, model.predict_proba, num_features=10\n",
    "                        )\n",
    "                        \n",
    "                        fig = explanation.as_pyplot_figure()\n",
    "                        fig.suptitle(f'{center} - {task} - {model_name}\\nLIME Explanation (Sample {sample_idx+1})')\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(f'../results_v3/interpretations/{center}_{task}_{model_name}_lime_sample_{sample_idx+1}.png', \n",
    "                                   dpi=300, bbox_inches='tight')\n",
    "                        plt.show()\n",
    "                \n",
    "                print(f\"      âœ… LIME ë¶„ì„ ì™„ë£Œ: {center} - {task} - {model_name}\")\n",
    "                analyzed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ LIME ë¶„ì„ ì‹¤íŒ¨: {center} - {task} - {model_name}, ì˜¤ë¥˜: {str(e)}\")\n",
    "                \n",
    "    except ImportError:\n",
    "        print(\"ğŸ’¡ LIME ë¶„ì„ì„ ìœ„í•´ì„œëŠ” `pip install lime` í›„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
    "\n",
    "if 'saved_best_tuned_models' in locals():\n",
    "    analyze_lime_selective(saved_best_tuned_models)\n",
    "\n",
    "# %% ì…€ 18: ì„±ëŠ¥ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„ (í•„ìˆ˜)\n",
    "def create_performance_comparison_charts(results_df, saved_models):\n",
    "    print(\"ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„ ìƒì„± (í•„ìˆ˜)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ë¹„êµí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # 1. ì„¼í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # íšŒê·€ ì„±ëŠ¥ ë¹„êµ (R2, RMSE)\n",
    "    reg_data = results_df[results_df['task'] == 'regression']\n",
    "    if len(reg_data) > 0:\n",
    "        # ì„¼í„°ë³„ ìµœê³  R2 ì„±ëŠ¥\n",
    "        best_r2_by_center = reg_data.loc[reg_data.groupby('center')['R2'].idxmax()]\n",
    "        \n",
    "        bars1 = axes[0,0].bar(best_r2_by_center['center'], best_r2_by_center['R2'])\n",
    "        axes[0,0].set_title('ì„¼í„°ë³„ ìµœê³  R2 ì„±ëŠ¥ (íšŒê·€)')\n",
    "        axes[0,0].set_ylabel('R2 Score')\n",
    "        axes[0,0].set_ylim(0, 1)\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for i, (bar, val) in enumerate(zip(bars1, best_r2_by_center['R2'])):\n",
    "            axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # ì„¼í„°ë³„ ìµœì € RMSE ì„±ëŠ¥ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "        best_rmse_by_center = reg_data.loc[reg_data.groupby('center')['RMSE'].idxmin()]\n",
    "        \n",
    "        bars2 = axes[0,1].bar(best_rmse_by_center['center'], best_rmse_by_center['RMSE'])\n",
    "        axes[0,1].set_title('ì„¼í„°ë³„ ìµœì € RMSE ì„±ëŠ¥ (íšŒê·€)')\n",
    "        axes[0,1].set_ylabel('RMSE')\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for i, (bar, val) in enumerate(zip(bars2, best_rmse_by_center['RMSE'])):\n",
    "            axes[0,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    # ë¶„ë¥˜ ì„±ëŠ¥ ë¹„êµ (F1_weighted, Accuracy)\n",
    "    clf_data = results_df[results_df['task'] == 'classification']\n",
    "    if len(clf_data) > 0:\n",
    "        # ì„¼í„°ë³„ ìµœê³  F1_weighted ì„±ëŠ¥\n",
    "        best_f1_by_center = clf_data.loc[clf_data.groupby('center')['F1_weighted'].idxmax()]\n",
    "        \n",
    "        bars3 = axes[1,0].bar(best_f1_by_center['center'], best_f1_by_center['F1_weighted'])\n",
    "        axes[1,0].set_title('ì„¼í„°ë³„ ìµœê³  F1_weighted ì„±ëŠ¥ (ë¶„ë¥˜)')\n",
    "        axes[1,0].set_ylabel('F1 Weighted Score')\n",
    "        axes[1,0].set_ylim(0, 1)\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for i, (bar, val) in enumerate(zip(bars3, best_f1_by_center['F1_weighted'])):\n",
    "            axes[1,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # ì„¼í„°ë³„ ìµœê³  Accuracy ì„±ëŠ¥\n",
    "        best_acc_by_center = clf_data.loc[clf_data.groupby('center')['Accuracy'].idxmax()]\n",
    "        \n",
    "        bars4 = axes[1,1].bar(best_acc_by_center['center'], best_acc_by_center['Accuracy'])\n",
    "        axes[1,1].set_title('ì„¼í„°ë³„ ìµœê³  Accuracy ì„±ëŠ¥ (ë¶„ë¥˜)')\n",
    "        axes[1,1].set_ylabel('Accuracy')\n",
    "        axes[1,1].set_ylim(0, 1)\n",
    "        \n",
    "        # ê°’ í‘œì‹œ\n",
    "        for i, (bar, val) in enumerate(zip(bars4, best_acc_by_center['Accuracy'])):\n",
    "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                          f'{val:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/performance_comparison_by_center.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥ ë¹„êµ\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # íšŒê·€ ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥\n",
    "    if len(reg_data) > 0:\n",
    "        reg_model_perf = reg_data.groupby('model')[['R2', 'RMSE', 'SMAPE']].mean().sort_values('R2', ascending=False)\n",
    "        \n",
    "        x = range(len(reg_model_perf))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = axes[0].bar([i - width for i in x], reg_model_perf['R2'], width, label='R2', alpha=0.8)\n",
    "        # RMSEì™€ SMAPEëŠ” ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)\n",
    "        rmse_normalized = 1 - (reg_model_perf['RMSE'] / reg_model_perf['RMSE'].max())\n",
    "        smape_normalized = 1 - (reg_model_perf['SMAPE'] / 100)  # SMAPEëŠ” ë°±ë¶„ìœ¨\n",
    "        \n",
    "        bars2 = axes[0].bar(x, rmse_normalized, width, label='1-RMSE(norm)', alpha=0.8)\n",
    "        bars3 = axes[0].bar([i + width for i in x], smape_normalized, width, label='1-SMAPE(norm)', alpha=0.8)\n",
    "        \n",
    "        axes[0].set_title('ëª¨ë¸ë³„ í‰ê·  íšŒê·€ ì„±ëŠ¥')\n",
    "        axes[0].set_ylabel('Normalized Score (Higher is Better)')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(reg_model_perf.index, rotation=45)\n",
    "        axes[0].legend()\n",
    "        axes[0].set_ylim(0, 1.1)\n",
    "    \n",
    "    # ë¶„ë¥˜ ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥\n",
    "    if len(clf_data) > 0:\n",
    "        clf_model_perf = clf_data.groupby('model')[['Accuracy', 'F1_weighted', 'F1_macro']].mean().sort_values('F1_weighted', ascending=False)\n",
    "        \n",
    "        x = range(len(clf_model_perf))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = axes[1].bar([i - width for i in x], clf_model_perf['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "        bars2 = axes[1].bar(x, clf_model_perf['F1_weighted'], width, label='F1_weighted', alpha=0.8)\n",
    "        bars3 = axes[1].bar([i + width for i in x], clf_model_perf['F1_macro'], width, label='F1_macro', alpha=0.8)\n",
    "        \n",
    "        axes[1].set_title('ëª¨ë¸ë³„ í‰ê·  ë¶„ë¥˜ ì„±ëŠ¥')\n",
    "        axes[1].set_ylabel('Score')\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels(clf_model_perf.index, rotation=45)\n",
    "        axes[1].legend()\n",
    "        axes[1].set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results_v3/visualizations/performance_comparison_by_model.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… ì„±ëŠ¥ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_performance_comparison_charts(results_df, saved_best_tuned_models if 'saved_best_tuned_models' in locals() else {})\n",
    "\n",
    "# %% ì…€ 19: ì˜ˆì¸¡ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "def predict_with_best_tuned_model(center, task, new_data):\n",
    "    \"\"\"ë² ìŠ¤íŠ¸ íŠœë‹ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡\"\"\"\n",
    "    model_files = [f for f in os.listdir('../models_v3/best_tuned_models/') \n",
    "                   if f.startswith(f'{center}_{task}_') and f.endswith('_tuned.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"âŒ {center} - {task} íŠœë‹ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    filepath = f\"../models_v3/best_tuned_models/{model_files[0]}\"\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = model_data['model']\n",
    "        feature_names = model_data['feature_names']\n",
    "        best_params = model_data['best_params']\n",
    "        \n",
    "        # í•„ìš”í•œ í”¼ì²˜ ì²´í¬\n",
    "        missing_features = [col for col in feature_names if col not in new_data.columns]\n",
    "        if missing_features:\n",
    "            print(f\"âŒ ëˆ„ë½ëœ í”¼ì²˜: {missing_features}\")\n",
    "            return None\n",
    "        \n",
    "        X_new = new_data[feature_names]\n",
    "        \n",
    "        if task == 'regression':\n",
    "            predictions = model.predict(X_new)\n",
    "            print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ (ìƒ˜í”Œ: {len(predictions)}ê°œ)\")\n",
    "            print(f\"ğŸ”§ ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "            return predictions\n",
    "        else:\n",
    "            predictions = model.predict(X_new)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                probabilities = model.predict_proba(X_new)\n",
    "                print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ (ìƒ˜í”Œ: {len(predictions)}ê°œ)\")\n",
    "                print(f\"ğŸ”§ ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "                return predictions, probabilities\n",
    "            else:\n",
    "                print(f\"âœ… {center} - {task} ì˜ˆì¸¡ ì™„ë£Œ (ìƒ˜í”Œ: {len(predictions)}ê°œ)\")\n",
    "                print(f\"ğŸ”§ ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {best_params}\")\n",
    "                return predictions\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_best_tuned_model(center, task):\n",
    "    \"\"\"ë² ìŠ¤íŠ¸ íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "    model_files = [f for f in os.listdir('../models_v3/best_tuned_models/') \n",
    "                   if f.startswith(f'{center}_{task}_') and f.endswith('_tuned.pkl')]\n",
    "    \n",
    "    if len(model_files) == 0:\n",
    "        print(f\"âŒ {center} - {task} íŠœë‹ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    filepath = f\"../models_v3/best_tuned_models/{model_files[0]}\"\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {center} - {task} - {model_data['model_name']}\")\n",
    "        print(f\"ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {model_data['best_params']}\")\n",
    "        return model_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"ğŸ”® ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# %% ì…€ 20: ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "def create_performance_summary_report(results_df, best_models_df):\n",
    "    print(\"ğŸ“„ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"âŒ ë¦¬í¬íŠ¸ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ë¦¬í¬íŠ¸ ë‚´ìš© ìƒì„±\n",
    "    report = []\n",
    "    report.append(\"# ğŸ† í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸\")\n",
    "    report.append(\"=\"*60)\n",
    "    report.append(f\"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report.append(f\"ì´ í•™ìŠµ ëª¨ë¸ ìˆ˜: {len(results_df)}\")\n",
    "    report.append(\"\")\n",
    "    \n",
    "    # ì„¼í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ìš”ì•½\n",
    "    report.append(\"## ğŸ“Š ì„¼í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ìš”ì•½\")\n",
    "    report.append(\"-\" * 40)\n",
    "    \n",
    "    for center in pipeline.centers:\n",
    "        report.append(f\"\\n### ğŸ¢ {center.upper()} ì„¼í„°\")\n",
    "        \n",
    "        # íšŒê·€ ë² ìŠ¤íŠ¸\n",
    "        reg_best = results_df[(results_df['center']==center) & (results_df['task']=='regression')]\n",
    "        if len(reg_best) > 0:\n",
    "            best_reg = reg_best.loc[reg_best['R2'].idxmax()]\n",
    "            report.append(f\"**íšŒê·€ ëª¨ë¸**: {best_reg['model']} ({best_reg['split_method']})\")\n",
    "            report.append(f\"- R2: {best_reg['R2']:.4f}\")\n",
    "            report.append(f\"- RMSE: {best_reg['RMSE']:.2f}\")\n",
    "            report.append(f\"- SMAPE: {best_reg['SMAPE']:.2f}%\")\n",
    "            \n",
    "        # ë¶„ë¥˜ ë² ìŠ¤íŠ¸\n",
    "        clf_best = results_df[(results_df['center']==center) & (results_df['task']=='classification')]\n",
    "        if len(clf_best) > 0:\n",
    "            best_clf = clf_best.loc[clf_best['F1_weighted'].idxmax()]\n",
    "            report.append(f\"**ë¶„ë¥˜ ëª¨ë¸**: {best_clf['model']} ({best_clf['split_method']})\")\n",
    "            report.append(f\"- F1_weighted: {best_clf['F1_weighted']:.4f}\")\n",
    "            report.append(f\"- Accuracy: {best_clf['Accuracy']:.4f}\")\n",
    "            report.append(f\"- F1_macro: {best_clf['F1_macro']:.4f}\")\n",
    "    \n",
    "    # ì „ì²´ ì„±ëŠ¥ í†µê³„\n",
    "    report.append(f\"\\n## ğŸ“ˆ ì „ì²´ ì„±ëŠ¥ í†µê³„\")\n",
    "    report.append(\"-\" * 40)\n",
    "    \n",
    "    reg_data = results_df[results_df['task']=='regression']\n",
    "    clf_data = results_df[results_df['task']=='classification']\n",
    "    \n",
    "    if len(reg_data) > 0:\n",
    "        report.append(f\"**íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ (R2)**:\")\n",
    "        report.append(f\"- ìµœê³ : {reg_data['R2'].max():.4f}\")\n",
    "        report.append(f\"- í‰ê· : {reg_data['R2'].mean():.4f}\")\n",
    "        report.append(f\"- ìµœì €: {reg_data['R2'].min():.4f}\")\n",
    "        \n",
    "    if len(clf_data) > 0:\n",
    "        report.append(f\"**ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (F1_weighted)**:\")\n",
    "        report.append(f\"- ìµœê³ : {clf_data['F1_weighted'].max():.4f}\")\n",
    "        report.append(f\"- í‰ê· : {clf_data['F1_weighted'].mean():.4f}\")\n",
    "        report.append(f\"- ìµœì €: {clf_data['F1_weighted'].min():.4f}\")\n",
    "    \n",
    "    # ë¦¬í¬íŠ¸ ì €ì¥\n",
    "    report_text = \"\\n\".join(report)\n",
    "    with open('../results_v3/model_performance_summary_report.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(report_text)\n",
    "    \n",
    "    print(\"âœ… ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥: ../results_v3/model_performance_summary_report.md\")\n",
    "    print(\"\\n\" + report_text)\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    create_performance_summary_report(results_df, best_tuned_models_df if 'best_tuned_models_df' in locals() else None)\n",
    "    \n",
    "    \n",
    "# %% ì…€ 21: ìµœì¢… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ìš”ì•½\n",
    "def final_completion_checklist():\n",
    "    print(\"ğŸ“‹ ìµœì¢… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸ - ê³ ê¸‰ ë²„ì „\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    checklist = {}\n",
    "    \n",
    "    # ê¸°ë³¸ ìš”êµ¬ì‚¬í•­\n",
    "    checklist[\"1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\"] = len(data_info) > 0 if 'data_info' in globals() else False\n",
    "    checklist[\"2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰\"] = len(pipeline.tuning_results) > 0\n",
    "    checklist[\"3. êµì°¨ê²€ì¦ ìˆ˜í–‰\"] = 'cv_results' in str(pipeline.results) if pipeline.results else False\n",
    "    checklist[\"4. ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ (SMOTE)\"] = any('used_smote' in str(r) for r in pipeline.results)\n",
    "    checklist[\"5. ì „ì²´ ê²°ê³¼ ì €ì¥\"] = os.path.exists('../results_v3/all_model_results_with_tuning.csv')\n",
    "    \n",
    "    # ì‹œê°í™” ìš”êµ¬ì‚¬í•­\n",
    "    viz_files = [\n",
    "        'hyperparameter_tuning_analysis.png',\n",
    "        'model_performance_comparison.png', \n",
    "        'comprehensive_performance_overview.png',\n",
    "        'cross_validation_analysis.png',\n",
    "        'advanced_roc_curves.png',\n",
    "        'confusion_matrices.png',\n",
    "        'performance_comparison_by_center.png',\n",
    "        'performance_comparison_by_model.png'\n",
    "    ]\n",
    "    viz_dir = '../results_v3/visualizations/'\n",
    "    viz_count = sum([os.path.exists(os.path.join(viz_dir, f)) for f in viz_files])\n",
    "    checklist[\"6. ì‹œê°í™” ìë£Œ (8ê°œ)\"] = viz_count >= 6\n",
    "    \n",
    "    # í•´ì„ ê°€ëŠ¥ì„± ë¶„ì„\n",
    "    interp_dir = '../results_v3/interpretations/'\n",
    "    shap_files = len([f for f in os.listdir(interp_dir) if 'shap' in f.lower()]) if os.path.exists(interp_dir) else 0\n",
    "    fi_files = len([f for f in os.listdir(interp_dir) if 'feature_importance' in f]) if os.path.exists(interp_dir) else 0\n",
    "    checklist[\"7. SHAP ë¶„ì„\"] = shap_files >= 3\n",
    "    checklist[\"8. Feature Importance ë¶„ì„\"] = fi_files >= 3\n",
    "    \n",
    "    # ë² ìŠ¤íŠ¸ ëª¨ë¸\n",
    "    model_dir = '../models_v3/best_tuned_models/'\n",
    "    model_files = len([f for f in os.listdir(model_dir) if f.endswith('_tuned.pkl')]) if os.path.exists(model_dir) else 0\n",
    "    checklist[\"9. ë² ìŠ¤íŠ¸ íŠœë‹ ëª¨ë¸ ì €ì¥ (8ê°œ)\"] = model_files >= 8\n",
    "    checklist[\"10. ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸\"] = os.path.exists('../results_v3/model_performance_summary_report.md')\n",
    "    \n",
    "    # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "    for item, status in checklist.items():\n",
    "        status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "        print(f\"{status_icon} {item}\")\n",
    "    \n",
    "    completed = sum(1 for v in checklist.values() if v)\n",
    "    total = len(checklist)\n",
    "    completion_rate = completed / total * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì „ì²´ ì™„ë£Œìœ¨: {completion_rate:.1f}% ({completed}/{total})\")\n",
    "    \n",
    "    if completion_rate >= 95:\n",
    "        print(\"ğŸ‰ ê³ ê¸‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í”„ë¡œì íŠ¸ê°€ ì™„ë²½í•˜ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    elif completion_rate >= 85:\n",
    "        print(\"ğŸŒŸ í”„ë¡œì íŠ¸ê°€ ê±°ì˜ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì¼ë¶€ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    return checklist\n",
    "\n",
    "final_checklist = final_completion_checklist()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸš€ ê³ ê¸‰ í•˜ìˆ˜ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"âœ¨ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, êµì°¨ê²€ì¦, ë¶ˆê· í˜• ì²˜ë¦¬, í¬ê´„ì  ë¶„ì„ ì™„ë£Œ!\")\n",
    "print(f\"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843ad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngwon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
